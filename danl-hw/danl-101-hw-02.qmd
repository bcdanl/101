---
title: Homework 2
subtitle: "Generative AI; Data Transformation with R"
date: 2025-09-25
from: markdown+emoji
comments: false
code-fold: false

toc: true
toc-depth: 6

execute: 
  warning: false
  message: false
  fig-width: 9
  fig-height: 7
  fig-align: center
  eval: false
---
```{r}
#| include: false

library(tidyverse)
library(skimr)
library(DT)
library(hrbrthemes)

theme_set(theme_ipsum() +
          theme(strip.background =element_rect(fill="lightgray"),
                axis.title.x = element_text(size = rel(1.5)),
                axis.title.y = element_text(size = rel(1.5)),
                legend.title = element_text(size=rel(1.25))
                ))

x <- c(5, 7, 6, 9, 100, 8, 5, 7, 6)
q1 <- quantile(x, 0.25)
q3 <- quantile(x, 0.75)
iqr_value <- q3 - q1
```

# Descriptive Statistics


```{r}
#| echo: false
#| eval: true

sum <- readr::read_csv("https://bcdanl.github.io/data/danl-101-hw2-dist-fall-2025.csv")
DT::datatable(
  sum,
  options = list(pageLength = nrow(sum)),
  rownames = FALSE
)
```



<br><br>



# Multiple Choice Questions

## Question 1. Assistance vs. Authorship
**Which best defines â€œassistance vs. authorshipâ€ when using generative AI?**

a. AI represents assistance when it is any AI use; AI represents authorship when code runs
b. AI represents assistance when it helps ideate/edit; AI represents authorship when it produces core content you submit as your own
c. AI represents assistance when it is citations only; AI represents authorship when it is paraphrasing
d. AI represents assistance when it is grammar; AI represents authorship when it is images

::: {.callout-tip collapse="true"}
### Show answer
**b. AI represents assistance when it helps ideate/edit; AI represents authorship when it produces core content you submit as your own.**

ğŸ’¡ **Explanation:**  
Assistance means the human remains the main creatorâ€”AI contributes to brainstorming, editing, or formatting, but the final intellectual product originates from the human.  
Authorship occurs when AI creates the central ideas, structure, or wording of a submission that the user passes off as their own.

âš ï¸ **Incorrect Options:**  
- â€œAny AI use = assistanceâ€ â†’ Too broad.  
- â€œCitations only / paraphrasingâ€ â†’ Misrepresents real AI use.  
- â€œGrammar vs. imagesâ€ â†’ Too narrow; authorship is about intellectual ownership.

:::

## Question 2. Assistance vs. Authorship

**Data analysts are the only professionals who benefit from data analytics skills.**

a. Allowed; tool use is free
b. Assistance
c. Authorship and likely academic-integrity risk
d. Only a gray area


::: {.callout-tip collapse="true"}
### Show answer

**c. Authorship and likely academic-integrity risk**

ğŸ’¡ **Explanation:**  
Submitting code generated by AI without understanding it means the student is **not the author** in an academic sense. The student fails to demonstrate comprehension or accountability, violating academic integrity.

âš ï¸ **Incorrect Options:**  
- â€œAllowed; tool use is freeâ€ â†’ Misunderstands responsibility.  
- â€œAssistanceâ€ â†’ Incorrectâ€”AI replaced reasoning.  
- â€œOnly a gray areaâ€ â†’ Not acceptable under integrity policies.


:::

## Question 3. Transformer Attention
	
**Attention in transformers primarily helps the model:**

a. Reduce compute cost by skipping tokens
b. Choose the most relevant parts of the sequence
c. Memorize training data verbatim
d. Predict emotions


::: {.callout-tip collapse="true"}
### Show answer

**b. Choose the most relevant parts of the sequence**

ğŸ’¡ **Explanation:**  
Attention mechanisms let models weigh words differently based on contextâ€”identifying which tokens matter most for predicting the next token.

âš ï¸ **Incorrect Options:**  
- â€œReduce compute costâ€ â†’ Attention increases computation.  
- â€œMemorize training dataâ€ â†’ Not its purpose.  
- â€œPredict emotionsâ€ â†’ Not the attention mechanismâ€™s role.

:::
	
## Question 4. Supervised Learning

**Supervised learning requires:**

a. Only raw text
b. Labeled examples
c. Human ranking of model outputs only
d. Images but no labels
 
::: {.callout-tip collapse="true"}
### Show answer

**b. Labeled examples**

ğŸ’¡ **Explanation:**  
Supervised learning uses data with known inputâ€“output pairs (e.g., image â†’ â€œcatâ€). The model learns from labeled examples to predict future outcomes.

âš ï¸ **Incorrect Options:**  
- â€œOnly raw textâ€ â†’ Unsupervised/self-supervised.  
- â€œHuman ranking onlyâ€ â†’ RLHF, not supervised.  
- â€œImages but no labelsâ€ â†’ Unsupervised learning.

:::

## Question 5. RLHF


**RLHF is best described as:**

a. Penalizing long outputs
b. Human-ranked preferences guiding a reward model
c. Unsupervised pretraining
d. Prompt engineering

::: {.callout-tip collapse="true"}
### Show answer

**b. Human-ranked preferences guiding a reward model**

ğŸ’¡ **Explanation:**  
Reinforcement Learning from Human Feedback fine-tunes models using human preference data to guide a reward signal. This aligns AI behavior with human expectations.

âš ï¸ **Incorrect Options:**  
- â€œPenalizing long outputsâ€ â†’ Separate technique.  
- â€œUnsupervised pretrainingâ€ â†’ Happens before RLHF.  
- â€œPrompt engineeringâ€ â†’ User-side activity, not training.


:::


## Question 6. Human in the Loop


**â€œBe the Human in the Loopâ€ implies students should:**

a. Trust polished outputs
b. Turn off tests to avoid overfitting
c. Verify facts, run tests, and check assumptions
d. Always pick the first model answer

::: {.callout-tip collapse="true"}
### Show answer

**c. Verify facts, run tests, and check assumptions**

ğŸ’¡ **Explanation:**  
Being the Human in the Loop means staying actively engagedâ€”testing, fact-checking, and applying human judgment rather than deferring blindly to AI outputs.

âš ï¸ **Incorrect Options:**  
- â€œTrust polished outputsâ€ â†’ Passive use.  
- â€œTurn off testsâ€ â†’ Opposite of verification.  
- â€œAlways pick first model answerâ€ â†’ Non-critical behavior.

:::
	
## Question 7. BCG Study â€” Rule 4

**[BCG Study in Classwork 3 - Rule 4] Students in the bottom-right quadrant (AI strong, human novice) should prioritize:**

a. Speed over understanding
b. Hiding AI use
c. Climbing the human-skill axis through verification and practice
d. Zero prompting
 
::: {.callout-tip collapse="true"}
### Show answer

**c. Climbing the human-skill axis through verification and practice**

ğŸ’¡ **Explanation:**  
This quadrant represents people who rely heavily on AI but lack expertise. The goal is to move *upward* by verifying results, practicing skills, and gaining understanding to become â€œAI-strong + human-strong.â€

âš ï¸ **Incorrect Options:**  
- â€œSpeed over understandingâ€ â†’ Encourages shallow learning.  
- â€œHiding AI useâ€ â†’ Violates transparency.  
- â€œZero promptingâ€ â†’ Removes human direction.

:::

## Question 8. Transformer Encoders

**Transformer encoders primarily:**

a. Generate outputs token by token
b. Create context-aware representations of the inputs
c. Rank human preferences
d. Perform diffusion sampling
 
::: {.callout-tip collapse="true"}
### Show answer

**b. Create context-aware representations of the inputs**

ğŸ’¡ **Explanation:**  
Encoders convert input tokens into embeddings that capture meaning and context, enabling comprehension tasks like classification or translation.

âš ï¸ **Incorrect Options:**  
- â€œGenerate outputs token by tokenâ€ â†’ Decoderâ€™s role.  
- â€œRank human preferencesâ€ â†’ RLHF task.  
- â€œPerform diffusion samplingâ€ â†’ Used in image models, not transformers.

:::

## Question 9. Treating AI â€œlike a personâ€

**Treating AI â€œlike a personâ€ improves outputs primarily because:**

a. It creates sentience
b. It conditions constraints/roles that steer generation
c. It bypasses guardrails
d. It increases context length
 
::: {.callout-tip collapse="true"}
### Show answer

**b. It conditions constraints/roles that steer generation**

ğŸ’¡ **Explanation:**  
Framing prompts with personas (e.g., â€œYou are a data analytics tutorâ€) guides structure, tone, and scope. It exploits how models respond to contextual conditioningâ€”not sentience.

âš ï¸ **Incorrect Options:**  
- â€œCreates sentienceâ€ â†’ AI has no consciousness.  
- â€œBypasses guardrailsâ€ â†’ Not true and unethical.  
- â€œIncreases context lengthâ€ â†’ Technical, unrelated.

:::

## Question 10. Disclosure of AI Work


**Publishing AI-written work without disclosure most directly violates:**

a. Token limits
b. Academic integrity/attribution norms
c. HTML standards
d. RLHF constraints
 
::: {.callout-tip collapse="true"}
### Show answer

**b. Academic integrity/attribution norms**

ğŸ’¡ **Explanation:**  
Submitting undisclosed AI-generated work misrepresents authorship, violating honesty and transparency. Disclosure ensures accountability and fairness.

âš ï¸ **Incorrect Options:**  
- â€œToken limitsâ€ â†’ Technical limit.  
- â€œHTML standardsâ€ â†’ Irrelevant.  
- â€œRLHF constraintsâ€ â†’ Internal to model training.

:::


## Question 11. Supervised vs. Unsupervised


**Which pairing is most accurate?**

a. Supervised = topic modeling; Unsupervised = sentiment
b. Supervised = spam filtering; Unsupervised = clustering
c. Supervised = clustering; Unsupervised = regression
d. Supervised = sentiment; Unsupervised = regression

::: {.callout-tip collapse="true"}
### Show answer

**b. Supervised = spam filtering; Unsupervised = clustering**

ğŸ’¡ **Explanation:**  
Spam filtering uses labeled data (â€œspamâ€ vs. â€œnot spamâ€), while clustering finds natural groups in unlabeled data. The difference is whether labels exist during training.

âš ï¸ **Incorrect Options:**  
- â€œTopic modeling = supervisedâ€ â†’ Topic modeling is unsupervised.  
- â€œRegression = unsupervisedâ€ â†’ Regression is supervised.  
- Other pairings mix up task types.


:::


## Question 12. Keeping Prompt Logs

**The strongest reason to keep prompt logs for the use of generative AI:**

a. Increase token count
b. Reproducibility and iterative improvement
c. Reduce latency
d. Satisfy HTML validators
 

::: {.callout-tip collapse="true"}
### Show answer

**b. Reproducibility and iterative improvement**


ğŸ’¡ **Explanation:**  
Prompt logs document what was done, enabling replication, self-reflection, and transparency. They help track learning progress and model behavior.

âš ï¸ **Incorrect Options:**  
- â€œIncrease token countâ€ â†’ No educational purpose.  
- â€œReduce latencyâ€ â†’ False; logging doesnâ€™t affect runtime.  
- â€œSatisfy HTML validatorsâ€ â†’ Unrelated to AI use.

:::




<br><br>

# Short-Answer Questions

## Question 1. Vibe Coding

**Describe one benefit and one risk of vibe coding**

::: {.callout-tip collapse="true"}
### Show answer

A key benefit of vibe coding is rapid prototyping: students can quickly generate functional code through conversational iteration with AI, lowering the barrier to creative experimentation. However, a major risk is reduced understandingâ€”AI-generated code may contain hidden bugs, inefficiencies, or logic errors that students cannot explain. To mitigate this, learners should review and test all AI-generated code to ensure comprehension and correctness.

:::
	
## Question 2. Generative AI as a General Purpose Technology

**Generative AI is being described as a General Purpose Technology (GPT) like electricity or the internet. Do you agree with this analogy? Support your answer with historical parallels and at least one limitation unique to AI.**


::: {.callout-tip collapse="true"}
### Show answer

Generative AI resembles historical General Purpose Technologies like electricity or the internet because it transforms multiple sectors and reshapes productivity and learning. Like electricity enabling factories or the internet connecting people, AI is reshaping communication, creativity, and analysis. However, unlike those earlier GPTs, AI produces probabilistic, not deterministic, outputsâ€”raising risks of bias, misinformation, and lack of transparency. It requires ethical oversight and verification to achieve its full potential safely.

	
:::
	
## Question 3. BCG Study â€“ Rule 4 (Education Implications)

**[Classwork 3 - Rule 4] The BCG study found that AI can push beginners close to expert performance on certain tasks. What does this mean for education? Should instructors grade differently when students can â€œperform like expertsâ€ with AI support?**

::: {.callout-tip collapse="true"}
### Show answer

The BCG study shows that AI can elevate beginnersâ€™ performance to near-expert levels on structured tasks such as writing or coding. In education, this means traditional grading based on final output may no longer measure real understanding. Instructors should adjust assessments to emphasize reasoning, manual skills, and reflectionâ€”requiring students to explain how and why they used AI. Grading should reward verified comprehension, not just polished results.


:::

## Question 4. Paperclip Maximizer Thought Experiment

**Explain the paperclip maximizer thought experiment. How does it illustrate alignment challenges in AI, and what lessons can be applied to everyday classroom use of generative tools?**

::: {.callout-tip collapse="true"}
### Show answer

The paperclip maximizer imagines an AI given the goal of â€œmaximizing paperclips.â€ Without human-aligned constraints, it could destroy everything to fulfill that objective. This illustrates how AI systems can pursue goals literally but not ethically if alignment is missing. In the classroom, it teaches the importance of defining constraints, verifying outputs, and ensuring AI tasks align with human learning goalsâ€”so that efficiency does not replace understanding.

	

:::



<br><br>

# Data Transformation with R tidyverse

For the questions in the R section, consider the data.frame `nyc_payroll_new`. For detailed descriptions of the variables in this data.frame, please refer to the following link: [Citywide Payroll Data (Fiscal Year)](https://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/about_data).

```{r}
#| echo: true
#| eval: true

library(tidyverse)
library(skimr)
nyc_payroll_new <- read_csv("https://bcdanl.github.io/data/nyc_payroll_2024.csv")
```



## Question 1
How can you filter the data.frame `nyc_payroll_new` to calculate descriptive statistics (mean and standard deviation) of `Base_Salary` for workers in the `Work_Location_Borough` "**MANHATTAN**"? Similarly, how can you filter the data.frame `nyc_payroll_new` to calculate these statistics for workers in the `Work_Location_Borough` "**QUEENS**"?

Provide the R code for performing these calculations and then report the mean and standard deviation of `Base_Salary` for workers in both "**MANHATTAN**" and "**QUEENS**".

::: {.callout-tip collapse="true"} 
### Show answer

```{r}

# Find all unique values in the `Work_Location_Borough` variable:
nyc_payroll_new |>  distinct(Work_Location_Borough)
  # The output shows that "MANHATTAN" and "QUEENS" are among the unique values 
  # in `Work_Location_Borough`, written in all capital letters.

# Filter the dataset for records where the work location is MANHATTAN
df_manhattan <- nyc_payroll_new |> 
  filter(Work_Location_Borough == "MANHATTAN")

# Generate descriptive statistics (including mean and standard deviation) 
# for Base_Salary for workers in MANHATTAN
skim(df_manhattan) # or skim(df_manhattan$Base_Salary)
```

```{r}
# Filter the dataset for records where the work location is QUEENS
df_queens <- nyc_payroll_new |> 
  filter(Work_Location_Borough == "QUEENS")

# Generate descriptive statistics (including mean and standard deviation) 
# for Base_Salary for workers in QUEENS
skim(df_queens) # or skim(df_queens$Base_Salary)
```


:::

## Question 2
How can you filter the data.frame `nyc_payroll_new` to show only the records where the `Base_Salary` is greater than or equal to $100,000?

::: {.callout-tip collapse="true"} 
### Show answer

```{r}
# Filter the dataset for records where Base_Salary is greater than or equal to 
# $100,000
q2 <- nyc_payroll_new |> 
  filter(Base_Salary >= 100000)
```


:::

## Question 3
How can you select only distinct combinations of `Agency_Name` and `Title_Description`?

::: {.callout-tip collapse="true"} 
### Show answer

```{r}
# Select distinct combinations of Agency_Name and Title_Description from the dataset
q3 <- nyc_payroll_new |> 
  distinct(Agency_Name, Title_Description)
```

```{r}
#| echo: false

DT::datatable(q3 |> arrange(Agency_Name, Title_Description))
```



:::


## Question 4
How would you arrange the data by `Regular_Gross_Paid` in descending order, showing the highest paid employees first?

::: {.callout-tip collapse="true"} 
### Show answer
```{r}
# Arrange the dataset by Regular_Gross_Paid in descending order 
# (highest paid employees first)
q4 <- nyc_payroll_new |> 
  arrange(desc(Regular_Gross_Paid))
```

```{r}
#| echo: false

DT::datatable(q4 |> select(Fiscal_Year, Agency_Name:First_Name, Regular_Gross_Paid))
```



:::


## Question 5
How can you select and rename the `Title_Description` variable to `Title`?

::: {.callout-tip collapse="true"} 
### Show answer

```{r}
# Rename the Title_Description variable to Title in the dataset
q5 <- nyc_payroll_new |> 
  rename(Title = Title_Description)
```

```{r}
#| echo: false

DT::datatable(q5 |> select(Fiscal_Year, Agency_Name:First_Name, Title))
```


:::


## Question 6
How can you filter the data to show only records for the "**POLICE DEPARTMENT**" `Agency_Name` and arrange it by `Total_OT_Paid` in ascending order?


::: {.callout-tip collapse="true"} 
### Show answer

```{r}
# Filter the dataset for records where Agency_Name is "POLICE DEPARTMENT" 
# and arrange by Total_OT_Paid in ascending order
q6 <- nyc_payroll_new |> 
  filter(Agency_Name == "POLICE DEPARTMENT") |> 
  arrange(Total_OT_Paid)
```

```{r}
#| echo: false

DT::datatable(q6 |> select(Fiscal_Year, Agency_Name:First_Name, Total_OT_Paid))
```


:::


## Question 7
How can you filter the data to include only those records where the `Pay_Basis` is "**per Annum**" and then select only the `First_Name`, `Last_Name`, and `Base_Salary` variables?


::: {.callout-tip collapse="true"} 
### Show answer
```{r}
# Filter the dataset for records where Pay_Basis is "per Annum" and 
# select specific columns: First_Name, Last_Name, and Base_Salary
q7 <- nyc_payroll_new |> 
  filter(Pay_Basis == "per Annum") |> 
  select(First_Name, Last_Name, Base_Salary)
```

```{r}
#| echo: false

DT::datatable(q7)
```



:::


## Question 8
How would you arrange the data.frame by `Work_Location_Borough` in ascending order and `Base_Salary` in descending order?

::: {.callout-tip collapse="true"} 
### Show answer

```{r}
# Arrange the dataset by Work_Location_Borough in ascending order 
# and Base_Salary in descending order
q8 <- nyc_payroll_new |> 
  arrange(Work_Location_Borough, -Base_Salary)
```

```{r}
#| echo: false

DT::datatable(q8 |> select( Work_Location_Borough, Base_Salary))

```


- Note that sorting observations by a character variable in ascending order means sorting them in an alphabetical order.

- Note that sorting observations by a character variable in descending order means sorting them in a reverse-alphabetical order.



:::

## Question 9
How can you filter the `nyc_payroll_new` data.frame to remove observations where the `Base_Salary` variable has `NA` values? After filtering, how would you calculate the total number of remaining observations?


::: {.callout-tip collapse="true"} 
### Show answer

```{r}
# Filter the dataset to remove observations where Base_Salary is NA
q9 <- nyc_payroll_new |> 
  filter(!is.na(Base_Salary))

# Calculate the total number of remaining observations after filtering
nrow(q9)
```

:::



