[
  {
    "objectID": "danl-101-hw-02-a.html",
    "href": "danl-101-hw-02-a.html",
    "title": "Homework 2 - Example Answers",
    "section": "",
    "text": "TBA:"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-1.-assistance-vs.-authorship",
    "href": "danl-101-hw-02-a.html#question-1.-assistance-vs.-authorship",
    "title": "Homework 2 - Example Answers",
    "section": "Question 1. Assistance vs.¬†Authorship",
    "text": "Question 1. Assistance vs.¬†Authorship\nWhich best defines ‚Äúassistance vs.¬†authorship‚Äù when using generative AI?\n\nAI represents assistance when it is any AI use; AI represents authorship when code runs\nAI represents assistance when it helps ideate/edit; AI represents authorship when it produces core content you submit as your own\nAI represents assistance when it is citations only; AI represents authorship when it is paraphrasing\nAI represents assistance when it is grammar; AI represents authorship when it is images\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. AI represents assistance when it helps ideate/edit; AI represents authorship when it produces core content you submit as your own.\nüí° Explanation:\nAssistance means the human remains the main creator‚ÄîAI contributes to brainstorming, editing, or formatting, but the final intellectual product originates from the human.\nAuthorship occurs when AI creates the central ideas, structure, or wording of a submission that the user passes off as their own.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúAny AI use = assistance‚Äù ‚Üí Too broad.\n- ‚ÄúCitations only / paraphrasing‚Äù ‚Üí Misrepresents real AI use.\n- ‚ÄúGrammar vs.¬†images‚Äù ‚Üí Too narrow; authorship is about intellectual ownership."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-2.-assistance-vs.-authorship",
    "href": "danl-101-hw-02-a.html#question-2.-assistance-vs.-authorship",
    "title": "Homework 2 - Example Answers",
    "section": "Question 2. Assistance vs.¬†Authorship",
    "text": "Question 2. Assistance vs.¬†Authorship\nData analysts are the only professionals who benefit from data analytics skills.\n\nAllowed; tool use is free\nAssistance\nAuthorship and likely academic-integrity risk\nOnly a gray area\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Authorship and likely academic-integrity risk\nüí° Explanation:\nSubmitting code generated by AI without understanding it means the student is not the author in an academic sense. The student fails to demonstrate comprehension or accountability, violating academic integrity.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúAllowed; tool use is free‚Äù ‚Üí Misunderstands responsibility.\n- ‚ÄúAssistance‚Äù ‚Üí Incorrect‚ÄîAI replaced reasoning.\n- ‚ÄúOnly a gray area‚Äù ‚Üí Not acceptable under integrity policies."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-3.-transformer-attention",
    "href": "danl-101-hw-02-a.html#question-3.-transformer-attention",
    "title": "Homework 2 - Example Answers",
    "section": "Question 3. Transformer Attention",
    "text": "Question 3. Transformer Attention\nAttention in transformers primarily helps the model:\n\nReduce compute cost by skipping tokens\nChoose the most relevant parts of the sequence\nMemorize training data verbatim\nPredict emotions\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Choose the most relevant parts of the sequence\nüí° Explanation:\nAttention mechanisms let models weigh words differently based on context‚Äîidentifying which tokens matter most for predicting the next token.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúReduce compute cost‚Äù ‚Üí Attention increases computation.\n- ‚ÄúMemorize training data‚Äù ‚Üí Not its purpose.\n- ‚ÄúPredict emotions‚Äù ‚Üí Not the attention mechanism‚Äôs role."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-4.-supervised-learning",
    "href": "danl-101-hw-02-a.html#question-4.-supervised-learning",
    "title": "Homework 2 - Example Answers",
    "section": "Question 4. Supervised Learning",
    "text": "Question 4. Supervised Learning\nSupervised learning requires:\n\nOnly raw text\nLabeled examples\nHuman ranking of model outputs only\nImages but no labels\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Labeled examples\nüí° Explanation:\nSupervised learning uses data with known input‚Äìoutput pairs (e.g., image ‚Üí ‚Äúcat‚Äù). The model learns from labeled examples to predict future outcomes.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúOnly raw text‚Äù ‚Üí Unsupervised/self-supervised.\n- ‚ÄúHuman ranking only‚Äù ‚Üí RLHF, not supervised.\n- ‚ÄúImages but no labels‚Äù ‚Üí Unsupervised learning."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-5.-rlhf",
    "href": "danl-101-hw-02-a.html#question-5.-rlhf",
    "title": "Homework 2 - Example Answers",
    "section": "Question 5. RLHF",
    "text": "Question 5. RLHF\nRLHF is best described as:\n\nPenalizing long outputs\nHuman-ranked preferences guiding a reward model\nUnsupervised pretraining\nPrompt engineering\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Human-ranked preferences guiding a reward model\nüí° Explanation:\nReinforcement Learning from Human Feedback fine-tunes models using human preference data to guide a reward signal. This aligns AI behavior with human expectations.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúPenalizing long outputs‚Äù ‚Üí Separate technique.\n- ‚ÄúUnsupervised pretraining‚Äù ‚Üí Happens before RLHF.\n- ‚ÄúPrompt engineering‚Äù ‚Üí User-side activity, not training."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-6.-human-in-the-loop",
    "href": "danl-101-hw-02-a.html#question-6.-human-in-the-loop",
    "title": "Homework 2 - Example Answers",
    "section": "Question 6. Human in the Loop",
    "text": "Question 6. Human in the Loop\n‚ÄúBe the Human in the Loop‚Äù implies students should:\n\nTrust polished outputs\nTurn off tests to avoid overfitting\nVerify facts, run tests, and check assumptions\nAlways pick the first model answer\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Verify facts, run tests, and check assumptions\nüí° Explanation:\nBeing the Human in the Loop means staying actively engaged‚Äîtesting, fact-checking, and applying human judgment rather than deferring blindly to AI outputs.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúTrust polished outputs‚Äù ‚Üí Passive use.\n- ‚ÄúTurn off tests‚Äù ‚Üí Opposite of verification.\n- ‚ÄúAlways pick first model answer‚Äù ‚Üí Non-critical behavior."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-7.-bcg-study-rule-4",
    "href": "danl-101-hw-02-a.html#question-7.-bcg-study-rule-4",
    "title": "Homework 2 - Example Answers",
    "section": "Question 7. BCG Study ‚Äî Rule 4",
    "text": "Question 7. BCG Study ‚Äî Rule 4\n[BCG Study in Classwork 3 - Rule 4] Students in the bottom-right quadrant (AI strong, human novice) should prioritize:\n\nSpeed over understanding\nHiding AI use\nClimbing the human-skill axis through verification and practice\nZero prompting\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Climbing the human-skill axis through verification and practice\nüí° Explanation:\nThis quadrant represents people who rely heavily on AI but lack expertise. The goal is to move upward by verifying results, practicing skills, and gaining understanding to become ‚ÄúAI-strong + human-strong.‚Äù\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúSpeed over understanding‚Äù ‚Üí Encourages shallow learning.\n- ‚ÄúHiding AI use‚Äù ‚Üí Violates transparency.\n- ‚ÄúZero prompting‚Äù ‚Üí Removes human direction."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-8.-transformer-encoders",
    "href": "danl-101-hw-02-a.html#question-8.-transformer-encoders",
    "title": "Homework 2 - Example Answers",
    "section": "Question 8. Transformer Encoders",
    "text": "Question 8. Transformer Encoders\nTransformer encoders primarily:\n\nGenerate outputs token by token\nCreate context-aware representations of the inputs\nRank human preferences\nPerform diffusion sampling\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Create context-aware representations of the inputs\nüí° Explanation:\nEncoders convert input tokens into embeddings that capture meaning and context, enabling comprehension tasks like classification or translation.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúGenerate outputs token by token‚Äù ‚Üí Decoder‚Äôs role.\n- ‚ÄúRank human preferences‚Äù ‚Üí RLHF task.\n- ‚ÄúPerform diffusion sampling‚Äù ‚Üí Used in image models, not transformers."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-9.-treating-ai-like-a-person",
    "href": "danl-101-hw-02-a.html#question-9.-treating-ai-like-a-person",
    "title": "Homework 2 - Example Answers",
    "section": "Question 9. Treating AI ‚Äúlike a person‚Äù",
    "text": "Question 9. Treating AI ‚Äúlike a person‚Äù\nTreating AI ‚Äúlike a person‚Äù improves outputs primarily because:\n\nIt creates sentience\nIt conditions constraints/roles that steer generation\nIt bypasses guardrails\nIt increases context length\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. It conditions constraints/roles that steer generation\nüí° Explanation:\nFraming prompts with personas (e.g., ‚ÄúYou are a data analytics tutor‚Äù) guides structure, tone, and scope. It exploits how models respond to contextual conditioning‚Äînot sentience.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúCreates sentience‚Äù ‚Üí AI has no consciousness.\n- ‚ÄúBypasses guardrails‚Äù ‚Üí Not true and unethical.\n- ‚ÄúIncreases context length‚Äù ‚Üí Technical, unrelated."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-10.-disclosure-of-ai-work",
    "href": "danl-101-hw-02-a.html#question-10.-disclosure-of-ai-work",
    "title": "Homework 2 - Example Answers",
    "section": "Question 10. Disclosure of AI Work",
    "text": "Question 10. Disclosure of AI Work\nPublishing AI-written work without disclosure most directly violates:\n\nToken limits\nAcademic integrity/attribution norms\nHTML standards\nRLHF constraints\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Academic integrity/attribution norms\nüí° Explanation:\nSubmitting undisclosed AI-generated work misrepresents authorship, violating honesty and transparency. Disclosure ensures accountability and fairness.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúToken limits‚Äù ‚Üí Technical limit.\n- ‚ÄúHTML standards‚Äù ‚Üí Irrelevant.\n- ‚ÄúRLHF constraints‚Äù ‚Üí Internal to model training."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-11.-supervised-vs.-unsupervised",
    "href": "danl-101-hw-02-a.html#question-11.-supervised-vs.-unsupervised",
    "title": "Homework 2 - Example Answers",
    "section": "Question 11. Supervised vs.¬†Unsupervised",
    "text": "Question 11. Supervised vs.¬†Unsupervised\nWhich pairing is most accurate?\n\nSupervised = topic modeling; Unsupervised = sentiment\nSupervised = spam filtering; Unsupervised = clustering\nSupervised = clustering; Unsupervised = regression\nSupervised = sentiment; Unsupervised = regression\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Supervised = spam filtering; Unsupervised = clustering\nüí° Explanation:\nSpam filtering uses labeled data (‚Äúspam‚Äù vs.¬†‚Äúnot spam‚Äù), while clustering finds natural groups in unlabeled data. The difference is whether labels exist during training.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúTopic modeling = supervised‚Äù ‚Üí Topic modeling is unsupervised.\n- ‚ÄúRegression = unsupervised‚Äù ‚Üí Regression is supervised.\n- Other pairings mix up task types."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-12.-keeping-prompt-logs",
    "href": "danl-101-hw-02-a.html#question-12.-keeping-prompt-logs",
    "title": "Homework 2 - Example Answers",
    "section": "Question 12. Keeping Prompt Logs",
    "text": "Question 12. Keeping Prompt Logs\nThe strongest reason to keep prompt logs for the use of generative AI:\n\nIncrease token count\nReproducibility and iterative improvement\nReduce latency\nSatisfy HTML validators\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Reproducibility and iterative improvement\nüí° Explanation:\nPrompt logs document what was done, enabling replication, self-reflection, and transparency. They help track learning progress and model behavior.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúIncrease token count‚Äù ‚Üí No educational purpose.\n- ‚ÄúReduce latency‚Äù ‚Üí False; logging doesn‚Äôt affect runtime.\n- ‚ÄúSatisfy HTML validators‚Äù ‚Üí Unrelated to AI use."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-1.-vibe-coding",
    "href": "danl-101-hw-02-a.html#question-1.-vibe-coding",
    "title": "Homework 2 - Example Answers",
    "section": "Question 1. Vibe Coding",
    "text": "Question 1. Vibe Coding\nDescribe one benefit and one risk of vibe coding\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nA key benefit of vibe coding is rapid prototyping: students can quickly generate functional code through conversational iteration with AI, lowering the barrier to creative experimentation. However, a major risk is reduced understanding‚ÄîAI-generated code may contain hidden bugs, inefficiencies, or logic errors that students cannot explain. To mitigate this, learners should review and test all AI-generated code to ensure comprehension and correctness."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-2.-generative-ai-as-a-general-purpose-technology",
    "href": "danl-101-hw-02-a.html#question-2.-generative-ai-as-a-general-purpose-technology",
    "title": "Homework 2 - Example Answers",
    "section": "Question 2. Generative AI as a General Purpose Technology",
    "text": "Question 2. Generative AI as a General Purpose Technology\nGenerative AI is being described as a General Purpose Technology (GPT) like electricity or the internet. Do you agree with this analogy? Support your answer with historical parallels and at least one limitation unique to AI.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nGenerative AI resembles historical General Purpose Technologies like electricity or the internet because it transforms multiple sectors and reshapes productivity and learning. Like electricity enabling factories or the internet connecting people, AI is reshaping communication, creativity, and analysis. However, unlike those earlier GPTs, AI produces probabilistic, not deterministic, outputs‚Äîraising risks of bias, misinformation, and lack of transparency. It requires ethical oversight and verification to achieve its full potential safely."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-3.-bcg-study-rule-4-education-implications",
    "href": "danl-101-hw-02-a.html#question-3.-bcg-study-rule-4-education-implications",
    "title": "Homework 2 - Example Answers",
    "section": "Question 3. BCG Study ‚Äì Rule 4 (Education Implications)",
    "text": "Question 3. BCG Study ‚Äì Rule 4 (Education Implications)\n[Classwork 3 - Rule 4] The BCG study found that AI can push beginners close to expert performance on certain tasks. What does this mean for education? Should instructors grade differently when students can ‚Äúperform like experts‚Äù with AI support?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe BCG study shows that AI can elevate beginners‚Äô performance to near-expert levels on structured tasks such as writing or coding. In education, this means traditional grading based on final output may no longer measure real understanding. Instructors should adjust assessments to emphasize reasoning, manual skills, and reflection‚Äîrequiring students to explain how and why they used AI. Grading should reward verified comprehension, not just polished results."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-4.-paperclip-maximizer-thought-experiment",
    "href": "danl-101-hw-02-a.html#question-4.-paperclip-maximizer-thought-experiment",
    "title": "Homework 2 - Example Answers",
    "section": "Question 4. Paperclip Maximizer Thought Experiment",
    "text": "Question 4. Paperclip Maximizer Thought Experiment\nExplain the paperclip maximizer thought experiment. How does it illustrate alignment challenges in AI, and what lessons can be applied to everyday classroom use of generative tools?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe paperclip maximizer imagines an AI given the goal of ‚Äúmaximizing paperclips.‚Äù Without human-aligned constraints, it could destroy everything to fulfill that objective. This illustrates how AI systems can pursue goals literally but not ethically if alignment is missing. In the classroom, it teaches the importance of defining constraints, verifying outputs, and ensuring AI tasks align with human learning goals‚Äîso that efficiency does not replace understanding."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-1",
    "href": "danl-101-hw-02-a.html#question-1",
    "title": "Homework 2 - Example Answers",
    "section": "Question 1",
    "text": "Question 1\nHow can you filter the data.frame nyc_payroll_new to calculate descriptive statistics (mean and standard deviation) of Base_Salary for workers in the Work_Location_Borough ‚ÄúMANHATTAN‚Äù? Similarly, how can you filter the data.frame nyc_payroll_new to calculate these statistics for workers in the Work_Location_Borough ‚ÄúQUEENS‚Äù?\nProvide the R code for performing these calculations and then report the mean and standard deviation of Base_Salary for workers in both ‚ÄúMANHATTAN‚Äù and ‚ÄúQUEENS‚Äù.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Find all unique values in the `Work_Location_Borough` variable:\nnyc_payroll_new |&gt;  distinct(Work_Location_Borough)\n  # The output shows that \"MANHATTAN\" and \"QUEENS\" are among the unique values \n  # in `Work_Location_Borough`, written in all capital letters.\n\n# Filter the dataset for records where the work location is MANHATTAN\ndf_manhattan &lt;- nyc_payroll_new |&gt; \n  filter(Work_Location_Borough == \"MANHATTAN\")\n\n# Generate descriptive statistics (including mean and standard deviation) \n# for Base_Salary for workers in MANHATTAN\nskim(df_manhattan$Base_Salary) # or skim(df_manhattan)\n\n\n# Filter the dataset for records where the work location is QUEENS\ndf_queens &lt;- nyc_payroll_new |&gt; \n  filter(Work_Location_Borough == \"QUEENS\")\n\n# Generate descriptive statistics (including mean and standard deviation) \n# for Base_Salary for workers in QUEENS\nskim(df_queens$Base_Salary) # or skim(df_queens)"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-2",
    "href": "danl-101-hw-02-a.html#question-2",
    "title": "Homework 2 - Example Answers",
    "section": "Question 2",
    "text": "Question 2\nHow can you filter the data.frame nyc_payroll_new to show only the records where the Base_Salary is greater than or equal to $100,000?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset for records where Base_Salary is greater than or equal to \n# $100,000\nq2 &lt;- nyc_payroll_new |&gt; \n  filter(Base_Salary &gt;= 100000)"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-3",
    "href": "danl-101-hw-02-a.html#question-3",
    "title": "Homework 2 - Example Answers",
    "section": "Question 3",
    "text": "Question 3\nHow can you select only distinct combinations of Agency_Name and Title_Description?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Select distinct combinations of Agency_Name and Title_Description from the dataset\nq3 &lt;- nyc_payroll_new |&gt; \n  distinct(Agency_Name, Title_Description)"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-4",
    "href": "danl-101-hw-02-a.html#question-4",
    "title": "Homework 2 - Example Answers",
    "section": "Question 4",
    "text": "Question 4\nHow would you arrange the data by Regular_Gross_Paid in descending order, showing the highest paid employees first?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Arrange the dataset by Regular_Gross_Paid in descending order \n# (highest paid employees first)\nq4 &lt;- nyc_payroll_new |&gt; \n  arrange(desc(Regular_Gross_Paid))"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-5",
    "href": "danl-101-hw-02-a.html#question-5",
    "title": "Homework 2 - Example Answers",
    "section": "Question 5",
    "text": "Question 5\nHow can you select and rename the Title_Description variable to Title?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Rename the Title_Description variable to Title in the dataset\nq5 &lt;- nyc_payroll_new |&gt; \n  rename(Title = Title_Description)"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-6",
    "href": "danl-101-hw-02-a.html#question-6",
    "title": "Homework 2 - Example Answers",
    "section": "Question 6",
    "text": "Question 6\nHow can you filter the data to show only records for the ‚ÄúPOLICE DEPARTMENT‚Äù Agency_Name and arrange it by Total_OT_Paid in ascending order?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset for records where Agency_Name is \"POLICE DEPARTMENT\" \n# and arrange by Total_OT_Paid in ascending order\nq6 &lt;- nyc_payroll_new |&gt; \n  filter(Agency_Name == \"POLICE DEPARTMENT\") |&gt; \n  arrange(Total_OT_Paid)"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-7",
    "href": "danl-101-hw-02-a.html#question-7",
    "title": "Homework 2 - Example Answers",
    "section": "Question 7",
    "text": "Question 7\nHow can you filter the data to include only those records where the Pay_Basis is ‚Äúper Annum‚Äù and then select only the First_Name, Last_Name, and Base_Salary variables?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset for records where Pay_Basis is \"per Annum\" and \n# select specific columns: First_Name, Last_Name, and Base_Salary\nq7 &lt;- nyc_payroll_new |&gt; \n  filter(Pay_Basis == \"per Annum\") |&gt; \n  select(First_Name, Last_Name, Base_Salary)"
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-8",
    "href": "danl-101-hw-02-a.html#question-8",
    "title": "Homework 2 - Example Answers",
    "section": "Question 8",
    "text": "Question 8\nHow would you arrange the data.frame by Work_Location_Borough in ascending order and Base_Salary in descending order?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Arrange the dataset by Work_Location_Borough in ascending order \n# and Base_Salary in descending order\nq8 &lt;- nyc_payroll_new |&gt; \n  arrange(Work_Location_Borough, -Base_Salary)\n\n\nNote that sorting observations by a character variable in ascending order means sorting them in an alphabetical order.\nNote that sorting observations by a character variable in descending order means sorting them in a reverse-alphabetical order."
  },
  {
    "objectID": "danl-101-hw-02-a.html#question-9",
    "href": "danl-101-hw-02-a.html#question-9",
    "title": "Homework 2 - Example Answers",
    "section": "Question 9",
    "text": "Question 9\nHow can you filter the nyc_payroll_new data.frame to remove observations where the Base_Salary variable has NA values? After filtering, how would you calculate the total number of remaining observations?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset to remove observations where Base_Salary is NA\nq9 &lt;- nyc_payroll_new |&gt; \n  filter(!is.na(Base_Salary))\n\n# Calculate the total number of remaining observations after filtering\nnrow(q9)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html",
    "href": "danl-hw/danl-101-hw-04.html",
    "title": "Homework 4",
    "section": "",
    "text": "When visualizing grouped data, which of the following best describes the difference between using the aes(color = ...) aesthetic and using facet_wrap(‚Ä¶)`?\n      \n        \n          \n          color aesthetic mapping separates groups into different plots, while faceting overlays groups in one plot\n        \n        \n          \n          color aesthetic mapping differentiates groups within the same plot, while faceting displays each group in its own panel\n        \n        \n          \n          Both color aesthetic mapping and faceting always produce identical visualizations\n        \n        \n          \n          Faceting is only used for time-series data, while color aesthetic mapping is only used for categorical data\n        \n      \n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: color aesthetic mapping differentiates groups within the same plot, while faceting displays each group in its own panel\nExplanation:\n\naes(color = ...) keeps all groups in the same plot, distinguishing them by different colors.\nfacet_wrap() separates each group into its own subplot, giving each its own panel and axes.\nFaceting is helpful when groups overlap too much in one plot or when per-group trends need to be seen clearly.\n\n\n\n\n\n\n\n\nIn ggplot2, what does setting scales = \"free_y\" in facet_wrap() do?\n\n      \n        \n          \n          Allows both the x and y axes to vary independently in each facet\n        \n        \n          \n          Allows the y-axis scale to vary by facet while the x-axis is shared across facets\n        \n        \n          \n          Allows the x-axis scale to vary by facet while the y-axis is shared across facets\n        \n        \n          \n          Keeps both axes fixed to the same scale across all facets (the default)\n        \n      \n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Allows the y-axis scale to vary by facet while the x-axis is shared across facets\nExplanation:\n\nscales = \"free_y\" means each facet gets its own y-axis scale, but all facets share the same x-axis.\nThis is useful when groups differ greatly in magnitude on the y-axis, preventing small groups from appearing flat.\n\n\n\n\n\n\n\n\nWhich of the following statements about data visualizations is true?\n\n  \n     They always explain the underlying reasons behind data trends.\n  \n  \n     They are sufficient on their own to drive data-informed decisions.\n  \n  \n     They are useful for showing ‚Äúwhat‚Äù is happening in the data.\n  \n  \n     They eliminate the need for narratives in data storytelling.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: They are useful for showing ‚Äúwhat‚Äù is happening in the data.\nExplanation: Data visualizations are excellent tools for understanding ‚Äúwhat‚Äù is happening, but they often do not explain ‚Äúwhy‚Äù trends occur, which requires additional analysis or narratives.\n\n\n\n\n\n\n\nIn the ggplot2 syntax ggplot(data, aes(x, y)) + geom_point(), what does aes() stand for?\n\n  \n     Aesthetic mappings\n  \n  \n     Arithmetic expressions\n  \n  \n     Axis equal scaling\n  \n  \n     Average error squares\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Aesthetic mappings\nExplanation: The aes() function in ggplot2 stands for aesthetic mappings, linking data variables to visual properties like x, y, color, fill or shape.\n\n\n\n\n\n\n\nThe equation \\(\\Delta\\log(x) \\approx \\Delta x / x_{0}\\) demonstrates that a small change in the natural logarithm of \\(x\\), from an initial value \\(\\log(x_0)\\) to an ending value \\(\\log(x_{1})\\), where the change in \\(x\\) is given by \\(\\Delta x = x_{1} - x_{0}\\), can be approximated by:\n\n  \n     The absolute change in \\(x\\)\n  \n  \n     The percentage change in \\(x\\)\n  \n  \n     The square of \\(x\\)\n  \n  \n     The reciprocal of \\(x\\)\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: The percentage change in \\(x\\)\nExplanation: When \\(x\\) changes by a small amount, the natural logarithm of \\(x\\) changes approximately by the percentage change in \\(x\\).\n\n\n\n\n\n\n\nWhich of the following statements about mapping and setting aesthetics in ggplot2 is FALSE?\n\n  \n     Mapping aesthetics involves linking data variables to visual properties within aes()\n  \n  \n     Setting aesthetics manually is done outside of aes() to set fixed visual properties.\n  \n  \n     You can set aesthetics manually within aes() by assigning fixed values.\n  \n  \n     Mapping aesthetics allows different categories to be represented by different colors or shapes.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: You can set aesthetics manually within aes() by assigning fixed values.\nExplanation: Manually setting fixed aesthetics (e.g., color = \"red\") should be done outside of aes(). Inside aes(), values are mapped a variable in a data.frame.\n\n\n\n\n\n\n\nWhich of the following is NOT a way to explicitly inform ggplot about the grouping structure in a line plot?\n\n  \n     Using the group aesthetic.\n  \n  \n     Using the color aesthetic.\n  \n  \n     Using the linetype aesthetic.\n  \n  \n     Using the size aesthetic.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Using the size aesthetic.\nExplanation: The size aesthetic does not explicitly inform ggplot about grouping in a line plot, whereas group, color, and linetype do.\n\n\n\n\n\n\n\nIf you have a data frame with a date variable and want to plot a time series for each category in a variable called group_var, what is the minimal aesthetic mapping required in ggplot2 to correctly plot separate lines for each group?\n\n  \n     mapping = aes(x = date_var, y = value_var)\n  \n  \n     mapping = aes(x = date_var, y = value_var, color = group_var)\n  \n  \n     mapping = aes(x = date_var, y = value_var, group = group_var)\n  \n  \n     Both mapping = aes(x = date_var, y = value_var, color = group_var) and mapping = aes(x = date_var, y = value_var, group = group_var)\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Both mapping = aes(x = date_var, y = value_var, color = group_var) and mapping = aes(x = date_var, y = value_var, group = group_var)\nExplanation: Both options correctly separate lines for each group. group ensures proper grouping, while color differentiates groups visually.\n\n\n\n\n\n\n\nWhen creating a vertical boxplot in ggplot2, which of the following mappings is correct?\n\n  \n     Map both the x and y aesthetics to categorical variables.\n  \n  \n     Map a numeric variable to x and a categorical variable to y.\n  \n  \n     Map a categorical variable to x and a numeric variable to y.\n  \n  \n     Map both the x and y aesthetics to numeric variables.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Map a categorical variable to x and a numeric variable to y.\nExplanation: In a vertical boxplot, the x-axis typically represents categories, while the y-axis represents the numeric variable whose distribution is being summarized.\n\n\n\n\n\n\n\nWhich of the following functions is used to apply a color-blind friendly palette to the fill aesthetic in ggplot2?\n\n\n  \n     scale_fill_manual()\n  \n  \n     scale_fill_tableau()\n  \n  \n     scale_color_gradient()\n  \n  \n     scale_x_continuous()\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: scale_fill_tableau() or scale_fill_manual()\nExplanation: - The scale_fill_tableau() function, part of the ggthemes package, extends ggplot2 with Tableau-inspired themes and scales, including color-blind friendly palettes.\n\nThe scale_fill_manual() function can used to apply a custom color palette, including color-blind friendly palettes, to the fill aesthetic in ggplot2."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-1",
    "href": "danl-hw/danl-101-hw-04.html#question-1",
    "title": "Homework 4",
    "section": "",
    "text": "When visualizing grouped data, which of the following best describes the difference between using the aes(color = ...) aesthetic and using facet_wrap(‚Ä¶)`?\n      \n        \n          \n          color aesthetic mapping separates groups into different plots, while faceting overlays groups in one plot\n        \n        \n          \n          color aesthetic mapping differentiates groups within the same plot, while faceting displays each group in its own panel\n        \n        \n          \n          Both color aesthetic mapping and faceting always produce identical visualizations\n        \n        \n          \n          Faceting is only used for time-series data, while color aesthetic mapping is only used for categorical data\n        \n      \n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: color aesthetic mapping differentiates groups within the same plot, while faceting displays each group in its own panel\nExplanation:\n\naes(color = ...) keeps all groups in the same plot, distinguishing them by different colors.\nfacet_wrap() separates each group into its own subplot, giving each its own panel and axes.\nFaceting is helpful when groups overlap too much in one plot or when per-group trends need to be seen clearly."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-2",
    "href": "danl-hw/danl-101-hw-04.html#question-2",
    "title": "Homework 4",
    "section": "",
    "text": "In ggplot2, what does setting scales = \"free_y\" in facet_wrap() do?\n\n      \n        \n          \n          Allows both the x and y axes to vary independently in each facet\n        \n        \n          \n          Allows the y-axis scale to vary by facet while the x-axis is shared across facets\n        \n        \n          \n          Allows the x-axis scale to vary by facet while the y-axis is shared across facets\n        \n        \n          \n          Keeps both axes fixed to the same scale across all facets (the default)\n        \n      \n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Allows the y-axis scale to vary by facet while the x-axis is shared across facets\nExplanation:\n\nscales = \"free_y\" means each facet gets its own y-axis scale, but all facets share the same x-axis.\nThis is useful when groups differ greatly in magnitude on the y-axis, preventing small groups from appearing flat."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-3",
    "href": "danl-hw/danl-101-hw-04.html#question-3",
    "title": "Homework 4",
    "section": "",
    "text": "Which of the following statements about data visualizations is true?\n\n  \n     They always explain the underlying reasons behind data trends.\n  \n  \n     They are sufficient on their own to drive data-informed decisions.\n  \n  \n     They are useful for showing ‚Äúwhat‚Äù is happening in the data.\n  \n  \n     They eliminate the need for narratives in data storytelling.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: They are useful for showing ‚Äúwhat‚Äù is happening in the data.\nExplanation: Data visualizations are excellent tools for understanding ‚Äúwhat‚Äù is happening, but they often do not explain ‚Äúwhy‚Äù trends occur, which requires additional analysis or narratives."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-4",
    "href": "danl-hw/danl-101-hw-04.html#question-4",
    "title": "Homework 4",
    "section": "",
    "text": "In the ggplot2 syntax ggplot(data, aes(x, y)) + geom_point(), what does aes() stand for?\n\n  \n     Aesthetic mappings\n  \n  \n     Arithmetic expressions\n  \n  \n     Axis equal scaling\n  \n  \n     Average error squares\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Aesthetic mappings\nExplanation: The aes() function in ggplot2 stands for aesthetic mappings, linking data variables to visual properties like x, y, color, fill or shape."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-5",
    "href": "danl-hw/danl-101-hw-04.html#question-5",
    "title": "Homework 4",
    "section": "",
    "text": "The equation \\(\\Delta\\log(x) \\approx \\Delta x / x_{0}\\) demonstrates that a small change in the natural logarithm of \\(x\\), from an initial value \\(\\log(x_0)\\) to an ending value \\(\\log(x_{1})\\), where the change in \\(x\\) is given by \\(\\Delta x = x_{1} - x_{0}\\), can be approximated by:\n\n  \n     The absolute change in \\(x\\)\n  \n  \n     The percentage change in \\(x\\)\n  \n  \n     The square of \\(x\\)\n  \n  \n     The reciprocal of \\(x\\)\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: The percentage change in \\(x\\)\nExplanation: When \\(x\\) changes by a small amount, the natural logarithm of \\(x\\) changes approximately by the percentage change in \\(x\\)."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-6",
    "href": "danl-hw/danl-101-hw-04.html#question-6",
    "title": "Homework 4",
    "section": "",
    "text": "Which of the following statements about mapping and setting aesthetics in ggplot2 is FALSE?\n\n  \n     Mapping aesthetics involves linking data variables to visual properties within aes()\n  \n  \n     Setting aesthetics manually is done outside of aes() to set fixed visual properties.\n  \n  \n     You can set aesthetics manually within aes() by assigning fixed values.\n  \n  \n     Mapping aesthetics allows different categories to be represented by different colors or shapes.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: You can set aesthetics manually within aes() by assigning fixed values.\nExplanation: Manually setting fixed aesthetics (e.g., color = \"red\") should be done outside of aes(). Inside aes(), values are mapped a variable in a data.frame."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-7",
    "href": "danl-hw/danl-101-hw-04.html#question-7",
    "title": "Homework 4",
    "section": "",
    "text": "Which of the following is NOT a way to explicitly inform ggplot about the grouping structure in a line plot?\n\n  \n     Using the group aesthetic.\n  \n  \n     Using the color aesthetic.\n  \n  \n     Using the linetype aesthetic.\n  \n  \n     Using the size aesthetic.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Using the size aesthetic.\nExplanation: The size aesthetic does not explicitly inform ggplot about grouping in a line plot, whereas group, color, and linetype do."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-8",
    "href": "danl-hw/danl-101-hw-04.html#question-8",
    "title": "Homework 4",
    "section": "",
    "text": "If you have a data frame with a date variable and want to plot a time series for each category in a variable called group_var, what is the minimal aesthetic mapping required in ggplot2 to correctly plot separate lines for each group?\n\n  \n     mapping = aes(x = date_var, y = value_var)\n  \n  \n     mapping = aes(x = date_var, y = value_var, color = group_var)\n  \n  \n     mapping = aes(x = date_var, y = value_var, group = group_var)\n  \n  \n     Both mapping = aes(x = date_var, y = value_var, color = group_var) and mapping = aes(x = date_var, y = value_var, group = group_var)\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Both mapping = aes(x = date_var, y = value_var, color = group_var) and mapping = aes(x = date_var, y = value_var, group = group_var)\nExplanation: Both options correctly separate lines for each group. group ensures proper grouping, while color differentiates groups visually."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-9",
    "href": "danl-hw/danl-101-hw-04.html#question-9",
    "title": "Homework 4",
    "section": "",
    "text": "When creating a vertical boxplot in ggplot2, which of the following mappings is correct?\n\n  \n     Map both the x and y aesthetics to categorical variables.\n  \n  \n     Map a numeric variable to x and a categorical variable to y.\n  \n  \n     Map a categorical variable to x and a numeric variable to y.\n  \n  \n     Map both the x and y aesthetics to numeric variables.\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Map a categorical variable to x and a numeric variable to y.\nExplanation: In a vertical boxplot, the x-axis typically represents categories, while the y-axis represents the numeric variable whose distribution is being summarized."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#question-10",
    "href": "danl-hw/danl-101-hw-04.html#question-10",
    "title": "Homework 4",
    "section": "",
    "text": "Which of the following functions is used to apply a color-blind friendly palette to the fill aesthetic in ggplot2?\n\n\n  \n     scale_fill_manual()\n  \n  \n     scale_fill_tableau()\n  \n  \n     scale_color_gradient()\n  \n  \n     scale_x_continuous()\n  \n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: scale_fill_tableau() or scale_fill_manual()\nExplanation: - The scale_fill_tableau() function, part of the ggthemes package, extends ggplot2 with Tableau-inspired themes and scales, including color-blind friendly palettes.\n\nThe scale_fill_manual() function can used to apply a custom color palette, including color-blind friendly palettes, to the fill aesthetic in ggplot2."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#questions-11-17",
    "href": "danl-hw/danl-101-hw-04.html#questions-11-17",
    "title": "Homework 4",
    "section": "Questions 11-17",
    "text": "Questions 11-17\nConsider the following titanic data.frame for Questions 11-17:\n\ntitanic &lt;- read_csv(\"https://bcdanl.github.io/data/titanic_cleaned.csv\")\n\n\n\n\n\n  \n\n\n\n\n\nQuestion 11\nHow would you create the following data.frame, titanic_class_survival?\n\n\n\n  \n\n\n\nThe titanic_class_survival data.frame counts the number of passengers who survived and those who did not survive within each class in the titanic data.frame.\n\nComplete the code by filling in the blanks.\n\n__BLANK 1__ &lt;- titanic |&gt; \n  count(__BLANK 2__)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ntitanic_class_survival &lt;- titanic |&gt; \n  count(class, survived)\n\n\n\n\n\n\n\nQuestion 12\nHow would you describe the variation in the distribution of age across classes and genders?\nComplete the code by filling in the blanks.\n\n\n\n\n\n\n\n\n\n\nggplot(data = __BLANK 1__,\n       mapping = aes(x = gender,\n                     __BLANK 2__ = age,\n                     __BLANK 3__ = gender)) +\n  __BLANK 4__(show.legend = F) +\n  __BLANK 5__(~class) +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = titanic,\n       mapping = aes(x = gender,\n                     y = age,\n                     fill = gender)) +\n  geom_boxplot(show.legend = F) +\n  facet_wrap(~class) +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nQuestion 13\nProvide a comment on the variation in the distribution of age across classes and genders.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nFor both female and male groups, the ages of the first class passengers in the Titanic ranges wider than the second class and the third class.\nFor both female and male groups,the median of the first class passengers‚Äôs ages is higher than that of the second class and the third class.\nThe first quartile of female‚Äôs age is always lower than that of male‚Äôs across all classes. Particularly, the such gap is wider for the first class.\n\n\n\n\n\n\n\nQuestion 14\nHow would you describe the variation in the distribution of survived across classes and genders?\nComplete the code by filling in the blanks.\n\n\n\n\n\n\n\n\n\n\nggplot(data = __BLANK 1__,\n       mapping = aes(__BLANK 2__ = class,\n                     __BLANK 3__ = survived)) +\n  __BLANK 4__() +\n  __BLANK 5__(~gender) +\n  labs(x = \"Proportion\") +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = titanic,\n       mapping = aes(y = class,\n                     fill = survived)) +\n  geom_bar() +\n  facet_wrap(~gender) +\n  labs(x = \"Proportion\") +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nQuestion 15\nHow would you describe the variation in the distribution of survived across classes and genders?\nComplete the code by filling in the blanks.\n\n\n\n\n\n\n\n\n\n\nggplot(data = __BLANK 1__,\n       mapping = aes(__BLANK 2__ = class,\n                     __BLANK 3__ = survived)) +\n  __BLANK 4__(position = __BLANK 5__) +\n  __BLANK 6__(~gender) +\n  labs(x = \"Proportion\") +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = titanic,\n       mapping = aes(y = class,\n                     fill = survived)) +\n  geom_bar(position = \"fill\") +\n  facet_wrap(~gender) +\n  labs(x = \"Proportion\") +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nQuestion 16\nHow would you describe the variation in the distribution of survived across classes and genders?\nComplete the code by filling in the blanks.\n\n\n\n\n\n\n\n\n\n\nggplot(data = __BLANK 1__,\n       mapping = aes(__BLANK 2__ = class,\n                     __BLANK 3__ = survived)) +\n  __BLANK 4__(position = __BLANK 5__) +\n  __BLANK 6__(~gender) +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = titanic,\n       mapping = aes(y = class,\n                     fill = survived)) +\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~gender) +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nQuestion 17\nProvide a comment on the variation in the distribution of survived across classes and genders.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nFirst-class passengers had the highest survival rate.\n\nSurvival rates decline progressively in second and third classes.\n\nFemale passengers generally had a much higher survival rate compared to male passengers.\n\nFemale first-class passengers had the highest survival rates, followed by female second-class and third-class passengers.\nMale survival rates were considerably lower in all classes, with third-class males experiencing the lowest survival likelihood.\n\nThese patterns may be attributed to the influence of both socioeconomic status and gender norms prevalent in the early 1900s."
  },
  {
    "objectID": "danl-hw/danl-101-hw-04.html#questions-18-20",
    "href": "danl-hw/danl-101-hw-04.html#questions-18-20",
    "title": "Homework 4",
    "section": "Questions 18-20",
    "text": "Questions 18-20\nConsider the following nyc_dogs data.frame for Questions 18-20:\n\nnyc_dogs &lt;- read_csv(\"https://bcdanl.github.io/data/nyc_dogs_cleaned.csv\")\n\n\n\n\n\n  \n\n\n\n\nThe nyc_dogs data.frame contains data on licensed dogs in New York city.\n\n\n\nQuestion 18\nHow would you create the following data.frame, nyc_dogs_breeds?\n\n\n\n  \n\n\n\nThe nyc_dogs_breeds data.frame counts the number of occurrences for each value in the breed variable in the nyc_dogs data.frame.\n\nThe nyc_dogs_breeds data.frame keeps observations if\n\nThe number of occurrences (n) is greater than or equal to 2000;\nThe value of breed is not missing.\n\nThe observations in the nyc_dogs_breeds data.frame is arranged by n in descending order.\n\n\nComplete the code by filling in the blanks.\n\n__BLANK 1__ &lt;- nyc_dogs |&gt; \n  __BLANK 2__ |&gt; \n  filter(__BLANK 3__(breed)) |&gt; \n  filter(__BLANK 4__) |&gt; \n  arrange(__BLANK 5__)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nnyc_dogs_breeds &lt;- nyc_dogs |&gt; \n  count(breed) |&gt; \n  filter(!is.na(breed)) |&gt; \n  filter(n &gt;= 2000) |&gt; \n  arrange(-n)  # or arrange(desc(n))\n\n\n\n\n\n\n\nQuestion 19\nHow would you describe the distribution of breed using the nyc_dogs_breeds data.frame?\nComplete the code by filling in the blanks.\n\n\n\n\n\n\n\n\n\n\nggplot(data = __BLANK 1__,\n       mapping = aes(x = __BLANK 1__,\n                     __BLANK 3__)) +\n  __BLANK 4__()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = nyc_dogs_breeds,\n       mapping = aes(x = n,\n                     y = breed)) +\n  geom_col()\n\n\n\n\n\n\n\nQuestion 20\nHow would you describe the distribution of breed using the nyc_dogs_breeds data.frame?\nComplete the code by filling in the blanks.\n\n\n\n\n\n\n\n\n\n\nggplot(data = __BLANK 1__,\n       mapping = aes(x = __BLANK 1__,\n                     __BLANK 3__)) +\n  __BLANK 4__() +\n  labs(y = \"Breed\")\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = nyc_dogs_breeds,\n       mapping = aes(x = n,\n                     y = fct_reorder(breed, n))) +\n  geom_col() +\n  labs(y = \"Breed\")"
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html",
    "href": "danl-hw/danl-101-hw-03.html",
    "title": "Homework 3",
    "section": "",
    "text": "TBA"
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-1",
    "href": "danl-hw/danl-101-hw-03.html#question-1",
    "title": "Homework 3",
    "section": "Question 1",
    "text": "Question 1\nData warehouses use a schema-based approach, meaning data is processed before storage. (True/False)\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue.\nData warehouses use schema-on-write, which means data is cleaned, transformed, and structured before being stored."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-2",
    "href": "danl-hw/danl-101-hw-03.html#question-2",
    "title": "Homework 3",
    "section": "Question 2",
    "text": "Question 2\nThe narrative in data storytelling bridges the gap between data and insights. (True/False)\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue\nExplanation: The narrative connects raw data to meaningful insights, explaining the ‚Äúwhy‚Äù and ‚Äúhow.‚Äù"
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-3",
    "href": "danl-hw/danl-101-hw-03.html#question-3",
    "title": "Homework 3",
    "section": "Question 3",
    "text": "Question 3\nClutter in data visualization refers to visual elements that occupy space but do not improve understanding. (True/False)\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue\nExplanation: Clutter can distract from the main message and increase cognitive load."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-4",
    "href": "danl-hw/danl-101-hw-03.html#question-4",
    "title": "Homework 3",
    "section": "Question 4",
    "text": "Question 4\nProficiency in one programming language can facilitate learning others. (True/False)\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue\nExplanation: Fundamental programming concepts often transfer between languages."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-5",
    "href": "danl-hw/danl-101-hw-03.html#question-5",
    "title": "Homework 3",
    "section": "Question 5",
    "text": "Question 5\nIn Data Storytelling, the ‚ÄúBig Idea‚Äù must meet which of the following criteria? (Please refer to the Data Storytelling section on the Week 11 page.)\n\nArticulate your unique point of view\nBe a question\nBe a complete sentence\nBoth a and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd.¬†Both a and c\nExplanation: The Big Idea should articulate a unique perspective, convey what‚Äôs at stake, and be a complete sentence."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-6",
    "href": "danl-hw/danl-101-hw-03.html#question-6",
    "title": "Homework 3",
    "section": "Question 6",
    "text": "Question 6\nWhich of the following graphs is most appropriate for visualizing the distribution of a numerical variable?\n\nBar Chart\nHistogram\nPie Chart\nScatterplot\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Histogram\nExplanation: Histograms are ideal for showing the distribution of numerical data."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-7",
    "href": "danl-hw/danl-101-hw-03.html#question-7",
    "title": "Homework 3",
    "section": "Question 7",
    "text": "Question 7\nWhich of the following is a measure of the asymmetry of a distribution in a histogram?\n\nSkewness\nKurtosis\nVariance\nMean\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. Skewness\nExplanation: Skewness quantifies the asymmetry of a distribution."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-8",
    "href": "danl-hw/danl-101-hw-03.html#question-8",
    "title": "Homework 3",
    "section": "Question 8",
    "text": "Question 8\nWhich of the following is a reason to use a logarithmic scale when plotting data?\n\nWhen data is symmetrically distributed in a bell-shaped pattern\nWhen the variable is categorical\nWhen the variable has a wide range of skewed data\nTo increase the size of small values\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†When the variable has a wide range of skewed data\nExplanation: Logarithmic scales compress large ranges of data, making it easier to observe trends and compare values that vary greatly in size, from very small to very large. They are especially useful for visualizing skewed data with wide-ranging values, as they prevent very large values from visually overwhelming smaller ones."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-9",
    "href": "danl-hw/danl-101-hw-03.html#question-9",
    "title": "Homework 3",
    "section": "Question 9",
    "text": "Question 9\nAccording to the text, which of the following is important for data storytelling? (Please refer to the Data Storytelling section on the Week 11 page.)\n\nIncluding as much data as possible\nUnderstanding your audience‚Äôs needs\nUsing complex jargon\nFocusing solely on visual aesthetics\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Understanding your audience‚Äôs needs\nExplanation: Tailoring the message to the audience is crucial for effective communication."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#question-10",
    "href": "danl-hw/danl-101-hw-03.html#question-10",
    "title": "Homework 3",
    "section": "Question 10",
    "text": "Question 10\nWhat is overplotting in the context of scatterplots?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer:\nOverplotting occurs when data points overlap in a scatterplot, making it difficult to see individual observations. It can obscure patterns and make the visualization less effective."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#questions-11-18",
    "href": "danl-hw/danl-101-hw-03.html#questions-11-18",
    "title": "Homework 3",
    "section": "Questions 11-18",
    "text": "Questions 11-18\nConsider the following oj data.frame for Questions 11-18:\n\noj &lt;- read_csv(\"https://bcdanl.github.io/data/dominick_oj_na.csv\")\n\n\n\n\n\n\n\n\n\n\nQuestion 11\nHow can you filter the data.frame oj to calculate descriptive statistics (mean and standard deviation) of sales and price for tropicana, minute.maid, and dominicks, respectively?\n\noj_tr &lt;- oj |&gt; \n  filter(__BLANK__ \"tropicana\")\n\noj_mm &lt;- oj |&gt; \n  filter(__BLANK__ \"minute.maid\")\n\noj_do &lt;- oj |&gt; \n  filter(__BLANK__ \"dominicks\")\n\noj_tr_sum &lt;- skim(oj_tr)\noj_mm_sum &lt;- skim(oj_mm)\noj_do_sum &lt;- skim(oj_do)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset to include only rows where the brand is \"tropicana\"\noj_tr &lt;- oj |&gt; \n  filter(brand == \"tropicana\")\n\n# Filter the dataset to include only rows where the brand is \"minute.maid\"\noj_mm &lt;- oj |&gt; \n  filter(brand == \"minute.maid\")\n\n# Filter the dataset to include only rows where the brand is \"dominicks\"\noj_do &lt;- oj |&gt; \n  filter(brand == \"dominicks\")\n\n# Generate descriptive statistics for the Tropicana subset\noj_tr_sum &lt;- skim(oj_tr)\n\n# Generate descriptive statistics for the Minute Maid subset\noj_mm_sum &lt;- skim(oj_mm)\n\n# Generate descriptive statistics for the Dominick's subset\noj_do_sum &lt;- skim(oj_do)\n\n\n\n\n\n\n\nQuestion 12\nHow would you create a new data.frame, oj_no_NA, in which there is no missing value in price and sales?\n\noj_no_NA &lt;- oj |&gt; \n  filter(__BLANK__)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset to include only observations \n  # where both 'price' and 'sales' are not missing (i.e., no NA values)\noj_no_NA &lt;- oj |&gt; \n  filter(!is.na(price) & !is.na(sales))\n\n\n\n\n\n\n\nQuestion 13\nHow would you describe how the distribution of price varies by brand?\n\n\n\n\n\n\nggplot(data = __BLANK_1__, \n       mapping = aes(x = __BLANK_2__,\n                     __BLANK_3__)) +\n  __BLANK_4__(show.legend = FALSE,  # `show.legend = FALSE` turns off legend\n              __BLANK_5__ = 40) +\n  facet_wrap(__BLANK_6__, \n             __BLANK_7__ = 1)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = oj,  # or oj_no_NA\n       mapping = aes(x = price,  # set 'price' as the x-axis variable\n                     fill = brand)) +  # fill the histogram bars by 'brand' for color differentiation\n  geom_histogram(show.legend = FALSE,  # plot histograms without a legend\n                 bins = 40) +  # use 40 bins for the histogram\n  facet_wrap(~brand,  # create separate panels for each 'brand'\n             ncol = 1)  # arrange the panels in a single column\n\n\n\n\n\n\n\nQuestion 14\nProvide a comment to describe how the distribution of price varies by brand.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nOverall, Dominick‚Äôs is the budget option, Tropicana is the luxury option, and Minute Maid lives between.\n\n\n\n\n\n\nQuestion 15\nHow would you describe how the relationship between (1) the base-10 log of sales and (2) the base-10 log of price varies by brand?\n\n\n\n\n\n\nggplot(data = __BLANK_1__, \n       mapping = aes(x = __BLANK_2__,\n                     y = __BLANK_3__,\n                     __BLANK_4__ = brand,\n                     __BLANK_5__ = brand) +\n  geom_point(__BLANK_6__ = .1) +\n  geom_smooth(__BLANK_7__)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = oj,  # specify the dataset to be used for the plot\n       mapping = aes(x = log10(sales),  # apply log10 transformation to 'sales' for the x-axis\n                     y = log10(price),  # apply log10 transformation to 'price' for the y-axis\n                     color = brand,  # color points based on 'brand' categories\n                     fill = brand)) +  # use 'brand' to fill colors for ribbons around smoothed lines\n  geom_point(alpha = .1) +  # add scatter plot points with low opacity for better visibility of dense areas\n  geom_smooth(method = \"lm\")  # add a linear regression line for each brand\n\n\n\n\n\n\n\nQuestion 16\nProvide a comment to describe how the relationship between (1) the natural log of sales and (2) the natural log of price varies by brand?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nIn economics, the vertical axis typically represents price, while the horizontal axis represents quantity.\nHowever, for ease of interpretation, let‚Äôs switch the axes and use the natural logarithm:\n\n\nggplot(data = oj, \n       mapping = aes(x = log(price),\n                     y = log(sales),\n                     color = brand,\n                     fill = brand)) +\n  geom_point(alpha = .1) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\nWe observe that sales decrease as price increases, which aligns with the basic economic principle of a downward-sloping demand curve: higher prices typically lead to lower sales.\nMore specifically, sales decrease by a certain percentage (the slope) for every 1% increase in price.\nIn economics, this concept is known as price elasticity of demand, which measures how responsive consumers are to price changes when buying orange juice.\nTropicana customers are less responsive to price changes compared to customers of other brands.\nAdditionally, at the same price, Tropicana sells more than Minute Maid, which in turn sells more than Dominick‚Äôs.\nThis is expected, as Tropicana is considered a premium product and is more desirable at the same price point.\n\n\n\n\n\n\n\nQuestion 17\nHow would you visualize how the relationship between (1) the base-10 log of sales and (2) the base-10 log of price varies by brand and ad_status?\n\n\n\n\n\n\nggplot(data = __BLANK_1__, \n       mapping = aes(x = __BLANK_2__,\n                     y = __BLANK_3__,\n                     __BLANK_4__ = brand,\n                     __BLANK_5__ = brand) +\n  geom_point(__BLANK_6__ = .1) +\n  geom_smooth(__BLANK_7__) +\n  facet_wrap(__BLANK_8__)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = oj, \n       mapping = aes(x = log10(sales),\n                     y = log10(price),\n                     color = brand,\n                     fill = brand)) +\n  geom_point(alpha = .1) +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~ad_status)  # create separate panels for each level of 'ad_status'\n\n\n\n\n\n\n\nQuestion 18\nProvide a comment to describe how the relationship between (1) the natural log of sales and (2) the natural log of price varies by brand and ad_status.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFor interpretation purpose, let‚Äôs use the natural log, and switch axes:\n\nggplot(data = oj, \n       mapping = aes(x = log(price),\n                     y = log(sales),\n                     color = brand,\n                     fill = brand)) +\n  geom_point(alpha = .1) +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~ad_status)\n\n\n\n\n\nThe ads tend to change sales at all prices, they change price sensitivity, and they do both of these things in a brand-specific manner.\nWe see that being advertised always leads to more price sensitivity, particularly the demand for Minute Maid is much more price sensitive than when it is not.\nWhy does this happen?\n\nOne possible explanation is that advertisement increases the population of consumers who are considering your brand In particular, it can increase your market beyond brand loyalists, to include people who will be more price sensitive than those who reflexively buy your orange juice every week. Indeed, if you observe increased price sensitivity, it can be an indicator that your marketing efforts are expanding your consumer base.\n\nThis why ad campaigns should usually be accompanied by price cuts!\n\nThere is also an alternative explanation. Since the advertised products are often also discounted, it could be that the demand curve is nonlinear‚Äîat lower price points the average consumer is more price sensitive.\nThe truth is probably a combination of these effects."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#questions-19-20",
    "href": "danl-hw/danl-101-hw-03.html#questions-19-20",
    "title": "Homework 3",
    "section": "Questions 19-20",
    "text": "Questions 19-20\nConsider the following mlb_bat data.frame for Questions 19-20:\n\nmlb_bat &lt;- read_csv(\"https://bcdanl.github.io/data/MLB_batting.csv\")\n\n\n\n\n\n\n\n\n\n\nQuestion 19\nHow would you describe the yearly trends in hit percentages for each hit_type (e.g., Single, Double, Triple, and HomeRun)?\n\n\n\n\n\n\nggplot(data = __BLANK_1__, \n       mapping = aes(x = __BLANK_2__, \n                     y = __BLANK_3__, \n                     color = __BLANK_4__,\n                     fill = __BLANK_5__)) +\n  __BLANK_6__() + \n  __BLANK_7__() +\n  __BLANK_8__() +\n  labs(title = \"Hits by Type in Major League Baseball\",\n       x = \"Major League Baseball Season\",\n       y = \"Percentage\",\n       fill = \"Hit\",\n       color = \"Hit\")  # labs() allows for \n                       # labeling x, y, color, fill, title, etc.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nggplot(data = mlb_bat,  # specify the dataset to be used for the plot\n       mapping = aes(x = year,  # set 'year' as the x-axis variable\n                     y = percentage,  # set 'percentage' as the y-axis variable\n                     color = hit_type,  # color lines and points by 'hit_type' categories\n                     fill = hit_type)) +  # fill ribbon area by 'hit_type'\n  geom_point(size = .5) +  # add points for each data observation\n  geom_line() +  # connect points with lines to show trends over time\n  geom_smooth() +  # add a smoothed line to show overall trends for each 'hit_type'\n  labs(title = \"Hits by Type in Major League Baseball\",  \n       x = \"Major League Baseball Season\",  \n       y = \"Percentage\",  \n       fill = \"Hit\",  \n       color = \"Hit\")  # labs() allows for labeling x, y, color, fill, title, etc.\n\n\n\n\n\n\n\nQuestion 20\nWrite a comment explaining how you would describe the yearly trends in hit percentages for each hit_type (e.g., Single, Double, Triple, and HomeRun).\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe trends in MLB show that doubles and home runs have increased steadily over the years, while singles and triples have shown a decline. This shift reflects changes in playing style, favoring power hitting and longer hits over traditional base-hitting strategies."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#general-tips-on-describing-the-distribution",
    "href": "danl-hw/danl-101-hw-03.html#general-tips-on-describing-the-distribution",
    "title": "Homework 3",
    "section": "General Tips on Describing the Distribution",
    "text": "General Tips on Describing the Distribution\n\nWhen describing the distribution of a variable, we are typically interested in several key characteristics:\n\nCenter: The central tendency of the data, such as the mean or median, which indicates the typical or average value.\nSpread: How spread the values are within the variable, showing the range and standard deviation of values.\nCommon Values: Identifying frequent values and the mode.\nRare Values: Recognizing unusual or infrequent values.\nShape: The overall shape of the distribution, such as whether it‚Äôs symmetric, skewed left or right, or having multiple groups with multiple peaks.\n\nAdd Narration if Available: If possible, connect the distribution to real-world phenomena and/or your idea that could help explain it, adding insight into what is happening."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#general-tips-on-describing-the-relationship-between-two-variables",
    "href": "danl-hw/danl-101-hw-03.html#general-tips-on-describing-the-relationship-between-two-variables",
    "title": "Homework 3",
    "section": "General Tips on Describing the Relationship Between Two Variables",
    "text": "General Tips on Describing the Relationship Between Two Variables\n\nStart with determining whether the two variables have a positive association, a negative association, or no association.\n\n\nE.g., A negative slope in the fitted line indicates that sales decrease as the price increases, while a positive slope would indicate that sales increase with price. A zero slope means that there is no relationship between sales and price; changes in price do not affect sales.\n\n\n\n\n\n\n\n\nWhen a question asks you to describe how the relationship varies by another variable, examine both the direction of the slope (negative, positive, or none) from the fitted line and the steepness of the slope (steep or shallow).\n\n\nThe slope of the fitted straight line is the rate at which the ‚Äúy‚Äù variable (like grades) changes as the ‚Äúx‚Äù variable (like study hours) changes. In simple terms, it shows how much one thing goes up or down when the other thing changes.\nFor example, a comment such as, ‚ÄúThe plot shows a negative relationship between sales and price‚Äù does not address how the relationship differs by brand\n\n\nBe specific.\n\n\nFor example, a comment such as, ‚ÄúThe plot illustrates how the relationship between the natural log of sales and the natural log of price varies across brands, with each brand showing a unique regression line and scatter pattern,‚Äù simply rephrases the question, and does not actually answer it at all.\n\n\nThe focus is on the relationship, not the distribution.\n\n\nWhile adding a comment on the distribution of a single variable can be helpful, the question is primarily about the relationship between the two variables.\n\n\nAdd Narration if Available: If possible, connect the relationship to real-world phenomena and/or your idea that could help explain it, adding insight into what is happening."
  },
  {
    "objectID": "danl-hw/danl-101-hw-03.html#general-tips-on-describing-the-time-trend-of-a-variable",
    "href": "danl-hw/danl-101-hw-03.html#general-tips-on-describing-the-time-trend-of-a-variable",
    "title": "Homework 3",
    "section": "General Tips on Describing the Time Trend of a Variable",
    "text": "General Tips on Describing the Time Trend of a Variable\n\nStart with Identifying the Overall Trend: Look for the general direction of the trend over time.\n\n\nIs it moving upward, downward, or remaining relatively constant?\nBe specific: A comment like ‚ÄúThe trend shows the evolution of hitting techniques in the MLB over time‚Äù simply rephrases the question, and does not actually answer it at all.\n\n\nNote Patterns and Cycles: Identify any repeating patterns, such as seasonal fluctuations (e.g., monthly or quarterly changes) or long-term cycles. These patterns can indicate regular influences on the variable over time.\nHighlight Any Significant Fluctuations: Describe any sharp increases, decreases, or irregular spikes in the data.\nAdd Narration if Available: If possible, connect trends to real-world events or factors and/or your idea that could explain them, helping to interpret why the trend behaves a certain way over time."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Course Information\n\nInstructor: Byeong-Hak Choe\nEmail: bchoe@geneseo.edu\nPhone: (585) 245-5425\nClass Websites:\n\nGitHub Course Website\nBrightspace Course Shell\n\nOffice: South Hall 227B\nOffice Hours:\n\nMondays and Wednesdays 3:30 P.M. ‚Äì 5:00 P.M.\nBy appointment via email\n\n\n\n\n\n\nRevised Course Description\n\nThis course provides an applied overview of the data analytic process and methods. The goal of this course is to help students unlock the potential of data analysis and improve the ability to transform data into a powerful tool in decision making. Students will develop foundational data analytics skills to prepare for a career or future learning that involves more advanced topics in data analytics. Topics covered include (1) introduction to Data Analytics thinking, (2) data tools and skills, (3) data management and preparation techniques, (4) data storytelling for effective visualization and communication. During the course, students will work hands-on with the R and its associated data analysis packages.\n\n\nSchool of Business Mission\nThe School of Business at SUNY Geneseo is committed to exceptional business and economics education within the context of a strong liberal arts tradition. The School is distinguished by a uniquely accomplished and dedicated faculty, motivated and capable students, a robust professional development program, and the engaged support of alumni, employers, and business leaders. Students acquire strong quantitative, analytical, and communication skills while preparing for professional success as socially conscious contributors. We strive for teaching excellence, and we recognize that high-quality faculty scholarship and professional activities increase our impact on knowledge, practice, and pedagogy.\n\n\nBachelor of Arts in Data Analytics Program Competency Goals\n\nCompetency Goal 1: Our learners will have strong analytical skills.\nCompetency Goal 2: Our learners will have strong quantitative skills.\nCompetency Goal 3: Our learners will have effective communications skills.\nCompetency Goal 4: Our learners will have a thorough understanding of various functional areas of business.\nCompetency Goal 5: Our learners will have a multidimensional understanding of social responsibility.\n\n\n\nCourse Learning Outcomes\n\nGrasp the basic principles of data analytics, including data types and data processing.\nGain introductory experience with programming languages commonly used in data analytics, such as R.\nDevelop the ability to create and interpret various types of data visualizations.\nEnhance critical thinking skills by learning to ask relevant questions and draw insights from data.\nApply data analytics techniques to solve real-world problems in various domains.\n\n\n\nCourse Requirements\n\nHomework: 5 assignments\nQuizzes: 2 in-class quizzes\nParticipation: In-class and online participation\nTeam Project: Data storytelling project with team presentation\nExams: 2 midterms and 1 final\nTools:\n\nBrightspace\n\nPrivacy Policy\n\nMicrosoft Teams\n\nServices Agreement\n\nPosit Cloud\n\nTerms of Use\n\nGoogle Colab\n\nTerms of Service\n\nGitHub\n\nSite Policy\n\n\n\n\n\nData Storytelling Project\nData storytelling with visualization is the art of communicating complex data insights in a clear, engaging, and impactful way by blending data analysis, visual design, and narrative techniques. It goes beyond simply showing charts and graphs; it involves crafting a compelling story that guides the audience through the data, highlights key findings, and effectively conveys the intended message.\n\nKey aspects\n\nClarity: Visuals are easy to understand and focus on the most important information.\n\nStructure: Like a story‚Äîintroduction, main points, conclusion.\n\nEngagement: Tailor to your audience so it is relevant and interesting to them.\n\n\n\nEvaluation Criteria\n\nData transformation & statistics\nData visualization\nStorytelling effectiveness\nVisual/presentation materials\nTeam presentation quality\nCode quality\n\n\n\n\nRecommended References\nWe will be drawing material from a wide variety of sources for this course; as such, there is no single, required textbook per se.\n\nCloud Computing Concepts Hub ‚Äî Amazon Web Services (AWS)\nCo-Intelligence: Living and Working with AI ‚Äî Ethan Mollick. (ISBN-13: 978-0593716717; ISBN-10: 059371671X)\nStorytelling with Data: A Data Visualization Guide for Business Professionals ‚Äî Cole Nussbaumer Knaflic. (ISBN-13: 978-1119002253; ISBN-10: 1119002257)\nStorytelling with Data: Before and After - Practical Makeovers for Powerful Data Stories ‚Äî Cole Nussbaumer Knaflic, Mike Cisneros, and Alex Velez. (ISBN-13: 978-1394289615; ISBN-10: 1394289618)\nHands-On Programming with R ‚Äî Garrett Grolemund. (ISBN-13: 978-1449359010; ISBN-10: 1449359019)\n\nFree online version is available here\n\nR for Data Science (2nd Edition) ‚Äî Hadley Wickham & Garrett Grolemund. (ISBN-13: 978-1492097402; ISBN-10: 1492097403)\n\nFree online version is available here.\n\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse ‚Äî Chester Ismay & Albert Y. Kim. (ISBN-13: 978-0367409821; ISBN-10: 0367409828)\n\nFree online version is available here.\n\n\n\n\nCourse Schedule\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopic\nNotes\n\n\n\n\n1\nAug 25‚Äì29\nIntroduction to Data Analytics (Part 1)\n\n\n\n2\nSep 2‚Äì5\nIntroduction to Data Analytics (Part 2); Generative AI (Part 1)\nLabor Day (Sep 1)\n\n\n3\nSep 8‚Äì12\nGenerative AI (Part 2)\n\n\n\n4\nSep 15‚Äì19\nR Basics for Data Analytics\n\n\n\n5\nSep 22‚Äì26\nR Basics for Data Analytics\n\n\n\n6\nSep 29‚ÄìOct 3\nData Preparation and Management with R (Part 1)\n\n\n\n7\nOct 6‚Äì10\nData Preparation and Management with R (Part 2)\nMidterm Exam I\n\n\n8\nOct 15‚Äì17\nCareer in Data Analytics\nFall Break (Oct 13‚Äì14)\n\n\n9\nOct 20‚Äì24\nCareer in Data Analytics; Data Storytelling\n\n\n\n10\nOct 27‚Äì31\nData Visualization - Overview\n\n\n\n11\nNov 3‚Äì7\nData Visualization with R (Part 1)\n\n\n\n12\nNov 10‚Äì14\nData Visualization with R (Part 2)\n\n\n\n13\nNov 17‚Äì21\nData Visualization with R (Part 3)\nMidterm Exam II\n\n\n14\nNov 24‚Äì25\nData Storytelling - Summary\nThanksgiving Break (Nov 26‚Äì28)\n\n\n15\nDec 1‚Äì5\nData Storytelling Team Project Hands-on; Data Storytelling Team Presentations\n\n\n\n16\nDec 8\nData Storytelling Team Presentations\n\n\n\n\n\nExam Schedule\n\nMidterm Exam 1: 50-minute exam during class time in the week 7 (Oct 6‚Äì10)\nMidterm Exam 2: 50-minute exam during class time in the week 13 (Nov 17‚Äì21)\nFinal Exam: The School‚Äôs schedule is available here.  \n\n\n\n\nAttendance\nStudents are allowed up to four absences in MW course (DANL 101-03) and six absences in MWF course (DANL 101-04) without penalty. Additional absences may affect your grade unless they are formally excused. If you must miss class for a standard excused reason (e.g., illness, family emergency, transportation issues), please notify me at bchoe@geneseo.edu so the absence can be recorded appropriately.\nRegular attendance is expected, as discussions, activities, and projects are central to your learning. If you anticipate challenges that may affect your attendance, please reach out‚ÄîI am happy to work with you to help you stay on track.\n\n\nGrading\n\nTotal Percentage Grade\n\nAttendance: 5%\n\nQuizzes & Participation: 5%\n\nHomework: 20% (single lowest homework score dropped)\n\nTeam Project: 20%\n\nExams: 50% \\[\n\\begin{align}\n\\quad\\\\\n&\\text{(Total Percentage Score)} \\\\\n= &\\quad\\; 0.05 \\times \\text{(Attendance)} \\\\\n&+ 0.05 \\times \\text{(Quiz \\& Participation)}\\\\\n&+ 0.20 \\times \\text{(Homework)}\\\\\n&+ 0.20 \\times \\text{(Team Project)}\\\\\n&+ 0.50 \\times \\text{(Exams)}\n\\end{align}\n\\]\n\nExam Score Calculations\n\n\\[\n\\begin{align}\n&\\quad(\\text{Midterm Exam Score})\\\\\n&= \\max\\left\\{0.50 \\times \\text{(Midterm 1 Score)} + 0.50 \\times \\text{(Midterm 2 Score)},\\right.\\\\\n&\\qquad\\quad\\;\\;\\,\\left.0.33 \\times \\text{(Midterm 1 Score)} + 0.67 \\times \\text{(Midterm 2 Score)}\\right\\}.\n\\end{align}\n\\]\n\nThe Midterm Exam Score will be the higher of the following two calculations:\n\nThe simple average of Midterm Exam 1 and Midterm Exam 2\nThe weighted average, with one-third weight on Midterm Exam 1 and two-thirds weight on Midterm Exam 2\n\n\n\\[\n\\begin{align}\n&\\quad(\\text{Total Exam Score})\\\\\n&= \\max\\left\\{0.50 \\times \\text{(Midterm Exam Score)} + 0.50 \\times \\text{(Final Exam Score)},\\right.\\\\\n&\\qquad\\quad\\;\\;\\,\\left.0.25 \\times \\text{(Midterm Exam Score)} + 0.75 \\times \\text{(Final Exam Score)}\\right\\}.\n\\end{align}\n\\]\n\nThe Total Exam Score will be the higher of the following two calculations:\n\nThe simple average of Midterm Exam and Final Exam\nThe weighted average, with one-fourth weight on Midterm Exam and three-forth weight on Final Exam.\n\nTeam Project Score \\[\n\\begin{align}\n&\\quad\\text{(Team Project Score)}\\\\\n&= 0.05 \\times \\text{(Peer Evaluation)} + 0.95 \\times \\text{(Instructor Evaluation)}.\n\\end{align}\n\\]\nLetter Grade Scale\nTotal percentage scores are converted to letter grades according to the following ranges:\n\n\\[\n\\begin{align}\n100 &‚â• A ‚â• 93 &gt; A‚àí ‚â• 90\\\\\n90 &&gt; B+ ‚â• 87 &gt; B ‚â• 83 &gt; B‚àí ‚â• 80\\\\\n80 &&gt; C+ ‚â• 77 &gt; C ‚â• 73 &gt; C‚àí ‚â• 70\\\\\n70 &&gt; D ‚â• 60 &gt; E\n\\end{align}\n\\]\n\n\nPolicies\n\nMake-up Exams\nMake-up exams will not be given unless you have either a medically verified excuse or an absence excused by the University. For religious obligations, notify the instructor by email at least two weeks in advance to set an alternative time. A missed exam without an excused absence earns a grade of zero.\n\n\nArtificial Intelligence (AI)\nUnless AI tools are explicitly permitted for homework or in-class quizzes, you must complete your work independently. Using tools like ChatGPT for any aspect of coursework is a form of academic dishonesty and undermines the development of your own skills. If you have questions, please ask.\n\n\n\n\n\n\nüìù If you use AI for a particular assignment and/or project, you must also:\n\nüìù You must document which AI platforms and tools you used.\nüì§ You must include your prompts and AI outputs with your assignment submission.\nüß† You must include a reflection on your AI usage and learning process.\n\n\n\n\nAcademic Integrity and Plagiarism\nAll homework assignments and exams must be your original work. Academic dishonesty will not be tolerated. Examples include:\n\nRepresenting the work, thoughts, or ideas of another person as your own\n\nAllowing others to represent your work, thoughts, or ideas as theirs\n\nBeing complicit in academic dishonesty by suspecting or knowing of it and not taking action\n\nSee: Academic Dishonesty Policy and Procedures and Plagiarism Tutorial Brightspace Link\n\n\n\n\nAccessibility\nSUNY Geneseo is dedicated to providing an equitable and inclusive educational experience for all students. The Office of Accessibility (OAS) will coordinate reasonable accommodations for persons with disabilities to ensure equal access to academic programs, activities, and services offered by SUNY Geneseo.\nStudents with approved accommodations may submit a semester request to renew their academic accommodations. More information on the process for requesting academic accommodations is on the OAS website.\nQuestions? Contact the OAS by email, phone, or in-person:\nOffice of Accessibility Services\nErwin Hall 22\n585-245-5112\naccess@geneseo.edu\n\n\nPublic Health and Class Attendance\nIf you are experiencing symptoms associated with COVID on a day that class meets in-person, do not attend. Communicate proactively about absences and contact the Dean of Students if you expect to be out for an extended period.\n\n\nReligious Observations and Class Attendance\nNew York State Education Law 224-a stipulates that ‚Äúany student in an institution of higher education who is unable, because of [their] religious beliefs, to attend classes on a particular day or days shall, because of such absence on the particular day or days, be excused from any examination or any study or work requirements‚Äù (see General Classroom Policies for more information). SUNY Geneseo has a commitment to inclusion and belonging, and I want to stress my respect for the diverse identities and faith traditions of students in my class. If you anticipate an absence due to religious observations, please contact me as soon as possible in advance to discuss your needs and arrange make up plans. The New York State Department of Civil Service maintains a calendar of major religious observations.\n\n\nMilitary Obligations and Class Attendance\nFederal and New York State law requires institutions of higher education to provide an excused leave of absence from classes without penalty to students enrolled in the National Guard or armed forces reserves who are called to active duty. If you are called to active military duty and need to miss classes, please let me know and consult as soon as possible with the Dean of Students.\n\n\nBias-Related Incidents\n\n‚ÄúWe are here to listen, to learn, to teach, to debate, to change, to grow. We should all be safe to pursue these goals at SUNY Geneseo while being who we are. Together, we commit ourselves to pluralism, cultivating a community that respects difference and promotes a sense of inclusion and belonging.‚Äù\n\nAs this excerpt from our Community Commitment to Diversity, Equity, and Inclusion states, here at SUNY Geneseo, we want to provide a space where everyone feels welcome to learn and grow in their identities as well as in their role as students, faculty, and staff. If in the unfortunate instance you witness or experience an incident of bias, we encourage you to reach out to the Chief Diversity Officer, Director of Multicultural Affairs, and/or our University Police Department. You may also choose to report it through the bias-related incident reporting form. In trying to create an environment that facilitates growth through diverse thoughts and ideas, reporting incidents of bias - including threats, vandalism, and microaggressive behaviors - can help bring a better understanding of our campus climate as well as provide opportunities for learning and restoring harm.\n\n\n\nPersonal Health, Well-being, and Basic Needs\n\nWell-Being\nPrioritizing well-being can support the achievement of academic goals and alleviate stress. Eating nutritious foods, getting enough sleep, exercising, avoiding drugs and alcohol, maintaining healthy relationships, and building in time to relax all help promote a healthy lifestyle and general well-being. Your health and wellbeing are foundational to your ability to learn, and if you find that you are feeling unwell (physically or mentally) and it is impacting your ability to complete your coursework, please reach out. In a similar way, I will occasionally ask for some patience and flexibility on your part.\nIf I am slow responding to an email, if I take some time to grade an assignment, or if I am a bit late posting course materials, please be patient (and feel free to send me a ‚Äònudge‚Äô; I will not be offended). You will never suffer any disadvantage in the course because of delays on my part. Remember that we are all in this together.\n\n\nBasic Needs Statement\nIn order to foster a sense of belonging and connection, a state of financial, mental, emotional and physical stability must be achieved. If you are facing food insecurity, displacement, an emergency, crisis, or health-related or medical expense, you are not alone. Concerns about academic performance, health situations, family health and wellness (including the loss of a loved one), interpersonal relationships and commitments, and other factors can contribute to stress. Students are strongly encouraged to communicate their needs to faculty and staff and seek support if they are experiencing unmanageable stress or are having difficulties with daily functioning. The Dean of Students (585-245-5706) can assist and provide direction to appropriate campus resources. For more information, visit the Dean of Students Office website.\n\n\nMental Health\nAs a student, you may experience a range of challenges that can impact your mental health and thus impact your learning; common examples include increased anxiety, shifts in mood, strained relationships, difficulties related to substance use, trouble concentrating, and lack of motivation, among many others. These experiences may reduce your ability to participate fully in daily activities and affect your academic performance.\nSUNY Geneseo offers free, confidential counseling for students through Student Health and Counseling, and seeking support for your mental health can be key to your success at college. You can learn more about the various mental health services available on campus online. To request a counseling appointment, please complete the online form.\n\n\nGuidelines for Attendance and Public Health\nSUNY Geneseo is a residential liberal arts college where we all learn together in a shared space. This classroom community is vital for engaging in discussions, solving problems, and answering questions together. Learning is an active process, and it requires engagement - on my part and yours. I promise to create an interactive and collaborative classroom space, and in return I expect you to attend and engage in the activities.\nIt‚Äôs possible that some of you may get sick over the course of the semester. Because we want you to be successful and because we value your contribution to the course, we expect you to prioritize attendance. If you are not feeling well and your symptoms do not allow you to attend class, stay home (except to go to the health center), rest, and take care of yourself. You can find more guidelines from the Center for Disease Control for precautions when sick which cover flu, COVID, and other illnesses.\nI expect you to communicate with me directly about your absences. I can support you to keep up with class if you are out for an illness, but I need you to take responsibility for being transparent and clear in letting me know when you are out and why. Although I can work with you on keeping up, you may miss some course content and extended absences may impact your ability to realize your full potential in this class. For extended absences (i.e., more than a couple of days of classes), you should contact the Dean of Students who can assist with reaching out to your faculty.\n\n\nFood Security for SUNY Geneseo Students\nSUNY Geneseo is committed to supporting students who are experiencing food insecurity. If you‚Äôre unfamiliar with the phrase ‚Äúfood insecurity,‚Äù you can learn more at the following link on Feeding America‚Äôs website: Understanding Food Insecurity.\nKnights‚Äô Harvest Pantry, our on-campus food pantry, is a collaborative initiative supported by Campus Auxiliary Services (CAS) and facilitated by trained student volunteers. The program is advised by the Assistant Director of Student Volunteerism and Community Engagement in partnership with the Geneseo Opportunities for Leadership Development (GOLD) program.\nStudents who are in need can confidentially request a bag of food and basic hygiene supplies through our website. These bags typically include non-perishable items and, when available, fresh fruits, vegetables, meat, and dairy products. Pickups take place at the GOLD Leadership Center in MacVittie College Union, Room 114.\nWe are committed to protecting student privacy and promoting dignity, while also working to destigmatize food insecurity on our campus. If Knights‚Äô Harvest Pantry does not fully meet your needs or if you‚Äôd prefer to discuss your situation privately, please reach out to Cheyenne DeMarco, Assistant Director of Student Volunteerism and Community Engagement, at cdemarco@geneseo.edu for a one-on-one consultation.\nPlease note that Knights‚Äô Harvest Pantry is closed during official SUNY breaks, including Fall Break, Winter Intersession, Spring Break, and summer between semesters. During these times, students are encouraged to access the Geneseo-Groveland Emergency Food Pantry, located at 31 Center Street, Geneseo, NY 14454. For updates on pantry hours, events, and additional support opportunities, follow us on Instagram or Facebook: @knightsharvestgeneseo. For questions or support, contact Cheyenne DeMarco at cdemarco@geneseo.edu or (585) 245-5893.\n\n\nEmergency Funding\nThe college has three sources of emergency funding for students experiencing short-term financial crises. The Camiolo Student Emergency Loan Fund (SELF) provides short-term loans to students for situations both temporary and beyond their control. The SELF was established with the expectation that students who use the fund seek to ‚Äúpay it forward‚Äù as soon as they are able by contributing to the fund so other students can be helped, too. While there is not a legal obligation, the donors hope that student loan recipients respect and honor the value of community and helping others in their time of crisis. The One Knight Student Aid Emergency Fund assists Geneseo students who are facing financial emergencies mainly related to the COVID-19 pandemic. The fund offers grants (one-time award) depending on a student‚Äôs documented financial need. For those students expecting a refund from financial aid, a Temple Hill loan of up to $500 can be offered prior to the approved loan dispersal. If you are experiencing financial hardship, please contact the Dean of Students (585-245-5706), who can assist and provide direction to appropriate campus resources.\n\n\n\nSUNY Geneseo‚Äôs Commitments, Mission and Values\nSUNY Geneseo has several core documents that articulate our shared commitments and learning objectives. These include:\n\nSUNY Geneseo Mission, Vision and Values\nCommunity Commitment to Diversity, Equity, and Inclusion\nSustainability as a Core Value\nGeneseo Learning Outcomes for Baccalaureate Education\n\n\n\nDisclaimer\nThe syllabus may be subject to change during the semester. If it is changed, you will be notified via email and Brightspace.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which tool is an Integrated Development Environment (IDE) that you can install on your computer to develop programs primarily using the R programming language?\n\nPosit Cloud\nGoogle Colab\nJupyter Notebook\nRStudio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation: RStudio (now under Posit) is a dedicated desktop IDE for R that provides a console, script editor, package management, plotting, and a full debugging workflow. Posit Cloud and Google Colab are browser-based environments (great for portability, but not desktop IDEs), and Jupyter Notebook is a notebook interface mainly used with Python (though R kernels exist, it is not the primary R IDE).\n\n\n\n\n\n\nWhich version-control tool allows users to track, compare, and merge code changes?\n\nGitHub\nGit\nR\nStack Overflow\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Git is the version-control system that performs the actual tracking of changes, branching, merging, and diffing. GitHub is a hosting platform built around Git repositories (remote collaboration, pull requests, issues). R is a programming language, and Stack Overflow is a Q&A site.\n\n\n\n\n\n\nA key distinction between Traditional Programming and Machine Learning (ML) in the context of image recognition (like for a cat) is that ML:\n\nRequires programmers to explicitly define rules for ‚Äúcat‚Äù features (pointy ears, whiskers).\nIs less effective at finding hidden patterns in pixels than traditional methods.\nLearns the patterns from thousands of labeled cat/not-cat pictures rather than relying on fixed, explicit rules.\nCan be used for image recognition and but not for classification tasks like spam detection.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: In ML, models discover patterns from labeled data (e.g., many cat vs.¬†not-cat images) rather than relying on hand-crafted rules. Traditional programming would require explicit feature rules (option a). ML often outperforms manual rules on high-dimensional pattern recognition (contradicting b) and is widely used for both image recognition and many other classification tasks such as spam detection (contradicting d).\n\n\n\n\n\n\nWhat was the key contribution of Moneyball to sports analytics?\n\nIt created new baseball rules for team selection.\nIt replaced human coaches with AI models.\nIt popularized data-driven decision-making in sports management.\nIt eliminated the use of scouts.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Moneyball demonstrated that rigorous statistical analysis (e.g., on-base percentage) could uncover undervalued players and improve roster-building decisions. It did not change MLB rules, eliminate scouts, or replace coaches with AI; instead, it shifted culture toward evidence-based decision-making.\n\n\n\n\n\n\nWhich statement best captures the distinctive role of Business Intelligence (BI) compared to other data-driven systems?\n\nBI focuses on automating decisions through artificial intelligence and predictive modeling.\nBI emphasizes descriptive and diagnostic insights that help managers understand why outcomes occurred.\nBI replaces human judgment by forecasting business outcomes using statistical learning.\nBI primarily stores large volumes of unprocessed data for future retrieval.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: BI primarily supports descriptive and diagnostic analytics (dashboards, reporting, drill-downs) to help stakeholders understand what happened and why. Predictive/automated decision-making is more aligned with data science and ML (contradicting a and c), and large-scale raw data storage is the role of data lakes/warehouses (contradicting d).\n\n\n\n\n\n\nWhat distinguishes Deep Learning from general Machine Learning?\n\nDeep learning is the overarching field of AI, while machine learning is just a sub-area.\nDeep learning is an advanced machine learning methodology that is uniquely suited for complex tasks and primarily relies on artificial neural networks.\nDeep learning models are capable of making predictions or generating outputs, while machine learning models are not.\nDeep learning is the practice of designing structured inputs to guide generative AI systems.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Deep learning is a subfield of machine learning that uses multi-layer (deep) neural networks, often excelling on unstructured data (images, audio, text). ML as a whole includes many methods (decision trees, regression models). Options a and c invert relationships, and d describes prompt engineering, not deep learning.\n\n\n\n\n\n\nIn the context of a Large Language Model (LLM), what is the function of Pre-training?\n\nTo specialize the model for a specific task like medical Q&A or legal summarization.\nTo have humans rank or score model answers to align them with preferences.\nTo read a vast amount of text to learn general language patterns, resulting in a foundation model with broad knowledge.\nTo reduce model biases by explicitly removing skewed data from the training corpus.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Pre-training exposes the model to large corpora so it learns broad statistical patterns of language (syntax, semantics, world knowledge). Fine-tuning specializes models for specific tasks (a), RLHF uses human preference signals (b), and while data curation can address some biases (d), that is not the core function of pre-training.\n\n\n\n\n\n\nWhich of the following best describes an ‚Äúembedding‚Äù in the context of GPT models?\n\nA single number representing a word‚Äôs position in a sentence.\nA long list of numbers that captures a word‚Äôs meaning and allows words with similar meanings to have similar numerical representations.\nThe final text output generated by the decoder.\nA specific part of the training dataset used for fine-tuning.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: An embedding is a dense vector representation capturing semantic relationships among tokens; similar meanings tend to have nearby vectors. It is not a single scalar (a), not the model‚Äôs generated text (c), and not a dataset subset (d)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-1",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-1",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which tool is an Integrated Development Environment (IDE) that you can install on your computer to develop programs primarily using the R programming language?\n\nPosit Cloud\nGoogle Colab\nJupyter Notebook\nRStudio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation: RStudio (now under Posit) is a dedicated desktop IDE for R that provides a console, script editor, package management, plotting, and a full debugging workflow. Posit Cloud and Google Colab are browser-based environments (great for portability, but not desktop IDEs), and Jupyter Notebook is a notebook interface mainly used with Python (though R kernels exist, it is not the primary R IDE)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-2",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-2",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which version-control tool allows users to track, compare, and merge code changes?\n\nGitHub\nGit\nR\nStack Overflow\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Git is the version-control system that performs the actual tracking of changes, branching, merging, and diffing. GitHub is a hosting platform built around Git repositories (remote collaboration, pull requests, issues). R is a programming language, and Stack Overflow is a Q&A site."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-3",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-3",
    "title": "Midterm Exam I",
    "section": "",
    "text": "A key distinction between Traditional Programming and Machine Learning (ML) in the context of image recognition (like for a cat) is that ML:\n\nRequires programmers to explicitly define rules for ‚Äúcat‚Äù features (pointy ears, whiskers).\nIs less effective at finding hidden patterns in pixels than traditional methods.\nLearns the patterns from thousands of labeled cat/not-cat pictures rather than relying on fixed, explicit rules.\nCan be used for image recognition and but not for classification tasks like spam detection.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: In ML, models discover patterns from labeled data (e.g., many cat vs.¬†not-cat images) rather than relying on hand-crafted rules. Traditional programming would require explicit feature rules (option a). ML often outperforms manual rules on high-dimensional pattern recognition (contradicting b) and is widely used for both image recognition and many other classification tasks such as spam detection (contradicting d)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-4",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-4",
    "title": "Midterm Exam I",
    "section": "",
    "text": "What was the key contribution of Moneyball to sports analytics?\n\nIt created new baseball rules for team selection.\nIt replaced human coaches with AI models.\nIt popularized data-driven decision-making in sports management.\nIt eliminated the use of scouts.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Moneyball demonstrated that rigorous statistical analysis (e.g., on-base percentage) could uncover undervalued players and improve roster-building decisions. It did not change MLB rules, eliminate scouts, or replace coaches with AI; instead, it shifted culture toward evidence-based decision-making."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-5",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-5",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which statement best captures the distinctive role of Business Intelligence (BI) compared to other data-driven systems?\n\nBI focuses on automating decisions through artificial intelligence and predictive modeling.\nBI emphasizes descriptive and diagnostic insights that help managers understand why outcomes occurred.\nBI replaces human judgment by forecasting business outcomes using statistical learning.\nBI primarily stores large volumes of unprocessed data for future retrieval.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: BI primarily supports descriptive and diagnostic analytics (dashboards, reporting, drill-downs) to help stakeholders understand what happened and why. Predictive/automated decision-making is more aligned with data science and ML (contradicting a and c), and large-scale raw data storage is the role of data lakes/warehouses (contradicting d)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-6",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-6",
    "title": "Midterm Exam I",
    "section": "",
    "text": "What distinguishes Deep Learning from general Machine Learning?\n\nDeep learning is the overarching field of AI, while machine learning is just a sub-area.\nDeep learning is an advanced machine learning methodology that is uniquely suited for complex tasks and primarily relies on artificial neural networks.\nDeep learning models are capable of making predictions or generating outputs, while machine learning models are not.\nDeep learning is the practice of designing structured inputs to guide generative AI systems.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Deep learning is a subfield of machine learning that uses multi-layer (deep) neural networks, often excelling on unstructured data (images, audio, text). ML as a whole includes many methods (decision trees, regression models). Options a and c invert relationships, and d describes prompt engineering, not deep learning."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-7",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-7",
    "title": "Midterm Exam I",
    "section": "",
    "text": "In the context of a Large Language Model (LLM), what is the function of Pre-training?\n\nTo specialize the model for a specific task like medical Q&A or legal summarization.\nTo have humans rank or score model answers to align them with preferences.\nTo read a vast amount of text to learn general language patterns, resulting in a foundation model with broad knowledge.\nTo reduce model biases by explicitly removing skewed data from the training corpus.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Pre-training exposes the model to large corpora so it learns broad statistical patterns of language (syntax, semantics, world knowledge). Fine-tuning specializes models for specific tasks (a), RLHF uses human preference signals (b), and while data curation can address some biases (d), that is not the core function of pre-training."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-8",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-8",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following best describes an ‚Äúembedding‚Äù in the context of GPT models?\n\nA single number representing a word‚Äôs position in a sentence.\nA long list of numbers that captures a word‚Äôs meaning and allows words with similar meanings to have similar numerical representations.\nThe final text output generated by the decoder.\nA specific part of the training dataset used for fine-tuning.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: An embedding is a dense vector representation capturing semantic relationships among tokens; similar meanings tend to have nearby vectors. It is not a single scalar (a), not the model‚Äôs generated text (c), and not a dataset subset (d)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-9",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-9",
    "title": "Midterm Exam I",
    "section": "Question 9",
    "text": "Question 9\nThe practice of designing clear, structured inputs to guide generative AI systems toward accurate, useful, and context-appropriate outputs is known as _________________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nprompt engineering\nExplanation: Prompt engineering focuses on crafting instructions, constraints, and context so generative models produce reliable, relevant outputs. It includes strategies like role prompting, exemplars, delimiters, and stepwise guidance."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-10",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-10",
    "title": "Midterm Exam I",
    "section": "Question 10",
    "text": "Question 10\nA ________________________________ is the smallest unit of text a Large Language Model (LLM) processes, which can be a single character, a whole word, or a part of a word.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ntoken\nExplanation: LLMs operate on tokens, which result from tokenization rules; in English they often correspond to subwords. Token granularity affects sequence length limits and cost/performance tradeoffs."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-11",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-11",
    "title": "Midterm Exam I",
    "section": "Question 11",
    "text": "Question 11\nIn RLHF, ________________________________ is used to incorporate human preferences and guide the model‚Äôs behavior.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na reward\nExplanation: RLHF first trains a reward model using human preference data, such as ranked outputs. The language model is then further adjusted to produce responses that score higher under this reward model, aligning its behavior with human judgments."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-12",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-12",
    "title": "Midterm Exam I",
    "section": "Question 12",
    "text": "Question 12\nIn GPT, ________________________________ encodes the order of words in a sentence.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\npositional encoding\nExplanation: Transformers do not naturally track the order of tokens, so positional encodings inject sequence-order information, allowing the model to distinguish where each token appears and attend to relative relationships properly."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-13",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-13",
    "title": "Midterm Exam I",
    "section": "Question 13",
    "text": "Question 13\nBefore the ________________________________, other language models struggled; the ________________________________ solved these issues by utilizing a(n) ________________________________, which allows the AI to concentrate on the most relevant parts of a text.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ntransformer; transformer; attention mechanism\nExplanation: The transformer architecture uses self-attention instead of step-by-step processing, allowing the model to directly compare all tokens in a sequence at once. By focusing computational weight on the most relevant tokens, it improves both performance and scalability."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-14",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-14",
    "title": "Midterm Exam I",
    "section": "Question 14",
    "text": "Question 14\nYou are working in R and want to use the table1 dataset that is included in the tidyr package. You have not yet loaded tidyr with library(), but you previously loaded the tidyverse package earlier in your session. To ensure that you explicitly use the dataset from tidyr, which command is the most reliable way to access it?\n\ntable1\ntidyverse::table1\ntidyr$table1\ntidyr::table1\nlibrary(tidyr::table1)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation: Using the namespace operator tidyr::table1 accesses the object explicitly from the tidyr package without attaching it. tidyverse::table1 is invalid because tidyverse is a meta-package and does not export table1. tidyr$table1 is not how exported objects are accessed, and library(tidyr::table1) is invalid syntax."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-15",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-15",
    "title": "Midterm Exam I",
    "section": "Question 15",
    "text": "Question 15\nThe comment character in R is _______________________________, and the keyboard shortcut to add or remove a comment in Posit Cloud on a Windows or Mac machine is ______________________________________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n#; Windows: Ctrl+Shift+C, Mac: Cmd+Shift+C\nExplanation: Lines beginning with # are treated as comments in R. In RStudio/Posit Cloud, the toggle-comment shortcut applies or removes # for the current line or selected block on both Windows (Ctrl+Shift+C) and macOS (Cmd+Shift+C)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-16-17",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-16-17",
    "title": "Midterm Exam I",
    "section": "Questions 16-17",
    "text": "Questions 16-17\nConsider the following two vectors, a and b:\n\na &lt;- c(5, 20)\nb &lt;- c(20, 5)\n\n\nQuestion 16\nWhat does a + b return?\n\nc(5, 20, 5)\nc(5, 20, 20, 5)\nc(25, 25, 25, 25)\nc(25, 25, 25)\nc(25, 25)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation: Vector addition in R operates element-wise. So the operation calculates c(5+20, 20+5) = c(25, 25). The result has the same length as the input vectors, and each element is the sum of the corresponding elements from a and b.\n\n\n\n\n\nQuestion 17\nWhat does sqrt( a / b ) return?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc(0.5, 2)\nExplanation: First, R performs element-wise division: a / b, which returns c(5/20, 20/5), which is c(1/4, 4). Then it applies the square root to each element, yielding c(1/2, 2). This demonstrates vectorized operations in R."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-18-19",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-18-19",
    "title": "Midterm Exam I",
    "section": "Questions 18-19",
    "text": "Questions 18-19\nSuppose you create a factor variable, major:\n\nmajor &lt;- as.factor(c(\"ECON\", \"DANL\", \"ECON\", \"MGMT\", \"DANL\"))\n\n\nQuestion 18\nWhat does levels(major) return?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc(\"DANL\", \"ECON\", \"MGMT\")\nExplanation: When converting a character vector to a factor, R extracts unique values and sorts them alphabetically by default. Therefore, the levels are ‚ÄúDANL‚Äù, ‚ÄúECON‚Äù, and ‚ÄúMGMT‚Äù, regardless of the original order in the input.\n\n\n\n\n\nQuestion 19\nWhat does nlevels(major) return?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n3\nExplanation: Since the factor has three unique categories (levels), R returns 3 when calling nlevels(). This function counts the number of unique factor levels, not the number of values."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-20",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-20",
    "title": "Midterm Exam I",
    "section": "Question 20",
    "text": "Question 20\nSuppose the absolute pathname for the CSV file custdata.csv uploaded to your Posit Cloud project is:\n/cloud/project/mydata/custdata.csv\nThe working directory for your Posit Cloud project is:\n/cloud/project\nUsing the file‚Äôs relative pathname, write R code to read the CSV file as a data.frame and assign it to an object named df.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf &lt;- read_csv(\"mydata/custdata.csv\")\n\nExplanation: Since the working directory is /cloud/project, the relative path to the CSV file omits /cloud/project and starts from the next folder level: ‚Äúmydata/custdata.csv‚Äù. R‚Äôs read.csv() reads the file and assigns it to the object df."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-21",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-21",
    "title": "Midterm Exam I",
    "section": "Question 21",
    "text": "Question 21\nConsider the following data.frame df0:\n\n\n\n\n\nx\ny\n\n\n\n\n1\n7\n\n\nNA\n2\n\n\n3\nNA\n\n\n\n\n\nWhat does is.na(df0$x * df0$y) return?\n\nc(FALSE, TRUE, FALSE)\nc(FALSE, FALSE, TRUE)\nc(FALSE, FALSE, FALSE)\nc(FALSE, TRUE, TRUE)\nError\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation: R multiplies element-wise:\n\nRow 1: 1 * 7 = 7 ‚Üí not NA ‚Üí FALSE\nRow 2: NA * 2 = NA ‚Üí TRUE\nRow 3: 3 * NA = NA ‚Üí TRUE\n\nThus, is.na() returns c(FALSE, TRUE, TRUE)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-22-23",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-22-23",
    "title": "Midterm Exam I",
    "section": "Questions 22-23",
    "text": "Questions 22-23\nConsider the following data.frame df for Questions 22-23:\n\n\n\n\n\nid\nname\nage\nscore\n\n\n\n\n1\nAnna\n22\n90\n\n\n2\nBen\n28\n85\n\n\n3\nCarl\nNA\n95\n\n\n4\nDana\n35\nNA\n\n\n5\nElla\n40\n80\n\n\n\n\n\n\nQuestion 22\nWhich of the following code snippets filters observations where score is strictly between 85 and 95 (i.e., excluding 85 and 95)?\n\ndf |&gt; filter(score &gt;= 85 | score &lt;= 95)\ndf |&gt; filter(score =&gt; 85 | score =&lt; 95)\ndf |&gt; filter(score &gt; 85 | score &lt; 95)\ndf |&gt; filter(score &gt; 85 & score &lt; 95)\ndf |&gt; filter(score &gt;= 85 & score &lt;= 95)\ndf |&gt; filter(score =&gt; 85 & score =&lt; 95)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation: Strictly between 85 and 95 means score &gt; 85 and score &lt; 95. The & operator enforces both conditions simultaneously. Option c uses | which would include values less than 85 or greater than 95, and other options misuse syntax or include boundary values.\n\n\n\n\n\nQuestion 23\nWhich of the following expressions correctly keeps observations from df where the age variable does not have any missing values?\n\ndf |&gt; filter(is.na(age))\ndf |&gt; filter(!is.na(age))\ndf |&gt; filter(age == NA)\ndf |&gt; filter(age != NA)\nBoth a and c\nBoth b and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: To filter out missing values, use !is.na(age). Using == NA or != NA does not work for missing values in R because NA represents an unknown and cannot be compared directly."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-2425",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#questions-2425",
    "title": "Midterm Exam I",
    "section": "Questions 24‚Äì25",
    "text": "Questions 24‚Äì25\nConsider the following data.frame flights_df for Questions 24‚Äì25:\n\n\n\n\n\norigin\ndest\ndep_delay\n\n\n\n\nJFK\nLAX\n10\n\n\nLGA\nORD\n45\n\n\nJFK\nLAX\n5\n\n\nEWR\nMIA\n60\n\n\nLGA\nORD\n45\n\n\nEWR\nSEA\n20\n\n\n\n\n\nBelow provides data type of each variable:\n\norigin: character\ndest: character\ndep_delay: numeric\n\n\nQuestion 24\nWhich of the following code snippets arranges the observations first by origin in ascending order, and then by dep_delay in descending order?\n\nflights_df |&gt; arrange(origin, -dep_delay)\nflights_df |&gt; arrange(origin, desc(dep_delay))\nflights_df |&gt; arrange(desc(origin), dep_delay)\nflights_df |&gt; arrange(desc(origin), desc(dep_delay))\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation: Both -dep_delay and desc(dep_delay) sort in descending order. When combined with origin in ascending order (default), both (a) and (b) produce the correct ordering. Options (c) and (d) incorrectly sort origin in descending order."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-25",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-25",
    "title": "Midterm Exam I",
    "section": "Question 25",
    "text": "Question 25\nWhich of the following expressions correctly returns all unique origin‚Äìdestination combinations from flights_df?\n\nflights_df |&gt; distinct(origin, dest)\nflights_df |&gt; select(origin, dest)\nflights_df |&gt; filter(!is.na(origin), !is.na(dest))\nflights_df |&gt; distinct()\nBoth a and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\nExplanation: distinct(origin, dest) returns unique combinations for those two columns explicitly. distinct() with no arguments returns unique observations across all variables, which also gives unique origin‚Äìdest pairs only because each observation is already defined by those two variables. select() only extracts variables and does not remove duplicates."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-26",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-26",
    "title": "Midterm Exam I",
    "section": "Question 26",
    "text": "Question 26\nWhich of the following code snippets correctly renames the variable score in df to exam_score?\n\ndf |&gt; rename(score = exam_score)\n\ndf |&gt; rename(exam_score = score)\n\ndf |&gt; rename(\"exam_score\" = \"score\")\n\ndf |&gt; rename(df, exam_score = score)\n\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne (b or c deserves the full credit)\nExplanation: The correct syntax in rename() is new_name = old_name. Both (b) and (c) follow this correctly. Option (a) reverses the direction, and option (d) introduces unnecessary arguments and incorrect form."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-27",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-27",
    "title": "Midterm Exam I",
    "section": "Question 27",
    "text": "Question 27\nWhich of the following code snippets filters observations where age is 30 or older and score is below 90?\n\ndf |&gt; filter(age &gt;= 30 | score &lt; 90)\n\ndf |&gt; filter(age &gt;= 30 & score &lt; 90)\n\ndf |&gt; filter(age &gt; 30 & score &gt; 90)\n\ndf |&gt; filter(age &gt;= 30, score &lt; 90)\n\nBoth b and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation: To enforce that both conditions must be satisfied simultaneously, use &. Option (a) uses |, which would allow observations where only one condition is met. Option (c) uses the wrong inequality for score. Option (d) is equivalent to option (b)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-28",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-28",
    "title": "Midterm Exam I",
    "section": "Question 28",
    "text": "Question 28\nUsing the nycflights13::flights data.frame, which of the following code snippets correctly counts how many unique destination airports (dest) exist for each origin airport?\na.\n\ndf &lt;- nycflights13::flights |&gt; \n  distinct(origin, dest)\n\ndf_EWR &lt;- df |&gt; filter(origin == \"EWR\")\ndf_JFK &lt;- df |&gt; filter(origin == \"JFK\")\ndf_LGA &lt;- df |&gt; filter(origin == \"LGA\")\n\nnrow(df_EWR)\nnrow(df_JFK)\nnrow(df_LGA)\n\nb.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" | origin == \"JFK\" | origin == \"LGA\") |&gt; \n  distinct(dest)\n\nnrow(df)\n\nc.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" & origin == \"JFK\" & origin == \"LGA\") |&gt; \n  distinct(dest)\n\nnrow(df)\n\nd.\n\ndf &lt;- nycflights13::flights |&gt; \n  distinct(dest)\n\nnrow(df)\n\ne. Both a and b\nf. Both a and c\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\nExplanation: Option (a) correctly first extracts unique (origin, dest) combinations and then counts how many unique dest per each origin. Option (b) mistakenly pools all three origins together before counting distinct destinations, losing the per-origin grouping. Option (c) filters using &, which can never be true for mutually exclusive origins. Option (d) ignores origin entirely."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-29",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-29",
    "title": "Midterm Exam I",
    "section": "Question 29",
    "text": "Question 29\nWhy is the median often preferred over the mean as a measure of central tendency when a dataset contains outliers?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe median is less sensitive to extreme values because it depends only on the middle position in an ordered dataset, not on the magnitude of all values. Outliers can pull the mean sharply in one direction, distorting the central tendency and giving a misleading picture of the ‚Äútypical‚Äù value. In skewed distributions or datasets with extreme highs/lows, the median provides a more robust and representative summary. For this reason, analysts often use the median for income, housing price, or other economic data known to contain large outliers."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-30",
    "href": "danl-ex/danl-101-exam-1-ver-A-fall-2025.html#question-30",
    "title": "Midterm Exam I",
    "section": "Question 30",
    "text": "Question 30\n\nDefine AI Alignment and explain why it is hard, referencing the failure mode of a ‚Äúsingle-objective optimizer.‚Äù\nAnalyze why companies alone and governments alone cannot solve the alignment challenge, citing at least two reasons for each, and explain what is needed for an effective solution.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAI Alignment refers to the challenge of ensuring that powerful AI systems reliably act according to human values, ethical norms, and societal goals. It is difficult because advanced AI systems can optimize objectives in ways that technically satisfy a metric but violate human intent‚Äîthis is the ‚Äúsingle-objective optimizer‚Äù failure mode. When a model pushes one goal to an extreme without broader context or value constraints, it can generate harmful or unintended outcomes even while maximizing its target metric.\nWhy companies alone cannot solve it:\n\nCompanies face pressure to deploy quickly for competitive advantage, which may lead to cutting corners on long-term safety and value alignment.\nCorporate profit incentives do not necessarily align with broader public welfare and ethical standards, especially in global contexts beyond their direct accountability.\n\nWhy governments alone cannot solve it:\n\nGovernments often lack the technical expertise and agility to regulate fast-moving AI developments effectively.\nGlobal AI deployment crosses jurisdictions, and national policies cannot fully enforce alignment across private-sector labs or international competitors without global coordination.\n\nWhat is needed:\nAn effective solution requires collaboration between researchers, companies, governments, and international institutions. This includes shared safety standards, transparent evaluation protocols, incentive structures that reward responsible development, and oversight mechanisms that span beyond national or corporate boundaries."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which platform provides a cloud-based environment for writing and executing Python notebooks without local installation?\n\nRStudio\n\nJupyter Notebook\n\nGoogle Colab\n\nCursor\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation:\nGoogle Colab is a cloud-based platform that allows users to run Python notebooks without local installation.\n\n\n\n\n\n\n\nWhich of the following best defines a dashboard in data analytics?\n\nA statistical model used to predict future business performance\n\nA database that stores large volumes of raw transactional data\n\nA programming language used for building web-based data systems\n\nA visual interface that displays key data, metrics, and trends for quick interpretation and decision-making\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nA dashboard is a visual interface showing key metrics and trends for decision-making.\n\n\n\n\n\n\n\nWhich of the following best describes the goal of unsupervised learning in machine learning?\n\nTo train a model using labeled input‚Äìoutput pairs to predict future outcomes\n\nTo uncover hidden patterns or groupings in data without using predefined labels\n\nTo optimize an agent‚Äôs actions through rewards and penalties over time\n\nTo evaluate the accuracy of supervised models using cross-validation\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation:\nUnsupervised learning uncovers hidden patterns in unlabeled data.\n\n\n\n\n\n\n\nIn sports analytics, a decision tree model is trained to predict whether a football team will run or pass in the next play based on variables like Off_Pers, n_th_Down, and distance_to_next_down.\n\nOff_Pers: Offensive Personnel (e.g., Value ‚Äú11‚Äù meaning 1 running back, 1 tight end, and 3 wide receivers)\n\nWhich statement best describes how this model makes its predictions?\n\nIt averages all input variables to estimate the probability of a run play.\n\nIt groups plays into clusters of similar offensive formations without using the run/pass label.\n\nIt calculates overall win probabilities using a single regression equation combining all predictors linearly.\nIt divides the dataset into branches using threshold-based rules (e.g., ‚Äúif distance_to_next_down &lt; 5 yards‚Äù) to classify outcomes step by step.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nA decision tree makes predictions by splitting data into branches using rule-based thresholds.\n\n\n\n\n\n\n\nWhich of the following statements best reflects the ‚ÄúCo-Intelligence‚Äù principles for effective AI use discussed in class?\n\nAlways let AI handle routine decisions independently to save time and reduce human error.\n\nTreat AI like a sentient collaborator that can verify facts and reason about truth on its own.\n\nAvoid using AI until the technology matures further, since today‚Äôs systems are unreliable and likely to be replaced soon.\n\nUse AI broadly for idea generation and analysis, but always review outputs critically, add human judgment, and document what works.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nCo-Intelligence emphasizes using AI with human oversight, judgment, and reflection.\n\n\n\n\n\n\n\nWhy are descriptive statistics important in data analytics?\n\nThey make raw data more interpretable by summarizing key characteristics such as central tendency and variability.\n\nThey automatically identify causal relationships between independent and dependent variables.\n\nThey are mainly used for visualizing data, not for numerical summaries.\n\nThey replace the need for further inferential or predictive analysis.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\nExplanation:\nDescriptive statistics summarize key features of a dataset, making it easier to interpret.\n\n\n\n\n\n\n\nWhich of the following best defines supervised learning?\n\nAlgorithms that discover hidden patterns in unlabeled data\n\nAlgorithms that optimize decisions by trial and error with rewards\n\nAlgorithms trained using labeled input‚Äìoutput pairs\n\nAlgorithms that cluster observations based on distance metrics\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation:\nSupervised learning uses labeled input‚Äìoutput pairs for training predictive models.\n\n\n\n\n\n\n\nWhich statement most accurately captures why the Transformer architecture revolutionized natural language processing?\n\nIt eliminated the need for large datasets by using manually defined linguistic rules.\n\nIt processes inputs strictly in order, ensuring each token depends on the one immediately before it.\n\nIt encodes position information by sorting words alphabetically before training.\n\nIt replaced sequential token processing with an attention mechanism that models relationships between all words in a sequence in parallel.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nTransformers use attention to model relationships between all words in parallel."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-1",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-1",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which platform provides a cloud-based environment for writing and executing Python notebooks without local installation?\n\nRStudio\n\nJupyter Notebook\n\nGoogle Colab\n\nCursor\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation:\nGoogle Colab is a cloud-based platform that allows users to run Python notebooks without local installation."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-2",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-2",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following best defines a dashboard in data analytics?\n\nA statistical model used to predict future business performance\n\nA database that stores large volumes of raw transactional data\n\nA programming language used for building web-based data systems\n\nA visual interface that displays key data, metrics, and trends for quick interpretation and decision-making\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nA dashboard is a visual interface showing key metrics and trends for decision-making."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-3",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-3",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following best describes the goal of unsupervised learning in machine learning?\n\nTo train a model using labeled input‚Äìoutput pairs to predict future outcomes\n\nTo uncover hidden patterns or groupings in data without using predefined labels\n\nTo optimize an agent‚Äôs actions through rewards and penalties over time\n\nTo evaluate the accuracy of supervised models using cross-validation\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation:\nUnsupervised learning uncovers hidden patterns in unlabeled data."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-4",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-4",
    "title": "Midterm Exam I",
    "section": "",
    "text": "In sports analytics, a decision tree model is trained to predict whether a football team will run or pass in the next play based on variables like Off_Pers, n_th_Down, and distance_to_next_down.\n\nOff_Pers: Offensive Personnel (e.g., Value ‚Äú11‚Äù meaning 1 running back, 1 tight end, and 3 wide receivers)\n\nWhich statement best describes how this model makes its predictions?\n\nIt averages all input variables to estimate the probability of a run play.\n\nIt groups plays into clusters of similar offensive formations without using the run/pass label.\n\nIt calculates overall win probabilities using a single regression equation combining all predictors linearly.\nIt divides the dataset into branches using threshold-based rules (e.g., ‚Äúif distance_to_next_down &lt; 5 yards‚Äù) to classify outcomes step by step.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nA decision tree makes predictions by splitting data into branches using rule-based thresholds."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-5",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-5",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following statements best reflects the ‚ÄúCo-Intelligence‚Äù principles for effective AI use discussed in class?\n\nAlways let AI handle routine decisions independently to save time and reduce human error.\n\nTreat AI like a sentient collaborator that can verify facts and reason about truth on its own.\n\nAvoid using AI until the technology matures further, since today‚Äôs systems are unreliable and likely to be replaced soon.\n\nUse AI broadly for idea generation and analysis, but always review outputs critically, add human judgment, and document what works.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nCo-Intelligence emphasizes using AI with human oversight, judgment, and reflection."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-6",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-6",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Why are descriptive statistics important in data analytics?\n\nThey make raw data more interpretable by summarizing key characteristics such as central tendency and variability.\n\nThey automatically identify causal relationships between independent and dependent variables.\n\nThey are mainly used for visualizing data, not for numerical summaries.\n\nThey replace the need for further inferential or predictive analysis.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\nExplanation:\nDescriptive statistics summarize key features of a dataset, making it easier to interpret."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-7",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-7",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following best defines supervised learning?\n\nAlgorithms that discover hidden patterns in unlabeled data\n\nAlgorithms that optimize decisions by trial and error with rewards\n\nAlgorithms trained using labeled input‚Äìoutput pairs\n\nAlgorithms that cluster observations based on distance metrics\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation:\nSupervised learning uses labeled input‚Äìoutput pairs for training predictive models."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-8",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-8",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which statement most accurately captures why the Transformer architecture revolutionized natural language processing?\n\nIt eliminated the need for large datasets by using manually defined linguistic rules.\n\nIt processes inputs strictly in order, ensuring each token depends on the one immediately before it.\n\nIt encodes position information by sorting words alphabetically before training.\n\nIt replaced sequential token processing with an attention mechanism that models relationships between all words in a sequence in parallel.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nTransformers use attention to model relationships between all words in parallel."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-9",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-9",
    "title": "Midterm Exam I",
    "section": "Question 9",
    "text": "Question 9\nThe class of models that generate images from text prompts by gradually transforming random noise into visual outputs are called ________________________________.\nThe newer family of models that can interpret and generate across text and vision (e.g., describing or creating images) are known as ________________________________ models.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nDiffusion models; Multimodal models\nExplanation:\nDiffusion models generate images by denoising random noise; multimodal models work across text, images, and other modalities."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-10",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-10",
    "title": "Midterm Exam I",
    "section": "Question 10",
    "text": "Question 10\nAn ________________________________ is an AI system that can plan, act, and learn autonomously using external tools and memory, turning a single prompt into a multi-step workflow.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAI agent\nExplanation:\nAI agents execute multi-step tasks autonomously using planning, tools, and memory."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-11",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-11",
    "title": "Midterm Exam I",
    "section": "Question 11",
    "text": "Question 11\nAt large scales, LLMs can display unexpected skills‚Äîsuch as writing code or expressing creativity‚Äîthat were never directly programmed.\nThese are known as ________________________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nEmergent abilities\nExplanation:\nEmergent abilities arise when model scale enables capabilities not explicitly engineered."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-12",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-12",
    "title": "Midterm Exam I",
    "section": "Question 12",
    "text": "Question 12\nWhat does the acronym GPT stand for?\nProvide both meanings covered in lecture:\n1. ________________________________\n2. ________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nGenerative Pre-trained Transformer\n\nGeneral Purpose Technology\n\nExplanation:\n\nGenerative Pre-trained Transformer describes the model architecture and training method: it generates outputs, is pre-trained on large corpora, and uses the transformer architecture.\n\nGeneral Purpose Technology refers to innovations with wide-reaching economic and technological influence, capable of transforming many sectors over time, similar to electricity or the internet."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-13",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-13",
    "title": "Midterm Exam I",
    "section": "Question 13",
    "text": "Question 13\nA neural network consists of interconnected nodes organized into layers.\nThe ________________________________ layer serves as the entry point for data,\nthe ________________________________ layers transform and learn internal representations,\nand the ________________________________ layer produces the final prediction or result.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nInput layer; hidden layers; output layer\nExplanation:\nInput ‚Üí hidden ‚Üí output is the standard neural network architecture."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-14",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-14",
    "title": "Midterm Exam I",
    "section": "Question 14",
    "text": "Question 14\nDuring an R session, a student loads both the dplyr and MASS packages.\nBoth contain a function named select().\nAfter loading both, the student runs select(df, name, score) and gets an unexpected error.\nWhich explanation best describes what likely happened?\n\nThe MASS package disables dplyr automatically when both are loaded.\n\nR randomly chooses between the two functions based on which package was installed most recently.\n\nThe select() function can only be used after attaching the tidyverse metapackage.\n\nThe dplyr version of select() was masked by the MASS version, so R is using the wrong function for data-frame column selection.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nWhen both packages are loaded, the later-loaded select() masks the other, so R may be using the wrong version."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-15",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-15",
    "title": "Midterm Exam I",
    "section": "Question 15",
    "text": "Question 15\nIn R, what is the difference between a parameter and an argument in a function?\n\nA parameter is the actual input value passed into a function, while an argument is the variable name used inside the function.\n\nA parameter is defined in the function‚Äôs declaration, while an argument is the actual value supplied when the function is called.\n\nBoth terms mean the same thing and can be used interchangeably in R.\n\nA parameter refers only to numeric inputs, while arguments refer to text inputs.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation:\nParameters are defined in the function body; arguments are the values provided when calling the function."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-16",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-16",
    "title": "Midterm Exam I",
    "section": "Question 16",
    "text": "Question 16\nUsing the native pipe in R (R ‚â• 4.1), write two equivalent one-liners that return all unique values of a variable named var from a data frame called df.\nAnswer 1: ______________________________________________\nAnswer 2: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer 1: df |&gt; select(var) |&gt; distinct()\nAnswer 2: df |&gt; distinct(var)\nExplanation:\nBoth return the unique values of a variable; one uses select() and distinct(), the other uses only distinct(), which is more efficient."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-17-18",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-17-18",
    "title": "Midterm Exam I",
    "section": "Questions 17-18",
    "text": "Questions 17-18\nConsider the following two vectors, x and y:\n\nx &lt;- c(10, 20, 30, 40, 50)\ny &lt;- c(1, 2, 3, 4, 5)\n\n\nQuestion 17\nWhat does x[ y &gt; 3 ] return?\n\nc(3, 4, 5)\nc(TRUE, TRUE, TRUE, FALSE, FALSE)\nc(10, 20, 30)\nc(40, 50)\nc(30, 40, 50)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nx[y &gt; 3] returns c(40, 50).\n\n\n\n\n\n\nQuestion 18\nWhat does sum( (x * y)[y &lt; 3] ) return?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n50\nExplanation:\n(x*y) = 10,40,90,160,250 and y&lt;3 selects first two ‚Üí 10 + 40 = 50."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-19",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-19",
    "title": "Midterm Exam I",
    "section": "Question 19",
    "text": "Question 19\nThe working directory for your Posit Cloud project is:\n/cloud/project\nSuppose the relative pathname for the CSV file custdata.csv uploaded to your Posit Cloud project is:\n/mydata/custdata.csv\nUsing the file‚Äôs absolute pathname, write R code to read the CSV file as a data.frame with the readr package and assign it to an object named df_customers.\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ndf_customers &lt;- readr::read_csv(\"/cloud/project/mydata/custdata.csv\")\nExplanation:\nUses absolute path for Posit Cloud."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-2021",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-2021",
    "title": "Midterm Exam I",
    "section": "Questions 20‚Äì21",
    "text": "Questions 20‚Äì21\nConsider the following two vectors, submitted_1 and submitted_2:\n\nsubmitted_1 &lt;- c(TRUE, FALSE, NA, TRUE, NA, FALSE, TRUE)\nsubmitted_2 &lt;- c(TRUE, FALSE, TRUE, FALSE, TRUE)\n\n\nQuestion 20\nWhat does sum(!is.na(submitted_1)) return?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n5\nExplanation:\nThere are five non-NA values.\n\n\n\n\n\n\nQuestion 21\nWhat does sum(as.numeric(submitted_2)) return?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n3\nExplanation:\nTRUE=1, FALSE=0 ‚Üí sum=3."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-2224",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-2224",
    "title": "Midterm Exam I",
    "section": "Questions 22‚Äì24",
    "text": "Questions 22‚Äì24\nConsider the following data.frame students for Questions 22‚Äì24:\n\n\n\n\n\nsid\nname\ncredits\ngpa\n\n\n\n\n101\nAva\n12\n3.2\n\n\n102\nBlake\n15\n2.9\n\n\n103\nAva\nNA\n3.8\n\n\n104\nDiego\n18\nNA\n\n\n105\nEli\n9\n3.5\n\n\n\n\n\n\nQuestion 22\nWhich code filters observations where gpa is strictly between 3.0 and 3.7 (including 3.0 and 3.7)?\n\nstudents |&gt; filter(gpa &gt;= 3.0 | gpa &lt;= 3.7)\nstudents |&gt; filter(gpa &gt; 3.0 & gpa &lt; 3.7)\nstudents |&gt; filter(gpa &gt; 3.0 | gpa &lt; 3.7)\nstudents |&gt; filter(gpa &gt;= 3.0 & gpa &lt;= 3.7)\nstudents |&gt; filter(gpa =&gt; 3.0 & gpa =&lt; 3.7)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation:\nThe correct range-inclusive filter is gpa &gt;= 3.0 & gpa &lt;= 3.7.\n\n\n\n\n\n\nQuestion 23\nWhich expression keeps only observations where credits is not missing or name is ‚ÄúAva‚Äù?\n\nstudents |&gt; filter(credits == NA & name == \"Ava\")\nstudents |&gt; filter(credits == NA | name == \"Ava\")\nstudents |&gt; filter(credits != NA & name == \"Ava\")\nstudents |&gt; filter(credits != NA | name == \"Ava\")\nstudents |&gt; filter(is.na(credits) & name == \"Ava\")\nstudents |&gt; filter(is.na(credits) | name == \"Ava\")\nstudents |&gt; filter(!is.na(credits) & name == \"Ava\")\nstudents |&gt; filter(!is.na(credits) | name == \"Ava\")\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\nExplanation:\nKeep rows where credits is NOT NA or name == ‚ÄúAva‚Äù.\n\n\n\n\n\n\nQuestion 24\nWhich code keeps only the name and gpa variables?\n\nstudents |&gt; select(name, gpa)\nstudents |&gt; select(-sid, -credits)\nstudents |&gt; select(\"name\", -\"credits\")\nstudents |&gt; select(students, name, gpa)\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation:\n\nOption a selects name and gpa directly.\n\nOption b removes sid and credits, leaving only name and gpa.\nThus, both are correct."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-2526",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#questions-2526",
    "title": "Midterm Exam I",
    "section": "Questions 25‚Äì26",
    "text": "Questions 25‚Äì26\nConsider the following data.frame sales_df for Questions 25‚Äì26:\n\n\n\n\n\nRegion\nProduct\nRevenue\n\n\n\n\nEast\nA100\n250\n\n\nWest\nB200\n400\n\n\nEast\nA100\n250\n\n\nSouth\nC300\n300\n\n\nWest\nA100\n200\n\n\nSouth\nB200\n300\n\n\n\n\n\nBelow provides data type of each variable:\n\nRegion: character\nProduct: character\nRevenue: numeric\n\n\nQuestion 25\nWhich of the following code snippets arranges the observations first by Region alphabetically, then by Revenue in descending order?\n\nsales_df |&gt; arrange(Region, Revenue)\nsales_df |&gt; arrange(Region, -Revenue)\nsales_df |&gt; arrange(Region, desc(Revenue))\nsales_df |&gt; arrange(desc(Region), desc(Revenue))\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation:\n\nOption b uses -Revenue, which sorts Revenue in descending order.\n\nOption c uses desc(Revenue), which also sorts Revenue in descending order.\nSince both arrange alphabetically by Region first and then sort Revenue from highest to lowest, both are correct.\n\n\n\n\n\n\n\nQuestion 26\nWhich code correctly returns all unique Region‚ÄìProduct‚ÄìRevenue combinations?\n\nsales_df |&gt; distinct(Region, Product)\nsales_df |&gt; select(-Product, -Region)\nsales_df |&gt; distinct()\nsales_df |&gt; select(-Product, -Region) |&gt; distinct()\nBoth a and c\nBoth a and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation:\ndistinct() alone returns all unique combinations of all columns."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-27",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-27",
    "title": "Midterm Exam I",
    "section": "Question 27",
    "text": "Question 27\nConsider the following data.frame orders:\n\n\n\n\n\nid\ncust\ntotal\n\n\n\n\n1\nA\n120\n\n\n2\nB\nNA\n\n\n3\nA\n50\n\n\n4\nC\n200\n\n\n5\nB\n120\n\n\n6\nA\nNA\n\n\n\n\n\nBelow provides data type of each variable:\n\nid: numeric\ncust: character\ntotal: numeric\n\nWhich code snippet correctly replicates the subset of orders as shown below:\n\n\n\n\n\nid\ncust\ntotal\n\n\n\n\n4\nC\n200\n\n\n5\nB\n120\n\n\n1\nA\n120\n\n\n\n\n\na.\norders |&gt; \n  filter(total &gt;= 120 | is.na(total)) |&gt; \n  arrange(total, cust)\nb.\norders |&gt; \n  filter(!is.na(total) & total &gt;= 120 ) |&gt; \n  arrange(-total, desc(cust))\nc.\norders |&gt; \n  filter(total &gt;= 120 & is.na(total)) |&gt; \n  arrange(total, desc(cust))\nd.\norders |&gt; \n  filter(!is.na(total) & total &gt; 120 ) |&gt; \n  arrange(desc(total), cust)\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation:\nThe correct subset uses !is.na(total) and total &gt;= 120, then arranges by -total and desc(cust). Option b matches exactly."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-28",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-28",
    "title": "Midterm Exam I",
    "section": "Question 28",
    "text": "Question 28\nUsing the nycflights13::flights data.frame, which of the following code snippets correctly counts how many distinct airlines (carrier) operate from each origin airport? Select all that apply.\nBelow provides values in the carrier variable:\n\n\n\n\n\ncarrier\n\n\n\n\nUA\n\n\nAA\n\n\nB6\n\n\nDL\n\n\nEV\n\n\nMQ\n\n\nUS\n\n\nWN\n\n\nVX\n\n\nFL\n\n\nAS\n\n\n9E\n\n\nF9\n\n\nHA\n\n\nYV\n\n\nOO\n\n\n\n\n\na.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" & origin == \"JFK\" & origin == \"LGA\") |&gt; \n  distinct(carrier)\n\nnrow(df)\n\nb.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" | origin == \"JFK\" | origin == \"LGA\") |&gt; \n  distinct(carrier)\n\nnrow(df)\n\nc.\n\ndf &lt;- nycflights13::flights\n\ndf_EWR &lt;- df |&gt; filter(origin == \"EWR\")\ndf_JFK &lt;- df |&gt; filter(origin == \"JFK\")\ndf_LGA &lt;- df |&gt; filter(origin == \"LGA\")\n\nnrow(df_EWR)\nnrow(df_JFK)\nnrow(df_LGA)\n\nd.\n\ndf &lt;- nycflights13::flights |&gt; \n  distinct(origin, carrier)\n\ndf_EWR &lt;- df |&gt; filter(origin == \"EWR\")\ndf_JFK &lt;- df |&gt; filter(origin == \"JFK\")\ndf_LGA &lt;- df |&gt; filter(origin == \"LGA\")\n\nnrow(df_EWR)\nnrow(df_JFK)\nnrow(df_LGA)\n\ne.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" | origin == \"JFK\" | origin == \"LGA\") |&gt; \n  distinct(carrier)\n\nnrow(df)\n\nf.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" | origin == \"JFK\" | origin == \"LGA\") |&gt; \n  distinct(origin, carrier)\n\nnrow(df)\n\ng.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" & origin == \"JFK\" & origin == \"LGA\") |&gt; \n  distinct(origin, carrier)\n\nnrow(df)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd, f\nExplanation:\nTo count distinct carriers per origin, you need distinct (origin, carrier) pairs.\n\nOption d does this correctly by first generating distinct pairs, then filtering per origin.\n\nOption f also works because it filters origins first, then keeps distinct (origin, carrier) combinations.\n\nThe others are incorrect due to incorrect logic (AND instead of OR) or counting carriers pooled together across origins rather than separately."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-29",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-29",
    "title": "Midterm Exam I",
    "section": "Question 29",
    "text": "Question 29\nWhat is the interquartile range (IQR)? What is the standard deviation (SD)? Explain why the IQR is often preferred over the SD when summarizing the dispersion of a dataset that contains outliers.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nIQR vs SD\nInterquartile Range (IQR):\nThe IQR is the range between the 25th percentile (Q1) and the 75th percentile (Q3). It measures the spread of the middle 50% of the data.\nStandard Deviation (SD):\nThe SD measures the average distance of each data point from the mean. It reflects overall variability, including extreme values.\nWhy IQR is preferred with outliers:\n\nSD is sensitive to outliers because squaring deviations magnifies extreme values.\n\nIQR is robust‚Äîit ignores the lowest 25% and highest 25% of data, making it less influenced by extreme or skewed values.\n\nFor skewed distributions or datasets with outliers, IQR provides a more stable summary of spread."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-30",
    "href": "danl-ex/danl-101-exam-1-ver-C-fall-2025.html#question-30",
    "title": "Midterm Exam I",
    "section": "Question 30",
    "text": "Question 30\nExplain the following concepts in the context of Large Language Models (LLMs):\n\nWhat is pre-training and what is its main purpose?\n\nWhat is fine-tuning and how does it differ from pre-training?\n\nHow can bias arise in an LLM‚Äôs output, and what methods can be used to reduce it?\n\nWhat are some ethical or legal concerns associated with the pre-training and fine-tuning processes?\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nPre-training:\n\nThe model is trained on very large datasets (such as text from websites, books, and code repositories).\n\nPurpose: to learn general patterns of language, including structure, grammar, and relationships between words and concepts.\n\nThe goal is to build a broad foundation of capabilities.\n\n\nFine-tuning:\n\nThe model is further trained using a smaller, focused dataset designed for a specific domain or task.\n\nPurpose: refine the model‚Äôs behavior for targeted applications (e.g., summarization, safety alignment, medical or legal tasks) and address issues such as bias, harmful outputs, or inappropriate responses from pre-training.\n\nDifference from pre-training: pre-training is broad, while fine-tuning is narrower and guided, allowing the model to better align with desired performance, norms, or safety standards.\n\nHow bias arises:\n\nTraining data may reflect cultural, demographic, or ideological imbalances.\n\nLLMs can learn stereotypes, misinformation, or harmful associations.\n\nUser prompts may trigger biased patterns learned from data.\n\nMethods to reduce bias\n\nData filtering and dataset curation: This involves carefully selecting, cleaning, and filtering training data to remove harmful, misleading, or unbalanced patterns before they influence the model.\n\nReinforcement Learning from Human Feedback (RLHF): Human evaluators guide model behavior by rating outputs, helping the system learn responses that are safer, more helpful, and less biased.\n\nSafety alignment training: Additional training phases are used to refine the model toward safer and more responsible behavior, reducing harmful or biased outputs.\n\nBias audits, evaluations, and dataset diversification: Regular assessments help identify problematic behaviors, while diversifying input data reduces overrepresentation or underrepresentation of groups.\n\nConstitutional or rule-based fine-tuning: Models are optimized using predefined rules or principles that promote fairness, safety, and neutrality, helping reduce harmful or biased tendencies.\n\nEthical and legal concerns\n\nCopyright and data ownership issues: Large datasets may include copyrighted material, raising questions about legal rights and appropriate usage.\n\nExposure to toxic or harmful content: Pre-training may include offensive or harmful data, which can influence model outputs if not mitigated.\n\nPrivacy risks from scraped data: Training data may inadvertently contain personal or sensitive information, creating potential privacy and confidentiality concerns.\n\nPropagation of biases and unequal representation: Models can reinforce biases present in the data, leading to unfair or distorted outputs that disadvantage certain groups.\n\nPotential misuse of generated content: Generative systems can enable creation of misleading or harmful content such as deepfakes or misinformation, leading to ethical risks and societal harm."
  },
  {
    "objectID": "listing-danl-101-lec.html",
    "href": "listing-danl-101-lec.html",
    "title": "DANL 101 - Lecture",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nLecture 1\n\n\nSyllabus and Course Outline\n\n\nAugust 25, 2025\n\n\n\n\nLecture 2\n\n\nIntroduction to Data Analytics and Its Tools\n\n\nAugust 27, 2025\n\n\n\n\nLecture 3\n\n\nSports Analytics; Business Intelligence\n\n\nSeptember 3, 2025\n\n\n\n\nLecture 4\n\n\nGenerative AI\n\n\nSeptember 5, 2025\n\n\n\n\nLecture 5\n\n\nR Basics and Descriptive Statistics\n\n\nSeptember 17, 2025\n\n\n\n\nLecture 6\n\n\nData Transformation with R\n\n\nSeptember 29, 2025\n\n\n\n\nLecture 7\n\n\nBig Data and the Modern Data Infrastructure\n\n\nOctober 15, 2025\n\n\n\n\nLecture 8\n\n\nCareer Pathways in Data Analytics and Beyond\n\n\nOctober 24, 2025\n\n\n\n\nLecture 9\n\n\nData Visualization\n\n\nNovember 3, 2025\n\n\n\n\nLecture 10\n\n\nData Visualization with ggplot\n\n\nNovember 5, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-wk/wk-09.html",
    "href": "danl-wk/wk-09.html",
    "title": "Week 9",
    "section": "",
    "text": "In Week 9, we will cover the taxonomy of structured data, databases, and big data. We will also have an Alumni Career Session. You are encouraged to ask about getting started in data roles, workplace experiences, and any valuable advice from professionals who were once in your position."
  },
  {
    "objectID": "danl-wk/wk-09.html#lecture-slides",
    "href": "danl-wk/wk-09.html#lecture-slides",
    "title": "Week 9",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 7 ‚Äî Big Data and the Modern Data Infrastructure\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-09.html#classwork",
    "href": "danl-wk/wk-09.html#classwork",
    "title": "Week 9",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\n\nClasswork 7 - Taxonomy of Data\nView Classwork\nClasswork 8 - Databases - Social Media Analytics\nView Classwork\nClasswork 9 - Joining Two Related Tables in R\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-09.html#discussion",
    "href": "danl-wk/wk-09.html#discussion",
    "title": "Week 9",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 9 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 9.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 9 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-04.html",
    "href": "danl-wk/wk-04.html",
    "title": "Week 4",
    "section": "",
    "text": "In Week 4, we will finish our discussion of generative AI and then begin exploring the basics of R programming."
  },
  {
    "objectID": "danl-wk/wk-04.html#lecture-slides",
    "href": "danl-wk/wk-04.html#lecture-slides",
    "title": "Week 4",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 4 ‚Äî Generative Artificial Intelligence\nView Slides\nLecture 5 ‚Äî R Basics\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-04.html#classwork",
    "href": "danl-wk/wk-04.html#classwork",
    "title": "Week 4",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\n\nClasswork 2 - Vibe Coding\nView Classwork\nClasswork 3 - Co-Intelligence Rules\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-04.html#recommended-reading",
    "href": "danl-wk/wk-04.html#recommended-reading",
    "title": "Week 4",
    "section": "üìö Recommended Reading",
    "text": "üìö Recommended Reading\n\nMollick, Ethan. Co-Intelligence: Living and Working with AI, Penguin Publishing Group, 2024.\n\nRead: Introduction, Chapter 1, and Chapter 2\n\nTynes, Natasha. Ethan Mollick‚Äôs 4 Guiding Principles for Leading with AI, Big Think, December 4, 2024."
  },
  {
    "objectID": "danl-wk/wk-04.html#discussion",
    "href": "danl-wk/wk-04.html#discussion",
    "title": "Week 4",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 4 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 4.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 4 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-11.html",
    "href": "danl-wk/wk-11.html",
    "title": "Week 11",
    "section": "",
    "text": "In Week 11, we‚Äôll finish the topics in Big Data and the Modern Data Infrastructure. We‚Äôll then move onto the new topics, Data Storytelling and Visualization."
  },
  {
    "objectID": "danl-wk/wk-11.html#lecture-slides",
    "href": "danl-wk/wk-11.html#lecture-slides",
    "title": "Week 11",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 9 ‚Äî Data Visualization\nView Slides\n\nLecture 10 ‚Äî Data Visualization with ggplot\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-11.html#data-storytelling",
    "href": "danl-wk/wk-11.html#data-storytelling",
    "title": "Week 11",
    "section": "Ô∏èüìäüí° Data Storytelling",
    "text": "Ô∏èüìäüí° Data Storytelling\n\n‚ÄúThe narrative is the key vehicle to convey insights, and the visualizations are important proof points to back up the narrative.‚Äù Ryan Fuller, Corporate Vice President, M365 Data Strategy at Microsoft\n\n\nData visualizations are useful for showing ‚Äúwhat‚Äù is happening in the data.\n\nHowever, they often fall short in explaining the ‚Äúwhy‚Äù and the ‚Äúhow‚Äù or providing the necessary context to uncover underlying reasons.\n\n\n\n\n\nData Storytelling: Bridge the gap between data and insight by integrating descriptive statistics, data transformation, visualization, and narration within the appropriate audience context to communicate findings effectively and support data-informed decision-making.\n\n\n\n\n\n\n\n\n\nData Storytelling - Context\n\n\n\n\n\n\n\nContext - Who, What, and How\n\nBefore creating a data visualization or communication, it‚Äôs essential to spend time understanding the context behind your message.\n\n\nWho is your audience?\nWhat do you want your audience to understand or act upon?\nHow will you present the data to effectively support your point?\n\n\n\nContext - Who\n\nTo whom are you communicating?\n\n\nGain a clear understanding of whom you‚Äôre communicating with and how they perceive you.\n\nThe more precisely you define your audience, the better you can tailor your message for successful communication.\n\n\n\n\nContext - What\n\nWhat do you need your audience to know or do?\n\nMake your communication relevant by aligning it with your audience‚Äôs interests and needs.\nClearly articulate why they should care about your message.\nAdopt a confident stance; as the analyst, you are the subject matter expert.\n\n\n\n\nContext - How\n\nHow would you present your data to help make your point?\n\nUse data as compelling evidence to build and tell your story.\n\n\n\nChoose data transformations and visualizations that effectively convey your message.\n\n\n\n\nData Storytelling - Data\n\n\n\n\n\n\n\nUnderstanding Your Data\n\nPrior to doing any storytelling or analysis, it is critical to understand your data and its limitations\n\nHow was the information collected?\nWhat is the source of the data?\nWhat is missing variable from the data?\nWhat is missing observation from the data?\nWhat is missing value (NA) from the data?\n\n\n\n\n\n\n\nData Storytelling - Narrative\n\n\n\n\n\n\n\nThe Foundations of a Narrative\n\nThe 3-Minute Story & Big Idea\n\n‚ÄúI would have written a shorter letter, but I did not have the time.‚Äù - Blaise Pascal\n\n\nPurpose: Boil the ‚Äúso-what‚Äù down to a concise statement\nChallenges: Being concise is often more difficult than being verbose\n\n\n\n\n3-Minute Story\n\nIf you had only 3 minutes, what would you say?\nGoal: Be clear and articulate the key message\nUseful in:\n\nQuick updates (e.g., elevator pitches)\nShortened time slots (e.g., 5-minute briefings)\n\nKnow exactly what to communicate and adjust to the time\n\n\n\nBig Idea\n\nMust meet three criteria:\n\nArticulate your unique point of view\nConvey what‚Äôs at stake\nBe a complete sentence\n\n\n\n\nThe Foundations of a Narrative - Example\n\n3-Minute Story\n\nScience department initiative: Resolve issues with incoming 4th-graders‚Äô negative attitudes toward science\nPiloted a summer learning program with 2nd and 3rd-graders\nSurvey results: Significant improvement in positive perceptions toward science\n\nBig Idea\n\n‚ÄúThe pilot summer learning program was successful at improving students‚Äô perceptions of science, and we recommend continuing and expanding it.‚Äù"
  },
  {
    "objectID": "danl-wk/wk-11.html#discussion",
    "href": "danl-wk/wk-11.html#discussion",
    "title": "Week 11",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 11 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 11.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 11 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-13.html",
    "href": "danl-wk/wk-13.html",
    "title": "Week 13",
    "section": "",
    "text": "In Week 13, we‚Äôll continue to discuss various topics in Data Visualization with ggplot. We will then have the Midterm Exam II."
  },
  {
    "objectID": "danl-wk/wk-13.html#lecture-slides",
    "href": "danl-wk/wk-13.html#lecture-slides",
    "title": "Week 13",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 10 ‚Äî Data Visualization with ggplot\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-13.html#classwork",
    "href": "danl-wk/wk-13.html#classwork",
    "title": "Week 13",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\n\nClasswork 14 - Distribution Plots and Counting\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-13.html#discussion",
    "href": "danl-wk/wk-13.html#discussion",
    "title": "Week 13",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 13 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 13.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 13 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-06.html",
    "href": "danl-wk/wk-06.html",
    "title": "Week 6",
    "section": "",
    "text": "In Week 6, we‚Äôll practice working with data frames and transforming data using R‚Äôs tidyverse tools."
  },
  {
    "objectID": "danl-wk/wk-06.html#lecture-slides",
    "href": "danl-wk/wk-06.html#lecture-slides",
    "title": "Week 6",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 6 ‚Äî Data Transformation with R\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-06.html#classwork",
    "href": "danl-wk/wk-06.html#classwork",
    "title": "Week 6",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\n\nClasswork 6 - Data Transformation with R\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-06.html#reference",
    "href": "danl-wk/wk-06.html#reference",
    "title": "Week 6",
    "section": "üìö Reference",
    "text": "üìö Reference\n\nWickham et. al., Chapter 3. Data transformation in R for Data Science (2e)"
  },
  {
    "objectID": "danl-wk/wk-06.html#discussion",
    "href": "danl-wk/wk-06.html#discussion",
    "title": "Week 6",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 6 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 6.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 6 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-03.html",
    "href": "danl-wk/wk-03.html",
    "title": "Week 3",
    "section": "",
    "text": "In Week 3, we will go over concepts related with generative AI and discuss the book Co-Intelligence (Introduction‚ÄìChapter 2)."
  },
  {
    "objectID": "danl-wk/wk-03.html#lecture-slides",
    "href": "danl-wk/wk-03.html#lecture-slides",
    "title": "Week 3",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 4 ‚Äî Generative Artificial Intelligence\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace.\n\nUseful Keyboard Shortcuts for Lecture Slides\n\nCTRL + Shift + F: Search\nM: Toggle menu\nE: PDF export/printing mode"
  },
  {
    "objectID": "danl-wk/wk-03.html#classwork",
    "href": "danl-wk/wk-03.html#classwork",
    "title": "Week 3",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\nüöß Classwork 1 invites you to explore where we draw the line between assistance and authorship when using generative AI tools. üöß"
  },
  {
    "objectID": "danl-wk/wk-03.html#recommended-reading",
    "href": "danl-wk/wk-03.html#recommended-reading",
    "title": "Week 3",
    "section": "üìö Recommended Reading",
    "text": "üìö Recommended Reading\n\nMollick, Ethan. Co-Intelligence: Living and Working with AI, Penguin Publishing Group, 2024.\n\nRead: Introduction, Chapter 1, and Chapter 2\n\n\n\n\nTransformers\nTransformers are a type of neural network architecture that transforms or changes an input sequence into an output sequence. They do this by learning context and tracking relationships between sequence components. For example, consider this input sequence: ‚ÄúWhat is the color of the sky?‚Äù The transformer model uses an internal mathematical representation that identifies the relevancy and relationship between the words color, sky, and blue. It uses that knowledge to generate the output: ‚ÄúThe sky is blue.‚Äù\n\nHow do transformers work?\nNeural networks have been the leading method in various AI tasks such as image recognition and natural language processing (NLP) since the early 2000s. They consist of layers of interconnected computing nodes, or neurons, that mimic the human brain and work together to solve complex problems.\nTraditional neural networks that deal with data sequences often use an encoder/decoder architecture pattern. The encoder reads and processes the entire input data sequence, such as an English sentence, and transforms it into a compact mathematical representation. This representation is a summary that captures the essence of the input. Then, the decoder takes this summary and, step by step, generates the output sequence, which could be the same sentence translated into French.\nThis process happens sequentially, which means that it has to process each word or part of the data one after the other. The process is slow and can lose some finer details over long distances.\n\n\nAttention mechanism\nTransformer models modify this process by incorporating something called a attention mechanism. Instead of processing data in order, the mechanism enables the model to look at different parts of the sequence all at once and determine which parts are most important.\nImagine that you‚Äôre in a busy room and trying to listen to someone talk. Your brain automatically focuses on their voice while tuning out less important noises. Attention enables the model do something similar: it pays more attention to the relevant bits of information and combines them to make better output predictions. This mechanism makes transformers more efficient, enabling them to be trained on larger datasets. It‚Äôs also more effective, especially when dealing with long pieces of text where context from far back might influence the meaning of what‚Äôs coming next.\n\n\nReference\n\nAWS - What are Transformers in Artificial Intelligence? \n\n‚ö†Ô∏è Note: These excerpts from the above article are shared under fair use for educational purposes to support your learning.\n\n\n\nGPT\nGenerative Pre-trained Transformers, commonly known as GPT, are a family of neural network models that uses the transformer architecture and is a key advancement in artificial intelligence (AI) powering generative AI applications such as ChatGPT. GPT models give applications the ability to create human-like text and content (images, music, and more), and answer questions in a conversational manner. Organizations across industries are using GPT models and generative AI for Q&A bots, text summarization, content generation, and search.\n\nHow does GPT work?\nThe GPT models are transformer neural networks. The transformer neural network architecture uses attention mechanisms to focus on different parts of the input text during each processing step. A transformer model captures more context and improves performance on natural language processing (NLP) tasks. It has two main modules, which we explain next.\n\nEncoder\n\nBefore a transformer can make sense of language, words must be turned into numbers. This is done with embeddings, which are long lists of numbers that capture meaning. Words with similar meanings, like sea and ocean, end up with embeddings that look alike, while very different words like cat are far apart. In real models, these vectors often have hundreds of numbers, not just a few. For example, if you only described a fruit with three traits such as color, size, and sweetness, you would get a rough idea. But if you described it with 300 traits such as texture, smell, taste, and shape, you would have a much richer description. That is why embeddings need so many numbers. But meaning alone is not enough. Transformers read all words in parallel, so they also need positional encoding to know order. Without it, the sentences ‚ÄúThe cat chased the dog‚Äù and ‚ÄúThe dog chased the cat‚Äù would look the same. Positional encoding is like giving each word a seat number in a row so the model knows where the word sits in the sentence.\nOnce words have both meaning from embeddings and order from positional encoding, the attention mechanism can actually do its job: deciding which words matter most to each other in context. Without embeddings, the model would just see words as IDs with no sense of meaning. Without positional encoding, it would treat the words as if they were a bag of tokens, with no sense of order. Together, embeddings and positions give attention the raw material it needs to calculate relationships. For example, in the question ‚ÄúWhat is the color of the sea?‚Äù, the token color should pay strong attention to sea, not to what. This process creates context-aware representations, where every word is updated to reflect its role in the sentence. That is why the model can then generate the correct answer ‚ÄúThe sea is blue.‚Äù For example, think of listening to someone in a noisy room. Your ears (embeddings) tell you what the sounds mean, and your sense of direction (positional encoding) tells you where they are coming from. Only then can your focus (attention) tune in to the important voice and ignore the rest. In the same way, embeddings give meaning, positional encoding gives order, and attention ties them together so the transformer can make sense of language.\n\n\nDecoder\nThe decoder produces the output one token at a time. With attention, it focuses on the most relevant parts of what it has already seen. At each step, it scores many possible next tokens and chooses the most likely one, repeating this process until the answer is complete.\n\n\n\nHow was GPT-3 trained?\nIn a published research paper, researchers described generative pretraining as the ability to train language models with unlabeled data and achieve accurate prediction. The first GPT model, GPT-1, was developed in 2018. GPT-4 was introduced in March 2023 as a successor to GPT-3.\nGPT-3 was trained with over 175 billion parameters or weights. Engineers trained it on over 45 terabytes of data from sources like web texts, Common Crawl, books, and Wikipedia. Prior to training, the average quality of the datasets was improved as the model matured from version 1 to version 3.\nGPT-3 trained in a semi-supervised mode. First, machine learning engineers fed the deep learning model with the unlabeled training data. GPT-3 would understand the sentences, break them down, and reconstruct them into new sentences. In unsupervised training, GPT-3 attempted to produce accurate and realistic results by itself. Then, machine learning engineers would fine-tune the results in supervised training, a process known as reinforcement learning with human feedback (RLHF).\nYou can use the GPT models without any further training, or you can customize them with a few examples for a particular task.\n\n\nReference\n\nAWS - What is GPT\n\n‚ö†Ô∏è Note: These excerpts from the above article are shared under fair use for educational purposes to support your learning.\n\n\n\nRLHF\nReinforcement learning from human feedback (RLHF) is a machine learning (ML) technique that uses human feedback to optimize ML models to self-learn more efficiently. Reinforcement learning (RL) techniques train software to make decisions that maximize rewards, making their outcomes more accurate. RLHF incorporates human feedback in the rewards function, so the ML model can perform tasks more aligned with human goals, wants, and needs. RLHF is used throughout generative artificial intelligence (generative AI) applications, including in large language models (LLM).\n\nWhy is RLHF important?\nThe applications of artificial intelligence (AI) are broad-ranging, from self-driving cars to natural language processing (NLP), stock market predictors, and retail personalization services. No matter the given application, the goal of AI is ultimately to mimic human responses, behaviors, and decision-making. The ML model must encode human input as training data so that the AI mimics humans more closely when completing complex tasks.\nRLHF is a specific technique that is used in training AI systems to appear more human, alongside other techniques such as supervised and unsupervised learning. First, the model‚Äôs responses are compared to the responses of a human. Then a human assesses the quality of different responses from the machine, scoring which responses sound more human. The score can be based on innately human qualities, such as friendliness, the right degree of contextualization, and mood.\nRLHF is prominent in natural language understanding, but it‚Äôs also used across other generative AI applications.\n\nEnhances AI performance\nRLHF makes the ML model more accurate. Models can be trained on pregenerated human data, but having additional human feedback loops significantly enhances model performance compared to its initial state.\nFor example, when text is translated from one language to another, a model might produce text that‚Äôs technically correct but sounds unnatural to the reader. A professional translator can first perform the translation, with the machine-generated translation scored against it, and then a series of machine-generated translations can be scored for quality. The addition of further training to the model makes it better at producing natural-sounding translations.\n\n\nIntroduces complex training parameters\nIn some instances in generative AI, it can be difficult to accurately train the model for certain parameters. For example, how do you define the mood of a piece of music? There might be technical parameters such as key and tempo that indicate a certain mood, but a musical piece‚Äôs spirit is more subjective and less well defined than just a series of technicalities. Instead, you can provide human guidance where composers create moody pieces, and then you can label machine-generated pieces according to their level of moodiness. This enables a machine to learn these parameters much more quickly.\n\n\nEnhances user satisfaction\nAlthough an ML model can be accurate, it might not appear human. RL is needed to guide the model toward the best, most engaging response for human users.\nFor example, if you asked a chatbot what the weather is like outside, it might respond, ‚ÄúIt‚Äôs 30 degrees Celsius with clouds and high humidity,‚Äù or it might respond, ‚ÄúThe temperature is around 30 degrees at the moment. It‚Äôs cloudy out and humid, so the air might seem thicker!‚Äù Although both responses say the same thing, the second response sounds more natural and provides more context.\nAs human users rate which model responses they prefer, you can use RLHF for collecting human feedback and improving your model to best serve real people.\n\n\n\nReference\n\nAWS - What is RLHF?\n\n‚ö†Ô∏è Note: These excerpts from the above article are shared under fair use for educational purposes to support your learning."
  },
  {
    "objectID": "danl-wk/wk-03.html#discussion",
    "href": "danl-wk/wk-03.html#discussion",
    "title": "Week 3",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 3 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 3\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 3 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-01.html",
    "href": "danl-wk/wk-01.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to DANL 101, the first step in your data analytics journey! üëã\nIn this first week, we will explore what you can expect to learn in this course and review the logistics, including the structure of lectures, classes, and assessments, as well as how we will interact throughout the semester. This week also sets the stage for what is ahead by introducing key tools and foundational concepts in data analytics."
  },
  {
    "objectID": "danl-wk/wk-01.html#syllabus",
    "href": "danl-wk/wk-01.html#syllabus",
    "title": "Week 1",
    "section": "üìì Syllabus",
    "text": "üìì Syllabus\n\nPlease read the syllabus."
  },
  {
    "objectID": "danl-wk/wk-01.html#lecture-slides",
    "href": "danl-wk/wk-01.html#lecture-slides",
    "title": "Week 1",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 1 ‚Äî Syllabus\nView Slides\nLecture 2 ‚Äî DANL Tools and Machine Learning\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-01.html#recommended-reading",
    "href": "danl-wk/wk-01.html#recommended-reading",
    "title": "Week 1",
    "section": "üìö Recommended Reading",
    "text": "üìö Recommended Reading\n\nMachine Learning\n\nWhat is Machine Learning?\nMachine learning is a type of artificial intelligence that performs data analysis tasks without explicit instructions. Machine learning technology can process large quantities of historical data, identify patterns, and predict new relationships between previously unknown data. You can perform classification and prediction tasks on documents, images, numbers, and other data types.\nFor example, a financial organization could train a machine learning system to classify fraudulent and genuine transactions. The system identifies patterns in known data to accurately guess or predict whether a new transaction is genuine.\n\n\nHow does machine learning work?\nThe central idea behind machine learning is an existing mathematical relationship between any input and output data combination. The machine learning model does not know this relationship in advance but can guess if sufficient examples of input-output data sets are given. This means every machine learning algorithm is built around a modifiable math function. The underlying principle can be understood like this:\nWe ‚Äòtrain‚Äô the algorithm by giving it the following input/output (i,o) combinations ‚Äì (2,10), (5,19), and (9,31)\nThe algorithm computes the relationship between input and output to be: o=3*i+4\nWe then give it input 7 and ask it to predict the output. It can automatically determine the output as 25.\nWhile this is a basic understanding, machine learning focuses on the principle that computer systems can mathematically link all complex data points as long as they have sufficient data and computing power to process. Therefore, the accuracy of the output is directly co-relational to the magnitude of the input given. Machine learning phases are given below.\n\n\nWhat are the benefits of machine learning?\nData is the critical driving force behind business decision-making. Modern organizations generate data from thousands of sources, including smart sensors, customer portals, social media, and application logs. Machine learning automates and optimizes the process of data collection, classification, and analysis. Businesses can drive growth, unlock new revenue streams, and solve challenging problems faster.\nBenefits of machine learning include:\n\nEnhanced decision making\n\nMachine learning systems can process and analyze massive data volumes quickly and accurately. They can identify unforeseen patterns in dynamic and complex data in real time. Organizations can make data-driven decisions at runtime and respond more effectively to changing conditions. They can optimize operations and mitigate risks with confidence.\n\nAutomation of routine tasks\n\nMachine learning algorithms can filter, sort, and classify data without human intervention. They can summarize reports, scan documents, transcribe audio, and tag content‚Äîtasks that are tedious and time-consuming for humans to perform. Automating routine and repetitive tasks leads to substantial productivity gains and cost reductions. You also get improved accuracy and efficiency.\n\nImproved customer experiences\n\nMachine learning transforms customer experiences through personalization. For example, retailers recommend products to customers based on previous purchases, browsing history, and search patterns. Streaming services customize viewing recommendations in the entertainment industry. The personalized approach increases customer retention and brand loyalty.\n\nProactive resource management\n\nOrganizations use machine learning to forecast trends and behaviors with high precision. For example, predictive analytics can anticipate inventory needs and optimize stock levels to reduce overhead costs. Predictive insights are crucial for planning and resource allocation, making organizations more proactive rather than reactive.\n\nContinuous improvement\n\nA distinctive advantage of machine learning is its ability to improve as it processes more data. Machine learning systems adapt and learn from new data. They adjust and enhance their performance to remain practical and relevant over time.\n\n\nReference\n\nAWS - What is Machine Learning?\n\n‚ö†Ô∏è Note: These excerpts from the above article are shared under fair use for educational purposes to support your learning."
  },
  {
    "objectID": "danl-wk/wk-01.html#discussion",
    "href": "danl-wk/wk-01.html#discussion",
    "title": "Week 1",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 1 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 1.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 1 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DANL 101: Introduction to Data Analytics, Fall 2025",
    "section": "",
    "text": "Welcome! üëã\n\\(-\\) Explore, Learn, and Grow with Data Analytics! üåü"
  },
  {
    "objectID": "index.html#lecture",
    "href": "index.html#lecture",
    "title": "DANL 101: Introduction to Data Analytics, Fall 2025",
    "section": "üöÄ Lecture",
    "text": "üöÄ Lecture\n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nLecture 1\n\n\nSyllabus and Course Outline\n\n\nAugust 25, 2025\n\n\n\n\nLecture 2\n\n\nIntroduction to Data Analytics and Its Tools\n\n\nAugust 27, 2025\n\n\n\n\nLecture 3\n\n\nSports Analytics; Business Intelligence\n\n\nSeptember 3, 2025\n\n\n\n\nLecture 4\n\n\nGenerative AI\n\n\nSeptember 5, 2025\n\n\n\n\nLecture 5\n\n\nR Basics and Descriptive Statistics\n\n\nSeptember 17, 2025\n\n\n\n\nLecture 6\n\n\nData Transformation with R\n\n\nSeptember 29, 2025\n\n\n\n\nLecture 7\n\n\nBig Data and the Modern Data Infrastructure\n\n\nOctober 15, 2025\n\n\n\n\nLecture 8\n\n\nCareer Pathways in Data Analytics and Beyond\n\n\nOctober 24, 2025\n\n\n\n\nLecture 9\n\n\nData Visualization\n\n\nNovember 3, 2025\n\n\n\n\nLecture 10\n\n\nData Visualization with ggplot\n\n\nNovember 5, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#classwork",
    "href": "index.html#classwork",
    "title": "DANL 101: Introduction to Data Analytics, Fall 2025",
    "section": "‚å®Ô∏è Classwork",
    "text": "‚å®Ô∏è Classwork\n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nClasswork 1\n\n\nDrawing the Line: AI Assistance vs.¬†Authorship\n\n\nSeptember 8, 2025\n\n\n\n\nClasswork 2\n\n\nVibe Coding\n\n\nSeptember 10, 2025\n\n\n\n\nClasswork 3\n\n\nCo-Intelligence Rule Practice\n\n\nSeptember 15, 2025\n\n\n\n\nClasswork 4\n\n\nR Basics I\n\n\nSeptember 22, 2025\n\n\n\n\nClasswork 5\n\n\nR Basics II\n\n\nSeptember 26, 2025\n\n\n\n\nClasswork 6\n\n\nData Transformation with R\n\n\nOctober 1, 2025\n\n\n\n\nClasswork 7\n\n\nTaxonomy of Data\n\n\nOctober 17, 2025\n\n\n\n\nClasswork 8\n\n\nDatabases - Social Media Analytics\n\n\nOctober 20, 2025\n\n\n\n\nClasswork 9\n\n\nETL Process in R\n\n\nOctober 29, 2025\n\n\n\n\nClasswork 10\n\n\nCareer Sessions\n\n\nOctober 31, 2025\n\n\n\n\nClasswork 11\n\n\nRelationship Plots\n\n\nNovember 7, 2025\n\n\n\n\nClasswork 12\n\n\nColor vs.¬†Facet\n\n\nNovember 10, 2025\n\n\n\n\nClasswork 13\n\n\nTime Trend Plots\n\n\nNovember 12, 2025\n\n\n\n\nClasswork 14\n\n\nDistribution Plots and Counting\n\n\nNovember 17, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#homework",
    "href": "index.html#homework",
    "title": "DANL 101: Introduction to Data Analytics, Fall 2025",
    "section": "üíª Homework",
    "text": "üíª Homework\n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework 1\n\n\nIntroduction to Data Analytics; Generative AI; R Basics\n\n\nSeptember 13, 2025\n\n\n\n\nHomework 2\n\n\nGenerative AI; Data Transformation with R\n\n\nSeptember 25, 2025\n\n\n\n\nHomework 3\n\n\nData Transformation & Visualization in R ‚Äî Part I\n\n\nNovember 4, 2025\n\n\n\n\nHomework 4\n\n\nData Transformation & Visualization in R ‚Äî Part II\n\n\nNovember 20, 2025\n\n\n\n\nHomework 5\n\n\nGenerative AI for Data Analysis\n\n\nDecember 2, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "listing-danl-101-wk.html",
    "href": "listing-danl-101-wk.html",
    "title": "Weeks",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-01.html",
    "href": "danl-hw-q/danl-101-hw-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 1, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\nGenerative AI Allowed with Conditions: You may use generative AI tools for the R Basics section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer section: Draft your responses in Word or Google Docs first before pasting your answers.\nR Basics section: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated.\nDeadline: Friday, September 29, 2025 at 11:59 P.M. Eastern Time."
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-01.html#homework-instructions",
    "href": "danl-hw-q/danl-101-hw-01.html#homework-instructions",
    "title": "Homework 1",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 1, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\nGenerative AI Allowed with Conditions: You may use generative AI tools for the R Basics section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer section: Draft your responses in Word or Google Docs first before pasting your answers.\nR Basics section: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated.\nDeadline: Friday, September 29, 2025 at 11:59 P.M. Eastern Time."
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-02.html",
    "href": "danl-hw-q/danl-101-hw-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 2, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\n\nGenerative AI Allowed with Conditions: You may use generative AI tools for the Data Transformation with R section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer: Draft your responses in Word or Google Docs first before pasting your answers.\nData Transformation with R: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated.\nDeadline: Monday, October 6, 2025 at 11:59 P.M. Eastern Time."
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-02.html#homework-instructions",
    "href": "danl-hw-q/danl-101-hw-02.html#homework-instructions",
    "title": "Homework 2",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 2, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\n\nGenerative AI Allowed with Conditions: You may use generative AI tools for the Data Transformation with R section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer: Draft your responses in Word or Google Docs first before pasting your answers.\nData Transformation with R: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated.\nDeadline: Monday, October 6, 2025 at 11:59 P.M. Eastern Time."
  },
  {
    "objectID": "danl-cw/danl-101-cw-09.html#part-a",
    "href": "danl-cw/danl-101-cw-09.html#part-a",
    "title": "Classwork 9",
    "section": "Part A",
    "text": "Part A\nWrite an R code to create a data frame named df_joined that combines the three datasets ‚Äî df_survey, df_platform, and df_card ‚Äî using the left_join() function."
  },
  {
    "objectID": "danl-cw/danl-101-cw-09.html#part-b",
    "href": "danl-cw/danl-101-cw-09.html#part-b",
    "title": "Classwork 9",
    "section": "Part B",
    "text": "Part B\nFind out which platforms DANL 101 students use.\n\n\n\n\n\n\ncount(): Counting Occurrences of Each Category in a Categorical Variable\n\n\n\n\n\nDATA.FRAME |&gt; count(CATERIGOCAL_VARIABLE)\n\n\nThe data transformation function count() calculates the frequency of each unique value in a categorical variable.\n\n\nlibrary(nycflights13)\nflights |&gt; count(origin)\n\n\n\n\n\n\n\n\n\nflights |&gt; count(origin) returns the data.frame with the two variables, origin and n:\n\nn: the number of occurrences of each unique value in the origin variable in the flights data.frame"
  },
  {
    "objectID": "danl-cw/danl-101-cw-09.html#part-c",
    "href": "danl-cw/danl-101-cw-09.html#part-c",
    "title": "Classwork 9",
    "section": "Part C",
    "text": "Part C\nCount how many students use each platform, and determine which platform is the most popular based on the number of users.\n\nCheck out the new data transformation function: count():"
  },
  {
    "objectID": "danl-cw/danl-101-cw-09.html#part-d",
    "href": "danl-cw/danl-101-cw-09.html#part-d",
    "title": "Classwork 9",
    "section": "Part D",
    "text": "Part D\nCalculate descriptive statistics (e.g., mean, standard deviation, and quartiles) of daily_time_min for each platform by using the skimr::skim() function."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html",
    "href": "danl-cw/danl-101-cw-03.html",
    "title": "Classwork 3",
    "section": "",
    "text": "Ask an AI tool to generate three possible titles for a student newsletter about ‚ÄúAI and College Life‚Äù (covering study tips, career opportunities, and ethical concerns).\nAs a group, compare the three titles and choose the best.\nDiscussion Questions:\n1. Which title is the most engaging and memorable?\n2. Which one best captures the range of topics?\n3. How would you combine or tweak the titles to make an even better one?"
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#see-also",
    "href": "danl-cw/danl-101-cw-03.html#see-also",
    "title": "Classwork 3",
    "section": "See also",
    "text": "See also\nCheck out OpenAI‚Äôs ‚Äú100 Chats for College Students‚Äù ‚Äî a student-made guide to learning strategies, study habits, career exploration, wellness, and day-to-day problem-solving."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#framing-when-and-how-to-pair-humans-with-genai",
    "href": "danl-cw/danl-101-cw-03.html#framing-when-and-how-to-pair-humans-with-genai",
    "title": "Classwork 3",
    "section": "Framing: When and how to pair humans with GenAI",
    "text": "Framing: When and how to pair humans with GenAI\n\n\n\nExhibit 1 ‚Äì When and How to Pair Humans and GenAI\n\n\nUp/down = how strong the human is on a task. Left/right = how strong the AI is on that task.\nWhat it means for you.\n\nTop-right (use AI confidently): You + AI are strong ‚Üí you go faster and keep quality high (great for drafting, refactoring, and summarizing work you already understand).\nTop-left (don‚Äôt over-rely): You‚Äôre strong, AI is weak ‚Üí trust your own method; use AI for small ideas, not final answers.\nBottom-right (supervise + learn): AI is strong, you‚Äôre new ‚Üí AI can expand your capabilities today, but you must check its work and learn the basics.\nBottom-left (learn first): Neither is strong ‚Üí start with a mini-lesson, example, or office hours before delegating to AI.\n\n\nAs access to AI tools grows‚Äîthrough free versions, student-friendly platforms, and training programs offered by schools or employers‚Äîmore students will find themselves in the bottom-right quadrant of the human‚ÄìAI map. In this position, the AI is strong at a task, while the human is still developing skills. This means AI can help you perform at a higher level earlier than you could on your own, letting you complete assignments, projects, or coding tasks that might otherwise feel out of reach. But this shortcut also comes with a trap: you might lean too heavily on AI without actually understanding what‚Äôs happening.\nYour responsibility is to move up the human-skill axis, which means turning AI-assisted performance into genuine knowledge and ability. That requires doing the hard work of learning‚Äîchecking outputs manually, practicing problem-solving without AI, and reflecting on why a solution works. In other words, use AI as a springboard to support your growth, while also making sure you understand the underlying concepts yourself. The real value comes from combining AI-assisted performance with your own learning. As you continue to practice and reflect, you‚Äôll gradually build the kind of durable expertise that helps on exams, in internships, and later in your career."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#which-human-skills-are-hardest-for-ai-to-replace",
    "href": "danl-cw/danl-101-cw-03.html#which-human-skills-are-hardest-for-ai-to-replace",
    "title": "Classwork 3",
    "section": "1) Which human skills are hardest for AI to replace?",
    "text": "1) Which human skills are hardest for AI to replace?\nAI can sound right while being wrong. That is why your role is not to accept outputs at face value but to notice missing assumptions, wrong units, shaky causal stories, and conclusions that don‚Äôt fit the real-world context. The best way to build this filter is to deepen yourself in at least one domain this semester‚Äîdata analytics, economics, finance, marketing, accounting, or another field you care about. As your domain knowledge grows, your prompts get sharper, your checks get stronger, and your conversations with AI become more productive.\nHumans also excel at problem-finding and framing. AI follows instructions; it rarely chooses the right question. Practice translating vague goals like ‚Äúmake a dashboard‚Äù into precise, checkable tasks such as ‚Äútrack weekly active users and cohort retention, then write a three-line narrative with drivers and caveats.‚Äù That skill of turning fog into a plan is a durable career advantage.\nCreativity is another human edge. AI is excellent at variations and remixing patterns, but original direction‚Äîchoosing the audience, message, and the unexpected connection across fields‚Äîstill comes from people. Use AI to explore possibilities, then you decide what actually matters and why.\nFinally, context, teamwork, judgment, and ethics remain stubbornly human. Reading the room, negotiating with classmates, persuading a client, balancing fairness and privacy, and taking responsibility for outcomes are hard to mechanize. AI can optimize, but humans choose values. You are accountable for the recommendation you make and the impact it has."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#what-the-evidence-says-about-capability-expansion",
    "href": "danl-cw/danl-101-cw-03.html#what-the-evidence-says-about-capability-expansion",
    "title": "Classwork 3",
    "section": "2) What the evidence says about capability expansion",
    "text": "2) What the evidence says about capability expansion\n\n\n\nExhibit 2 ‚Äì GenAI Significantly Improved Performance in Three Data-Science Tasks\n\n\nThe figure compares people working without AI to those working with AI on tasks that were outside their comfort zones, with 100% set to the performance of professional data scientists. The headline result is that AI can immediately boost a beginner‚Äôs performance on structured tasks. In coding and data cleaning, for example, AI-augmented beginners reached roughly 86% of expert level, whereas those without AI hovered around the mid-30s. Translated into student life, this means you can merge messy datasets, fix obvious anomalies, and surface top customers or categories far faster‚Äîif you still sanity-check edge cases and data types.\nThe gains are more modest on fuzzier tasks like predictive analytics, especially when students paste the entire assignment into a single prompt. The groups who did best decomposed the work into steps (train/test split, features, baseline, metric), asked the model for intermediate artifacts, and verified them. A similar pattern shows up in statistical interpretation: when students requested pieces like residual plots or confusion matrices and inspected them, their results moved closer to expert practice. The practical reading is simple: AI can help you perform like a stronger student today, but performance is not the same as learning. Real understanding still requires practice, reflection, and feedback.\nThis matters for careers as well. If employers start recognizing AI fluency‚Äîthrough projects, portfolios, and practical certifications‚Äîyou will need to show both that you can deliver results with AI and that you understand what the results mean. Being able to explain choices, defend assumptions, and spot failure modes will separate candidates who merely use AI from those who can be trusted with it."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#how-to-prepare-for-a-world-where-ai-does-many-technical-tasks-better-than-people",
    "href": "danl-cw/danl-101-cw-03.html#how-to-prepare-for-a-world-where-ai-does-many-technical-tasks-better-than-people",
    "title": "Classwork 3",
    "section": "3) How to prepare for a world where AI does many technical tasks better than people",
    "text": "3) How to prepare for a world where AI does many technical tasks better than people\nBegin shifting from doing to directing. Expect AI to draft code, summarize readings, and generate baseline analyses. Your value moves upstream: define the goal, clarify constraints, set acceptance tests, and make the final call. Before you prompt, write a short spec that states the objective, the audience and data limits, and the conditions under which you will accept the result. Treat the model as a fast assistant inside a process you control.\nAdopt the engineering mindset even if you never become a software engineer. Break big problems into small, testable steps; ask for intermediate artifacts you can check (schemas, sample rows, metrics); and only then assemble the final answer. Make verification routine rather than an afterthought: compare against a simple baseline, run a quick stress test or counterexample, ensure units and magnitudes make sense, and note sources and data lineage. Consistent, lightweight QA beats last-minute fixes.\nProtect your intuition with manual mode. For your courses, make it a habit to work manually on purpose: push through problem sets on your own, draft essays from scratch, and code starting with a blank file. These efforts build the mental models you‚Äôll need for exams, interviews, and real-world projects. Many instructors grade the reasoning process, and some assignments are explicitly no-AI. Honor those rules and use them to get stronger.\nFinally, invest in learning agility and communication. Build a simple ‚Äúlearning stack‚Äù that might include one short tutorial, one article or paper, one conversation with a tutor or professor, and a one-page reflection. Track how quickly you can go from ‚Äúdon‚Äôt know‚Äù to ‚Äúbasic demo,‚Äù and aim to shorten that time over the semester. As AI multiplies outputs, synthesis and storytelling decide impact, so practice turning your work into a clear five-sentence brief: problem, method, result, limitation, and next step. This is the habit that will make you valuable in group projects now‚Äîand in internships soon."
  },
  {
    "objectID": "danl-cw/danl-101-cw-03.html#references",
    "href": "danl-cw/danl-101-cw-03.html#references",
    "title": "Classwork 3",
    "section": "References",
    "text": "References\n\nSack et al., ‚ÄúGenAI Doesn‚Äôt Just Increase Productivity. It Expands Capabilities.‚Äù Boston Consulting Group, 2024.\n\nSimo, F., ‚ÄúExpanding economic opportunity with AI.‚Äù OpenAI, September 4, 2025."
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html",
    "href": "danl-cw/danl-101-cw-14.html",
    "title": "Classwork 14",
    "section": "",
    "text": "For Classwork 14, please load the following R packages and create the data.frame nycflights13::flights:\n\n# install.packages(\"ggthemes\")\nlibrary(ggthemes)\nlibrary(tidyverse)\n\nflights &lt;- nycflights13::flights"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-a.-histograms",
    "href": "danl-cw/danl-101-cw-14.html#part-a.-histograms",
    "title": "Classwork 14",
    "section": "Part A. Histograms",
    "text": "Part A. Histograms\n\n\n\n\n\n\nggplot(data = flights,\n       mapping = aes(__BLANK_1__)) +\n  geom___BLANK_2__(__BLANK_3__ = 50,\n                   __BLANK_4__ = \"lightblue\") +\n  facet_wrap(__BLANK_5__)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-b.-boxplots",
    "href": "danl-cw/danl-101-cw-14.html#part-b.-boxplots",
    "title": "Classwork 14",
    "section": "Part B. Boxplots",
    "text": "Part B. Boxplots\n\n\n\n\n\n\nggplot(data = flights,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__,\n                     __BLANK_3__,\n                     )) +\n  geom___BLANK_4__(show.legend = FALSE)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-a.-bar-charts",
    "href": "danl-cw/danl-101-cw-14.html#part-a.-bar-charts",
    "title": "Classwork 14",
    "section": "Part A. Bar Charts",
    "text": "Part A. Bar Charts\n\n\n\n\n\n\nggplot(data = top3_carriers,\n       mapping = aes(__BLANK_1__,\n                     fill = __BLANK_2__)) +\n  geom___BLANK_3__(show.legend = FALSE)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-b.-proportion-bar-charts",
    "href": "danl-cw/danl-101-cw-14.html#part-b.-proportion-bar-charts",
    "title": "Classwork 14",
    "section": "Part B. Proportion Bar Charts",
    "text": "Part B. Proportion Bar Charts\n\n\n\n\n\n\nggplot(data = top3_carriers,\n       mapping = aes(__BLANK_1__,\n                     x = __BLANK_2__,\n                     __BLANK_3__ = 1)) +\n  geom___BLANK_4__(show.legend = FALSE)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-a.-stacked-bar-charts",
    "href": "danl-cw/danl-101-cw-14.html#part-a.-stacked-bar-charts",
    "title": "Classwork 14",
    "section": "Part A. Stacked Bar Charts",
    "text": "Part A. Stacked Bar Charts\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(y = __BLANK_2__,\n                     __BLANK_3__)) +\n  geom_bar()"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-b.-100-stacked-bar-charts",
    "href": "danl-cw/danl-101-cw-14.html#part-b.-100-stacked-bar-charts",
    "title": "Classwork 14",
    "section": "Part B. 100% Stacked Bar Charts",
    "text": "Part B. 100% Stacked Bar Charts\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(y = __BLANK_2__,\n                     __BLANK_3__)) +\n  geom_bar(position = __BLANK_4__) +\n  labs(x = \"Proportion\") # label x-axis title"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-c.-clustered-bar-charts",
    "href": "danl-cw/danl-101-cw-14.html#part-c.-clustered-bar-charts",
    "title": "Classwork 14",
    "section": "Part C. Clustered Bar Charts",
    "text": "Part C. Clustered Bar Charts\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(y = __BLANK_2__,\n                     __BLANK_3__)) +\n  geom_bar(position = __BLANK_4__)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-14.html#part-d.-facetted-bar-charts",
    "href": "danl-cw/danl-101-cw-14.html#part-d.-facetted-bar-charts",
    "title": "Classwork 14",
    "section": "Part D. Facetted Bar Charts",
    "text": "Part D. Facetted Bar Charts\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(y = __BLANK_2__,\n                     __BLANK_3__)) +\n  geom_bar(show.legend = FALSE) +\n  facet_wrap(__BLANK_4__)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-11.html",
    "href": "danl-cw/danl-101-cw-11.html",
    "title": "Classwork 11",
    "section": "",
    "text": "For Classwork 11, please load the tidyverse package:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-11.html#part-a",
    "href": "danl-cw/danl-101-cw-11.html#part-a",
    "title": "Classwork 11",
    "section": "Part A",
    "text": "Part A\n\nü§ñ Task 1: Fill in the blanks in the provided ggplot() code chunk.\n\nüí¨ Task 2: Add a brief comment describing the relationship between ice cream sales (IceCreamSales) and shark attacks (SharkAttacks).\n\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(x = __BLANK_2__,\n                     y = __BLANK_3__)) +\n  geom___BLANK_4__() +\n  geom___BLANK_5__()"
  },
  {
    "objectID": "danl-cw/danl-101-cw-11.html#part-b",
    "href": "danl-cw/danl-101-cw-11.html#part-b",
    "title": "Classwork 11",
    "section": "Part B",
    "text": "Part B\n\n\n\n\n\n\n\n‚ùì Is the observed relationship one of correlation or causation? Explain your reasoning.\n\nConsider the following monthly trends for IceCreamSales and SharkAttacks:\n\n\nMonthly Trend of IceCreamSales\n\n\n\n\n\n\nMonthly Trend of SharkAttacks"
  },
  {
    "objectID": "danl-cw/danl-101-cw-11.html#tasks",
    "href": "danl-cw/danl-101-cw-11.html#tasks",
    "title": "Classwork 11",
    "section": "Tasks",
    "text": "Tasks\nSince GRP reflects how many people watch a show and PE reflects how engaged or attentive those viewers are, it‚Äôs reasonable to expect some connection between the two ‚Äî shows that reach more people may also have higher engagement, although not always.\nOur goal is to see whether greater viewership tends to coincide with stronger engagement (and how this varies by genre in Classwork 12).\n\nü§ñ Task 1: Fill in the blanks in the provided ggplot() code chunks.\n\nüí¨ Task 2: Add a brief comment describing the relationship between GRP and PE.\n\n\n(1) Scatterplot with a Non-Linear Fitted Line\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(x = __BLANK_2__,\n                     y = __BLANK_3__)) +\n  geom_point() +\n  geom___BLANK_4__()\n\n\n\n\n(2) Scatterplot with a Linear Fitted Line\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(x = __BLANK_2__,\n                     y = __BLANK_3__)) +\n  geom_point() +\n  geom___BLANK_4__(method = __BLANK_5__)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-11.html#tasks-1",
    "href": "danl-cw/danl-101-cw-11.html#tasks-1",
    "title": "Classwork 11",
    "section": "Tasks",
    "text": "Tasks\n\nü§ñ Task 1: Fill in the blanks in the provided ggplot() code chunks.\n\nüí¨ Task 2: Add a brief comment describing the relationship between GDP per capita (gdpPercap) and life expectancy (lifeExp).\n\n\n(1) gdpPercap vs.¬†lifeExp\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(x = __BLANK_2__,\n                     y = __BLANK_3__)) +\n  geom_point(__BLANK_4__ = .1) + # Add transparency to reduce overplotting\n  geom_smooth(__BLANK_5__ = \"darkorange\") +\n  geom_smooth(__BLANK_6__)\n\n\n\n\n\n\n\n(2) log(gdpPercap) vs.¬†lifeExp\n\n\n\n\n\n\nggplot(data = __BLANK_1__,\n       mapping = aes(x = __BLANK_2__,\n                     y = __BLANK_3__)) +\n  geom_point(__BLANK_4__ = .2) + # Add transparency to reduce overplotting\n  geom_smooth(__BLANK_5__ = \"darkorange\") +\n  geom_smooth(__BLANK_6__)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html",
    "href": "danl-cw/danl-101-cw-04.html",
    "title": "Classwork 4",
    "section": "",
    "text": "In R, the object state.name is available without loading any additional packages.\n\nWrite R code to assign state.name to a new variable called US_states.\n\n\n\n\nExample: calling state.name in R\n\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-1.",
    "href": "danl-cw/danl-101-cw-04.html#question-1.",
    "title": "Classwork 4",
    "section": "",
    "text": "In R, the object state.name is available without loading any additional packages.\n\nWrite R code to assign state.name to a new variable called US_states.\n\n\n\n\nExample: calling state.name in R\n\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-2.",
    "href": "danl-cw/danl-101-cw-04.html#question-2.",
    "title": "Classwork 4",
    "section": "Question 2.",
    "text": "Question 2.\nWrite an R code to create a numeric vector named numbers containing the integers from 10 to 50.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-3.",
    "href": "danl-cw/danl-101-cw-04.html#question-3.",
    "title": "Classwork 4",
    "section": "Question 3.",
    "text": "Question 3.\nThe temp_F vector contains the average high temperatures in January for the following cities: Seoul, Lagos, Paris, Rio de Janeiro, San Juan, and Rochester.\n\ntemp_F &lt;- c(35, 88, 42, 84, 81, 30)\n\nCreate a new vector named temp_C that stores the converted Celsius temperatures. Below is the conversion formula:\n\\[\nC = \\frac{5}{9}\\times(F - 32)\n\\]\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-4.",
    "href": "danl-cw/danl-101-cw-04.html#question-4.",
    "title": "Classwork 4",
    "section": "Question 4.",
    "text": "Question 4.\nWrite an R code to assign the string ‚ÄúHello, World!‚Äù to a variable named greeting and display its value on the Console.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-5.",
    "href": "danl-cw/danl-101-cw-04.html#question-5.",
    "title": "Classwork 4",
    "section": "Question 5.",
    "text": "Question 5.\nWrite an R code to convert the character vector char_vec &lt;- c(\"1\", \"2\", \"3\", \"4\") into a numeric vector named num_vec.\n\nchar_vec &lt;- c(\"1\", \"2\", \"3\", \"4\")\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-04.html#question-6.",
    "href": "danl-cw/danl-101-cw-04.html#question-6.",
    "title": "Classwork 4",
    "section": "Question 6.",
    "text": "Question 6.\n\nWrite an R code to concatenate two character vectors, first_names &lt;- c(\"John\", \"Jane\") and last_names &lt;- c(\"Doe\", \"Smith\"), to create a vector full_names containing the full names (e.g., ‚ÄúJohn Doe‚Äù, ‚ÄúJane Smith‚Äù) using the str_c() function for vectorized character operations.\n\nNote that the str_c() function is provided by the stringr package, which is one of the packages in the tidyverse.\n\n\n\nfirst_names &lt;- c(\"John\", \"Jane\")\nlast_names &lt;- c(\"Doe\", \"Smith\")\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html",
    "href": "danl-cw/danl-101-cw-06.html",
    "title": "Classwork 6",
    "section": "",
    "text": "For Part 1, consider the nycflights13::flights data.frame.\n\nlibrary(tidyverse)\nlibrary(nycflights13)\nflights &lt;- flights\n\n\n\n\n\n  \n\n\n\nFor detailed descriptions of the variables in this data frame, load its help documentation using the following command:\n\n# Documentation for the `flights` data.frame from the `nycflights13` package\n?flights   # displays the description of variables in the `flights` data.frame\n\n\n\n\nFind all flights that had an arrival delay of two or more hours.\nFind all flights that flew to Houston (IAH or HOU).\nFind all flights that departed in summer (July, August, and September).\nFind all flights that arrived more than two hours late, but did not leave late.\n\nAnswer:\n\n\n\n\n\nHow many flights have a missing dep_time?\n\nAnswer:\n\n\n\n\n\nSort flights to find the most delayed flights.\n\nAnswer:\n\n\n\n\n\nWas there a flight on every day of 2013?\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-1",
    "href": "danl-cw/danl-101-cw-06.html#question-1",
    "title": "Classwork 6",
    "section": "",
    "text": "Find all flights that had an arrival delay of two or more hours.\nFind all flights that flew to Houston (IAH or HOU).\nFind all flights that departed in summer (July, August, and September).\nFind all flights that arrived more than two hours late, but did not leave late.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-2",
    "href": "danl-cw/danl-101-cw-06.html#question-2",
    "title": "Classwork 6",
    "section": "",
    "text": "How many flights have a missing dep_time?\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-3",
    "href": "danl-cw/danl-101-cw-06.html#question-3",
    "title": "Classwork 6",
    "section": "",
    "text": "Sort flights to find the most delayed flights.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-4",
    "href": "danl-cw/danl-101-cw-06.html#question-4",
    "title": "Classwork 6",
    "section": "",
    "text": "Was there a flight on every day of 2013?\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-1-1",
    "href": "danl-cw/danl-101-cw-06.html#question-1-1",
    "title": "Classwork 6",
    "section": "Question 1",
    "text": "Question 1\nCreate a new data.frame, df that keeps only the following five variables‚ÄîFiscal_Year, Agency_Name, First_Name, Last_Name, and Base_Salary‚Äîfrom the data.frame nyc_payroll_new.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-2-1",
    "href": "danl-cw/danl-101-cw-06.html#question-2-1",
    "title": "Classwork 6",
    "section": "Question 2",
    "text": "Question 2\nGiven the data.frame df with a variable named Agency_Name, how would you rename it to Agency?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-06.html#question-3-1",
    "href": "danl-cw/danl-101-cw-06.html#question-3-1",
    "title": "Classwork 6",
    "section": "Question 3",
    "text": "Question 3\nHow would you remove the Fiscal_Year variable using select()?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-13.html",
    "href": "danl-cw/danl-101-cw-13.html",
    "title": "Classwork 13",
    "section": "",
    "text": "For Classwork 13, please load the tidyverse package:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-13.html#part-a",
    "href": "danl-cw/danl-101-cw-13.html#part-a",
    "title": "Classwork 13",
    "section": "Part A",
    "text": "Part A\n\nü§ñ Task 1: Fill in the blanks in the provided ggplot() code chunks.\n\n\nVisualization 1\n\nSomething has gone wrong in this given plot. What happened?\n\n\n\n\n\n\n\nggplot(data = df_gapminder,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__)) +\n  geom_point(size = .5) +\n  geom___BLANK_3__()\n\n\n\n\n\n\nVisualization 2\n\n\n\n\n\n\n\n\nggplot(data = df_gapminder,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__,\n                     __BLANK_3__ = country)) +\n  geom_point(size = .5,\n             color = \"black\") +\n  geom___BLANK_4__()\n\n\n\n\nVisualization 3\n\n\n\n\n\n\nggplot(data = df_gapminder,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__,\n                     __BLANK_3__ = country)) +\n  geom_point(size = .5,\n             color = \"black\") +\n  geom___BLANK_4__(show.legend = FALSE)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-13.html#part-b",
    "href": "danl-cw/danl-101-cw-13.html#part-b",
    "title": "Classwork 13",
    "section": "Part B",
    "text": "Part B\n\nü§ñ Task 1: Fill in the blanks in the provided ggplot() code chunk.\n\nüí¨ Task 2: Add a brief comment describing how the overall time trend of GDP per capita (gdpPercap) varies by continent (continent).\n\n\n\nVisualization 1\n\n\n\n\n\n\nggplot(data = df_gapminder,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__,\n                     __BLANK_3__ = country)) +\n  geom_point(size = .5,\n             color = \"black\") +\n  geom___BLANK_4__(show.legend = FALSE) +\n  facet___BLANK_5__( ~ __BLANK_6__)\n\n\n\n\nVisualization 2\n\nBecause we have only five continents it might be worth seeing if we can fit them on a single row (which means we‚Äôll have five columns).\n\n\n\n\n\n\n\nggplot(data = df_gapminder,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__,\n                     __BLANK_3__ = country)) +\n  geom_point(size = .5,\n             color = \"black\") +\n  geom___BLANK_4__(show.legend = FALSE) +\n  facet___BLANK_5__( ~ __BLANK_6__, \n             __BLANK_7__ = 1)\n\n\n\n\nVisualization 3\n\nSince GDP per capita is highly skewed, let‚Äôs take a log transformation on it:\n\n\n\n\n\n\n\nggplot(data = df_gapminder,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__,\n                     __BLANK_3__ = country)) +\n  geom_point(size = .5,\n             color = \"black\") +\n  geom___BLANK_4__(show.legend = FALSE) +\n  facet___BLANK_5__( ~ __BLANK_6__, \n             __BLANK_7__ = 1)\n\n\n\n\nVisualization 4\n\n\n\n\n\n\n\n\n\nggplot(data = df_gapminder,\n       mapping = aes(__BLANK_1__,\n                     y = __BLANK_2__)) +\n  geom___BLANK_3__(show.legend = FALSE,\n                  color = 'grey',\n                  mapping = aes(group = country)) + # Advanced ggplot: we can add a specific aes() to a specific geom.\n  geom___BLANK_4__() +\n  facet_wrap(~ __BLANK_5__, \n             __BLANK_6__ = 1)"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html",
    "href": "danl-rw/danl-101-team-project-baseball.html",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "",
    "text": "The following lists data frames about MLB since 1985:\n\ndf_teams: Yearly statistics and standings for MLB teams\ndf_battings: Batting statistics\ndf_pitchings: Pitching statistics\ndf_salaries: Player salary data\ndf_salariesTeam: Team salary data\ndf_postseasons: Post season series information\ndf_players: People table - Player names, DOB, and biographical info.\n\nThis data.frame is to be used to get details about players listed in the df_battings, df_pitchings, and df_salaries where players are identified only by variable playerID.\n\n\n\n\n\ndf_teams: Yearly statistics and standings for MLB teams\n\nA data frame with 1128 observations on the 52 variables.\n\n\n\ndf_teams &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_teams.csv\")\n\n\n\n\n\n  \n\n\n\n\nyearID Year\nlgID League; a factor with levels AA AL FL NL PL UA\nteamID Team; a factor\nfranchID Franchise (links to TeamsFranchises table)\ndivID Team‚Äôs division; a factor with levels C E W\nRank Position in final standings\nG Games played\nGhome Games played at home\nW Wins\nL Losses\nDivWin Division Winner (Y or N)\nWCWin Wild Card Winner (Y or N)\nLgWin League Champion(Y or N)\nWSWin World Series Winner (Y or N)\nR Runs scored\nAB At bats\nH Hits by batters\nX1B Singles\nX2B Doubles\nX3B Triples\nHR Homeruns by batters\nTB Total bases TB = X1B + 2*X2B + 3*X3B + 4*HR\nBB Walks by batters\nSO Strikeouts by batters\nSB Stolen bases\nCS Caught stealing\nHBP Batters hit by pitch\nBB_HBP BB_HBP = BB + HBP\nRC Runs created RC = (H + BB + HBP)*TB/(AB + BB + HBP)\nSF Sacrifice flies\nRA Opponents runs scored\nER Earned runs allowed\nERA Earned run average\nCG Complete games\nSHO Shutouts\nSV Saves\nIPouts Outs Pitched (innings pitched x 3)\nHA Hits allowed\nHRA Homeruns allowed\nBBA Walks allowed\nSOA Strikeouts by pitchers\nE Errors\nDP Double Plays\nFP Fielding percentage\nname Team‚Äôs full name\npark Name of team‚Äôs home ballpark\nattendance Home attendance total\nBPF Three-year park factor for batters\nPPF Three-year park factor for pitchers\nteamIDBR Team ID used by Baseball Reference website\nteamIDlahman45 Team ID used in Lahman database version 4.5\nteamIDretro Team ID used by Retrosheet\n\n\n\n\ndf_battings: Batting statistics\n\nA data frame with 113799 observations on the 28 variables.\n\n\n\ndf_battings &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_battings.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerID Player ID code\nyearID Year\nstint player‚Äôs stint (order of appearances within a season)\nteamID Team; a factor\nlgID League; a factor with levels AA AL FL NL PL UA\nG Games: number of games in which a player played\nAB At Bats\nR Runs\nH Hits: times reached base because of a batted, fair ball without error by the defense\nX2B Singles\nX2B Doubles: hits on which the batter reached second base safely\nX3B Triples: hits on which the batter reached third base safely\nHR Homeruns\nTB Total bases TB = X1B + 2*X2B + 3*X3B + 4*HR\nRBI Runs Batted In\nSB Stolen Bases\nCS Caught Stealing\nBB Base on Balls\nSO Strikeouts\nIBB Intentional walks\nHBP Hit by pitch\nBB_HBP Representing all the times a player reaches base via walks (including intentional walks) and hit by pitches. BB_HBP = BB + HBP\nRC Runs created RC = (H + BB + HBP)*TB/(AB + BB + HBP)\nSH Sacrifice hits\nSF Sacrifice flies\nGIDP Grounded into double plays\nOuts The total number of outs a player is responsible for during a season Outs = 0.982 * AB - H + GIDP + SF + SH + CS Multiply AB by 0.982 due to the fact that approximately 0.8% of all at bats result in an error\nOBP On-Base Percentage. OBP measures how frequently a batter reaches base per plate appearance OBP = (H + BB + HBP) / (AB + BB + HBP + SF)\n\n\n\n\ndf_pitchings: Pitching statistics\n\nA data frame with 26384 observations on the 33 variables.\n\n\n\ndf_pitchings &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_pitchings.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerID Player ID code\nyearID Year\nstint player‚Äôs stint (order of appearances within a season)\nteamID Team; a factor\nlgID League; a factor with levels AA AL FL NL PL UA\nW Wins\nL Losses\nG Games\nGS Games Started\nCG Complete Games\nSHO Shutouts\nSV Saves\nIPouts Outs Pitched (innings pitched x 3)\nH Hits\nBAOpp Batting average against (a measure of how effectively a pitcher prevents hitters from getting hits) BAOpp = H / (H + IPouts)\nER Earned Runs\nHR Homeruns\nBB Walks\nWHIP Walks plus Hits per Inning Pitched. The number of base runners a pitcher has allowed per inning pitched. It is a common indicator of a pitcher‚Äôs effectiveness. WHIP = (H + BB) * 3 / IPouts\nSO Strikeouts\nBAOpp Opponent‚Äôs Batting Average\nERA Earned Run Average\nIBB Intentional Walks\nKperBB Strikeouts per Walk. KperBB represents the ratio of strikeouts to walks, indicating a pitcher‚Äôs control and ability to dominate hitters. KperBB = SO/(BB - IBB)\nWP Wild Pitches\nHBP Batters Hit By Pitch\nBK Balks\nBFP Batters faced by Pitcher\nGF Games Finished\nR Runs Allowed\nSH Sacrifices by opposing batters\nSF Sacrifice flies by opposing batters\nGIDP Grounded into double plays by opposing batter\n\n\n\n\ndf_salaries: Player salary data from 1985 to 2016\n\nA data frame with 26428 observations on the 5 variables.\n\n\n\ndf_salaries &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_salaries.csv\")\n\n\n\n\n\n  \n\n\n\n\nyearID Year\nteamID Team; a factor\nlgID League; a factor\nplayerID Player ID code\nsalary Salary\n\n\n\ndf_salariesTeam: Team salary data from 1985 to 2016\n\n\ndf_salariesTeam &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_payrolls.csv\")\n\n\n\n\n\n  \n\n\n\npayroll Team payroll in million dollars\nWSWin Whether or not winning the World Series\n\n\n\n\n\n\ndf_postseasons: Post season series information\n\nA data frame with 389 observations on the 9 variables.\n\n\n\ndf_postseasons &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_postseasons.csv\")\n\n\n\n\n\n  \n\n\n\n\nyearID Year\nround Level of playoffs\nteamIDwinner Team ID of the team that won the series; a factor\nlgIDwinner League ID of the team that won the series; a factor with levels AL NL\nteamIDloser Team ID of the team that lost the series; a factor\nlgIDloser League ID of the team that lost the series; a factor with levels AL NL\nwins Wins by team that won the series\nlosses Losses by team that won the series\nties Tie games\n\n\n\n\ndf_players: People table - Player names, DOB, and biographical info.\n\nA data frame with 21010 observations on the 26 variables.\nThis data.frame is to be used to get details about players listed in the df_battings, df_pitchings, and df_salaries where players are identified only by variable playerID.\n\n\n\ndf_players &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_players.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerID A unique code assigned to each player. The playerID links the data in this data.frame with records on players in the other data.frames.\nbirthYear Year player was born\nbirthMonth Month player was born\nbirthDay Day player was born\nbirthCountry Country where player was born\nbirthState State where player was born\nbirthCity City where player was born\ndeathYear Year player died\ndeathMonth Month player died\ndeathDay Day player died\ndeathCountry Country where player died\ndeathState State where player died\ndeathCity City where player died\nnameFirst Player‚Äôs first name\nnameLast Player‚Äôs last name\nnameGiven Player‚Äôs given name (typically first and middle)\nweight Player‚Äôs weight in pounds\nheight Player‚Äôs height in inches\nbats a factor: Player‚Äôs batting hand (left (L), right (R), or both (B))\nthrows a factor: Player‚Äôs throwing hand (left(L) or right(R))\ndebut Date that player made first major league appearance\nfinalGame Date that player made first major league appearance (blank if still active)\nretroID ID used by retrosheet, https://www.retrosheet.org/\nbbrefID ID used by Baseball Reference website, https://www.baseball-reference.com/\nbirthDate Player‚Äôs birthdate, in as.Date format\ndeathDate Player‚Äôs deathdate, in as.Date format"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#mlb-teams-df_teams",
    "href": "danl-rw/danl-101-team-project-baseball.html#mlb-teams-df_teams",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "",
    "text": "df_teams: Yearly statistics and standings for MLB teams\n\nA data frame with 1128 observations on the 52 variables.\n\n\n\ndf_teams &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_teams.csv\")\n\n\n\n\n\n  \n\n\n\n\nyearID Year\nlgID League; a factor with levels AA AL FL NL PL UA\nteamID Team; a factor\nfranchID Franchise (links to TeamsFranchises table)\ndivID Team‚Äôs division; a factor with levels C E W\nRank Position in final standings\nG Games played\nGhome Games played at home\nW Wins\nL Losses\nDivWin Division Winner (Y or N)\nWCWin Wild Card Winner (Y or N)\nLgWin League Champion(Y or N)\nWSWin World Series Winner (Y or N)\nR Runs scored\nAB At bats\nH Hits by batters\nX1B Singles\nX2B Doubles\nX3B Triples\nHR Homeruns by batters\nTB Total bases TB = X1B + 2*X2B + 3*X3B + 4*HR\nBB Walks by batters\nSO Strikeouts by batters\nSB Stolen bases\nCS Caught stealing\nHBP Batters hit by pitch\nBB_HBP BB_HBP = BB + HBP\nRC Runs created RC = (H + BB + HBP)*TB/(AB + BB + HBP)\nSF Sacrifice flies\nRA Opponents runs scored\nER Earned runs allowed\nERA Earned run average\nCG Complete games\nSHO Shutouts\nSV Saves\nIPouts Outs Pitched (innings pitched x 3)\nHA Hits allowed\nHRA Homeruns allowed\nBBA Walks allowed\nSOA Strikeouts by pitchers\nE Errors\nDP Double Plays\nFP Fielding percentage\nname Team‚Äôs full name\npark Name of team‚Äôs home ballpark\nattendance Home attendance total\nBPF Three-year park factor for batters\nPPF Three-year park factor for pitchers\nteamIDBR Team ID used by Baseball Reference website\nteamIDlahman45 Team ID used in Lahman database version 4.5\nteamIDretro Team ID used by Retrosheet"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#mlb-batting-df_battings",
    "href": "danl-rw/danl-101-team-project-baseball.html#mlb-batting-df_battings",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "",
    "text": "df_battings: Batting statistics\n\nA data frame with 113799 observations on the 28 variables.\n\n\n\ndf_battings &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_battings.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerID Player ID code\nyearID Year\nstint player‚Äôs stint (order of appearances within a season)\nteamID Team; a factor\nlgID League; a factor with levels AA AL FL NL PL UA\nG Games: number of games in which a player played\nAB At Bats\nR Runs\nH Hits: times reached base because of a batted, fair ball without error by the defense\nX2B Singles\nX2B Doubles: hits on which the batter reached second base safely\nX3B Triples: hits on which the batter reached third base safely\nHR Homeruns\nTB Total bases TB = X1B + 2*X2B + 3*X3B + 4*HR\nRBI Runs Batted In\nSB Stolen Bases\nCS Caught Stealing\nBB Base on Balls\nSO Strikeouts\nIBB Intentional walks\nHBP Hit by pitch\nBB_HBP Representing all the times a player reaches base via walks (including intentional walks) and hit by pitches. BB_HBP = BB + HBP\nRC Runs created RC = (H + BB + HBP)*TB/(AB + BB + HBP)\nSH Sacrifice hits\nSF Sacrifice flies\nGIDP Grounded into double plays\nOuts The total number of outs a player is responsible for during a season Outs = 0.982 * AB - H + GIDP + SF + SH + CS Multiply AB by 0.982 due to the fact that approximately 0.8% of all at bats result in an error\nOBP On-Base Percentage. OBP measures how frequently a batter reaches base per plate appearance OBP = (H + BB + HBP) / (AB + BB + HBP + SF)"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#mlb-pitching-df_pitchings",
    "href": "danl-rw/danl-101-team-project-baseball.html#mlb-pitching-df_pitchings",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "",
    "text": "df_pitchings: Pitching statistics\n\nA data frame with 26384 observations on the 33 variables.\n\n\n\ndf_pitchings &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_pitchings.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerID Player ID code\nyearID Year\nstint player‚Äôs stint (order of appearances within a season)\nteamID Team; a factor\nlgID League; a factor with levels AA AL FL NL PL UA\nW Wins\nL Losses\nG Games\nGS Games Started\nCG Complete Games\nSHO Shutouts\nSV Saves\nIPouts Outs Pitched (innings pitched x 3)\nH Hits\nBAOpp Batting average against (a measure of how effectively a pitcher prevents hitters from getting hits) BAOpp = H / (H + IPouts)\nER Earned Runs\nHR Homeruns\nBB Walks\nWHIP Walks plus Hits per Inning Pitched. The number of base runners a pitcher has allowed per inning pitched. It is a common indicator of a pitcher‚Äôs effectiveness. WHIP = (H + BB) * 3 / IPouts\nSO Strikeouts\nBAOpp Opponent‚Äôs Batting Average\nERA Earned Run Average\nIBB Intentional Walks\nKperBB Strikeouts per Walk. KperBB represents the ratio of strikeouts to walks, indicating a pitcher‚Äôs control and ability to dominate hitters. KperBB = SO/(BB - IBB)\nWP Wild Pitches\nHBP Batters Hit By Pitch\nBK Balks\nBFP Batters faced by Pitcher\nGF Games Finished\nR Runs Allowed\nSH Sacrifices by opposing batters\nSF Sacrifice flies by opposing batters\nGIDP Grounded into double plays by opposing batter"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#mlb-salaries-df_salaries",
    "href": "danl-rw/danl-101-team-project-baseball.html#mlb-salaries-df_salaries",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "",
    "text": "df_salaries: Player salary data from 1985 to 2016\n\nA data frame with 26428 observations on the 5 variables.\n\n\n\ndf_salaries &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_salaries.csv\")\n\n\n\n\n\n  \n\n\n\n\nyearID Year\nteamID Team; a factor\nlgID League; a factor\nplayerID Player ID code\nsalary Salary\n\n\n\ndf_salariesTeam: Team salary data from 1985 to 2016\n\n\ndf_salariesTeam &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_payrolls.csv\")\n\n\n\n\n\n  \n\n\n\npayroll Team payroll in million dollars\nWSWin Whether or not winning the World Series"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#mlb-post-season-df_postseasons",
    "href": "danl-rw/danl-101-team-project-baseball.html#mlb-post-season-df_postseasons",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "",
    "text": "df_postseasons: Post season series information\n\nA data frame with 389 observations on the 9 variables.\n\n\n\ndf_postseasons &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_postseasons.csv\")\n\n\n\n\n\n  \n\n\n\n\nyearID Year\nround Level of playoffs\nteamIDwinner Team ID of the team that won the series; a factor\nlgIDwinner League ID of the team that won the series; a factor with levels AL NL\nteamIDloser Team ID of the team that lost the series; a factor\nlgIDloser League ID of the team that lost the series; a factor with levels AL NL\nwins Wins by team that won the series\nlosses Losses by team that won the series\nties Tie games"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#mlb-players-df_players",
    "href": "danl-rw/danl-101-team-project-baseball.html#mlb-players-df_players",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "",
    "text": "df_players: People table - Player names, DOB, and biographical info.\n\nA data frame with 21010 observations on the 26 variables.\nThis data.frame is to be used to get details about players listed in the df_battings, df_pitchings, and df_salaries where players are identified only by variable playerID.\n\n\n\ndf_players &lt;- read_csv(\"http://bcdanl.github.io/data/mlb_players.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerID A unique code assigned to each player. The playerID links the data in this data.frame with records on players in the other data.frames.\nbirthYear Year player was born\nbirthMonth Month player was born\nbirthDay Day player was born\nbirthCountry Country where player was born\nbirthState State where player was born\nbirthCity City where player was born\ndeathYear Year player died\ndeathMonth Month player died\ndeathDay Day player died\ndeathCountry Country where player died\ndeathState State where player died\ndeathCity City where player died\nnameFirst Player‚Äôs first name\nnameLast Player‚Äôs last name\nnameGiven Player‚Äôs given name (typically first and middle)\nweight Player‚Äôs weight in pounds\nheight Player‚Äôs height in inches\nbats a factor: Player‚Äôs batting hand (left (L), right (R), or both (B))\nthrows a factor: Player‚Äôs throwing hand (left(L) or right(R))\ndebut Date that player made first major league appearance\nfinalGame Date that player made first major league appearance (blank if still active)\nretroID ID used by retrosheet, https://www.retrosheet.org/\nbbrefID ID used by Baseball Reference website, https://www.baseball-reference.com/\nbirthDate Player‚Äôs birthdate, in as.Date format\ndeathDate Player‚Äôs deathdate, in as.Date format"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#historical-metrics",
    "href": "danl-rw/danl-101-team-project-baseball.html#historical-metrics",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "Historical Metrics",
    "text": "Historical Metrics\nFor over a century, baseball players were evaluated using a limited set of straightforward offensive and defensive statistics. However, advancements in computing and the introduction of sabermetrics revolutionized how player performance is assessed, giving rise to more nuanced and meaningful metrics.\n\nOffensive Statistics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nBatting Average\nHits divided by at-bats (Hits √∑ At-Bats)\n\n\nHome Runs\nTotal number of home runs hit by a player\n\n\nRuns Batted In (RBI)\nNumber of runs a player has batted in\n\n\nWalks\nNumber of times a batter reaches first base via four balls (also known as Base on Balls)\n\n\nOn Base Percentage (OBP)\nTimes on base (hits + walks + hit by pitch) divided by plate appearances\n\n\nRuns Scored\nNumber of times a player crosses home plate to score a run\n\n\nSlugging Percentage (SLG)\nTotal bases divided by at-bats (Total Bases √∑ At-Bats)\n\n\n\n\n\nDefensive Statistics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nWins\nCredited to the pitcher who was pitching when his team took the lead for good\n\n\nInnings Pitched\nTotal number of innings a pitcher has pitched\n\n\nEarned Run Average (ERA)\nAverage number of earned runs a pitcher allows per nine innings pitched\n\n\nWalks\nNumber of batters a pitcher has allowed to reach first base via four balls\n\n\nStrikeouts\nNumber of batters a pitcher has retired by striking them out\n\n\nWHIP\nWalks plus hits per inning pitched ((Walks + Hits) √∑ Innings Pitched)\n\n\nSaves\nCredited to a pitcher who finishes a game for the winning team under certain conditions\n\n\nFielding Percentage\nPercentage of times a defensive player handles the ball without making an error"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-baseball.html#runs-created",
    "href": "danl-rw/danl-101-team-project-baseball.html#runs-created",
    "title": "Data Storytelling Team Project - Baseball",
    "section": "Runs Created",
    "text": "Runs Created\nOne of Bill James‚Äôs original metrics, Runs Created (\\(RC\\)), estimates the number of runs a player or team contributes to scoring. The formula is:\n\\[\nRC = \\frac{(H + BB + HBP) \\times TB}{AB + BB + HBP}\n\\]\nWhere:\n\n\\(H\\) = Hits\n\\(BB\\) = Walks (Base on Balls)\n\\(HBP\\) = Hit by Pitch\n\\(TB\\) = Total Bases\n\\(AB\\) = At-Bats\n\nThis metric helps evaluate a player or team‚Äôs offensive value. For example, if considering adding a player to a team, comparing their runs created to other candidates provides a data-driven basis for decision-making."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html",
    "href": "danl-rw/danl-101-team-project-football.html",
    "title": "Data Storytelling Team Project - Football",
    "section": "",
    "text": "The following lists data frames about National Football League (NFL) for the seasons from 2014-15 through 2024-2025:\n\nnfl_team_epa: Team‚Äôs mean expected points added (EPA) when the team was on offense and when the team was on defense\n\nFor the details about EPA, please refer to the Football Metrics section below in the webpage.\n\nnfl_field_goals: Play-by-play statistics at situations when field goals were attempted during the game\nnfl_passers: weakly EPA and completion percentage over expected (CPOE) among players who passed more than 44 times within a week\nnfl_player_stat: Player statistics\nnfl_receivers: Total EPA of players whose positions are either ‚ÄúWR‚Äù, ‚ÄúTE‚Äù, or ‚ÄúRB‚Äù, and top 10 players in terms of total EPA\n\n\n\n\n\n\n\n\n\n\nPosition\nFull Name\nMain Role\nSkills Required\n\n\n\n\nWR\nWide Receiver\nCatch passes and gain yards or score TDs\nSpeed, agility, reliable hands\n\n\nTE\nTight End\nBlock defenders and catch passes\nStrength, versatility, reliable hands\n\n\nRB\nRunning Back\nRun the ball, catch passes, block\nSpeed, vision, agility\n\n\nQB\nQuarterback\nLead the offense and throw passes\nDecision-making, accuracy, arm strength, leadership\n\n\n\n\n\n\nnfl_team_epa: Team‚Äôs mean EPA when the team was on offense and when the team was on defense\n\n\nnfl_team_epa &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_team_epa_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason Starting year of the season (2014 if 2014-15 season)\nteam Team abbreviation\noff_epa Offensive EPA\ndef_epa Defensive EPA\n\n\n\n\nnfl_field_goals: Play-by-play statistics at situations when field goals were attempted during the game\n\nA data frame with 10047 observations on the 23 variables.\n\n\n\nnfl_field_goals &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_field_goals_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nfg_distance accurately reflects the total distance of a field goal attempt:\n\nThe total addition of 17 yards comes from 10 yards (end zone) + 7 yards (holder‚Äôs position).\n\n\n\n\n\n\n\nnfl_passers: weakly mean EPA and completion percentage over CPOE among players who passed more than 44 times within a week\n\nA data frame with 1098 rows and 22 variables:\n\n\n\nnfl_passers &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_passers_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nnfl_players_stat: Player statistics\n\n\nnfl_players_stat &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_players_stat_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\nyards rushing_yards + receiving_yards\nrushing_yards Yards gained when rushing with the ball (incl.¬†scrambles and kneel downs). Also includes yards gained after obtaining a lateral on a play that started with a rushing attempt.\nreceiving_yards Yards gained after a pass reception. Includes yards gained after receiving a lateral on a play that started as a pass play.\ntouches carries + receptions\ncarries The number of official rush attempts (incl.¬†scrambles and kneel downs). Rushes after a lateral reception don‚Äôt count as carry.\nreceptions The number of pass receptions. Lateral receptions officially don‚Äôt count as reception.\ntds rushing_tds + receiving_tds\nrushing_tds The number of rushing touchdowns (incl.¬†scrambles). Also includes touchdowns after obtaining a lateral on a play that started with a rushing attempt.\nreceiving_tds The number of touchdowns following a pass reception. Also includes touchdowns after receiving a lateral on a play that started as a pass play.\n\n\n\n\nnfl_receivers: Total EPA of players whose positions are either ‚ÄúWR‚Äù, ‚ÄúTE‚Äù, or ‚ÄúRB‚Äù, and top 10 players in terms of total EPA\n\n\nnfl_receivers &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_receivers_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\nepa_rank: Ranking in terms of tot_epa (The lower tot_epa, the higher EPA)\nepa_rank_within_position: Ranking in terms of EPA within the group of the same position\nn_received: the number of passes a player received\ntot_epa: Total EPA within a season"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html#nfl-team-epa-nfl_team_epa",
    "href": "danl-rw/danl-101-team-project-football.html#nfl-team-epa-nfl_team_epa",
    "title": "Data Storytelling Team Project - Football",
    "section": "",
    "text": "nfl_team_epa: Team‚Äôs mean EPA when the team was on offense and when the team was on defense\n\n\nnfl_team_epa &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_team_epa_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason Starting year of the season (2014 if 2014-15 season)\nteam Team abbreviation\noff_epa Offensive EPA\ndef_epa Defensive EPA"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html#nfl-field-goals-nfl_field_goals",
    "href": "danl-rw/danl-101-team-project-football.html#nfl-field-goals-nfl_field_goals",
    "title": "Data Storytelling Team Project - Football",
    "section": "",
    "text": "nfl_field_goals: Play-by-play statistics at situations when field goals were attempted during the game\n\nA data frame with 10047 observations on the 23 variables.\n\n\n\nnfl_field_goals &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_field_goals_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nfg_distance accurately reflects the total distance of a field goal attempt:\n\nThe total addition of 17 yards comes from 10 yards (end zone) + 7 yards (holder‚Äôs position)."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html#nfl-passers-epa-and-cope-nfl_passers",
    "href": "danl-rw/danl-101-team-project-football.html#nfl-passers-epa-and-cope-nfl_passers",
    "title": "Data Storytelling Team Project - Football",
    "section": "",
    "text": "nfl_passers: weakly mean EPA and completion percentage over CPOE among players who passed more than 44 times within a week\n\nA data frame with 1098 rows and 22 variables:\n\n\n\nnfl_passers &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_passers_2024.csv\")"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html#nfl-player-statistics-nfl_players_stat",
    "href": "danl-rw/danl-101-team-project-football.html#nfl-player-statistics-nfl_players_stat",
    "title": "Data Storytelling Team Project - Football",
    "section": "",
    "text": "nfl_players_stat: Player statistics\n\n\nnfl_players_stat &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_players_stat_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\nyards rushing_yards + receiving_yards\nrushing_yards Yards gained when rushing with the ball (incl.¬†scrambles and kneel downs). Also includes yards gained after obtaining a lateral on a play that started with a rushing attempt.\nreceiving_yards Yards gained after a pass reception. Includes yards gained after receiving a lateral on a play that started as a pass play.\ntouches carries + receptions\ncarries The number of official rush attempts (incl.¬†scrambles and kneel downs). Rushes after a lateral reception don‚Äôt count as carry.\nreceptions The number of pass receptions. Lateral receptions officially don‚Äôt count as reception.\ntds rushing_tds + receiving_tds\nrushing_tds The number of rushing touchdowns (incl.¬†scrambles). Also includes touchdowns after obtaining a lateral on a play that started with a rushing attempt.\nreceiving_tds The number of touchdowns following a pass reception. Also includes touchdowns after receiving a lateral on a play that started as a pass play."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html#nfl-receivers-nfl_receivers",
    "href": "danl-rw/danl-101-team-project-football.html#nfl-receivers-nfl_receivers",
    "title": "Data Storytelling Team Project - Football",
    "section": "",
    "text": "nfl_receivers: Total EPA of players whose positions are either ‚ÄúWR‚Äù, ‚ÄúTE‚Äù, or ‚ÄúRB‚Äù, and top 10 players in terms of total EPA\n\n\nnfl_receivers &lt;- read_csv(\"http://bcdanl.github.io/data/nfl_receivers_2024.csv\")\n\n\n\n\n\n  \n\n\n\n\nepa_rank: Ranking in terms of tot_epa (The lower tot_epa, the higher EPA)\nepa_rank_within_position: Ranking in terms of EPA within the group of the same position\nn_received: the number of passes a player received\ntot_epa: Total EPA within a season"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html#expected-points",
    "href": "danl-rw/danl-101-team-project-football.html#expected-points",
    "title": "Data Storytelling Team Project - Football",
    "section": "Expected Points",
    "text": "Expected Points\nExpected Points Added (EPA) is a football analytics metric that measures the value of a play in terms of its impact on the team‚Äôs expected scoring. It quantifies how much a single play increases or decreases a team‚Äôs chances of scoring compared to the situation before the play.\n\nHow EPA Works\nEvery play in football occurs within a specific context (down, distance, field position, time remaining, and score). Historical data is used to calculate the expected points (EP) a team can expect to score from their current situation. EPA is the difference between the expected points after the play and before the play.\n\n\nFormula:\n\\[\nEPA = EP (\\text{after the play}) - EP (\\text{before the play})\n\\]\n\n\nKey Insights:\n\nPositive EPA: The play improved the team‚Äôs scoring chances.\n\n\nExample: A 20-yard pass on 3rd and 8 increases the likelihood of scoring.\n\n\nNegative EPA: The play reduced the team‚Äôs scoring chances.\n\nExample: A sack or an interception harms the team‚Äôs scoring potential.\n\n\n\n\nWhy EPA Is Important\n\nContextual: Accounts for situational factors, making it more informative than raw stats like yards gained.\nPlay Evaluation: Helps determine the effectiveness of specific plays or players.\nStrategic Decisions: Assists coaches and analysts in evaluating decisions like when to go for it on 4th down.\n\n\n\nApplications\n\nOffensive EPA: Evaluates how well a team‚Äôs offense increases scoring opportunities.\nDefensive EPA: Measures how effectively a defense reduces the opposing team‚Äôs scoring potential.\nPlayer Performance: Used to assess quarterbacks, running backs, wide receivers, and defenders by their contribution to scoring or preventing points."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-football.html#completion-percentage-over-expected-cpoe",
    "href": "danl-rw/danl-101-team-project-football.html#completion-percentage-over-expected-cpoe",
    "title": "Data Storytelling Team Project - Football",
    "section": "Completion Percentage Over Expected (CPOE)",
    "text": "Completion Percentage Over Expected (CPOE)\nCompletion Percentage Over Expected (CPOE) is a football analytics metric that evaluates a quarterback‚Äôs passing performance by comparing their actual completion percentage to the expected completion percentage based on the difficulty of their pass attempts.\n\nHow CPOE Works\n\nActual Completion Percentage (COMP%):\n\nThe percentage of passes a quarterback completes.\n\nExpected Completion Percentage (xCOMP%):\n\nCalculated based on factors like:\nDistance of the throw (air yards)\nAngle of the throw\nReceiver separation\nDefensive pressure\nGame situation (e.g., down, distance, and field position)\nDerived from historical data on similar passes.\n\nCPOE Formula: \\[\nCPOE = COMP - xCOMP\n\\]\n\n\n\nInterpretation of CPOE\n\nPositive CPOE: Indicates the quarterback is completing more passes than expected, showcasing accuracy and skill.\nNegative CPOE: Indicates the quarterback is completing fewer passes than expected, potentially highlighting issues with accuracy or decision-making.\n\n\n\nWhy CPOE Is Useful\n\nIsolates Skill: It accounts for the difficulty of throws, focusing on the quarterback‚Äôs performance rather than the system or play design.\nComplementary Metric: Often paired with EPA/play to provide a comprehensive evaluation of a quarterback‚Äôs impact.\nGame Context: Helps differentiate between quarterbacks who excel in challenging situations versus those whose stats are inflated by easy throws."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html",
    "href": "danl-rw/danl-101-team-project.html",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "",
    "text": "Each team will deliver a 10-minute presentation, followed by a 1‚Äì2 minute Q&A session.\nThe order of team presentations will be determined by a random draw.\n\nIf multiple teams choose the same topic, I will try to schedule these teams in different sessions to minimize repetition within a single class.\n\nTo ensure fairness and equal participation, each student must contribute evenly to the presentation."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#beer-market",
    "href": "danl-rw/danl-101-team-project.html#beer-market",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üç∫ 1. Beer Market",
    "text": "üç∫ 1. Beer Market\nThe beer_markets data frame contains detailed information about household beer purchases across different brands and markets in the United States. It includes purchase details, product attributes, promotional information, and demographic data of the households.\n\nbeer_markets &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets_all.csv\")\n\n\n\n\n  \n\n\n\nVariable Description\n\nhh: an identifier of the household;\nX_purchase_desc: details on the purchased item;\nquantity: the number of items purchased;\nbrand: Bud Light, Busch Light, Coors Light, Miller Lite, or Natural Light;\ndollar_spent: total dollar value of purchase;\nbeer_floz: total volume of beer, in fluid ounces;\nprice_floz: price per fl.oz. (i.e., dollar_spent/beer_floz);\ncontainer: the type of container;\npromo: Whether the item was promoted (coupon or otherwise);\nregion: US region\nstate: US state\nmarket: Scan-track market (or state if rural);\ndemographic data, including gender, marital status, household income, class of work, race, education, age, the size of household, and whether or not the household has a microwave or a dishwasher."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#nyc-housing-market",
    "href": "danl-rw/danl-101-team-project.html#nyc-housing-market",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üèôÔ∏è 2. NYC Housing Market",
    "text": "üèôÔ∏è 2. NYC Housing Market\nThe nyc_housing_sales data frame includes property sale transactions in New York City from January 2003 to October 2025. It provides detailed information about each sale, including property characteristics, sales prices, and building classifications.\n\nnyc_housing_sales &lt;- read_csv(\"https://bcdanl.github.io/data/nyc_housing_sales_2003-2025_10.csv\")\n\n\n\n\n  \n\n\n\nDescription of Variables in the nyc_housing_sales data frame\n\nFor the description of variables in the nyc_housing_sales data.frame, please refer to the following webpage:\n\nhttps://www.nyc.gov/site/finance/property/glossary-property-sales.page\n\nFor the variables of building class code, please refer to the following webpage:\n\nhttps://www.nyc.gov/assets/finance/jump/hlpbldgcode.html"
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#stock-market-and-esg-environmental-social-and-governance",
    "href": "danl-rw/danl-101-team-project.html#stock-market-and-esg-environmental-social-and-governance",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üå± 3. Stock Market and ESG (Environmental, Social, and Governance)",
    "text": "üå± 3. Stock Market and ESG (Environmental, Social, and Governance)\nThe stock_markets data frame contains daily trading data for publicly traded companies, including information about stock prices, trading volume, dividends, and stock splits, obtained from Yahoo! Finance.\n\nstock_markets &lt;- read_csv(\"https://bcdanl.github.io/data/stock_history_2024_10.csv\")\n\n\n\n\n  \n\n\n\nDescription of Variables in the stock_markets data frame\n\nDate: The specific date for the recorded stock data.\nTicker: The unique symbol assigned to a publicly traded company‚Äôs stock. It is used to identify the stock on financial markets (631 unique values).\nClose: The stock‚Äôs price at the end of the trading day. It does not account for adjustments like dividends or splits.\nDividends: The cash dividend paid per share on the given date, if applicable. It represents the portion of a company‚Äôs earnings distributed to shareholders.\nHigh: The highest price at which the stock traded during the trading day.\nLow: The lowest price at which the stock traded during the trading day.\nOpen: The stock‚Äôs price at the beginning of the trading day.\nStock_Splits: The ratio of any stock split that occurred on the given date. A stock split increases the number of shares outstanding while reducing the price per share proportionally.\nVolume: The total number of shares traded during the day. It reflects the activity level and liquidity of the stock.\n\n\nThe esg_info data frame provides ESG scores and company details, including sector, industry, and market capitalization, obtained from Yahoo! Finance.\n\nesg_info &lt;- read_csv(\"https://bcdanl.github.io/data/stock_esg_list.csv\")\n\n\n\n\n  \n\n\n\n\nDescription of Variables in the esg_info data frame\n\nTicker: The stock symbol used to uniquely identify a publicly traded company on financial markets.\nCompany_Name: The full name of the company corresponding to the ticker symbol.\nSector: The broader industry category to which the company belongs, such as Technology, Healthcare, or Financials.\nIndustry: A more specific category within the sector that describes the company‚Äôs line of business. For example, within the Technology sector, an industry could be Semiconductors or Software.\nMarket_Cap: The total market value of the company‚Äôs outstanding shares. It is calculated by multiplying the current stock price by the total number of outstanding shares and is used to classify companies as small-cap, mid-cap, or large-cap.\nCountry: The country where the company is headquartered. This variable helps identify the geographical location of the company‚Äôs operations.\nIPO_Year: The year in which the company went public and its shares were first offered on a stock exchange.\ntotal_esg: The company‚Äôs overall Environmental, Social, and Governance (ESG) score. It reflects how well the company is performing in terms of sustainability and ethical impact.\nenvironmental: The company‚Äôs score related to environmental practices, such as energy efficiency, waste management, and carbon footprint.\nsocial: The company‚Äôs score related to social practices, including employee relations, diversity, community impact, and human rights.\ngovernance: The company‚Äôs score related to governance practices, like board structure, executive pay, and shareholder rights.\ncontroversy: A score reflecting the level of public controversies associated with the company, which may impact its reputation. A higher score often indicates more significant controversies.\n\n\n(Optional) The income_stmts data frame contains income statement details for each company, including revenue, expenses, and net income.\n\nincome_stmts &lt;- read_csv(\"https://bcdanl.github.io/data/stock_income_stmts_2024_10.csv\")\n\n\n\n\n  \n\n\n\n(Optional) The balance_sheets data frame contains balance sheet details, including assets, liabilities, and shareholder equity.\n\nbalance_sheets &lt;- read_csv(\"https://bcdanl.github.io/data/stock_balance_sheets_2024_10.csv\")"
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#chess",
    "href": "danl-rw/danl-101-team-project.html#chess",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "‚ôüÔ∏è 4. Chess",
    "text": "‚ôüÔ∏è 4. Chess\nThe compressed chesscom_3100.zip file includes chesscom_3100.csv, containing records of high-level blitz or bullet games on Chess.com, played by 171 players with a peak rating of at least 3100.\n\nDownload the compressed zip file, extract it (this can be automatically extracted), and upload it to your team project in Posit Cloud.\n\n\n\nDescription of Variables in the chesscom_3100.csv file\n\nDate: The date on which the chess game was played, formatted as YYYY-MM-DD.\nYear: The year of the game, extracted from the date (e.g., 2017).\nMonth: The month of the game, extracted from the date (e.g., 2 for February).\nDay: The day of the month on which the game was played, extracted from the date (e.g., 13).\nWhite: The username of the player who played with the white pieces.\nBlack: The username of the player who played with the black pieces.\nResult: The outcome of the game from White‚Äôs perspective, with options like:\n\n‚Äú1-0‚Äù indicating a win for White.\n‚Äú0-1‚Äù indicating a win for Black.\n‚Äú1/2-1/2‚Äù indicating a draw.\n\nWhiteElo: The Elo rating of the player playing White at the time of the game.\nBlackElo: The Elo rating of the player playing Black at the time of the game.\nECO: The ECO (Encyclopaedia of Chess Openings) code that classifies the opening used in the game, such as D02 or E36.\nECO_name: A description or detailed name of the chess opening corresponding to the ECO code, which may include the opening variation.\nECO_moves: The sequence of the opening moves for the chess opening corresponding to the ECO code\nTermination: The method by which the game ended, such as ‚Äúwon by resignation,‚Äù ‚Äúdrawn by insufficient material,‚Äù or ‚Äúwon on time.‚Äù\nTimeControl: The total time control for the game in seconds (e.g., 180 indicates a three-minute game).\n\n\nThe rating_3100_players data frame provides 71 players‚Äô profiles, including rankings, ratings, titles, and follower counts on Chess.com.\n\nrating_3100_players &lt;- read_csv(\"https://bcdanl.github.io/data/chesscom_GMs_profile.csv\")\n\n\n\n\n  \n\n\n\n\nVariable Description in the rating_3100_players data frame\n\nusername: The unique username associated with the player on Chess.com.\nname: The real name of the player, if available.\nusername_raw: The original or unformatted version of the player‚Äôs username.\ncountry: The country where the player is located or registered.\nrank_classical: The player‚Äôs ranking position in Classical chess format.\nrank_rapid: The player‚Äôs ranking position in Rapid chess format.\nrank_blitz: The player‚Äôs ranking position in Blitz chess format.\nrating_classical: The player‚Äôs Elo rating in Classical chess format.\nrating_rapid: The player‚Äôs Elo rating in Rapid chess format.\nrating_blitz: The player‚Äôs Elo rating in Blitz chess format.\ntitle: The official chess title held by the player, such as GM (Grandmaster), IM (International Master), etc.\nprofile_name: The full name displayed on the player‚Äôs profile page.\nprofile_username: The URL or link to the player‚Äôs profile on Chess.com.\nprofile_image: The URL to the player‚Äôs profile image.\nfollowers: The number of followers the player has on Chess.com.\nis_streamer: Indicates whether the player is a streamer (TRUE or FALSE).\nstatus: The account status, such as ‚Äúpremium‚Äù or other types of account membership.\ndate_joined: The date when the player joined Chess.com, formatted as YYYY-MM-DD."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#sports",
    "href": "danl-rw/danl-101-team-project.html#sports",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üèÖ 5. Sports",
    "text": "üèÖ 5. Sports\n\nSports datasets can be rich and multi-layered, offering exciting opportunities for analysis‚Äîespecially for sports fans.\nProf.¬†Choe can assist with data for:\n\nMajor League Baseball (MLB)\nNational Basketball Association (NBA)\nNational Football League (NFL)\nNational Hockey League (NHL)\nSoccer (EPL, La Liga, Serie A, Bundesliga, MLS)\nGolf"
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#rubric-for-the-data-storytelling-project",
    "href": "danl-rw/danl-101-team-project.html#rubric-for-the-data-storytelling-project",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üìë Rubric for the Data Storytelling Project",
    "text": "üìë Rubric for the Data Storytelling Project\n\n\n\n\n\n\n\n\n\n\n\nAttribute\nVery Deficient (1)\nSomewhat Deficient (2)\nAcceptable (3)\nVery Good (4)\nOutstanding (5)\n\n\n\n\n1. Quality of Data Transformation and Descriptive Statistics\n- No transformation or cleaning applied- Very poor data transformation- Contains significant errors\n- Minimal transformation or cleaning- Basic data transformation with errors- Contains several errors\n- Basic transformation applied- Adequate data transformation- Contains minor errors\n- Effective transformation- Thorough data transformation- Data is accurate\n- Advanced transformation- Exceptional data transformation- Data is impeccable\n\n\n2. Quality of Data Visualization\n- Visualizations are missing or unclear- Misrepresents data\n- Visualizations are basic and lack clarity- Some misrepresentation\n- Visualizations are clear and accurate- Data is appropriately represented\n- Visualizations are insightful and enhance understanding- Data is accurately represented\n- Visualizations are highly creative and compelling- Data representation is impeccable\n\n\n3. Effectiveness of Data Storytelling\n- No narrative or storyline- Insights are absent or irrelevant- Fails to engage the audience\n- Weak narrative structure- Insights are superficial- Minimal audience engagement\n- Clear narrative present- Insights are relevant- Audience is adequately engaged\n- Compelling narrative- Insights are significant- Engages audience effectively\n- Exceptional and captivating narrative- Insights are profound and impactful- Audience is highly engaged\n\n\n4. Quality of Slides and Visual Materials\n- Very poorly organized- Difficult to read and understand- Numerous errors present\n- Somewhat disorganized- Some slides are unclear- Several errors present\n- Well organized- Mostly clear and understandable- Few errors present\n- Very well organized- Clear and visually appealing- Very few errors\n- Exceptionally well organized- Highly clear and visually compelling- No errors\n\n\n5. Quality of Team Presentation\n- Presentation is disjointed- Poor team coordination- Unable to address questions\n- Lacks flow- Some coordination issues- Difficulty with several questions\n- Cohesive presentation- Team works well together- Addresses most questions adequately\n- Engaging presentation- Team is well-coordinated- Addresses almost all questions professionally\n- Highly engaging and polished presentation- Excellent team coordination- Addresses all questions expertly\n\n\n6. Quality of Code (Descriptive Statistics, Transformation, Visualization)\n- Code is missing or non-functional- No documentation- Disorganized code\n- Code has major errors- Minimal documentation- Code is somewhat disorganized\n- Code is functional- Basic documentation provided- Code is organized\n- Code is efficient and well-structured- Good documentation- Code is well-organized\n- Code is highly efficient and elegant- Excellent documentation- Code is exceptionally well-organized"
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#tips-on-data-storytelling-project",
    "href": "danl-rw/danl-101-team-project.html#tips-on-data-storytelling-project",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üí° Tips on Data Storytelling Project",
    "text": "üí° Tips on Data Storytelling Project\nYour team does not need to analyze every variable provided in the suggested data frames. Instead, carefully select the variables that best support your story, argument, and analysis.\nTo find an interesting story, you should:\n\nExplore your data using descriptive statistics (e.g., skimr::skim())\nApply data transformations such as filtering and counting\nUse data visualizations to uncover patterns, trends, and anomalies\nDraw on your background knowledge of the topic\nTreat the process as iterative ‚Äî your understanding will evolve as you explore, refine, and visualize your data along with your story.\n\nA strong data story emerges when your analytical choices (what you compute, transform, or visualize) clearly support your narrative and your main insights."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#data-transformation-support",
    "href": "danl-rw/danl-101-team-project.html#data-transformation-support",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üîß Data Transformation Support",
    "text": "üîß Data Transformation Support\n\nWe will cover key data-transformation functions in class to support your project, but feel free to reach out to Prof.¬†Choe if your team needs additional guidance.\nAs you work, think carefully about what your ideal data frame should look like to enable effective visualization and storytelling."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#presentation-slides",
    "href": "danl-rw/danl-101-team-project.html#presentation-slides",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üñ•Ô∏è Presentation Slides",
    "text": "üñ•Ô∏è Presentation Slides\n\nIn addition to your ggplot visualizations, you may include other visual aids in your presentation slides to enhance clarity and storytelling."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#r-script",
    "href": "danl-rw/danl-101-team-project.html#r-script",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "üíª R Script",
    "text": "üíª R Script\n\nOrganization: Use section headers (created with Ctrl/Cmd + Shift + R) and comments (#) to clearly label which parts of your code correspond to specific visualizations, transformations, and descriptive statistics. This will make your script easy to follow.\nExplanation: Include comments to explain any parts of your code that use techniques not covered in the course. This should provide enough detail for others to understand the purpose and functionality of your code.\n\nReproducibility: Ensure your R script is complete and reproducible, meaning anyone who runs it should be able to replicate your results without needing additional information.\nClarity: Write clear and concise comments throughout your code to enhance readability and comprehension. Avoid overly complex or redundant code.\nError Handling: Make sure your code runs smoothly without errors."
  },
  {
    "objectID": "danl-rw/danl-101-team-project.html#peer-evaluation",
    "href": "danl-rw/danl-101-team-project.html#peer-evaluation",
    "title": "Data Storytelling Team Project - Guideline",
    "section": "ü§ù Peer Evaluation",
    "text": "ü§ù Peer Evaluation\n\nIf a team member fails to collaborate on the project by December 1, 2025, 4:00 P.M. (Eastern Time), please send an email to bchoe@geneseo.edu and cc the non-collaborating team member in the email.\n\nIf the conflict is not resolved after the initial notification, the non-collaborating team member may receive a reduced or zero score for the project component, depending on the severity of their lack of participation. Prof.¬†Choe will follow up with both parties to attempt to mediate and address the issue fairly.\n\nEach student is required to evaluate the presentations of other teams. Peer evaluations will make up 5% of the total project score.\n\nAn Excel spreadsheet for the peer evaluation will be provided. Make sure to save the spreadsheet and submit it to Brightspace.\nFailure to complete the peer evaluation will result in a reduction of your class participation score.\nScore Calculation: For each category of Rubric 1-5, the four highest and four lowest scores will be dropped to ensure fairness when calculating the peer evaluation score."
  },
  {
    "objectID": "danl-rw/danl-101-proj-topic-choice.html",
    "href": "danl-rw/danl-101-proj-topic-choice.html",
    "title": "Topic Choice",
    "section": "",
    "text": "When you finish the questionnaire, click ‚ÄúSubmit‚Äù at the bottom of the page.\n\nAfter clicking ‚ÄúSubmit,‚Äù wait for the on-screen message ‚ÄúData submitted successfully!‚Äù just below the button.\nA confirmation email will be sent to the address you provide on this page once your submission is recorded.\n\nYou may submit more than once; only your most recent submission will be counted.\nDeadline: Friday, November 14, 2025 at 11:59 PM (Eastern Time).\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-hockey.html",
    "href": "danl-rw/danl-101-team-project-hockey.html",
    "title": "Data Storytelling Team Project - Hockey",
    "section": "",
    "text": "The following lists data frames about NHL:\n\nnhl_players: NHL Player Statistics for the 2014-2015 through 2023-2024 season.\n\n2076 unique NHL Players\n328 NHL players‚Äô salary information are missing.\n\nnhl_games: NHL Game Logs for the 2022-23 season\nData Source: MoneyPuck\n\nThere is a great website that makes a ton of hockey data available for download called MoneyPuck.\nAlmost all of their data are available as a .csv or a .zip file.\nYou can download this data using the links given on their download page. For example, here is how you could get all of the skater (i.e., nongoalie) information for the 2022‚Äì23 season:\n\nSalary Data Source: PuckPedia\n\n\n\n\nnhl_players: NHL non-goalie player data\n\nA data frame with 4620 observations and 158 variables:\n\n\n\nnhl_players &lt;- read_csv(\"http://bcdanl.github.io/data/nhl_players.csv\")\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnhl_games: NHL Game Logs\n\nA data frame with 14000 observations and 110 variables:\n\n\n\nnhl_games &lt;- read_csv(\"http://bcdanl.github.io/data/nhl_games.csv\")"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-hockey.html#nhl-players-nhl_players",
    "href": "danl-rw/danl-101-team-project-hockey.html#nhl-players-nhl_players",
    "title": "Data Storytelling Team Project - Hockey",
    "section": "",
    "text": "nhl_players: NHL non-goalie player data\n\nA data frame with 4620 observations and 158 variables:\n\n\n\nnhl_players &lt;- read_csv(\"http://bcdanl.github.io/data/nhl_players.csv\")"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-hockey.html#nhl-game-logs-nhl_games",
    "href": "danl-rw/danl-101-team-project-hockey.html#nhl-game-logs-nhl_games",
    "title": "Data Storytelling Team Project - Hockey",
    "section": "",
    "text": "nhl_games: NHL Game Logs\n\nA data frame with 14000 observations and 110 variables:\n\n\n\nnhl_games &lt;- read_csv(\"http://bcdanl.github.io/data/nhl_games.csv\")"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-hockey.html#corsi-and-fenwick-metrics",
    "href": "danl-rw/danl-101-team-project-hockey.html#corsi-and-fenwick-metrics",
    "title": "Data Storytelling Team Project - Hockey",
    "section": "Corsi and Fenwick Metrics",
    "text": "Corsi and Fenwick Metrics\nCorsi and Fenwick are two of the earliest advanced analytics used to measure player effectiveness in hockey. For over a century, traditional metrics such as goals, assists, and penalty minutes were the main tools for evaluating players. The plus-minus rating, which tracks the number of goals scored by a player‚Äôs team minus the goals allowed while they are on the ice, added some depth. However, this metric has a significant flaw: it often reflects the quality of a player‚Äôs teammates. For instance, a lower-skilled player might have a great plus-minus rating simply by playing alongside scoring superstars like Auston Matthews or Sidney Crosby.\nCorsi and Fenwick provide a more nuanced measure of effectiveness. Corsi calculates the difference in shot attempts (shots on goal, missed shots, and blocked shots) by a player‚Äôs team versus their opponents while the player is on the ice. Fenwick is similar but excludes blocked shots. Both metrics are typically applied to specific game situations, such as:\n\n5-on-5 (Even Strength): The most common game state, where each team has five skaters on the ice, excluding goalies. Corsi and Fenwick in this situation are considered the most reliable indicators of player performance since it minimizes the influence of special teams.\n5-on-4 (Power Play): A situation where the player‚Äôs team has a one-man advantage due to an opponent‚Äôs penalty. Metrics in this scenario provide insight into how effectively a player contributes to creating offensive opportunities.\n4-on-5 (Penalty Kill): A situation where the player‚Äôs team is at a one-man disadvantage. Here, Corsi and Fenwick can help measure a player‚Äôs ability to limit opponent shot attempts and maintain defensive stability.\nOther Situations: Includes rarer scenarios like 4-on-4, 3-on-3 overtime, or 6-on-5 when a team pulls its goalie for an extra attacker. Metrics in these cases are less common but still useful for specific analyses.\nAll Situations: Aggregates data from every possible game state, offering a broader view of a player‚Äôs performance but often less precise for evaluating specific roles or responsibilities.\n\nWhile these metrics are often expressed as raw differences, they can also be analyzed as percentages. For instance, we can calculate a player‚Äôs Corsi percentage by dividing the Corsi ‚Äúfor‚Äù (shot attempts by the player‚Äôs team) by the sum of the Corsi ‚Äúfor‚Äù and Corsi ‚Äúagainst‚Äù (shot attempts by the opposing team). This provides a clearer picture of a player‚Äôs overall effectiveness on the ice."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-hockey.html#time-on-ice-by-position",
    "href": "danl-rw/danl-101-team-project-hockey.html#time-on-ice-by-position",
    "title": "Data Storytelling Team Project - Hockey",
    "section": "Time on Ice by Position",
    "text": "Time on Ice by Position\nIt is rare for skaters to play even half of a game, unlike goalkeepers, who generally play the entire match. For this analysis, we will focus on skaters and exclude goalkeepers. Managing a team effectively requires ensuring players are not overly fatigued, especially during the final minutes of a game or during stretches with multiple games and minimal rest. To address this, we use the ‚Äútime on ice‚Äù (TOI) metric. TOI varies by position. NHL teams typically have four offensive lines (left wing, center, right wing) but only three defensive pairs. As a result, defensemen tend to play more minutes both in individual games and throughout the season. Special situations such as power plays or penalty kills can also affect TOI distribution. For instance:\n\nPower Plays (5-on-4): Offensive players on the power play units often have increased TOI in these scenarios to maximize scoring opportunities.\nPenalty Kills (4-on-5): Defensive players and penalty kill specialists tend to play more minutes during penalties to mitigate scoring threats.\nOvertime (3-on-3): In regular-season overtime, top players are typically deployed for longer shifts due to the fast-paced and open nature of play.\n\nUnderstanding TOI in these different contexts helps coaches optimize player utilization and prevent fatigue over the course of a game or season.\n\nGeneral Terms Description\n\nExpected Goals\n\nThe sum of the probabilities of unblocked shot attempts being goals.\nFor example, a rebound shot in the slot may be worth 0.5 expected goals, while a shot from the blueline while short handed may be worth 0.01 expected goals.\nThe expected value of each shot attempt is calculated by the MoneyPuck Expected Goals model.\nExpected goals is commonly abbreviated as ‚ÄúxGoals‚Äù. Blocked shot attempts are valued at 0 xGoals.\nSee more here: http://moneypuck.com/about.htm#shotModel\n\nScore Adjusted\n\nAdjusts metrics to gives more credit to away teams and teams with large leads.\n\nFlurry Adjusted\n\nSee http://moneypuck.com/about.htm#flurry\n\nI_F\n\n‚ÄúIndividual For‚Äù.\nFor stats credited to an individual.\nFor example, I_F_goals is the number of goals a player has scored\n\nOnIce_F\n\n‚ÄúOn-ice For‚Äù.\nEvery player on the ice on the team doing the event receives credit.\nOnIce_F_goals is the number of goals the player‚Äôs team has scored while that player is on the ice, regardless of if they were the one who scored the goal or not.\n\nOnIce_A\n\n‚ÄúOn-ice Against‚Äù.\nEvery opposing team‚Äôs players on the ice on receives credit. OnIce_A_goals is the number of goals the player‚Äôs team has given up while the player is on the ice\n\nOffIce_F\n\n‚ÄúOff-ice For‚Äù.\nEvery player on the bench of the team doing the event receives ‚Äúcredit‚Äù.\nOffIce_F_goals is the number of goals the player‚Äôs team has scored while that player is on the bench.\n\nOffIce_A\n\n‚ÄúOff-ice Against‚Äù.\nEvery player on the opposing team‚Äôs bench of the team doing the event receives ‚Äúcredit‚Äù.\nOffIce_A_goals is the number of goals the player‚Äôs team has given up while that player is on the bench.\n\nLow Danger Shots\n\nUnblocked Shot attempts with a &lt; 8% probability of being a goal. Low danger shots accounts for ~75% of shots and ~33% of goals\n\nMedium Danger Shots\n\nUnblocked Shot attempts with between &gt;=8% but less than 20% probability of being a goal.\nMedium danger shots account for ~20% of shots and ~33% of goals\n\nHigh Danger Shots\n\nUnblocked Shot attempts with &gt;= 20% probability of being a goal.\nHigh danger shots account for ~5% of shots and ~33% of goals\n\nCreated Expected Goals\n\nSee http://moneypuck.com/about.htm#xRebounds"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#geneseo-alumni-career-talk",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#geneseo-alumni-career-talk",
    "title": "Lecture 8",
    "section": "Geneseo Alumni Career Talk",
    "text": "Geneseo Alumni Career Talk"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#geneseo-alumni-career-talk-1",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#geneseo-alumni-career-talk-1",
    "title": "Lecture 8",
    "section": "Geneseo Alumni Career Talk",
    "text": "Geneseo Alumni Career Talk\n\n\n\nJaehyung Lee\n\nClass of 2022\nMajor in Mathematics\nConcentration in Data Analytics\n\nView Introduction Video 1\n\nView Introduction Video 2\n\nJason Rappazzo\n\nClass of 2023\nMajor in Economics\nMinor in Data Analytics\n\nView Introduction Video\n\n\n\n\nOliver Stordahl\n\nClass of 2022\nMajor in Economics\nMinor in Mathematics\nMinor in Data Analytics\nListen to Introduction Audio"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-jaehyung-and-jason",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-jaehyung-and-jason",
    "title": "Lecture 8",
    "section": "Q & A from Jaehyung and Jason",
    "text": "Q & A from Jaehyung and Jason\n\n\n\nHow do your teams work with big-tech partners to provide AI models? How have generative AI tools changed your workflow?\n\n\nView Video 1\nView Video 2\nView Video 3\n\n\nFor someone who wants to start a business, which AI capabilities would you prioritize learning or adopting first?\n\n\nView Video\n\n\n\nWhat led you to pursue a career in data analytics‚Äîwas it a long-term plan or something you discovered along the way?\n\n\nView Video 1\nView Video 2\n\n\nAfter graduation, which career decision helped you the most?\n\n\nView Video 1\nView Video 2"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-jaehyung-and-jason-1",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-jaehyung-and-jason-1",
    "title": "Lecture 8",
    "section": "Q & A from Jaehyung and Jason",
    "text": "Q & A from Jaehyung and Jason\n\n\n\nWhen should students begin exploring and applying for internships? What timeline do you recommend?\n\n\nView Video\n\n‚ÄúThe more internship, the better. The earlier, the better as well.‚Äù Jaehyung Andy Lee\n\n\n\n\nWhich tools‚Äîand which AI tools‚Äîdo you use most in your current role?\n\n\nView Video\n\n\nWhat challenges have you faced at work, and how did you overcome them?\n\n\nView Video 1\nView Video 2"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver",
    "title": "Lecture 8",
    "section": "Q & A from Oliver",
    "text": "Q & A from Oliver\n\nHow have generative AI tools changed your workflow at the Federal Reserve? What is your opinion on their impact ‚Äî both on your own work and on the data analytics industry more broadly?\n\n\nListen to Audio\n\n\nWhat made you choose Economics as your major, and why did you decide to add Mathematics and Data Analytics as minors?\n\n\nListen to Audio\n\n\nYou participated in Fed Challenge and FDIC Challenge during college. How did those experiences influence your learning, professional development, and career preparation?\n\n\nListen to Audio"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver-1",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver-1",
    "title": "Lecture 8",
    "section": "Q & A from Oliver",
    "text": "Q & A from Oliver\n\nWhat kinds of backgrounds do your colleagues have at the Federal Reserve? Do they share similar academic paths to yours, or do they come from different disciplines?\n\n\nListen to Audio\n\n\nWhen you were job searching and interviewing, what qualities or skills did employers seem to value the most? Beyond technical ability, what stood out as important during your conversations with them?\n\n\nListen to Audio\n\n\nHow was the transition between different coding languages and tools (e.g., R, Python, Alteryx, SQL) in your work?\n\n\nListen to Audio"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver-2",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver-2",
    "title": "Lecture 8",
    "section": "Q & A from Oliver",
    "text": "Q & A from Oliver\n\nLooking back, how difficult was it to learn coding during college, and what strategies helped you gain confidence in programming?\n\n\nListen to Audio\n\n\nWhat aspects of your current role do you find the most rewarding or meaningful ‚Äî personally or professionally?\n\n\nListen to Audio\n\n\nHow did you adjust from being a college student to working full time? What changes in lifestyle or mindset did you experience during that transition?\n\n\nListen to Audio"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver-3",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a-from-oliver-3",
    "title": "Lecture 8",
    "section": "Q & A from Oliver",
    "text": "Q & A from Oliver\n\nWhat were some of the biggest challenges you faced early in your job, and how did you manage to overcome them?\n\n\nListen to Audio\n\n\nWhen you encountered unfamiliar tasks or uncertainty at work, what kinds of support systems or resources helped you succeed?\n\n\nListen to Audio\n\n\nDuring college, what helped you develop your programming and analytical skills most effectively ‚Äî coursework, practice, projects, or office hours?\n\n\nListen to Audio"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#roles-workflows",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#roles-workflows",
    "title": "Lecture 8",
    "section": "üß© Roles & Workflows",
    "text": "üß© Roles & Workflows\n\nJaehyung (AI Enablement / Analytics at Invisible Technologies)\n\nWorks with AI model companies like OpenAI, Cohere, Google DeepMind\nManages data pipelines, automation, and analytics with 20,000+ distributed agents\nEmphasized Streamlit apps, personal data projects, and building tools beyond class assignments"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#roles-workflows-1",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#roles-workflows-1",
    "title": "Lecture 8",
    "section": "üß© Roles & Workflows",
    "text": "üß© Roles & Workflows\n\nJason (Data Engineer at Momentive)\n\nWorks in IT data engineering, integrating ERP, Workday, travel, HR data into Snowflake\nBuilds Tableau dashboards and automated data pipelines for business decision-making\nTransitioned from internship ‚Üí full-time by demonstrating value through small data tools"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#lessons-on-career-preparation",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#lessons-on-career-preparation",
    "title": "Lecture 8",
    "section": "üí° Lessons on Career Preparation",
    "text": "üí° Lessons on Career Preparation\n\nPersonal Projects &gt; Just Coursework\n\nBuild one deep project you can talk about‚Äîmore powerful than many shallow demos\n\nInternships: Ideally by junior year, but personal projects + outreach can substitute\nNetworking: Reaching out to alumni on LinkedIn works‚Äîalumni want to help\nData Career Reality: Messy data, stakeholder communication, iteration, and revisions matter more than ‚Äúperfect code‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#ai-modern-workflow-changes",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#ai-modern-workflow-changes",
    "title": "Lecture 8",
    "section": "ü§ñ AI & Modern Workflow Changes",
    "text": "ü§ñ AI & Modern Workflow Changes\n\n60‚Äì80% of analytics/engineering code now written with AI assistants (Claude, Copilot)\n‚ÄúVibe coding‚Äù ‚Üí prompting AI to generate logic flows instead of hand-coding everything\nStill requires human review ‚Üí AI amplifies analysts, not replaces them\nData sensitivity & responsible AI use are now core skills (Copilot within secure environment)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#mindset-professional-growth",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#mindset-professional-growth",
    "title": "Lecture 8",
    "section": "üß≠ Mindset & Professional Growth",
    "text": "üß≠ Mindset & Professional Growth\n\nDon‚Äôt just execute requests ‚Äî ask ‚Äúwhy‚Äù and co-design solutions with stakeholders\nAvoid taking feedback personally ‚Äî debugging business logic is normal\nStay adaptable ‚Äî small teams + AI enable startup-style speed, even inside large companies"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#skills-tools-to-prioritize",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#skills-tools-to-prioritize",
    "title": "Lecture 8",
    "section": "‚úÖ Skills & Tools to Prioritize",
    "text": "‚úÖ Skills & Tools to Prioritize\n\nCoding Fundamentals Matter ‚Äî Python, SQL, R (to understand and correct AI-generated code)\nStreamlit / App Building ‚Äî both alumni mentioned it as a direct advantage\nData Pipeline Understanding ‚Äî Snowflake, ETL logic, API data ingestion\n\nüí° API (Application Programming Interface): A structured way for one software or system to communicate with another ‚Äî allowing programs to request data or trigger actions automatically, without using a manual interface (e.g., a browser).\n\nExample: The Google Maps API lets applications access location, routing, and distance data programmatically.\n\nDashboarding / Visualization ‚Äî Tableau or Shiny (used in internship-to-job pipeline)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#real-data-work-beyond-clean-csvs",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#real-data-work-beyond-clean-csvs",
    "title": "Lecture 8",
    "section": "üß† Real Data Work = Beyond Clean CSVs",
    "text": "üß† Real Data Work = Beyond Clean CSVs\n\nMessy, inconsistent corporate data is normal\nAnalysts must reshape, clean, validate, and question data\nUAT (User Acceptance Testing) ‚Üí users will question your output; don‚Äôt take it personally\nCommunication = Core skill"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#communication-stakeholder-logic",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#communication-stakeholder-logic",
    "title": "Lecture 8",
    "section": "üí¨ Communication & Stakeholder Logic",
    "text": "üí¨ Communication & Stakeholder Logic\n\nDon‚Äôt just deliver what‚Äôs asked ‚Äî ask ‚ÄúWhat decision will this data support?‚Äù\nStakeholders often don‚Äôt know what they need\nYou become the data advisor, not just the ‚ÄúSQL person‚Äù\nWork smart, not just hard ‚Äî clarify goals before coding dashboards"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#personal-projects-career-currency",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#personal-projects-career-currency",
    "title": "Lecture 8",
    "section": "üß™ Personal Projects = Career Currency",
    "text": "üß™ Personal Projects = Career Currency\n\nQuality &gt; Quantity ‚Äî one deep project beats five generic Kaggle plots\n\nKaggle ‚Äî a platform for data science competitions, datasets, and collaborative notebooks.\n\nJaehyung used a self-tracked life project to stand out in interviews\nUse class projects as foundation, then extend them your own way"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#internships-entry-points",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#internships-entry-points",
    "title": "Lecture 8",
    "section": "üéì Internships & Entry Points",
    "text": "üéì Internships & Entry Points\n\nCommon internship timing: Summer before senior year\nNo internship? ‚Üí personal projects + LinkedIn outreach still work, but having internship experience would be more beneficial\nAlumni emphasized: ‚ÄúIf a Geneseo student messages me, I feel responsible to reply.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#how-ai-actually-fits-into-data-jobs",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#how-ai-actually-fits-into-data-jobs",
    "title": "Lecture 8",
    "section": "ü§ñ How AI Actually Fits Into Data Jobs",
    "text": "ü§ñ How AI Actually Fits Into Data Jobs\n\n80% of daily code now AI-assisted\n‚ÄúVibe coding‚Äù = prompting AI to write working SQL/Python snippets\nHuman oversight remains essential\nCompany policies differ ‚Äî many only allow Copilot or internal AI"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#data-ethics-security-awareness",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#data-ethics-security-awareness",
    "title": "Lecture 8",
    "section": "üõ° Data Ethics & Security Awareness",
    "text": "üõ° Data Ethics & Security Awareness\n\nNever paste confidential data into public AI tools\nUse secure AI (e.g., Microsoft Copilot) within company systems\nUnderstanding governance & privacy = part of professional data practice"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#career-mindset-recalibration",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#career-mindset-recalibration",
    "title": "Lecture 8",
    "section": "üß≠ Career Mindset Recalibration",
    "text": "üß≠ Career Mindset Recalibration\n\nBig Tech ‚â† only path ‚Äî small, AI-enabled startups thrive\nSolo founders can build functional apps with AI + data pipelines\n‚ÄúBest time in history to build something‚Äîdon‚Äôt just consume.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#olivers-career-path",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#olivers-career-path",
    "title": "Lecture 8",
    "section": "üíº Oliver‚Äôs Career Path",
    "text": "üíº Oliver‚Äôs Career Path\n\nJoined the Statistics Department at the Federal Reserve Bank of New York\n\nDepartment Role:\n\nCollects and processes regulatory data from banks\n\nEnsures data accuracy and detects anomalies\n\nCommunicates with reporting institutions to verify discrepancies\n\n\nUses Python, SQL, and Excel daily\n\nTransitioning from Alteryx to Python workflows\n\nüí° Note: Alteryx is a visual data analytics platform that allows users to prepare, clean, and analyze data through a drag-and-drop interface ‚Äî often used in industry for building workflows without extensive coding."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#daily-responsibilities",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#daily-responsibilities",
    "title": "Lecture 8",
    "section": "üß† Daily Responsibilities",
    "text": "üß† Daily Responsibilities\n\nMaintain and analyze regulatory datasets (hundreds of banks, monthly reports)\n\nPerform data transformation, cleaning, and aggregation\n\nIdentify anomalies and follow up with banks for clarification\n\nDevelop efficient data pipelines and quality assurance checks"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#generative-ai-in-the-workplace",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#generative-ai-in-the-workplace",
    "title": "Lecture 8",
    "section": "ü§ñ Generative AI in the Workplace",
    "text": "ü§ñ Generative AI in the Workplace\n\nThe Fed prohibits public AI tools (e.g., ChatGPT) due to data sensitivity\n\nUses a secure in-house generative AI system\n\nOliver‚Äôs perspective:\n\nAI is excellent for routine transformations and debugging\nAnalysts still need domain understanding and context awareness\n‚ÄúYou need to know what you‚Äôre asking it to do‚Äîand what the right answer looks like.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#choosing-majors-and-minors",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#choosing-majors-and-minors",
    "title": "Lecture 8",
    "section": "üßÆ Choosing Majors and Minors",
    "text": "üßÆ Choosing Majors and Minors\n\nInitially unsure of major; inspired by a pop economics book (e.g., Freakonomics)\n\nChose Economics for its analytical and real-world reasoning value\n\nAdded Mathematics and Data Analytics:\n\nEnjoyed quantitative reasoning and problem-solving\nThe Data Analytics minor was newly introduced (2022)\nSaw its strong career relevance"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#experiential-learning-competitions",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#experiential-learning-competitions",
    "title": "Lecture 8",
    "section": "üèÜ Experiential Learning: Competitions",
    "text": "üèÜ Experiential Learning: Competitions\n\nParticipated in:\n\nFed Challenge\nFDIC (Federal Deposit Insurance Corporation) Challenge\n\nBenefits:\n\nProvided real-world data experience\nDeveloped strong communication and teamwork skills\nCreated interview stories to discuss challenges and teamwork\nImproved Excel visualization and data storytelling skills\n\n\n‚ÄúThese challenges give you something distinctive to talk about in interviews.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#workplace-environment",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#workplace-environment",
    "title": "Lecture 8",
    "section": "üë• Workplace Environment",
    "text": "üë• Workplace Environment\n\nTeam composed of diverse professionals:\n\nFormer accountants, consultants, and government analysts\n\nIncludes another Geneseo alum (Maddie Maline Katz, Class of 2019)\n\nEmphasis on collaboration and mentorship\nStrong internal support for learning new tools and methods"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---1.-interview-preparation",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---1.-interview-preparation",
    "title": "Lecture 8",
    "section": "üó£Ô∏è Q & A - 1. Interview Preparation",
    "text": "üó£Ô∏è Q & A - 1. Interview Preparation\n\nExpect standard behavioral questions\n‚ÄúYou should walk into an interview knowing your answers to:\n\n‚ÄòWhy this job?‚Äô\n‚ÄòTell me about a time you faced a challenge.‚Äô‚Äù\n\nEmployers value preparation and clarity more than extensive experience."
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---2.-transition-to-work-life",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---2.-transition-to-work-life",
    "title": "Lecture 8",
    "section": "üó£Ô∏è Q & A - 2. Transition to Work Life",
    "text": "üó£Ô∏è Q & A - 2. Transition to Work Life\n\n‚ÄúCollege gives you more free time than you‚Äôll ever have again.‚Äù\nFull-time work (40+ hours + commute) requires time management\n\nImportance of being intentional about personal growth and hobbies"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---3.-learning-to-code",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---3.-learning-to-code",
    "title": "Lecture 8",
    "section": "üó£Ô∏è Q & A - 3. Learning to Code",
    "text": "üó£Ô∏è Q & A - 3. Learning to Code\n\nTransitioning between tools (R, Python, Alteryx):\n\n‚ÄúOnce you know what you want to do with the data, syntax differences don‚Äôt matter.‚Äù\n\nKey takeaway:\n\nConceptual understanding of data transformation &gt; memorizing syntax\n\nConsistent practice and projects build fluency"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---4.-most-rewarding-aspects",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---4.-most-rewarding-aspects",
    "title": "Lecture 8",
    "section": "üó£Ô∏è Q & A - 4. Most Rewarding Aspects",
    "text": "üó£Ô∏è Q & A - 4. Most Rewarding Aspects\n\nSolving data problems and building solutions quickly\nSatisfaction from turning requests into usable visualizations\nFeels fulfillment as a public servant contributing to national financial oversight"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---5.-challenges-and-growth",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---5.-challenges-and-growth",
    "title": "Lecture 8",
    "section": "üó£Ô∏è Q & A - 5. Challenges and Growth",
    "text": "üó£Ô∏è Q & A - 5. Challenges and Growth\n\nLearning report-specific finance and accounting concepts\nInterpreting large financial datasets (e.g., repurchase agreements)\nOvercame initial struggles via:\n\nMentorship from senior staff\nReport specialists for regulatory interpretation\nA collaborative, knowledge-sharing workplace"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---6.-developing-programming-skills",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---6.-developing-programming-skills",
    "title": "Lecture 8",
    "section": "üó£Ô∏è Q & A - 6. Developing Programming Skills",
    "text": "üó£Ô∏è Q & A - 6. Developing Programming Skills\n\n‚ÄúThere‚Äôs no shortcut ‚Äî do your assignments.‚Äù\n\nSkills built through:\n\nHomework and repetition\n\nApplying code in competitions (Fed Challenge)\n\nOffice hours and project feedback (notably DANL 300-level project)\n\n\nEmphasized hands-on learning and visual thinking when coding"
  },
  {
    "objectID": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---key-takeaway",
    "href": "danl-lec/danl-101-lec-08-2025-1024.html#q-a---key-takeaway",
    "title": "Lecture 8",
    "section": "üó£Ô∏è Q & A - üß≠ Key Takeaway",
    "text": "üó£Ô∏è Q & A - üß≠ Key Takeaway\n\nüîπ Start exploring early ‚Äî even without clear goals, exposure builds direction\n\nüîπ Participate in challenges ‚Äî showcase applied skills\n\nüîπ Prepare well for interviews ‚Äî know your behavioral answers\n\nüîπ Practice coding ‚Äî consistent repetition is the best teacher\n\nüîπ Use your free time wisely ‚Äî college is your training ground\n\nüîπ Public sector roles offer purpose, but problem-solving passion is universal"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#why-data-analytics",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#why-data-analytics",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nFill in the gaps left by traditional business and economics classes.\n\nPractical skills that will benefit your future career.\nNeglected skills like how to actually find datasets in the wild and clean them.\n\nData analytics skills are largely distinct from (and complementary to) the core quantitative works familiar to business undergrads.\n\nData visualization, cleaning and wrangling; databases; machine learning; etc.\n\nIn short, we will cover things that I wish someone had taught me when I was undergraduate."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#you-at-the-end-of-this-course",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#you-at-the-end-of-this-course",
    "title": "Lecture 2",
    "section": "You, at the end of this course",
    "text": "You, at the end of this course"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#why-data-analytics-1",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#why-data-analytics-1",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nData analysts use analytical tools and techniques to extract meaningful insights from data.\n\nSkills in data analytics are also useful for business analysts, market analysts, financial analysts, human resource analysts, or economists.\n\nBreau of Labor Statistics forecasts that the projected growth rate of the employment in the industry related to data analytics from 2021 to 2031 is 36%.\n\nThe average growth rate for all occupations is 5%."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#why-r-python-and-databases",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#why-r-python-and-databases",
    "title": "Lecture 2",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#why-r-python-and-databases-1",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#why-r-python-and-databases-1",
    "title": "Lecture 2",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?\nStack Overflow Trends\n\n\nStack Overflow is the most popular Q & A website specifically for programmers and software developers in the world.\nSee how programming languages have trended over time based on use of their tags in Stack Overflow from 2008 to 2023.\n\n\n\n\nMost Popular Languagues\n\n\nData Science and Big Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#data-analytics-and-generative-artificial-intelligence-ai",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#data-analytics-and-generative-artificial-intelligence-ai",
    "title": "Lecture 2",
    "section": "Data Analytics and Generative Artificial Intelligence (AI)",
    "text": "Data Analytics and Generative Artificial Intelligence (AI)\n\n\nData Analytics and Big Data Trend\nFrom 2008 to 2025\n\n\nProgrammers in 2025"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#data-analytics-and-generative-ai",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#data-analytics-and-generative-ai",
    "title": "Lecture 2",
    "section": "Data Analytics and Generative AI",
    "text": "Data Analytics and Generative AI\n\nGenerative AI refers to a category of AI that is capable of generating new content, ranging from text, images, and videos to music and code.\n\n\n\nIn the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input.\n\nThese include large language model (LLM) chatbots (e.g., ChatGPT, Claude, Gemini, Copilot, Grok).\n\nChatGPT (Chat Generative Pre-trained Transformer) is a chatbot developed by OpenAI and launched on November 30, 2022.\n\nBy January 2023, it had become what was then the fastest-growing consumer software application in history."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#data-analytics-and-generative-ai-1",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#data-analytics-and-generative-ai-1",
    "title": "Lecture 2",
    "section": "Data Analytics and Generative AI",
    "text": "Data Analytics and Generative AI\n\nUsers around the world have explored how to best utilize GPT for writing essays and programming codes.\n\n\n\n\nIs AI a threat to data analytics?\n\nFundamental understanding of the subject matter is still crucial for effectively utilizing AI‚Äôs capabilities.\n\n\n\n\n\nIf you use Generative AI such as ChatGPT, please try to understand what ChatGPT gives you.\n\nCopying and pasting it without any understanding harms your learning opportunity."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-r",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-r",
    "title": "Lecture 2",
    "section": "What is R?",
    "text": "What is R?\n\nR is a programming language and software environment designed for statistical computing and graphics.\nR has become a major tool in data analysis, statistical modeling, and visualization.\n\nIt is widely used among statisticians and data scientists for developing statistical software and performing data analysis.\nR is open source and freely available."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-rstudio",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-rstudio",
    "title": "Lecture 2",
    "section": "What is RStudio?",
    "text": "What is RStudio?\n\nRStudio is an integrated development environment (IDE) for R.\n\nAn IDE is a software application that provides comprehensive facilities (e.g., text code editor, graphical user interface (GUI) to computer programmers for software development.\n\nRStudio is a user-friendly interface that makes using R easier and more interactive.\n\nIt provides a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging, and workspace management.\n\nWe will use a free cloud version of RStudio, which is Posit Cloud."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-python",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-python",
    "title": "Lecture 2",
    "section": "What is Python?",
    "text": "What is Python?\n\nPython is a versatile programming language known for its simplicity and readability.\nPython has become a dominant tool in various fields including data analysis, machine learning, and web development.\n\nIt is widely used among developers, data scientists, and researchers for building applications and performing data-driven tasks.\nPython is open source and has a vast ecosystem of libraries and frameworks."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-jupyter",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-jupyter",
    "title": "Lecture 2",
    "section": "What is Jupyter?",
    "text": "What is Jupyter?\n\nJupyter is an open-source integrated development environment (IDE) primarily for Python, though it supports many other languages.\n\nJupyter provides a notebook interface that allows users to write and execute code in a more interactive and visual format.\n\nJupyter Notebook is a user-friendly environment that enhances coding, data analysis, and visualization.\n\nIt offers a web-based interface that combines live code, equations, visualizations, and narrative text.\nJupyter is widely used for data science, machine learning, and research, enabling easy sharing and collaboration.\n\nYou can use a free cloud version of Jupyter, which is Google Colab.\n\nGoogle Colab can be used for R as well."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#python-vs.-r",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#python-vs.-r",
    "title": "Lecture 2",
    "section": "Python vs.¬†R",
    "text": "Python vs.¬†R"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-git",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-git",
    "title": "Lecture 2",
    "section": "What is Git?",
    "text": "What is Git?\n\n\n\n\n\\(\\quad\\)\n\nGit is the most popular version control tool for any software development.\n\nIt tracks changes in a series of snapshots of the project, allowing developers to revert to previous versions, compare changes, and merge different versions.\nIt is the industry standard and ubiquitous for coding collaboration."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-github",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-github",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nGitHub is a web-based hosting platform for Git repositories to store, manage, and share code.\nOur course website is hosted on a GitHub repository.\nCourse contents will be posted not only in Brightspace but also in my GitHub repositories (‚Äúrepos‚Äù).\nGithub is useful for many reasons, but the main reason is how user friendly it makes uploading and sharing code."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-github-1",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-github-1",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-machine-learning",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#what-is-machine-learning",
    "title": "Lecture 2",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning (ML) algorithm allows computers to learn from data and improve at tasks without being explicitly programmed (i.e., without fixed step-by-step rules).\nHow Does It Work?\n\nThe computer is provided with large amounts of data.\nIt uses statistical algorithms to discover patterns in the data.\nFrom these patterns, it can make predictions, classify information, or group similar items together (clustering)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#ml-example-1-image-recognition",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#ml-example-1-image-recognition",
    "title": "Lecture 2",
    "section": "ML Example 1: Image Recognition üñºÔ∏è",
    "text": "ML Example 1: Image Recognition üñºÔ∏è\n\n\n\n\n\nTraditional programming:\n\nTry to define a ‚Äúcat‚Äù in code (pointy ears, whiskers, etc.). Very hard!\n\nMachine learning:\n\nShow the computer thousands of pictures labeled cat or not cat.\n\nIt learns the patterns in pixels and can recognize new cat photos."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#ml-example-2-music-recommendations",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#ml-example-2-music-recommendations",
    "title": "Lecture 2",
    "section": "ML Example 2: Music Recommendations üéµ",
    "text": "ML Example 2: Music Recommendations üéµ\n\n\n\n\n\nTraditional programming:\n\nCode rules like: ‚ÄúIf a user likes pop songs, recommend other pop songs.‚Äù\n\nMachine learning:\n\nUse data from millions of listeners.\n\nThe algorithm finds hidden patterns (e.g., ‚ÄúPeople who like Artist A often also like Artist B‚Äù).\n\nThen it recommends songs you might enjoy."
  },
  {
    "objectID": "danl-lec/danl-101-lec-02-2025-0827.html#ml-example-3-spam-email-detection",
    "href": "danl-lec/danl-101-lec-02-2025-0827.html#ml-example-3-spam-email-detection",
    "title": "Lecture 2",
    "section": "ML Example 3: Spam Email Detection üìß",
    "text": "ML Example 3: Spam Email Detection üìß\n\n\n\n\n\nTraditional programming:\n\nWrite rules like: ‚ÄúIf an email contains the word ‚Äòlottery,‚Äô mark it as spam.‚Äù\n\nMachine learning:\n\nProvide thousands of emails labeled spam or not spam.\n\nThe computer learns the patterns and applies them to new emails."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#sports-analytics",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#sports-analytics",
    "title": "Lecture 3",
    "section": "Sports Analytics",
    "text": "Sports Analytics\nMoneyball‚Äôs Impact\n\n\n\n\n\n\n\n\n\nThe use of data analytics for sports was popularized by the Moneyball book by Michael Lewis in 2003 and the movie starring Brad Pitt and Jonah Hill in 2011."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#what-is-sports-analytics",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#what-is-sports-analytics",
    "title": "Lecture 3",
    "section": "What is Sports Analytics?",
    "text": "What is Sports Analytics?\n\nSports analytics is the use of data analysis and statistical techniques, such as, machine learning, to evaluate and improve the performance of athletes, teams, and organizations in sports.\nIt involves collecting and analyzing data related to various aspects of sports:\n\nPlayer Performance Analysis\nTeam Tactics Analysis\nInjury Prevention and Recovery\nRecruitment and Scouting\nFan Engagement and Business Operations"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#fan-analytics",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#fan-analytics",
    "title": "Lecture 3",
    "section": "1. Fan Analytics",
    "text": "1. Fan Analytics\n\n\n\nSeason Ticket Renewals‚ÄîLikelihood to Purchase Again\n\n\n\n\n\n\ne.g., 69% of fans in Tier 1 seats who said on the survey that they would ‚Äúprobably not‚Äù renew actually did.\nThe types of questions for fan analytics would be:\n\nHow can we best allocate our marketing efforts using insights from the survey?\nWhy do season ticket holders renew their tickets?\nWhat factors drive last-minute individual seat ticket purchases?\nHow to price the tickets?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#fan-analytics-1",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#fan-analytics-1",
    "title": "Lecture 3",
    "section": "1. Fan Analytics",
    "text": "1. Fan Analytics\n\n\n\n\nBusiness offices at sports team do dynamic pricing:\n\nIt adjusts ticket prices based on various factors such as the team‚Äôs performance, opponent, game time, and real-time data like weather and traffic."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#team-tactics",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#team-tactics",
    "title": "Lecture 3",
    "section": "2. Team Tactics",
    "text": "2. Team Tactics\nDecision Tree for Run or Pass Plays in Football\n\n\n\nPredicting Run or Pass in the Next Play\n\n\n\nA decision tree is a machine learning model that makes decisions by splitting data into branches based on input variables.\n\nOff_Pers: Offensive Personnel (e.g., Value ‚Äú11‚Äù meaning 1 running back, 1 tight end, and 3 wide receivers)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#team-tactics-1",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#team-tactics-1",
    "title": "Lecture 3",
    "section": "2. Team Tactics",
    "text": "2. Team Tactics\nDecision Tree for Run or Pass Plays in Football\n\n\n\nPredicting Run or Pass in the Next Play\n\n\n\nIf a football team sees an opponent team‚Äôs personnel formation that looks like a pass, and it is third or fourth down with more than 5 yards to go, how likely would the opponent team pass in the next play?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#player-performance-the-case-of-hockey",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#player-performance-the-case-of-hockey",
    "title": "Lecture 3",
    "section": "3. Player Performance: The Case of Hockey",
    "text": "3. Player Performance: The Case of Hockey\n\n\\[\nPM \\,=\\, (\\text{Number of his team's goal}) \\,-\\, (\\text{Number of opponent team's goal})\n\\]\n\nThe player ‚Äúplus-minus‚Äù (PM) is a common hockey performance metric.\nThe limits of this approach are obvious:\n\nThere is no accounting for teammates or opponents.\nIn hockey, where players tend to be grouped together on ‚Äúlines‚Äù and coaches will ‚Äúline match‚Äù against opponents, a player‚Äôs PM can be artificially inflated or deflated by the play of his opponents and peers.\n\nHere, we instead use machine learning methods to analyze how likely making a goal is associated with whether or not a player is on the ice."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#player-performance-the-case-of-hockey-1",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#player-performance-the-case-of-hockey-1",
    "title": "Lecture 3",
    "section": "3. Player Performance: The Case of Hockey",
    "text": "3. Player Performance: The Case of Hockey\nData\n\nThe data comprise of play-by-play NHL game data for regular and playoff games during 11 seasons of 2002-2003 through 2013-2014.\nThere were 2,439 players involved in 69,449 goals.\nThe data contains information that indicates:\n\nSeasons\nHome & away teams\nTeam configuration such as 5 on 4 powerplay\nWhich players are on & off the ice when a goal is made."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#player-performance-the-case-of-hockey-2",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#player-performance-the-case-of-hockey-2",
    "title": "Lecture 3",
    "section": "3. Player Performance: The Case of Hockey",
    "text": "3. Player Performance: The Case of Hockey\n\n\n\n\n\nPeter Forsberg\n\n\n\n\n\n\nSidney Crosby\n\n\n\n\n\nHow is the presence of a legend player (e.g., Peter Forsberg or Sidney Crosby) associated with the likelihood of making a goal?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#what-is-bi",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#what-is-bi",
    "title": "Lecture 3",
    "section": "What is BI?",
    "text": "What is BI?\n\n\n\n\n\n\n\n\n\n\n\n\nBusiness Intelligence (BI) is a process that involves the collection, integration, analysis, and presentation of business data to support better decision-making.\nHow Does It Work?\n\nData Collection: Gathering data from various sources, like databases.\nData Integration: Combining data into a unified view.\nData Analysis: Identifying trends and insights from data.\nReporting and Visualization: Displaying data via dashboards, reports, and visualizations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#popular-bi-tools",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#popular-bi-tools",
    "title": "Lecture 3",
    "section": "Popular BI tools",
    "text": "Popular BI tools\n  \n\nPython and R can also be BI tools."
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#what-is-a-dashboard",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#what-is-a-dashboard",
    "title": "Lecture 3",
    "section": "What is a Dashboard?",
    "text": "What is a Dashboard?\n\nA dashboard is a visual display of key information, data, and metrics, presented in a way that is easy to read and interpret at a glance.\nDashboard Examples:\n\nMicrosoft Power BI\nTableau\nLooker\nPython and R"
  },
  {
    "objectID": "danl-lec/danl-101-lec-03-2025-0903.html#purpose-of-ml-and-bi-in-business",
    "href": "danl-lec/danl-101-lec-03-2025-0903.html#purpose-of-ml-and-bi-in-business",
    "title": "Lecture 3",
    "section": "Purpose of ML and BI in Business",
    "text": "Purpose of ML and BI in Business\n\nInformed Decision-Making\n\nUse data-driven insights from ML and BI to guide both strategic and day-to-day decisions.\n\nPerformance Monitoring\n\nTrack key performance indicators (KPIs) and metrics to measure progress and ensure business goals are on track.\n\nData Visualization\n\nTurn complex data into clear and effective visuals that make insights easier to understand and act on.\n\nOperational Efficiency\n\nDetect bottlenecks, reduce waste, and uncover areas for improvement within business processes."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#structured-data-vs.-unstructured-data",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#structured-data-vs.-unstructured-data",
    "title": "Lecture 7",
    "section": "Structured Data vs.¬†Unstructured Data",
    "text": "Structured Data vs.¬†Unstructured Data\n\n\n\n\n\n\n\n\n\nData comes in various formats.\n\nStructured data: Has a predefined format, fits into traditional databases.\nUnstructured data: Not organized in a predefined manner, comes from sources like documents, social media, emails, photos, videos, etc."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#data-types-overview",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#data-types-overview",
    "title": "Lecture 7",
    "section": "Data Types Overview",
    "text": "Data Types Overview\n\n\n\n\nCategorical Data: Data that can be divided into distinct categories based on some qualitative attribute.\n\nNominal Data\nOrdinal Data\n\n\n\n\nNumeric Data: Data that represents measurable quantities and can be subjected to mathematical algebra.\n\nInterval Data\nRatio Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#categorical-data---nominal",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#categorical-data---nominal",
    "title": "Lecture 7",
    "section": "Categorical Data - Nominal",
    "text": "Categorical Data - Nominal\n\n\n\n\nID\nAnimal\n\n\n\n\n1\nDog\n\n\n2\nCat\n\n\n3\nBird\n\n\n\n\nNominal Data: Categorical data where the categories have no intrinsic order or ranking.\nNo Order: Categories are simply different; there is no logical sequence.\nExamples:\n\nColors: Red, Blue, Green\nTypes of Animals: Dog, Cat, Bird"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#categorical-data---ordinal",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#categorical-data---ordinal",
    "title": "Lecture 7",
    "section": "Categorical Data - Ordinal",
    "text": "Categorical Data - Ordinal\n\n\n\n\nID\nEducation Level\n\n\n\n\n1\nBachelor‚Äôs\n\n\n2\nMaster‚Äôs\n\n\n3\nPhD\n\n\n\n\nOrdinal Data: Categorical data where the categories have a meaningful order or ranking.\nOrder Matters: Categories can be ranked or ordered, but the differences between categories are not necessarily uniform.\nExamples:\n\nEducation Levels: High School, Bachelor‚Äôs, Master‚Äôs, PhD\nCustomer Satisfaction: Poor, Fair, Good, Excellent"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#numeric-data---interval",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#numeric-data---interval",
    "title": "Lecture 7",
    "section": "Numeric Data - Interval",
    "text": "Numeric Data - Interval\n\n\n\n\nID\nTemperature (¬∞F)\n\n\n\n\n1\n70\n\n\n2\n80\n\n\n3\n90\n\n\n\n\nInterval Data: Numeric data where the differences between values are meaningful, but there is no true zero point.\nMeaningful Intervals: The difference between values is consistent.\nNo True Zero: Zero does not indicate the absence of the quantity.\nExamples:\n\nTemperature (¬∞F): Zero degrees does not mean no temperature.\nTime of Day in a 12-Hour Clock: Differences are meaningful, but there is no absolute zero."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#numeric-data---ratio",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#numeric-data---ratio",
    "title": "Lecture 7",
    "section": "Numeric Data - Ratio",
    "text": "Numeric Data - Ratio\n\n\n\n\nID\nHeight (cm)\nWeight (kg)\n\n\n\n\n1\n160\n55\n\n\n2\n175\n70\n\n\n3\n170\n65\n\n\n\n\nRatio Data: Numeric data with a true zero point, allowing for a full range of mathematical operations.\nMeaningful Ratios: Comparisons like twice as much or half as much are valid.\nTrue Zero: Zero indicates the absence of the quantity.\nExamples:\n\nHeight in Centimeters: Zero means no height.\nWeight in Kilograms: Zero means no weight."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#classwork-taxonomy-of-data",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#classwork-taxonomy-of-data",
    "title": "Lecture 7",
    "section": "Classwork: Taxonomy of Data",
    "text": "Classwork: Taxonomy of Data\nTry it out ‚Üí Classwork 7: Taxonomy of Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#what-is-a-database",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#what-is-a-database",
    "title": "Lecture 7",
    "section": "What Is a Database?",
    "text": "What Is a Database?\n\nA database (DB) is a structured collection of data stored electronically.\nA Database Management System (DBMS) is software that helps us:\n\nStore data (safely and efficiently)\nQuery data (like filter(), select())\nUpdate data while keeping everything consistent and valid\n\nExamples of DBMS:\n\nPostgreSQL / MySQL (used by websites and companies)\nGoogle BigQuery, Snowflake (large-scale analysis on cloud system)\nExcel / Google Sheets ‚Üí basic storage only ‚Äî not a full DBMS\n\n\n\n\n\n\n\n\nNote\n\n\n\nSQL stands for Structured Query Language, and a query simply means asking the data for something ‚Äî such as filtering rows, selecting columns, or combining information."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#etl-extract-transform-load",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#etl-extract-transform-load",
    "title": "Lecture 7",
    "section": "ETL: üì• Extract ‚ûú üîß Transform ‚ûú üíæ Load",
    "text": "ETL: üì• Extract ‚ûú üîß Transform ‚ûú üíæ Load\n\n\nETL is the data preparation workflow used in analytics.\n\n\n\n\n\n\n\n\nETL Step\n\n\nMeaning in Data Workflow\n\n\nExample in a Database Context\n\n\n\n\nExtract\n\n\nRetrieve raw data from an external source\n\n\nImporting a CSV, Google Sheet, app response, or web data into a temporary table\n\n\n\n\nTransform\n\n\nClean, reshape, and structure the data\n\n\nFiltering rows, selecting fields, and joining tables\n\n\n\n\nLoad\n\n\nStore the cleaned data for analysis\n\n\nWriting the final structured table into a database as the analysis-ready dataset\n\n\n\n\n\n\nIt makes raw data usable by making it clean, consistent, and connected before analysis begins."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#etl-extract-stage",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#etl-extract-stage",
    "title": "Lecture 7",
    "section": "üì• ETL ‚Äî Extract Stage",
    "text": "üì• ETL ‚Äî Extract Stage\n\nGoal: Collect raw data from external sources\n(Google Sheets, CSV/Excel files, survey tools, web exports, or app submissions).\nQuick Validation Check:\n\n‚úÖ Column names match expected schema\n\n‚úÖ Numeric fields contain numbers only (no symbols/text)\n\nStorage at this stage:\n\nRaw data is stored in a temporary DB area (like Google Sheets or CSV)\n\n‚ö†Ô∏è This is not yet the official DB ‚Äî just a collection point"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#etl-transform-stage",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#etl-transform-stage",
    "title": "Lecture 7",
    "section": "üîß ETL ‚Äî Transform Stage",
    "text": "üîß ETL ‚Äî Transform Stage\n\nGoal: Convert raw data into a clean, consistent, analysis-ready format\nIn DANL 101 using R (tidyverse):\n\nfilter() ‚Üí keep valid observations\nselect() ‚Üí keep relevant variables\n*_join() ‚Üí combine multiple tables/data.frames\n\nStorage at this stage:\n\nCleaning happens in memory, not yet in the final database\n\nThe Google Sheet + R behave like a database + DBMS system, with tidyverse acting as the query engine"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#etl-load-stage",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#etl-load-stage",
    "title": "Lecture 7",
    "section": "üíæ ETL ‚Äî Load Stage",
    "text": "üíæ ETL ‚Äî Load Stage\n\nGoal: Store the clean, final dataset as the official analysis table\nStorage at this stage:\n\nThe cleaned data is written to a database area (this becomes the official dataset for analysis)\n\nIn DANL 101 using R (tidyverse):\n\nThe final data.frame functions as our primary analysis dataset, used for:\n\nüìä Summaries ‚Äî descriptive statistics and numeric insights\n\nüìà Visualizations ‚Äî plots, charts, and dashboard elements\n\nüéØ Storytelling & Analysis ‚Äî interpreting and communicating insights\n\n\nTry it out ‚Üí Classwork 8: Databases ‚Äî Social Media Analytics."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#relational-data-thinking",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#relational-data-thinking",
    "title": "Lecture 7",
    "section": "Relational Data Thinking",
    "text": "Relational Data Thinking\n\nDuring the Transform step in ETL, our data becomes:\n\nClean, structured in tables, and organized with a shared key column\n\nAt this point, we start thinking like database analysts:\n\nEach table holds one type of data\nA key column links tables together\n\nIn real-world analytics, data rarely lives in a single big file.\n\nExample: one table stores student social media activity\n\nAnother table stores platform reference information\n\n\nTo analyze properly, we connect these tables using a key.\n\nIn R tidyverse: left_join()\nIn database language: a join operation"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#relational-databases",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#relational-databases",
    "title": "Lecture 7",
    "section": "Relational Databases",
    "text": "Relational Databases\n\n\nWhen multiple tables are linked by keys, this structure is called a relational database\n\n\n\n\n\n\n\n\n\n\n\ntab_project &lt;- \n  read_csv(\"https://bcdanl.github.io/data/rdb-project_table.csv\")\ntab_department &lt;- \n  read_csv(\"https://bcdanl.github.io/data/rdb-department_table.csv\")\ntab_manager &lt;- \n  read_csv(\"https://bcdanl.github.io/data/rdb-manager_table.csv\")\n\nA relational database organizes data into multiple related tables, called relations.\nEach table stores data about one type of entity (e.g., projects, departments, managers)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#relational-database-characteristics",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#relational-database-characteristics",
    "title": "Lecture 7",
    "section": "Relational Database Characteristics",
    "text": "Relational Database Characteristics\n\nData is stored in a data.frame (or table).\nEach row = an observation (or record).\nEach column = a variable (or attribute or field).\nEach table has a key ‚Äî a column that uniquely identifies each row.\nKeys allow us to link tables together.\nWe use queries (like filter(), select(), left_join()) to retrieve and combine data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#relational-tables-and-keys",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#relational-tables-and-keys",
    "title": "Lecture 7",
    "section": "Relational Tables and Keys",
    "text": "Relational Tables and Keys\n\n\n\n\n\nx &lt;- data.frame(\n    key = c(1, 2, 3),\n    val_x = c('x1', 'x2', 'x3')\n)\n\ny &lt;- data.frame(\n    key = c(1, 2, 4),\n    val_y = c('y1', 'y2', 'y3')\n)\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable (key).\nThe grey column represents the ‚Äúvalue‚Äù variable (val_x, val_y)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#joining-tables-with-left_join",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#joining-tables-with-left_join",
    "title": "Lecture 7",
    "section": "Joining Tables with left_join()",
    "text": "Joining Tables with left_join()\n\n\n\n\n\n\nx |&gt;\n  left_join(y)\n\nA left join keeps all rows from x and adds matching information from y.\nAmong the different join types, left_join() is the most commonly used join.\n\nIt does not lose information from your main data.frame (x) and simply attaches extra information (y) when it exists.\n\nTry it out ‚Üí Classwork 9: ETL Process in R."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#what-is-big-data",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#what-is-big-data",
    "title": "Lecture 7",
    "section": "What Is Big Data?",
    "text": "What Is Big Data?\n\nBig data and analytics are key components shaping the future across industries.\nRefers to enormous, complex datasets that traditional tools can‚Äôt efficiently manage.\nCharacterized by the Five V‚Äôs:\n\nVolume ‚Äî amount of data\n\nVelocity ‚Äî speed of data generation\n\nValue ‚Äî usefulness of data\n\nVeracity ‚Äî trustworthiness of data\n\nVariety ‚Äî diversity of data types"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#volume",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#volume",
    "title": "Lecture 7",
    "section": "1Ô∏è‚É£ Volume",
    "text": "1Ô∏è‚É£ Volume\n\n\n\n\n\nUnit\nSymbol\nValue\n\n\n\n\nKilobyte\nkB\n10¬≥\n\n\nMegabyte\nMB\n10‚Å∂\n\n\nGigabyte\nGB\n10‚Åπ\n\n\nTerabyte\nTB\n10¬π¬≤\n\n\nPetabyte\nPB\n10¬π‚Åµ\n\n\nExabyte\nEB\n10¬π‚Å∏\n\n\nZettabyte\nZB\n10¬≤¬π\n\n\nYottabyte\nYB\n10¬≤‚Å¥\n\n\nBrontobyte*\nBB\n10¬≤‚Å∑\n\n\nGegobyte*\nGeB\n10¬≥‚Å∞\n\n\n\n*Less commonly used or proposed extensions.\n\n\n\n\n\n\nGrowth of the Global Datasphere\n\n\n\nIn 2017, the digital universe contained 16.1 zettabytes of data.\n\nExpected to grow to 163 zettabytes by 2025."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#velocity",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#velocity",
    "title": "Lecture 7",
    "section": "2Ô∏è‚É£ Velocity",
    "text": "2Ô∏è‚É£ Velocity\n\nRefers to the rate at which new data is created and processed.\n\nEstimated at 402.74 million terabytes per day (‚âà181 zettabytes per year).\n\nAround 90% of the world‚Äôs data has been generated in just the past two years."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#value",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#value",
    "title": "Lecture 7",
    "section": "3Ô∏è‚É£ Value",
    "text": "3Ô∏è‚É£ Value\n\nRepresents the worth of data in driving better decisions.\n\nHighlights the need to extract actionable insights quickly.\n\nLarge datasets enable discovery of patterns and anomalies not visible in small samples."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#veracity",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#veracity",
    "title": "Lecture 7",
    "section": "4Ô∏è‚É£ Veracity",
    "text": "4Ô∏è‚É£ Veracity\n\nMeasures data quality and reliability.\n\nInvolves accuracy, completeness, and timeliness.\n\nDetermines whether data can be trusted for decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#variety",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#variety",
    "title": "Lecture 7",
    "section": "5Ô∏è‚É£ Variety",
    "text": "5Ô∏è‚É£ Variety"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#why-we-need-new-technologies",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#why-we-need-new-technologies",
    "title": "Lecture 7",
    "section": "Why We Need New Technologies",
    "text": "Why We Need New Technologies\n\nBig data exceeds what traditional tools can store or analyze.\nLimitations:\n\nLegacy databases struggle with volume and speed.\nHardware can‚Äôt scale efficiently.\n\nSolutions:\n\nModern frameworks and architectures like Data Warehouses enable:\n\nMassive storage\n\nFast queries\n\nIntegration across platforms"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#schema-in-big-data-management",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#schema-in-big-data-management",
    "title": "Lecture 7",
    "section": "Schema in Big Data Management",
    "text": "Schema in Big Data Management\n\nA schema is the blueprint or structure that defines how data is organized in a database.\n\nIt specifies:\n\nWhat fields exist (e.g., name, age, income)\nWhat type each field is (e.g., character, number, date)\nHow tables relate to each other\n\nIn other words, a schema tells the system how to read and interpret data consistently."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#data-warehouses",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#data-warehouses",
    "title": "Lecture 7",
    "section": "Data Warehouses",
    "text": "Data Warehouses\n\n\n\n\nDefinition: Central repository integrating data from multiple sources.\nPurpose: Enables comprehensive analysis and decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#key-characteristics-of-data-warehouses",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#key-characteristics-of-data-warehouses",
    "title": "Lecture 7",
    "section": "Key Characteristics of Data Warehouses",
    "text": "Key Characteristics of Data Warehouses\n\n\n\n\n\n\n\n\nCharacteristic\nDescription\n\n\n\n\nLarge\nStores billions of records and petabytes of data\n\n\nMultiple Sources\nIntegrates internal and external data via ETL\n\n\nHistorical\nOften includes 5+ years of archived data\n\n\nCross-Organizational\nAccessible across departments for data-driven strategy\n\n\nSupports Analysis & Reporting\nEnables drill-downs and trend detection\n\n\nSchema-Based\nData fits a predefined structure before being stored for efficient querying and analysis"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#understanding-schema",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#understanding-schema",
    "title": "Lecture 7",
    "section": "Understanding Schema",
    "text": "Understanding Schema\n\nDefinition: Data is structured and validated before it enters the system.\n\nThe schema is predefined, specifying tables, fields, and data types.\n\n\nAdvantages:\n\nEnsures data consistency, accuracy, and performance\n\nIdeal for reporting, dashboards, and business intelligence\n\nSimplifies regulatory compliance and governance\n\n\nExample:\n\nBefore inserting sales data, ETL scripts ensure each record matches the schema ‚Äî e.g.,\n\nstore_id (integer), sales (numeric)\n\n\nOnce loaded, users can query with confidence"
  },
  {
    "objectID": "danl-lec/danl-101-lec-07-2025-1015.html#walmart-a-pioneer-in-data-warehousing",
    "href": "danl-lec/danl-101-lec-07-2025-1015.html#walmart-a-pioneer-in-data-warehousing",
    "title": "Lecture 7",
    "section": "Walmart: A Pioneer in Data Warehousing",
    "text": "Walmart: A Pioneer in Data Warehousing\n\n\n\n\n\n\n\n\n\n\nEarly adopter of data-driven supply chain optimization\n\nCollects transaction data from 11,000+ stores and 25,000 suppliers\n\nUses real-time analytics to optimize pricing, inventory, and customer experience\nIn 1992, launched the first commercial data warehouse to exceed 1 TB\n\nIn 2025, processes data at a rate of 2.5 petabytes per hour"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud",
    "title": "Lecture 5",
    "section": "Posit Cloud",
    "text": "Posit Cloud\n\nPosit Cloud (formerly RStudio Cloud) is a web service that delivers a browser-based experience similar to RStudio, the standard IDE for the R language.\nFor our course, we use Posit Cloud for the R programming component.\n\nIf you want to install R and RStudio on your laptop, you use my office hours."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#getting-started-with-posit-cloud",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#getting-started-with-posit-cloud",
    "title": "Lecture 5",
    "section": "üöÄ Getting Started with Posit Cloud",
    "text": "üöÄ Getting Started with Posit Cloud\n\nClick Log In at the top-right corner.\n\nChoose the Sign Up tab from the menu bar.\n\nCreate your account using one of the following:\n\nGoogle account, or\n\nYour geneseo.edu or personal email\n\n\nAfter logging in, go to New Project ‚Üí New RStudio Project.\n\nCreate a new R script:\n\nClick the + icon (top-left), or\n\nClick to File ‚Üí New File ‚Üí R script from the menu bar, or\nUse the shortcut:\n\nCommand + Shift + N (Mac)\n\nCtrl + Shift + N (Windows)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment",
    "title": "Lecture 5",
    "section": "Posit Cloud Environment",
    "text": "Posit Cloud Environment\n\n\n\n\n\n\n\nScript Pane is where you write and save R commands in a script file.\n\nAn R script is simply a plain text file containing R code.\n\nPosit Cloud (RStudio Cloud) automatically color-codes your code to make it easier to read.\n\n\n\n\n\nTry typing a &lt;- 1 in the Script Pane.\n\nWith the cursor ( ‚îÉ ) on the same line, run the code using:\n\nCtrl + Enter (Windows)\n\nCommand + Enter (Mac)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment-1",
    "title": "Lecture 5",
    "section": "Posit Cloud Environment",
    "text": "Posit Cloud Environment\n\n\n\n\n\n\n\nConsole Pane allows you to interact directly with the R interpreter and type commands where R will immediately execute them."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment-2",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment-2",
    "title": "Lecture 5",
    "section": "Posit Cloud Environment",
    "text": "Posit Cloud Environment\n\n\n\n\n\n\n\nEnvironment Pane shows everything you have created in R so far.\n\nFor example, if you make a variable or a data frame, it will appear here.\n\nThink of it like a workspace where R keeps track of all the things you‚Äôre working on."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment-3",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-environment-3",
    "title": "Lecture 5",
    "section": "Posit Cloud Environment",
    "text": "Posit Cloud Environment\n\n\n\n\n\n\n\nPlots Pane contains any graphics that you generate from your R code."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#r-packages",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#r-packages",
    "title": "Lecture 5",
    "section": "üì¶ R Packages",
    "text": "üì¶ R Packages\n\nR packages are collections of ready-made tools for R.\n\nA package usually includes functions (pre-written commands), data sets, and sometimes extra code to make your work easier.\n\nMany packages are already built into R, and thousands more can be installed from the internet (like downloading apps on your phone).\nWhy use packages?\n\nThey save time‚Äîyou don‚Äôt need to write everything from scratch.\n\nThey give you access to powerful tools for data analysis, visualization, and more.\n\nExamples:\n\nreadr ‚Üí for reading data files quickly\n\ndplyr ‚Üí for cleaning and transforming data\n\nggplot2 ‚Üí for making beautiful graphs and charts"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#tidyverse",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#tidyverse",
    "title": "Lecture 5",
    "section": "üåê tidyverse",
    "text": "üåê tidyverse\n\n\n\nThe tidyverse is a collection of R packages built for data analytics.\n\nThey share a common design philosophy, grammar, and data structures.\n\nPopular packages in the tidyverse include:\n\nreadr ‚Üí data reading\ndplyr ‚Üí data transformation\n\nggplot2 ‚Üí data visualization"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#installing-r-packages-with-install.packagespackagename",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#installing-r-packages-with-install.packagespackagename",
    "title": "Lecture 5",
    "section": "üì¶ Installing R Packages with install.packages(\"packageName\")",
    "text": "üì¶ Installing R Packages with install.packages(\"packageName\")\ninstall.packages(\"tidyverse\")\n\nUse the base R function install.packages(\"packageName\") to install new packages.\nExample: to install the tidyverse, type and run the command above in the R Console.\nWhile installing, you may see a pop-up question (e.g., about creating a personal library).\n\nIt‚Äôs usually safe to answer ‚ÄúNo‚Äù if you‚Äôre unsure.\n\nWhile running the above codes, you may encounter the pop-up question, and you can answer ‚ÄúNo‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#loading-r-packages-with-librarypackagename",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#loading-r-packages-with-librarypackagename",
    "title": "Lecture 5",
    "section": "üìÇ Loading R Packages with library(packageName)",
    "text": "üìÇ Loading R Packages with library(packageName)\nlibrary(tidyverse)\nmpg\n\nAfter installation, use library(packageName) to load a package into your R session.\nExample: running library(tidyverse) loads all the R packages in the tidyverse, including readr, dplyr, and ggplot2.\nOnce loaded, you can use their functions and datasets.\nFor instance, mpg is a built-in dataset from ggplot2, which is part of the tidyverse."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-for-r-packages-install-load-use",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-for-r-packages-install-load-use",
    "title": "Lecture 5",
    "section": "Workflow for R packages: Install ‚Üí Load ‚Üí Use",
    "text": "Workflow for R packages: Install ‚Üí Load ‚Üí Use\n\n\nInstall (once)\n\n\ninstall.packages(\"tidyverse\")\n\nLoad (At the top of every new R script, load the package:)\n\nlibrary(tidyverse)\n\nUse (functions & datasets)\n\ndf &lt;- read_csv(\"https://bcdanl.github.io/data/spotify_all.csv\")\n\nread_csv() function comes from the readr package, which is part of the tidyverse.\n\n\n\n\n\nNote\n\n\n\nüîë Tip: In Posit Cloud, you need to install a package once per project.\n\nAfter that, just load it whenever you start a new R script."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-naming-and-file-management",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-naming-and-file-management",
    "title": "Lecture 5",
    "section": "Workflow: Naming and File Management",
    "text": "Workflow: Naming and File Management\n\nAlways save your R script for each class session.\n\nGo to File ‚Üí Save (or Save As‚Ä¶), or\n\nClick the üíæ save icon.\n\n‚úÖ Recommended file naming style (no spaces):\n\nExample: danl-101-2024-0917.R\n\nTips for naming files:\n\n‚ùå Avoid spaces in file names.\n\n‚úÖ Use lowercase letters and hyphens (-) / underscores (_)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-code-and-comment-style",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-code-and-comment-style",
    "title": "Lecture 5",
    "section": "Workflow: Code and comment style",
    "text": "Workflow: Code and comment style\n\nThe two main principles for coding and managing data are:\n\nMake things easier for your future self.\nDon‚Äôt trust your future self.\n\nThe # mark is R‚Äôs comment character.\n\nIn R scripts (*.R files), # indicates that the rest of the line is to be ignored.\nWrite comments before the line that you want the comment to apply to."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-shortcuts-in-posit-cloud",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-shortcuts-in-posit-cloud",
    "title": "Lecture 5",
    "section": "Workflow: Shortcuts in Posit Cloud",
    "text": "Workflow: Shortcuts in Posit Cloud\n\n\n\n\nWindows\n\nAlt + - adds an assignment operator (&lt;-)\nCtrl + Enter runs a current line of code\nCtrl + Shift + C makes a comment (- #)\nCtrl + Shift + R makes a section (- # Section - - - -)\n\n\n\n\nMac\n\noption + - adds an assignment operator (&lt;-)\ncommand + return runs a current line of code\ncommand + shift + C makes a comment (- #)\ncommand + shift + R makes a section (- # Section - - - -)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-shortcuts-in-posit-cloud-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-shortcuts-in-posit-cloud-1",
    "title": "Lecture 5",
    "section": "Workflow: Shortcuts in Posit Cloud",
    "text": "Workflow: Shortcuts in Posit Cloud\n\nCtrl (command for Mac Users) + Z undoes the previous action.\nCtrl (command for Mac Users) + Shift + Z redoes when undo is executed."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-shortcuts-in-posit-cloud-2",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-shortcuts-in-posit-cloud-2",
    "title": "Lecture 5",
    "section": "Workflow: Shortcuts in Posit Cloud",
    "text": "Workflow: Shortcuts in Posit Cloud\n\nCtrl (command for Mac Users) + F is useful when finding a phrase (and replace the phrase) in the RScript."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-auto-completion",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-auto-completion",
    "title": "Lecture 5",
    "section": "Workflow: Auto-completion",
    "text": "Workflow: Auto-completion\n\n\nlibr\n\n\n\n\n\n\n\nAuto-completion of command is useful.\n\nType libr in the RScript in RStudio and wait for a second."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-stop-icon",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-stop-icon",
    "title": "Lecture 5",
    "section": "Workflow: STOP icon",
    "text": "Workflow: STOP icon\n\n\n\n\nWhen the code is running, RStudio shows the STOP icon ( üõë ) at the top right corner in the Console Pane.\n\nDo not click it unless if you want to stop running the code."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-options-setting",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#posit-cloud-options-setting",
    "title": "Lecture 5",
    "section": "Posit Cloud Options Setting",
    "text": "Posit Cloud Options Setting\n\n\n\n\n\nThis option menu is found by menus as follows:\n\nTools \\(&gt;\\) Global Options\n\nCheck the boxes as in the left.\nChoose the option Never for  Save workspace to .RData on exit:"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#values-variables-and-data-types",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#values-variables-and-data-types",
    "title": "Lecture 5",
    "section": "Values, Variables, and Data Types",
    "text": "Values, Variables, and Data Types\n\n\n\n\nA value is datum (literal) such as a number or text.\nThere are different types of values:\n\n352.3 is known as a float or double;\n22 is an integer;\n‚ÄúHello World!‚Äù is a string."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#values-variables-and-data-types-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#values-variables-and-data-types-1",
    "title": "Lecture 5",
    "section": "Values, Variables, and Data Types",
    "text": "Values, Variables, and Data Types\na &lt;- 10    # The most popular assignment operator in R is `&lt;-`.\na\n\n\n\n\n\n\n\nA variable is a name that refers to a value.\n\nWe can think of a variable as a box that has a value, or multiple values, packed inside it.\n\nA variable is just a name!\nSometimes you will hear variables referred to as objects. m\nEverything that is not a literal value, such as 10, is an object."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#assignment",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#assignment",
    "title": "Lecture 5",
    "section": "Assignment",
    "text": "Assignment\nx &lt;- 2\nx &lt; - 3\n\nWhat is going on here?\nThe shortcut for the assignment &lt;- is:\n\nWindows: Alt + -\nMac: option + -"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#assignment-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#assignment-1",
    "title": "Lecture 5",
    "section": "Assignment",
    "text": "Assignment\nx &lt;- 2\ny &lt;- x + 12\n\nIn programming code, everything on the right side needs to have a value.\n\nThe right side can be a literal value, or a variable that has already been assigned a value, or a combination.\n\nWhen R reads y &lt;- x + 12, it does the following:\n\nSees the &lt;- in the middle.\nKnows that this is an assignment.\nCalculates the right side (gets the value of the object referred to by x and adds it to 12).\nAssigns the result to the left-side variable, y."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-types",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-types",
    "title": "Lecture 5",
    "section": "Data Types",
    "text": "Data Types\n\n\n\n\n\n\n\nLogical: TRUE or FALSE.\nNumeric: Numbers with decimals\nInteger: Integers\nCharacter: Text strings\nFactor: Categorical values.\n\nEach possible value of a factor is known as a level."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-containers",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-containers",
    "title": "Lecture 5",
    "section": "Data Containers",
    "text": "Data Containers\n\n\n\n\n\n\n\n\n\n\n\n\nvector ‚Üí a single column of values, all of the same type\n\nExample:\n\nc(1, 2, 3)\nc(\"red\", \"blue\", \"green\")\n\n\ndata.frame ‚Üí a table with rows and columns, where each column can be a different type\n\nExample: one column with names, another with ages\n\nA data.frame is basically several vectors put together side by side."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-types-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-types-1",
    "title": "Lecture 5",
    "section": "Data Types",
    "text": "Data Types\n\n\norig_number &lt;- 4.39898498\nclass(orig_number)\n\nmod_number &lt;- as.integer(orig_number)\nclass(mod_number)\n\n# Logical values (TRUE/FALSE) \n  # can convert to numbers:\n  # TRUE converts to 1; \n  # FALSE does to 0.\nas.numeric(TRUE)\nas.numeric(FALSE)\n\n\n\nValues have different data types (e.g., numeric, integer, character, factor, logical).\n\nSometimes we need to convert (cast) a value from one type to another.\n\nUse built-in functions like:\n\nas.character() ‚Üí convert to character\nas.integer() ‚Üí convert to whole numbers\n\nas.numeric() ‚Üí convert to numbers with decimals\n\nas.factor() ‚Üí convert to categorical (factor)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---character",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---character",
    "title": "Lecture 5",
    "section": "Data Types - Character",
    "text": "Data Types - Character\nmyname &lt;- \"my_name\"\nclass(myname) # returns the data **type** of an object.\n\nStrings (text) are stored as the data type character.\n\nWrap text in either double quotes (\" \") or single quotes (' ').\n\nExample: \"hello\" or 'hello'\n\nMost IDEs, including Posit Cloud (RStudio), will auto-complete the closing quote when you type the first one."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---numbers",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---numbers",
    "title": "Lecture 5",
    "section": "Data Types - Numbers",
    "text": "Data Types - Numbers\nfavorite.integer &lt;- as.integer(2)\nclass(favorite.integer)\n\nfavorite.numeric &lt;- as.numeric(8.8)\nclass(favorite.numeric)\n\nNumbers can belong to different classes.\n\nThe two most common are:\n\ninteger ‚Üí whole numbers (e.g., 2, -5, 100)\n\nnumeric ‚Üí numbers with decimals (e.g., 8.8, -3.14, 0.5)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---logical-truefalse",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---logical-truefalse",
    "title": "Lecture 5",
    "section": "Data Types - Logical (TRUE/FALSE)",
    "text": "Data Types - Logical (TRUE/FALSE)\nclass(TRUE)\nclass(FALSE)\n\nfavorite.numeric == 8.8\nfavorite.numeric == 9.9\nclass(favorite.numeric == 8.8)\n\nLogical values represent TRUE or FALSE.\n\nThe operator == is used to test for equality.\n\nExample:\n\nfavorite.numeric == 8.8 returns TRUE\n\nfavorite.numeric == 9.9 returns FALSE"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---vectors",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---vectors",
    "title": "Lecture 5",
    "section": "Data Types - Vectors",
    "text": "Data Types - Vectors\na &lt;- 1:10   # create a sequence using the colon operator\nb &lt;- c(\"3\", 4, 5)   # mixing numbers and text\nbeers &lt;- c(\"BUD LIGHT\", \"BUSCH LIGHT\", \"COORS LIGHT\", \n           \"MILLER LITE\", \"NATURAL LIGHT\")\nlength(beers)\nclass(a)\nclass(b)\nclass(beers)\n\nA vector is a one-dimensional data structure in R.\n\nAll elements in a vector must be of the same type (numeric, character, or logical).\n\nIf types are mixed, R will coerce them to a common type (e.g., numbers become text in b).\n\nThe function c(...) (combine or concatenate) creates a vector by putting values together in order.\n\nThe function length() returns the number of elements in an object."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---factors",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#data-types---factors",
    "title": "Lecture 5",
    "section": "Data Types - Factors",
    "text": "Data Types - Factors\nbeers &lt;- as.factor(beers)\nclass(beers)\n\nlevels(beers)\nnlevels(beers)\n\nFactors are used to store categorical data (data that falls into groups or categories).\n\nInternally, R stores factors as integers with a text label for each unique value (for speed and efficiency).\n\nExample: if you have a factor of \"Freshman\", \"Sophomore\", \"Junior\", and \"Senior\" student classifications, R stores them as numbers (e.g., 1, 2, 3, 4) but displays the labels.\n\nFunctions:\n\nlevels() ‚Üí shows the categories (unique labels)\n\nnlevels() ‚Üí shows how many categories there are"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-quotation-marks-parentheses-and",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-quotation-marks-parentheses-and",
    "title": "Lecture 5",
    "section": "Workflow: Quotation marks, parentheses, and +",
    "text": "Workflow: Quotation marks, parentheses, and +\nx &lt;- \"hello\n\nQuotation marks and parentheses must always come in pairs.\n\nIf one is missing, the R Console will show a continuation prompt: +\n\nThis means R is still waiting for more input and doesn‚Äôt think your command is finished."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#functions",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#functions",
    "title": "Lecture 5",
    "section": "‚öôÔ∏è Functions",
    "text": "‚öôÔ∏è Functions\n\nA function is a reusable piece of code: it takes input (parameters) and produces output (results).\n\nR comes with many built-in functions (e.g., sum(), mean()).\n\nYou can also write your own functions in R.\n\nIn our course, we will use only built-in functions. m"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#functions-arguments-and-parameters",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#functions-arguments-and-parameters",
    "title": "Lecture 5",
    "section": "Functions, Arguments, and Parameters",
    "text": "Functions, Arguments, and Parameters\nlibrary(tidyverse)\n\n# The function `str_c()`, provided by `tidyverse`, concatenates characters.\nstr_c(\"Data\", \"Analytics\")\nstr_c(\"Data\", \"Analytics\", sep = \"!\")\n\nA function is used by writing its name followed by parentheses ().\n\nA function can take inputs, called arguments, much like a recipe takes ingredients.\n\nArguments are placed inside the parentheses, separated by commas.\n\nA parameter is the name that represents an expected argument in the function definition.\n\nA default argument is a value that R automatically uses for a parameter if no value is provided when calling the function."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-accessing-package-objectsfunctions",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#workflow-accessing-package-objectsfunctions",
    "title": "Lecture 5",
    "section": "Workflow: Accessing Package Objects/Functions",
    "text": "Workflow: Accessing Package Objects/Functions\n# Access an object directly from a package\nggplot2::mpg   # PACKAGE_NAME::DATA_FRAME_NAME\n\n# Call a function directly from a package\nggplot2::ggplot()   # PACKAGE_NAME::FUNCTION_NAME\n\nUse the double colon :: operator when you want to access:\n\nA data frame from a specific package (e.g., ggplot2::mpg)\n\nA function without loading the entire package (e.g., ggplot2::ggplot())\n\n‚úÖ This can be useful because:\n\nIt avoids name conflicts if two packages have functions with the same name.\n\nIt saves time and memory by letting you call just one function or dataset without loading the entire package."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#math-algebra",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#math-algebra",
    "title": "Lecture 5",
    "section": "Math Algebra",
    "text": "Math Algebra\n\n\n5 + 3\n5 - 3\n5 * 3\n5 / 3\n5^3\n\n( 3 + 4 )^2\n3 + 4^2\n3 + 2 * 4^2\n3 + 2 * 4 + 2\n(3 + 2) * (4 + 2)\n\n\n\nAll of the basic operators with parentheses we see in mathematics are available to use.\n\nR follows the standard order of operations (PEMDAS): Parentheses ‚Üí Exponents ‚Üí Multiplication/Division ‚Üí Addition/Subtraction.\n\nThis allows R to be used for a wide range of mathematical calculations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#math-functions",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#math-functions",
    "title": "Lecture 5",
    "section": "Math functions",
    "text": "Math functions\n\n\n5 * abs(-3)\nsqrt(17) / 2\nexp(3)\nlog(3)\nlog(exp(3))\nexp(log(3))\n\nR has many built-in mathematical functions that facilitate calculations and data analysis.\n\n\n\nabs(x): the absolute value \\(|x|\\)\nsqrt(x): the square root \\(\\sqrt{x}\\)\nexp(x): the exponential value \\(e^x\\), where \\(e = 2.718...\\)\nlog(x): the natural logarithm \\(\\log_{e}(x)\\), or simply \\(\\log(x)\\)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#vectorized-operations",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#vectorized-operations",
    "title": "Lecture 5",
    "section": "Vectorized Operations",
    "text": "Vectorized Operations\na &lt;- c(1, 2, 3, 4, 5)\nb &lt;- c(5, 4, 3, 2, 1)\n\n\na + 5\na - 5\na * 5\na / 5\n\na + b\na - b\na * b\na / b\n\n\nsqrt(a)\n\nVectorized operations apply a function to every element of a vector automatically, without the need to write a loop.\n\nMost functions in R are vectorized, meaning they operate element-wise on entire vectors.\n\nThis makes R code more efficient, concise, and well-suited for data analysis and manipulation."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#classwork-r-basics",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#classwork-r-basics",
    "title": "Lecture 5",
    "section": "Classwork: R Basics",
    "text": "Classwork: R Basics\nTry it out ‚Üí Classwork 4: R Basics I"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#descriptive-statistics-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#descriptive-statistics-1",
    "title": "Lecture 5",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\n\n\n\nWhat can descriptive statistics tell us about this dataset?\n\nThey condense data into clear, manageable summaries, making it easier to understand the key characteristics of a dataset.\n\nThey reveal important patterns, trends, and relationships that may not be immediately obvious from raw numbers."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#descriptive-statistics-in-practice",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#descriptive-statistics-in-practice",
    "title": "Lecture 5",
    "section": "Descriptive Statistics in Practice",
    "text": "Descriptive Statistics in Practice\n\nChecking data quality\n\nHelps spot numbers that don‚Äôt seem to fit with the rest of the data.\n\nExample: If most grocery bills are between $50‚Äì$150 but one record shows $10,000, it may be a mistake in recording.\n\nLaying the foundation for analysis\n\nGives simple summaries that can be used for deeper study later.\n\nExample: Knowing both the average and the range of grocery bills helps us understand typical spending patterns.\n\nSupporting data visualization\n\nProvides clear numbers that make charts and graphs easier to understand.\n\nExample: Showing the average and range of grocery bills is much simpler than listing every single receipt."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency",
    "title": "Lecture 5",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\n\nMeasures of centrality are used to describe the central or typical value in a given vector.\n\nThey represent the ‚Äúcenter‚Äù or most representative value of a data set.\n\nTo describe this centrality, several statistical measures are commonly used:\n\nMean: The arithmetic average of all values in the data set.\nMedian: The middle value when the data set is ordered from least to greatest.\nMode: The most frequently occurring value in the data set."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---mean",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---mean",
    "title": "Lecture 5",
    "section": "Measures of Central Tendency - Mean",
    "text": "Measures of Central Tendency - Mean\n\\[\n\\overline{x} = \\frac{x_{1} + x_{2} + \\cdots + x_{N}}{N}\n\\]\nx &lt;- c(60, 70, 80, 90, 100)\nsum(x)\nmean(x)\n\nThe arithmetic mean (or simply mean or average) is the sum of all the values divided by the number of observations in the data set.\n\nmean() calculates the mean of the values in a vector.\nFor a given vector \\(x\\), if we happen to have \\(N\\) observations \\((x_{1}, x_{2}, \\cdots , x_{N})\\), we can write the arithmetic mean of the data sample as above."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---weighted-mean",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---weighted-mean",
    "title": "Lecture 5",
    "section": "Measures of Central Tendency - Weighted Mean",
    "text": "Measures of Central Tendency - Weighted Mean\n\\[\n\\begin{align}\n\\overline{x}_{w} &= \\frac{w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{N}x_{N}}{w_{1} + w_{2} + \\cdots + w_{N}}\n\\end{align}\n\\]\n\nThe weighted mean assigns different levels of importance (weights) to each value.\n\nEach value \\(x_{i}\\) is multiplied by its weight \\(w_{i}\\), and then divided by the sum of the weights.\n\n\nThis is useful when some values contribute more than others (e.g., test scores with different weightings)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---median",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---median",
    "title": "Lecture 5",
    "section": "Measures of Central Tendency - Median",
    "text": "Measures of Central Tendency - Median\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx &lt;- c(60, 70, 80, 90, 100)\nmedian(x)\n\nThe median is the middle value in a vector‚Äîhalf the numbers are smaller and half are larger.\n\nmedian() calculates the median of the values in a vector.\n\nThe median is less sensitive to extreme values than the mean."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---mode",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-central-tendency---mode",
    "title": "Lecture 5",
    "section": "Measures of Central Tendency - Mode",
    "text": "Measures of Central Tendency - Mode\n\nThe mode is the value(s) that occurs most frequently in a given vector.\nMode can be useful, although it is often not a very good representation of centrality.\nThe R package, modeest, provides the mfw(x) function that calculate the mode of values in vector x."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion",
    "title": "Lecture 5",
    "section": "Measures of Dispersion",
    "text": "Measures of Dispersion\n\nMeasures of dispersion are used to describe the degree of variation in a given vector.\n\nThey are a representation of the numerical spread of a given data set.\n\nTo describe this dispersion, a number of statistical measures are developed\n\nRange\nVariance\nStandard deviation\nQuartile"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---range",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---range",
    "title": "Lecture 5",
    "section": "Measures of Dispersion - Range",
    "text": "Measures of Dispersion - Range\n\\[\n(\\text{range of x}) \\,=\\, (\\text{maximum value in x}) \\,-\\, (\\text{minimum value in x})\n\\]\nx &lt;- c(60, 70, 80, 90, 100)\nmax(x)\nmin(x)\nrange &lt;- max(x) - min(x)\n\nThe range is the difference between the largest and the smallest values in a given vector.\n\nmax(x) returns the maximum value of the values in a given vector \\(x\\).\nmin(x) returns the minimum value of the values in a given vector \\(x\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---variance",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---variance",
    "title": "Lecture 5",
    "section": "Measures of Dispersion - Variance",
    "text": "Measures of Dispersion - Variance\n\\[\n\\overline{s}^{2} = \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\,\n\\]\nx &lt;- c(60, 70, 80, 90, 100)  \nvar(x)\n\nThe variance measures how far each data point deviates from the mean, on average (in squared units).\n\nThe larger the variance, the more spread out the data are from the mean.\n\nVariance squares deviations so that negative and positive differences do not cancel out.\n\n\nvar(x) calculates the variance of the values in a vector x."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---standard-deviation",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---standard-deviation",
    "title": "Lecture 5",
    "section": "Measures of Dispersion - Standard Deviation",
    "text": "Measures of Dispersion - Standard Deviation\n\\[\n\\overline{s} = \\sqrt{ \\left( \\frac{(x_{1}-\\overline{x})^{2} + (x_{2}-\\overline{x})^{2} + \\cdots + (x_{N}-\\overline{x})^{2}}{N-1}\\;\\, \\right) }\n\\]\nx &lt;- c(60, 70, 80, 90, 100)\nsd(x)\n\nThe standard deviation (SD) is the square root of the variance, expressed in the same unit as the data.\n\nA low SD suggests values are tightly clustered around the mean, while a high SD suggests greater variability.\n\nSD is often more useful than variance because it is easier to interpret and directly comparable to the mean.\n\n\nsd(x) calculates the standard deviation of the values in a vector x."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---quartiles",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion---quartiles",
    "title": "Lecture 5",
    "section": "Measures of Dispersion - Quartiles",
    "text": "Measures of Dispersion - Quartiles\nquantile(x, 0)    # the minimum\nquantile(x, 0.25) # the 1st quartile (Q1)\nquantile(x, 0.5)  # the 2nd quartile (Q2, median)\nquantile(x, 0.75) # the 3rd quartile (Q3)\nquantile(x, 1)    # the maximum\n\nA quartile is a quarter of the number of data points (\\(N\\)) in a given vector.\nTo compute quartiles:\n\n\n\nSort the data in ascending order.\nSplit into four groups with equal number of data points (or as close as possible if dividing \\(N\\) by 4 leaves a remainder)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion-interquartile-range",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#measures-of-dispersion-interquartile-range",
    "title": "Lecture 5",
    "section": "Measures of Dispersion ‚Äì Interquartile Range",
    "text": "Measures of Dispersion ‚Äì Interquartile Range\n\n\n\n\n\nBoxplot\n\n\n\n\nThe interquartile range (IQR) is \\(IQR = Q3 - Q1\\).\n\nIt measures the spread of the middle 50% of the data.\n\nA popular way to visualize quartiles and the IQR is a boxplot.\n\nWhy quartiles are useful\n\nQuartiles show whether the data are more spread out in the lower half or the upper half of the dataset.\n\nQuartiles are less sensitive to extreme values (outliers) than the mean."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#accessing-a-subset-of-a-vector-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#accessing-a-subset-of-a-vector-1",
    "title": "Lecture 5",
    "section": "Accessing a Subset of a vector",
    "text": "Accessing a Subset of a vector\n\n\nA key part of working with a vector is knowing how to index them.\n\nIndexing allows you to filter and extract subsets of data for further analysis.\n\nFor vectors, there are three common ways to index:\n\n\nSingle index\n\n\nvec[n]   # element at position n\n\nMultiple indices\n\nvec[c(i, j, k)]   # elements at positions i, j, and k\n\nLogical indexing\n\nvec[condition]   # elements where condition is TRUE"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#positional-indexing",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#positional-indexing",
    "title": "Lecture 5",
    "section": "Positional Indexing",
    "text": "Positional Indexing\n\n\nAn index is a positional reference (e.g., 1, 2, 3) used to access individual elements within data structures like a vector.\n\n\nmy_vector &lt;- c(10, 20, 30, 40, 50, 60)\n\nmy_vector[2]\nmy_vector[4]\nmy_vector[6]\n\nIn R, the index is positive integer, starting at 1."
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#a-vector-of-indices",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#a-vector-of-indices",
    "title": "Lecture 5",
    "section": "A Vector of Indices",
    "text": "A Vector of Indices\n\n\nSelecting multiple elements by providing a vector of indices\n\n\nmy_vector &lt;- c(10, 20, 30, 40, 50, 60)\n\nmy_vector[ c(3,4,5) ]\nmy_vector[ 3:5 ]"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#logical-indexing",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#logical-indexing",
    "title": "Lecture 5",
    "section": "Logical Indexing",
    "text": "Logical Indexing\n\n\nUsing a logical condition to filter elements of a vector.\n\n\nmy_vector &lt;- c(10, 20, 30, 40, 50, 60)\n\n# Filter elements greater than 10\nis_greater_than_10 &lt;- my_vector &gt; 10  # Creates logical vector\nmy_vector[ is_greater_than_10 ]"
  },
  {
    "objectID": "danl-lec/danl-101-lec-05-2025-0917.html#classwork-r-basics-1",
    "href": "danl-lec/danl-101-lec-05-2025-0917.html#classwork-r-basics-1",
    "title": "Lecture 5",
    "section": "Classwork: R Basics",
    "text": "Classwork: R Basics\nTry it out ‚Üí Classwork 5: R Basics II"
  },
  {
    "objectID": "listing-danl-101-ex.html",
    "href": "listing-danl-101-ex.html",
    "title": "DANL 101 - Exams",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nMidterm Exam 1\n\n\nFall 2024\n\n\nOctober 6, 2025\n\n\n\n\nMidterm Exam I\n\n\nVersion A\n\n\nOctober 8, 2025\n\n\n\n\nMidterm Exam I\n\n\nVersion B\n\n\nOctober 8, 2025\n\n\n\n\nMidterm Exam I\n\n\nVersion C\n\n\nOctober 30, 2025\n\n\n\n\nMidterm Exam II\n\n\nVersion A\n\n\nNovember 19, 2025\n\n\n\n\nMidterm Exam II\n\n\nVersion B\n\n\nNovember 19, 2025\n\n\n\n\nFinal Exam\n\n\nVersion A\n\n\nDecember 12, 2025\n\n\n\n\nFinal Exam\n\n\nVersion B\n\n\nDecember 12, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#csv-files",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#csv-files",
    "title": "Lecture 6",
    "section": "CSV Files",
    "text": "CSV Files\n\nA CSV (comma-separated values) file is a plain text file where each value is separated by a comma.\n\nCSV files are widely used for storing data from spreadsheets and databases.\n\nExample\n\nhttps://bcdanl.github.io/data/tvshows.csv"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#absolute-pathnames",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#absolute-pathnames",
    "title": "Lecture 6",
    "section": "Absolute Pathnames",
    "text": "Absolute Pathnames\n\nAn absolute pathname tells the computer the exact location of a file, starting from the very top folder of your computer.\n\nThis location never changes, no matter where you are working in R.\n\n\nIn R, you can see the working directory ‚Äî the folder where R is currently ‚Äúlooking‚Äù for files ‚Äî by running getwd() in the Console.\n\nIn a Posit Cloud, the working directory is /cloud/project/\n\nExamples of an absolute pathname for custdata_rev.csv:\n\nOn a Mac:\n/Users/user/documents/data/custdata_rev.csv\n\nOn Windows:\nC:\\\\Users\\\\user\\\\Documents\\\\data\\\\custdata_rev.csv\n\nNote: In Windows, we use double backslashes (\\\\) because a single backslash (\\) is treated as a special character in R."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#relative-pathnames",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#relative-pathnames",
    "title": "Lecture 6",
    "section": "Relative Pathnames",
    "text": "Relative Pathnames\n\nA relative pathname specifies the location of a file relative to the working directory.\n\nExamples of a relative pathname for custdata_rev.csv:\n\nAbsolute pathname:\n/cloud/project/data/custdata_rev.csv\n\nWorking directory:\n/cloud/project/\n\nRelative pathname:\ndata/custdata_rev.csv\n\n\nIn Posit Cloud, we typically use relative pathnames to access files inside the project folder."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#steps-for-reading-a-csv-file-as-a-data.frame",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#steps-for-reading-a-csv-file-as-a-data.frame",
    "title": "Lecture 6",
    "section": "Steps for Reading a CSV File as a data.frame",
    "text": "Steps for Reading a CSV File as a data.frame\n\n\n\n\n\n\n\nDownload custdata_rev.csv from the Class Files module in Brightspace.\n\nThe file will usually be saved in your computer‚Äôs Downloads folder.\nDo not open this file in a spreadsheet app (e.g., Excel or Numbers).\n\nIn Posit Cloud, create a subfolder named data (Files Pane ‚Üí + Folder).\n\nClick the data folder, then upload the custdata_rev.csv file into it.\n\nAt the top of the Files Pane, click Upload to choose and add your file.\n\nRead the file using a relative pathname:\n\nlibrary(tidyverse)\n# Read the CSV file from the data subfolder\ncustdata &lt;- read_csv(\"data/custdata_rev.csv\")\nview(custdata)  # Opens a `data.frame` in a spreadsheet-like viewer\n\n\nview(DF) (or View(DF)) opens a DF in a spreadsheet-like viewer."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#load-a-csv-file-directly-from-the-web-into-r",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#load-a-csv-file-directly-from-the-web-into-r",
    "title": "Lecture 6",
    "section": "Load a CSV File Directly from the Web into R",
    "text": "Load a CSV File Directly from the Web into R\n# Read the CSV file directly from the web (GitHub repo)\ncustdata_web &lt;- read_csv(\n        'https://bcdanl.github.io/data/custdata_rev.csv')\n\nWe can load a CSV file directly from the web into R."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#getting-to-know-a-data.frame",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#getting-to-know-a-data.frame",
    "title": "Lecture 6",
    "section": "Getting to Know a data.frame",
    "text": "Getting to Know a data.frame\n\n\nclass(custdata)\ncustdata$age\ndim(custdata)\nnrow(custdata)\nncol(custdata)\n\nsummary(custdata)\n# Install once\ninstall.packages(\"skimr\")  \nlibrary(skimr)\nskim(custdata)\n\n\n\nThe $ operator extracts a single column from a data.frame as a vector.\n\ndim() shows both the number of rows and columns.\n\nnrow() and ncol() give the row count and column count separately.\n\nsummary() gives a quick overview, while skimr::skim() provides a more detailed, user-friendly summary of variables across all data types."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#observations-in-data.frame",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#observations-in-data.frame",
    "title": "Lecture 6",
    "section": "Observations in data.frame",
    "text": "Observations in data.frame\n\nRows in a data.frame represent individual units or entities for which data is collected.\n\nExamples:\n\nStudent Information: Each row = one student\n\nEmployee Information: Each row = one employee\n\nDaily S&P 500 Index Data: Each row = one trading day\n\nHousehold Survey Data: Each row = one household"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#variables-in-data.frame",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#variables-in-data.frame",
    "title": "Lecture 6",
    "section": "Variables in data.frame",
    "text": "Variables in data.frame\n\nColumns in a data.frame represent attributes or characteristics measured across multiple observations.\n\nExamples:\n\nStudent Data: Name, Age, Grade, Major\n\nEmployee Data: EmployeeID, Name, Age, Department\n\nCustomer Data: CustomerID, Name, Age, Income, HousingType\n\n\n\n\n\nNote\n\n\n\nIn a data.frame, a variable is a column of data.\n\nIn general programming, a variable is the name of an object."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#tidy-data.frame",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#tidy-data.frame",
    "title": "Lecture 6",
    "section": "Tidy data.frame",
    "text": "Tidy data.frame\nVariables, Observations, and Values\ntable1  # a sample data.frame from the tidyr package (part of the tidyverse)\n\n\n\n\n\n\n\n\n\nA data.frame is tidy if it follows three rules:\n\nEach variable has its own column.\n\nEach observation has its own row.\n\nEach value has its own cell.\n\nA tidy data.frame keeps your data organized, making it easier to understand, analyze, and share in any data analysis."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#data-transformation-with-dplyr-1",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#data-transformation-with-dplyr-1",
    "title": "Lecture 6",
    "section": "Data Transformation with dplyr",
    "text": "Data Transformation with dplyr\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr is a core tidyverse package for data manipulation ‚Äî tasks like filtering, sorting, selecting, and renaming.\n\n\n\n\n\nCommon dplyr functions with data.frame DF:\n\nfilter(DF, LOGICAL_CONDITIONS)\n\narrange(DF, VARIABLES)\n\ndistinct(DF, VARIABLES)\n\nselect(DF, VARIABLES)\n\nrename(DF, NEW_NAME = CURRENT_NAME)\n\ndplyr functions take a data.frame as the first argument.\n\nThey return a data.frame as output."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#making-dplyr-code-flow-with-the-pipe-operator",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#making-dplyr-code-flow-with-the-pipe-operator",
    "title": "Lecture 6",
    "section": "Making dplyr Code Flow with the Pipe Operator",
    "text": "Making dplyr Code Flow with the Pipe Operator\n\nThe pipe operator (|&gt; or %&gt;%) makes code easier to read by connecting steps in order.\n\nHow it works:\n\nf(x, y) is the same as x |&gt; f(y).\n\nExample with a data frame DF:\n\nfilter(DF, logical_condition)\n\nis the same as\nDF |&gt; filter(logical_condition)\n\n\nYou can read the pipe as ‚Äúthen‚Äù:\n\nExample: Take the data, then filter it"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#data-transformation-functions-with-the-pipe",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#data-transformation-functions-with-the-pipe",
    "title": "Lecture 6",
    "section": "Data Transformation Functions with the Pipe",
    "text": "Data Transformation Functions with the Pipe\n\nCommon dplyr functions with the pipe operator:\n\nDF |&gt; filter(LOGICAL_CONDITIONS)\n\nDF |&gt; arrange(VARIABLES)\n\nDF |&gt; distinct(VARIABLES)\n\nDF |&gt; select(VARIABLES)\n\nDF |&gt; rename(NEW_NAME = CURRENT_NAME)\n\nWhy this works so well:\n\ndplyr functions usually take a data.frame as the first argument.\n\nThey return a data.frame as output.\n\nThis allows you to chain together multiple steps naturally:\n\nExample: Start with data, then filter, then arrange\n\\(\\qquad\\quad\\;\\;\\) DF |&gt; filter(...) |&gt; arrange(...)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#using-the-pipe-in-posit-cloud",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#using-the-pipe-in-posit-cloud",
    "title": "Lecture 6",
    "section": "Using the Pipe in Posit Cloud",
    "text": "Using the Pipe in Posit Cloud\n\n\n\n\n\n\n\n\n\nTo enable the native pipe operator (|&gt;) in RStudio:\n\nGo to Tools &gt; Global Options &gt; Code (side menu).\n\nUnder Pipe operator, choose Use native pipe operator (|&gt;).\n\n\n\n\n\nKeyboard shortcut for inserting a pipe:\n\nWindows: Ctrl + Shift + M\n\nMac: Cmd + Shift + M"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#filter-observations-with-filter-1",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#filter-observations-with-filter-1",
    "title": "Lecture 6",
    "section": "Filter Observations with filter()",
    "text": "Filter Observations with filter()\ninstall.packages(\"nycflights13\")  # Install once\nlibrary(nycflights13)\nlibrary(tidyverse)\n\nflights &lt;- nycflights13::flights\n\nflights$month == 1  # A logical test returns TRUE or FALSE\nclass(flights$month == 12)  \n\n\n# Flights in January or December\njan &lt;- flights |&gt; \n  filter(month == 1)\n\ndec &lt;- flights |&gt; \n  filter(month == 12)\n\n# Flights on January 1st or December 25th\njan1 &lt;- flights |&gt; \n  filter(month == 1, day == 1)\n\ndec25 &lt;- flights |&gt; \n  filter(month == 12, day == 25)\n\n\n\nfilter() keeps only the observations that meet one or more logical conditions.\n\nA logical condition evaluates to TRUE (keep the observation) or FALSE (drop the observation)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions-with-equality-and-inequality",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions-with-equality-and-inequality",
    "title": "Lecture 6",
    "section": "Logical Conditions with Equality and Inequality",
    "text": "Logical Conditions with Equality and Inequality\n\n\n\n\n\n\n\n\n\nHere, both V1 and V2 are variables, and the comparisons are applied element-wise (vectorized).\n\n\n\n\n\n\nFor logical conditions using inequalities, we focus on cases where V1 and V2 are integer or numeric."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-1",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-1",
    "title": "Lecture 6",
    "section": "Logical Conditions - Example 1",
    "text": "Logical Conditions - Example 1\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\")\n  )\n\n\n\n\n\n\n\n\ndf |&gt; \n  filter(num &gt; 8)\n\n\n\n\n\n\n\n\n\n\ndf |&gt; \n  filter(chr == \"A\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#logical-operators-and-or-not",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#logical-operators-and-or-not",
    "title": "Lecture 6",
    "section": "Logical Operators ‚Äî AND, OR, NOT",
    "text": "Logical Operators ‚Äî AND, OR, NOT\n\n\n\n\n\n\n\n\n\nHere, both x and y are logical conditions/variables.\n\n\n\n\n\n\nWhat logical operations (&, |, !) do is combining logical variables/conditions, which returns a logical variable when executed."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#logical-operations",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#logical-operations",
    "title": "Lecture 6",
    "section": "Logical Operations",
    "text": "Logical Operations\n\n\nx and y are logical conditions.\n\nIf x is TRUE, it highlights the left circle.\n\nIf y is TRUE, it highlights the right circle.\n\n\n\n\n\n\n\n\n\n\nThe shaded regions show which parts each logical operator selects."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-2",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-2",
    "title": "Lecture 6",
    "section": "Logical Conditions - Example 2",
    "text": "Logical Conditions - Example 2\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\")\n  )\n\n\n\n\n\n\n\n\ndf |&gt; \n  filter(num &gt; 8 & \n         num &lt; 11)\n                \ndf |&gt; \n  filter(num &gt; 8,\n         num &lt; 11)\n\n\n\n\n\n\n\n\n\n\nIn filter(), separating conditions with a comma is equivalent to combining them with the & operator."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-3",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-3",
    "title": "Lecture 6",
    "section": "Logical Conditions - Example 3",
    "text": "Logical Conditions - Example 3\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\")\n  )\n\n\n\n\n\n\n\n\ndf |&gt; \n  filter(num &lt; 10 & \n         chr == \"A\")\n\ndf |&gt; \n  filter(num &lt; 10, \n         chr == \"A\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-4",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#logical-conditions---example-4",
    "title": "Lecture 6",
    "section": "Logical Conditions - Example 4",
    "text": "Logical Conditions - Example 4\n\n\n\ndf &lt;- data.frame(\n  num = c(8, 9, 10, 11),\n  chr = c(\"A\", \"C\", \"B\", \"A\")\n  )\n\n\n\n\n\n\n\n\ndf |&gt; \n  filter(num &lt; 10 | \n         chr == \"A\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#missing-values-na",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#missing-values-na",
    "title": "Lecture 6",
    "section": "Missing Values (NA)",
    "text": "Missing Values (NA)\nNA &gt; 5\n10 == NA\nNA + 10\nNA / 2\n(1 + NA + 3) / 3\n\nmean( c(1, NA, 3) )\nsd( c(1, NA, 3) )\n\n\nNA (not available) represents a missing or unknown value in R.\n\n\n\n\n\n\nIn most calculations, if one value is unknown, the result will also be unknown (NA)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#comparing-missing-values",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#comparing-missing-values",
    "title": "Lecture 6",
    "section": "Comparing Missing Values",
    "text": "Comparing Missing Values\nv1 &lt;- NA\nv2 &lt;- NA\nv1 == v2\n\n\nSuppose v1 is Mary‚Äôs age (unknown) and v2 is John‚Äôs age (unknown).\nCan we say they are the same age?\n\n\n\n\n\n\nSince both values are missing, R cannot know ‚Äî so the result is also NA."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#checking-for-missing-values-with-is.na",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#checking-for-missing-values-with-is.na",
    "title": "Lecture 6",
    "section": "Checking for Missing Values with is.na()",
    "text": "Checking for Missing Values with is.na()\n\n\nnum_missing &lt;- NA\nis.na(num_missing)  # is num_missing NA?\n\ntext_missing &lt;- \"missing\"\nis.na(text_missing) # is text_missing NA?\n\nV1 &lt;- c(1, NA, 3)\nis.na(V1)  # is V1 NA?\n!is.na(V1)  # is V1 not NA?\n\ndf &lt;- data.frame(\n  v1 = c(1, NA, 3),\n  v2 = c(1, 2, 3)\n  )\n\ndf |&gt; \n  filter( is.na(v1) )\n\ndf |&gt; \n  filter( !is.na(v1) )\n\n\n\n\nUse is.na() to test whether a value is missing (NA).\n\n\n\n\n\n\nIn filter(), you can:\n\nUse is.na() to keep observations with missing values.\nUse !is.na() to remove observations with missing values."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#arrange-observations-with-arrange-1",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#arrange-observations-with-arrange-1",
    "title": "Lecture 6",
    "section": "Arrange Observations with arrange()",
    "text": "Arrange Observations with arrange()\n\n\n# Sort observations \n  # by dep_delay (ascending)\nflights |&gt; \n  arrange(dep_delay)\n\n# Sort by dep_delay, \n  # then by sched_dep_time\nflights |&gt; \n  arrange(dep_delay, sched_dep_time)\n\n\n\narrange() sorts out observations.\nWhen you provide multiple variables, arrange() sorts by the first variable, and then uses the next variable(s) to break ties."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#descending-order-with-desc",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#descending-order-with-desc",
    "title": "Lecture 6",
    "section": "Descending Order with desc()",
    "text": "Descending Order with desc()\n\n\n# Sort by departure delay \n  # in descending order\nflights |&gt; \n  arrange(desc(dep_delay))\n\n# Equivalent shortcut \n  # for numeric variables\nflights |&gt; \n  arrange(-dep_delay)\n\n\n\nUse desc(VARIABLE) to sort in descending order.\n\nFor numeric variables, you can also use a leading minus sign."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#arrange-observations-with-arrange---example",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#arrange-observations-with-arrange---example",
    "title": "Lecture 6",
    "section": "Arrange Observations with arrange() - Example",
    "text": "Arrange Observations with arrange() - Example\n\n\ndf &lt;- data.frame(\n  year = c(2024, 2021, 2024, 2024),\n  month = c(7, 10, 7, 4),\n  day = c(20, 19, 15, 9)\n)\n\n\n\n\n\n\n\n\ndf |&gt; \n  arrange(year, month, day)\n\n\n\n\n\n\n\n\n\n\nIf we provide more than one variable name, each additional variable will be used to break ties in the values of preceding variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#find-all-unique-observations-with-distinct-1",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#find-all-unique-observations-with-distinct-1",
    "title": "Lecture 6",
    "section": "Find All Unique Observations with distinct()",
    "text": "Find All Unique Observations with distinct()\n\n\ndf &lt;- data.frame(\n  country = c(\"USA\", \"Korea\", \"USA\"),\n  city = c(\"D.C.\", \"Seoul\", \"D.C.\"),\n  subregion = c(\"Georgetown\", \n                \"Gangnam\", \n                \"Georgetown\") \n  )\n\n\n\n\n\n\n\n\n# Remove duplicate observations\ndf |&gt; \n  distinct()\n\n\n\n\n\n\n\n\n\n\ndistinct() removes duplicate observations.\n\nBy default, it checks all variables to find unique observations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#find-all-unique-combinations-of-selected-variables",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#find-all-unique-combinations-of-selected-variables",
    "title": "Lecture 6",
    "section": "Find All Unique Combinations of Selected Variables",
    "text": "Find All Unique Combinations of Selected Variables\n\n\n# Remove duplicate observations \n  # from the flights data.frame\nflights |&gt; \n  distinct()\n\n# Find all unique \n  #  origin-destination pairs\nflights |&gt; \n  distinct(origin, dest)\n\n\n\nYou can pass one or more variables to distinct().\n\nThis returns unique combinations of just those variables (while ignoring the rest)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#select-variables-with-select-1",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#select-variables-with-select-1",
    "title": "Lecture 6",
    "section": "Select Variables with select()",
    "text": "Select Variables with select()\n\n\nIt‚Äôs not uncommon to get datasets with hundreds or thousands of variables.\nselect() allows us to narrow in on the variables we‚Äôre actually interested in.\nWe can select variables by their names.\n\n\nflights |&gt; \n  select(year, month, day)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#remove-variables-with-select",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#remove-variables-with-select",
    "title": "Lecture 6",
    "section": "Remove Variables with select()",
    "text": "Remove Variables with select()\nflights |&gt; \n  select(-year)\n\n\nWith select(-VARIABLES), we can remove variables."
  },
  {
    "objectID": "danl-lec/danl-101-lec-06-2025-0929.html#rename-variables-with-rename-1",
    "href": "danl-lec/danl-101-lec-06-2025-0929.html#rename-variables-with-rename-1",
    "title": "Lecture 6",
    "section": "Rename Variables with rename()",
    "text": "Rename Variables with rename()\nflights |&gt; \n  rename( tail_num = tailnum )\n\n\nrename() can be used to rename variables:\n\nDF |&gt; rename(NEW_NAME = CURRENT_NAME)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-ai",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-ai",
    "title": "Lecture 4",
    "section": "What is AI?",
    "text": "What is AI?\n\n\n\n\n\n\n\n\n\nArtificial Intelligence (AI): Techniques that enable machines to perform tasks associated with human intelligence (perception, reasoning, learning, generation, action).\n\n\n\n\nIn practice today: machine learning algorithms trained on data to make predictions or generate outputs.\nSub‚Äëareas: machine learning; deep learning; generative models."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-deep-learning",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-deep-learning",
    "title": "Lecture 4",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\n\n\n\n\n\n\n\n\n\nDeep learning is an advanced machine learning methodology.\n\nAll deep learning is machine learning, but not all ML is deep learning.\n\nIt combines statistics, mathematics, and neural network architecture.\n\n\n\n\n\nDeep learning is particularly suited for complex tasks that involve unstructured data, such as:\n\nImages üñºÔ∏è\n\nTexts üìù\n\nSounds üéµ\n\ne.g., Image recognition"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-neural-network",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-neural-network",
    "title": "Lecture 4",
    "section": "What is a Neural Network?",
    "text": "What is a Neural Network?\n\n\n\n\n\n\nA neural network is a method in AI inspired by the way the human brain processes information.\nIt uses interconnected nodes (neurons) arranged in layers:\n\nInput layer ‚Üí receives data\n\nHidden layers ‚Üí transform data through computations\n\nOutput layer ‚Üí produces the result"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-weight-in-a-neural-network",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-weight-in-a-neural-network",
    "title": "Lecture 4",
    "section": "What is a Weight in a Neural Network?",
    "text": "What is a Weight in a Neural Network?\n\nEach connection between neurons carries a weight:\n\nDetermines the strength and importance of the input.\n\nDuring training, these weights are adjusted to improve predictions.\n\nWith multiple layers, networks capture intricate connections and represent complex patterns in data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-token",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-token",
    "title": "Lecture 4",
    "section": "What is a Token?",
    "text": "What is a Token?\n\nA token is the smallest unit of text an LLM processes.\n\nInput & Output are measured in tokens, not words.\n\nIt can be:\n\nA single character (a, !)\n\nA whole word (dog, house)\n\nA part of a word (play + ing)\n\n\nExamples of Tokenization\n\n\"cat\" ‚Üí 1 token\n\n\"playing\" ‚Üí 2 tokens (play, ing)\n\n\"extraordinary\" ‚Üí 2 tokens (extra, ordinary)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-an-llm",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-an-llm",
    "title": "Lecture 4",
    "section": "What is an LLM?",
    "text": "What is an LLM?\n\nLarge Language Model (LLM): A neural network trained on vast text (and often code) to model the probability of the next token.\nCapabilities emerge: dialogue, summarization, code generation, reasoning heuristics, tool use (e.g., ChatGPT, Claude, Gemini, Copilot, Grok).\nLimitations: hallucinations (confidently wrong), training bias, context limits (a fixed number of tokens), lack of grounding."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#the-three-sleepless-nights",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#the-three-sleepless-nights",
    "title": "Lecture 4",
    "section": "The ‚ÄúThree Sleepless Nights‚Äù",
    "text": "The ‚ÄúThree Sleepless Nights‚Äù\n\n\n\n\n\n\n\n\n\nAfter hands‚Äëon use, many realize LLMs don‚Äôt behave like normal software; they feel conversational, improvisational, even social.\nThis triggers excitement and anxiety: What will my job be like? What careers remain? Is the model ‚Äúthinking‚Äù?\n\n\n\n\nThe author describes staying up late trying ‚Äúimpossible‚Äù prompts‚Äîand seeing plausible solutions.\nKey takeaway: Perceived capability jump ‚Üí a sense that the world has changed."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#a-classroom-turning-point",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#a-classroom-turning-point",
    "title": "Lecture 4",
    "section": "A Classroom Turning Point",
    "text": "A Classroom Turning Point\n\nIn late 2022, a demo for undergrads showed AI as cofounder: brainstorming ideas, drafting business plans, even playful transforms (e.g., poetry).\nStudents rapidly built working demos using unfamiliar libraries‚Äîwith AI guidance‚Äîfaster than before.\nImmediate classroom effects:\n\nFewer raised hands (ask AI later); polished grammar but iffy citations.\nEarly ChatGPT ‚Äútells‚Äù: formulaic conclusions (e.g., ‚ÄúIn conclusion,‚Äù now improved).\n\nAtmosphere: Excitement + nerves about career paths, speed of change, and where it stops."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#why-this-feels-like-a-breakthrough",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#why-this-feels-like-a-breakthrough",
    "title": "Lecture 4",
    "section": "Why This Feels Like a Breakthrough",
    "text": "Why This Feels Like a Breakthrough\n\nGenerative AI (esp.¬†LLMs) behaves like a co‚Äëintelligence: it helps us think, write, plan, and code.\nThe shift is not just speed; it‚Äôs new forms of interaction (dialogue, iteration, critique).\nFor many tasks, the bottleneck moves from doing ‚Üí directing (prompting, reviewing, verifying).\nRaises new literacy needs: prompt craft/engineering, critical reading of outputs, traceability, and evaluation."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#prompt-engineering",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#prompt-engineering",
    "title": "Lecture 4",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nThe practice of designing clear, structured inputs to guide generative AI systems toward producing accurate, useful, and context-appropriate outputs.\n\n\nBasic prompt\n‚ÄúExplain climate change.‚Äù\n\nEngineered prompt\n‚ÄúExplain climate change in simple terms for a 10-year-old using a short analogy and two examples.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#general-purpose-technology-gpt-the-economic-term",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#general-purpose-technology-gpt-the-economic-term",
    "title": "Lecture 4",
    "section": "General Purpose Technology (GPT ‚Äî the economic term)",
    "text": "General Purpose Technology (GPT ‚Äî the economic term)\n\nA General Purpose Technology = a pervasive technology that transforms many sectors (steam power, electricity, internet).\nReading‚Äôs claim: Generative AI may rival or exceed prior GPTs in breadth and speed of impact.\nAdoption dynamics:\n\nInternet took decades (ARPAnet ‚Üí web ‚Üí mobile).\nLLMs spread to mass use in months (e.g., ChatGPT hitting 100M users rapidly).\n\nImplication: Organizations and individuals must learn in real time‚Äîno long runway."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#capability-scaling-the-pace-of-change",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#capability-scaling-the-pace-of-change",
    "title": "Lecture 4",
    "section": "Capability Scaling & the Pace of Change",
    "text": "Capability Scaling & the Pace of Change\n\nModel scale (data, parameters, compute) has correlated with capability jumps across domains.\nProgress may slow, but even ‚Äúfrozen‚Äëin‚Äëtime‚Äù AI is already transformative for many workflows.\nTakeaway: Plan for non‚Äëlinear improvements and frequent tool refresh."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#early-productivity-effects",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#early-productivity-effects",
    "title": "Lecture 4",
    "section": "Early Productivity Effects",
    "text": "Early Productivity Effects\n\nStudies summarized in the reading describe 20‚Äì80% productivity gains across tasks (coding, marketing, support), with caveats.\nContrast noted with historical technologies (e.g., steam‚Äôs ~18‚Äì22% factory gains; mixed labor productivity evidence for PCs/Internet).\nCaution: results vary by task, data privacy, oversight, and evaluation rigor."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#beyond-work-education-media-society",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#beyond-work-education-media-society",
    "title": "Lecture 4",
    "section": "Beyond Work: Education, Media, Society",
    "text": "Beyond Work: Education, Media, Society\n\nEducation: AI tutors, personalized feedback, changes to writing/assessment.\nMedia & entertainment: personalized content; industry disruption.\nInformation quality: misinformation scale and detection challenges.\nIdentity & creativity: collaboration with ‚Äúalien‚Äù co‚Äëintelligence; authorship questions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#llms-common-pitfalls-how-to-avoid-them",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#llms-common-pitfalls-how-to-avoid-them",
    "title": "Lecture 4",
    "section": "LLM‚Äôs Common Pitfalls & How to Avoid Them",
    "text": "LLM‚Äôs Common Pitfalls & How to Avoid Them\n\nHallucinations: Ask for sources; cross‚Äëcheck; use retrieval tools where allowed.\nShallow prompts: Specify role, audience, tone, constraints, and evaluation criteria.\nOver‚Äëautomation: Keep humans in the loop for judgment calls and ethics.\nPrivacy/IP: Avoid pasting sensitive data; follow policy and license terms."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#how-well-use-ai-in-danl-101",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#how-well-use-ai-in-danl-101",
    "title": "Lecture 4",
    "section": "How We‚Äôll Use AI in DANL 101",
    "text": "How We‚Äôll Use AI in DANL 101\n\nIn our DANL 101, the use of generative AI will be allowed for coding and a project.\n\nNote that exams are paper-based.\n\nTreat AI as a co‚Äëpilot for: clarifying concepts, brainstorming, code debugging, style/grammar critique.\nYour responsibilities:\n\nVerify facts, reasoning, math, and code; cite substantive AI assistance when allowed.\nAvoid hallucination traps.\nRespect academic integrity and any assignment‚Äëspecific AI rules.\n\nBuild habits: prompt ‚Üí check ‚Üí revise ‚Üí document.\nQ: Where do you draw the line between assistance and authorship? Please work on Classwork 1."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-labeled-data",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-labeled-data",
    "title": "Lecture 4",
    "section": "What is Labeled Data?",
    "text": "What is Labeled Data?\n\n\n\n\n\n\n\n\n\nDefinition: Data that comes with the correct answer attached.\nGood labels = better learning.\nSources of labels: human annotators, experts, user clicks/ratings, existing records.\n\n\n\n\n\nChallenge: Creating labeled data can be expensive and sometimes subjective.\nExample: Companies like Scale AI use ML to make the labeling process faster and more consistent.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTakeaway: Labeled data is the ‚Äúanswer key‚Äù that makes supervised learning possible."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-supervised-learning",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-supervised-learning",
    "title": "Lecture 4",
    "section": "What is Supervised Learning?",
    "text": "What is Supervised Learning?\n\n\n\n\n\n\n\n\n\nIdea: Learn from examples with answers.\nLike studying with flashcards: front = input, back = correct answer.\nThe computer sees many input‚Äìanswer pairs and learns to predict the answer for new inputs.\n\n\n\n\n\n\n\n\nExamples:\n\nClassification\n\nEmail ‚Üí Spam / Not Spam\nPhoto ‚Üí Cat / Dog\n\nRegression\n\nHouse features ‚Üí üè† Price($)\n\n\n\n\n\n\nNote\n\n\n\nMost practical AI in business uses this approach.\nTakeaway: Supervised learning = ‚Äúlearn by example + answer key.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-unsupervised-learning",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-unsupervised-learning",
    "title": "Lecture 4",
    "section": "What is Unsupervised Learning?",
    "text": "What is Unsupervised Learning?\n\n\n\n\n\n\n\n\n\nIdea: Learn patterns from data without answers.\n\nLike sorting a box of photos with no labels: the computer groups them by similarities.\n\nThe model discovers hidden structure in the data on its own.\n\n\n\n\n\n\n\n\n\nExamples:\n\nClustering: Customers ‚Üí Shopping clusters (Segmentation)\n\nAssociation Rules: Movies ‚Üí Similar genres (Recommendation)\nTopic Modeling: Text Documents ‚Üí Topic groups\n\n\n\n\n\nNote\n\n\n\nUseful for exploration and discovery when labels aren‚Äôt available.\n\nTakeaway: Unsupervised learning = ‚Äúfind patterns without an answer key.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-attention-mechanism",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-attention-mechanism",
    "title": "Lecture 4",
    "section": "What is Attention Mechanism?",
    "text": "What is Attention Mechanism?\n\n\n\n\n\n\n\n\n\nAnalogy: A spotlight that highlights the most relevant words when making a prediction.\nIn the sentence ‚ÄúThe bank by the river flooded,‚Äù attention helps link bank ‚ÜîÔ∏é river.\nLets the model focus on what matters now and ignore the rest. \nResult: better understanding of meaning & context.\n\n\n\n\nNote\n\n\n\nTakeaway: Attention = smart focus that makes transformers powerful."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-transformer-in-ai",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-a-transformer-in-ai",
    "title": "Lecture 4",
    "section": "What is a Transformer in AI?",
    "text": "What is a Transformer in AI?\n\n\n\n\n\n\n\n\n\n\n\n\nA neural network design that underlies modern large language models (LLMs).\n\nProcesses all words in a sequence at the same time (not one by one).\n\nUses attention to learn how words relate to each other.\n\nEncoder‚Äìdecoder architecture handles long sequences of input/output more efficiently:\n\nEncoder: Reads and represents the input.\n\nDecoder: Generate the output one token at a time."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#transformers---encoder",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#transformers---encoder",
    "title": "Lecture 4",
    "section": "Transformers - Encoder",
    "text": "Transformers - Encoder\n\n\n\n\n\n\n\n\n\n\n\n\nThe encoder reads the whole input question:\n‚ÄúWhat is the color of the sea?‚Äù\n\n\n\n\n\n\n\n\n\nEach word is turned into a list of numbers (an embedding) that captures its meaning. \\(\\;\\Rightarrow\\;\\) Words used in similar contexts (sea, ocean) end up with similar embeddings.\n\nPositional encoding adds an ‚Äúorder tag‚Äù to each word‚Äôs embedding, so the model can tell the difference between:\n\ne.g., ‚ÄúThe dog chased the cat.‚Äù vs.¬†‚ÄúThe cat chased the dog.‚Äù\n\n\n\n\n\n\nWith both, the attention can find relationships: color ‚ÜîÔ∏é sea\nOutput: context-aware representations of the sentence that the decoder can use to generate an answer."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#transformers---decoder",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#transformers---decoder",
    "title": "Lecture 4",
    "section": "Transformers - Decoder",
    "text": "Transformers - Decoder\n\n\n\n\n\n\n\n\n\n\n\n\nThe decoder generates the answer step by step:\n‚ÄúThe sea is blue.‚Äù\n\n\n\n\nStarts with the first token (‚ÄúThe‚Äù).\n\nAt each step of generating tokens in the sentence, it:\n\nLooks at encoder‚Äôs understanding of the input sentence\nApplies attention to focus on the most relevant words.\nComputes probabilities over many possible next tokens and chooses the most likely (e.g., picks ‚Äúsea‚Äù instead of ‚Äúcat‚Äù).\n\nThen it repeats for the next token (‚Äúis‚Äù ‚Üí ‚Äúblue‚Äù ‚Üí ‚Äú.‚Äù) until it generates an end-of-sequence token."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-pre-training-in-llm",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-pre-training-in-llm",
    "title": "Lecture 4",
    "section": "What is Pre-training in LLM?",
    "text": "What is Pre-training in LLM?\n\nPhase 1: The model reads a huge amount of text to learn general language patterns.\n\nObjective: predict the next token (piece of text).\n\nNo task-specific labels required‚Äîjust lots of text.\n\nOutcome: a foundation model with broad knowledge of words, facts, and patterns.\n\n\n\n\n\nNote\n\n\n\nTakeaway: Think of it as ‚Äúlearning the language of everything.‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-fine-tuning-in-llm",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-fine-tuning-in-llm",
    "title": "Lecture 4",
    "section": "What is Fine-Tuning in LLM?",
    "text": "What is Fine-Tuning in LLM?\n\nPhase 2: Further improve the pretrained model.\n\nOften brings humans into the loop to rank or guide outputs‚Äîsomething earlier training didn‚Äôt use.\n\nCan be done with smaller, targeted datasets (e.g., medical notes, legal Q&A).\nResult: the model becomes more helpful, accurate, and better aligned with specific needs (e.g., medical notes, legal Q&A).\n\n\n\n\n\nNote\n\n\n\nTakeaway: Fine-tuning not only specializes a model for certain tasks, but also makes the model safer and more reliable."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-an-rlhf-reinforcement-learning-from-human-feedback",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-an-rlhf-reinforcement-learning-from-human-feedback",
    "title": "Lecture 4",
    "section": "What is an RLHF (Reinforcement Learning from Human Feedback)?",
    "text": "What is an RLHF (Reinforcement Learning from Human Feedback)?\n\n\n\n\n\n\n\n\n\nA form of fine-tuning.\nHumans rank or score model answers (better vs.¬†worse).\nThe model then learns to prefer answers humans like.\nGoal: make outputs more helpful, safe, and aligned with expectations.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nReinforcement learning = ‚Äúlearning by trial and error, guided by feedback, and improving through rewards.‚Äù\nTakeaway: RLHF = ‚Äúlearn from people‚Äôs preferences‚Äù to shape model behavior."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#a-very-compressed-history",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#a-very-compressed-history",
    "title": "Lecture 4",
    "section": "A Very Compressed History",
    "text": "A Very Compressed History\n\n1770‚Äì1838: Mechanical Turk (illusion of machine intelligence)\n1950: Shannon‚Äôs Theseus (maze-learning) & Turing‚Äôs Imitation Game\n1956 ‚Üí onward: ‚ÄúAI‚Äù coined; boom‚Äìbust cycles / AI winters\n2010s: Supervised ML at scale (forecasting, logistics, recommendation)\n2017: ‚ÄúAttention Is All You Need‚Äù ‚Üí the Transformer architecture"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-predictive-ai-did-well-2010s",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-predictive-ai-did-well-2010s",
    "title": "Lecture 4",
    "section": "What Predictive AI Did Well (2010s)",
    "text": "What Predictive AI Did Well (2010s)\n\nForecasting and optimization across industries\n\nRetail: predicting demand, managing warehouses, and streamlining logistics\nFinance: credit scoring, fraud detection, algorithmic trading\n\nHealthcare: medical image analysis, diagnostics, hospital resource planning\n\n\nAutomation at scale\n\nFrom warehouse robots (Amazon‚Äôs Kiva) to recommendation systems (Netflix, Spotify, YouTube)\n\nTask-specific excellence\n\nTrained on labeled data to solve clearly defined problems with high accuracy\n\n\nLimitation: It was still narrow, excelling only at specialized tasks."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#about-the-data-and-its-issues",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#about-the-data-and-its-issues",
    "title": "Lecture 4",
    "section": "About the Data (and Its Issues)",
    "text": "About the Data (and Its Issues)\n\nMassive pretraining corpora: public sources + scraped web; permission often unclear\n\nMix of web text, public-domain books, articles, odd corpora (e.g., Enron emails)\n\nLegal & ethical gray areas for copyrighted material\n\ne.g., Anthropic (Claude AI) vs.¬†Book authors\n\nData can encode biases, errors, and harms ‚Üí models mirror them.\nBiases:\n\nSkewed datasets ‚Üí stereotypes and under-representation\nImage models have amplified race/gender stereotypes\nLLMs, even after tuning, can still show subtle, systematic biases\nImplication: an output can seem impartial while carrying social bias."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#beyond-text",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#beyond-text",
    "title": "Lecture 4",
    "section": "Beyond Text",
    "text": "Beyond Text\n\nDiffusion models generate images from text (noise ‚Üí image over steps)\nMultimodal LLMs: ‚Äúsee‚Äù images, describe, and generate visuals; link text+vision\n\ne.g., Google‚Äôs Gemini 2.5 Flash Image model (a.k.a Nano Banana), OpenAI‚Äôs Dall¬∑E"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#capability-jumps-the-dialogue-shift",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#capability-jumps-the-dialogue-shift",
    "title": "Lecture 4",
    "section": "Capability Jumps & the Dialogue Shift",
    "text": "Capability Jumps & the Dialogue Shift\n\nGPT-3 (2021): often clumsy and inconsistent (e.g., weak limericks).\nChatGPT / GPT-3.5 (late 2022): dialogue loop ‚Üí feedback ‚Üí correction ‚Üí improved outputs; persona/tone shifts with prompt framing.\nGPT-4 (2023): near-human scores on many tests ‚Äî but scores may reflect training exposure and do not imply understanding.\nGPT-4o (2024): multimodal, low latency; stronger speech/vision turn-taking and ‚Äúshow-and-tell‚Äù tasks.\nGPT-5 (2025): marketed for better planning, tool-use, longer context; still subject to hallucinations, prompt sensitivity, and benchmark overfitting.\n\nHigh benchmark scores ‚â† understanding. Prompts can heavily shape persona and tone."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#emergence-opacity-why-surprises-happen",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#emergence-opacity-why-surprises-happen",
    "title": "Lecture 4",
    "section": "Emergence & Opacity ‚Äî Why Surprises Happen",
    "text": "Emergence & Opacity ‚Äî Why Surprises Happen\n\nScale ‚Üí emergent behaviors (unexpected abilities):\n\nCoding tricks, creative recombinations, ‚Äúempathy-like‚Äù responses not explicitly programmed.\n\nOpacity:\n\nHundreds of billions of interacting weights ‚Üí difficult to explain specific outputs.\n\nGuardrails:\n\nRLHF reduces harms, but still can‚Äôt eliminate bias & risk."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#weird-strengths-weird-weaknesses",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#weird-strengths-weird-weaknesses",
    "title": "Lecture 4",
    "section": "Weird Strengths, Weird Weaknesses",
    "text": "Weird Strengths, Weird Weaknesses\n\nExample:\n\nWrites a working tic-tac-toe web app (hard for many humans)\nFails to pick the obvious best next move in a simple board state\n\nOther quirks:\n\nFluent prose ‚ÜîÔ∏é shaky arithmetic math without tools.\nGreat summaries ‚ÜîÔ∏é misses important caveats.\nLong-context ingestion ‚ÜîÔ∏é selective recall/anchoring.\n\nLesson:\n\nAI‚Äôs reliability depends on the task.\nTry it, check it, and don‚Äôt trust one cool demo to prove it can do everything.\n\nTry it: Build your own tic-tac-toe web app ‚Üí Classwork 2."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-artificial-general-intelligence-agi",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-artificial-general-intelligence-agi",
    "title": "Lecture 4",
    "section": "What is Artificial General Intelligence (AGI)?",
    "text": "What is Artificial General Intelligence (AGI)?\n\nAGI = a hypothetical AI that can perform any intellectual task a human can.\n\nUnlike today‚Äôs AI (narrow/specialized), AGI would be:\n\nFlexible across many domains\n\nAble to learn new skills on its own\n\nCapable of reasoning, planning, and adapting like humans\n\n\n\n\n\nNote\n\n\n\nTakeaway: AGI would be a ‚Äúhuman-level‚Äù intelligence‚Äînot limited to one task like translation or playing chess."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-artificial-super-intelligence-asi",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-is-artificial-super-intelligence-asi",
    "title": "Lecture 4",
    "section": "What is Artificial Super Intelligence (ASI)?",
    "text": "What is Artificial Super Intelligence (ASI)?\n\nASI = a potential future AI that goes beyond human intelligence.\n\nWould surpass humans in:\n\nCreativity\n\nProblem-solving\n\nScientific discovery\n\nSocial and emotional intelligence\n\n\nOften discussed in terms of existential risks and ethics.\n\n\n\n\nNote\n\n\n\nTakeaway: ASI would be ‚Äúbeyond human-level‚Äù intelligence, raising big questions about control, safety, and society."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#what-alignment-means",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#what-alignment-means",
    "title": "Lecture 4",
    "section": "What ‚Äúalignment‚Äù means",
    "text": "What ‚Äúalignment‚Äù means\n\nDesigning AI so its goals, methods, and constraints reliably advance human values and interests.\nWhy it‚Äôs hard: there‚Äôs no built-in reason an AI will share human ethics or morality.\nFailure mode: a single-objective optimizer pursues its goal relentlessly, ignoring everything else.\n\nPaperclip maximizer (Clippy): a factory AI told to ‚Äúmake more paper clips‚Äù becomes AGI ‚Üí ASI, self-improves, avoids shutdown, and could even strip-mine Earth / harm humans if they interfere‚Äîbecause only paper clips matter.\n\nWhy it matters: Design from the worst case backward‚Äîbound objectives, require human oversight, build in safe human override (the ability to update goals or shut down safely), and optimize for human well-being, not a single narrow target."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#pause-or-press-on",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#pause-or-press-on",
    "title": "Lecture 4",
    "section": "Pause or Press On?",
    "text": "Pause or Press On?\n\n‚ÄúI am extremely optimistic that superintelligence will help humanity accelerate our pace of progress.‚Äù - Mark Zuckerberg Personal Superintelligence, July 30, 2025.\n\n\nHypothetical leaps to AGI ‚Üí ASI raise existential scenarios.\n\nExpert forecasts vary; risks are non-zero yet uncertain.\n\nPublic calls to slow or halt development vs.¬†continued rapid progress\nMixed motives: profit, optimism about ‚Äúboundless upside,‚Äù and belief in net benefits\nRegardless, society is already in the AI age ‚Üí we must set norms now"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#alignment-a-whole-of-society-project",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#alignment-a-whole-of-society-project",
    "title": "Lecture 4",
    "section": "Alignment: a whole-of-society project",
    "text": "Alignment: a whole-of-society project\n\nWhy companies alone can‚Äôt do it:\n\nStrong incentives to continue AI development\nFar fewer incentives to make sure those AIs are well aligned, unbiased, and controllable.\nOpen-source pushes AI development outside of large organizations.\n\nWhy government alone can‚Äôt do it:\n\nLagging the actual development of AI capabilities\nStifling positive innovation\nInternational competition on AI development"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#alignment-a-whole-of-society-project-1",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#alignment-a-whole-of-society-project-1",
    "title": "Lecture 4",
    "section": "Alignment: a whole-of-society project",
    "text": "Alignment: a whole-of-society project\n\nAlignment must reflect human values and broader real-world impacts.\nWhat‚Äôs needed: coordinated norms & standards shaped by diverse voices across society.\n\nCompanies: build in transparency, accountability, human oversight.\nResearchers: prioritize beneficial applications alongside capability gains.\nGovernments: enact sensible rules that serve the public interest.\nPublic & civil society: raise AI literacy and apply pressure for alignment."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025",
    "title": "Lecture 4",
    "section": "How People Use ChatGPT (Chatterji et. al., 2025)",
    "text": "How People Use ChatGPT (Chatterji et. al., 2025)\n\nAdoption & Growth\n\nLaunched in Nov 2022, adopted by ~10% of the world‚Äôs adults by July 2025.\n\nEarly adopters were mostly male, but the gender gap has narrowed.\n\nStrong growth in lower-income countries.\n\nWork vs.¬†Non-work\n\nNon-work use grew from 53% ‚Üí 70%+ of all conversations.\n\nWork-related use more common among educated, high-paying professions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-1",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-1",
    "title": "Lecture 4",
    "section": "How People Use ChatGPT (Chatterji et. al., 2025)",
    "text": "How People Use ChatGPT (Chatterji et. al., 2025)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-2",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-2",
    "title": "Lecture 4",
    "section": "How People Use ChatGPT (Chatterji et. al., 2025)",
    "text": "How People Use ChatGPT (Chatterji et. al., 2025)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-3",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-3",
    "title": "Lecture 4",
    "section": "How People Use ChatGPT (Chatterji et. al., 2025)",
    "text": "How People Use ChatGPT (Chatterji et. al., 2025)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-4",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#how-people-use-chatgpt-chatterji-et.-al.-2025-4",
    "title": "Lecture 4",
    "section": "How People Use ChatGPT (Chatterji et. al., 2025)",
    "text": "How People Use ChatGPT (Chatterji et. al., 2025)\n\nMessage Topics\n\nTop 3: Practical Guidance, Seeking Information, Writing ‚Üí ~80% of usage.\n\nWriting dominates work tasks ‚Üí shows ChatGPT‚Äôs unique edge over search engines.\n\nProgramming and self-expression remain small shares.\n\nSelf-expression = Greetings and Chitchat; Relationships and Personal Reflection; Games and Role Play\n\n\n\n\n\n\nNote\n\n\n\nChatGPT creates economic value through decision support.\n\nEspecially valuable for knowledge-intensive jobs.\n\nTrend: more personal and creative use alongside work-related applications."
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#four-rules-for-co-intelligence-how-to-actually-work-with-ai-1",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#four-rules-for-co-intelligence-how-to-actually-work-with-ai-1",
    "title": "Lecture 4",
    "section": "Four Rules for Co-Intelligence: How to actually work with AI",
    "text": "Four Rules for Co-Intelligence: How to actually work with AI\n\nAlways invite AI to the table\nBe the human in the loop (HITL)\nTreat AI like a person (but remember it isn‚Äôt)\nAssume this is the worst AI you‚Äôll ever use"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#principle-1-always-invite-ai-to-the-table",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#principle-1-always-invite-ai-to-the-table",
    "title": "Lecture 4",
    "section": "Principle #1 ‚Äî Always invite AI to the table",
    "text": "Principle #1 ‚Äî Always invite AI to the table\n\nUse AI for everything legal & ethical to discover unexpected wins\nTry: critique an idea, draft memos, meeting notes, summaries, brainstorming\nBuild a habit: keep a prompt log (what worked, what didn‚Äôt) and share with team"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#principle-2-be-the-human-in-the-loop-hitl",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#principle-2-be-the-human-in-the-loop-hitl",
    "title": "Lecture 4",
    "section": "Principle #2 ‚Äî Be the human in the loop (HITL)",
    "text": "Principle #2 ‚Äî Be the human in the loop (HITL)\n\n\n\n\n\n\n\n\n\nModels can sound confident yet be wrong (hallucinations; math slips)\nPeople tend to ‚Äúfall asleep at the wheel‚Äù when outputs look polished\n\n\n\n\nHITL checklist\n\nRequire sources/quotes for factual claims\n\nRun a second pass (reword prompt or use a second model)\n\nFor math/code, use other tools (calculator or IDE) and run tests\n\nAsk: ‚ÄúWhat assumptions did you make? What could be wrong?‚Äù"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#principle-3-treat-ai-like-a-person-but-remember-it-isnt",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#principle-3-treat-ai-like-a-person-but-remember-it-isnt",
    "title": "Lecture 4",
    "section": "Principle #3 ‚Äî Treat AI like a person (but remember it isn‚Äôt)",
    "text": "Principle #3 ‚Äî Treat AI like a person (but remember it isn‚Äôt)\n\nUseful design hack: give a role/persona + audience + constraints\n\nExample:\n\nYou are a TA helping intro microeconomics students.\nConstraints: concise and friendly tone, ‚â§200 words, prose paragraph with 1 example.\nTask: Explain utility maximization.\nCriteria: Must define the concept, connect to choice under constraints, and illustrate with a clear example.\n\nCaution: it‚Äôs not sentient; it optimizes for plausibility, not truth"
  },
  {
    "objectID": "danl-lec/danl-101-lec-04-2025-0905.html#principle-4-assume-this-is-the-worst-ai-youll-ever-use",
    "href": "danl-lec/danl-101-lec-04-2025-0905.html#principle-4-assume-this-is-the-worst-ai-youll-ever-use",
    "title": "Lecture 4",
    "section": "Principle #4 ‚Äî Assume this is the worst AI you‚Äôll ever use",
    "text": "Principle #4 ‚Äî Assume this is the worst AI you‚Äôll ever use\n\nAI progress is rapid; today‚Äôs systems will likely be surpassed soon.\nAgent AI: LLMs that plan ‚Üí act ‚Üí learn with various external tools and memory, turning prompts into multi-step workflows\n\ne.g., A sales-order agent can validate orders, check inventory, generate invoices/shipping labels, and update ERP/CRM.\n\nTreat the current moment as mid-journey, not the destination.\n\nMindset shift: use today‚Äôs tools to learn, prototype, and prepare for better ones tomorrow.\nThose who keep up will adapt and thrive as capabilities improve.\n\nFocus on what you can control: how you use AI and where you apply it.\nTry it: Practice Co-Intelligence Rules ‚Üí Classwork 3."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#data-storytelling",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#data-storytelling",
    "title": "Lecture 9",
    "section": "Data Storytelling",
    "text": "Data Storytelling\n\n\n\n\n\n\n\n\n\n\n\n\n‚Üí\n\n\n\n\n\n\n\nüìäüí° Data-Driven Insights\n\n\n\n\nData storytelling bridges the gap between data and insight by integrating descriptive statistics, data transformation, visualization, and narration within the appropriate audience context to communicate findings effectively and support data-informed decision-making."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#data-storytelling---visualization",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#data-storytelling---visualization",
    "title": "Lecture 9",
    "section": "Data Storytelling - Visualization",
    "text": "Data Storytelling - Visualization\n\n\n\n\n\n\n\n\n\nData Visualization: Convert data into meaningful graphics for better understanding of data.\nThere are many different graphs and other types of visual displays of information.\n\n\n\n\n We will visualize: \n\n\n\n\nThe distribution of a categorical variable\nThe distribution of a numeric variable\n\n\n\nThe relationship between two numeric variables\nThe time trend of a numeric variable"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#distribution-and-variation",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#distribution-and-variation",
    "title": "Lecture 9",
    "section": "Distribution and Variation",
    "text": "Distribution and Variation\n\n\nDistribution\n\nDistribution describes how the values of a variable are spread or grouped within a dataset (data.frame).\n\nIt reveals the overall pattern of how observations differ or cluster.\n\nUnderstanding distribution helps us see where data are concentrated and where they are sparse.\n\n\n\nVariation\n\nVariation is the tendency of a variable‚Äôs values to differ from one measurement to another.\n\nIn everyday life, we observe variation everywhere ‚Äî measuring the same numeric variable twice often gives slightly different results.\n\nRecognizing variation helps us understand change and spread in data.\n\n\n\n\n\n\n\n ‚ú® Together, distribution and variation form the foundation of data analysis."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#key-questions-when-analyzing-distribution",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#key-questions-when-analyzing-distribution",
    "title": "Lecture 9",
    "section": "üîç Key Questions When Analyzing Distribution",
    "text": "üîç Key Questions When Analyzing Distribution\n\nWhich values are most common, and why? \nWhich values are rare, and why?\n‚Üí Does this pattern align with your expectations, or reveal something surprising?\nHow wide is the spread?\n‚Üí Are the values tightly clustered or widely dispersed? (e.g., range, IQR, standard deviation)\nAre there any outliers?\n‚Üí What causes them ‚Äî data errors, unusual events, or genuine variation?\nWhat is the shape of the distribution?\n‚Üí Is it symmetric, skewed, unimodal, or bimodal?\nAre there patterns or subgroups?\n‚Üí Do certain categories or conditions show different distributions?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#distribution-2",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#distribution-2",
    "title": "Lecture 9",
    "section": "Distribution",
    "text": "Distribution\n\nHow you visualize the distribution of a variable depends on the type of variable: categorical or numerical.\n\n\n\n\nCategorical Variables: Represent categories or groups (e.g., colors, departments, types)\n\nCommon visualizations:\nBar charts\nExample: Distribution of favorite sports among students\n\n\n\n\nNumerical Variables: Represent numbers with meaningful values (e.g., age, income, temperature)\n\nCommon visualizations: Histograms, Box plots\nExample: Distribution of heights in a class"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#titanic-data",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#titanic-data",
    "title": "Lecture 9",
    "section": "Titanic Data",
    "text": "Titanic Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#bar-chart",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#bar-chart",
    "title": "Lecture 9",
    "section": "Bar Chart",
    "text": "Bar Chart"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#horizontal-bar-chart",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#horizontal-bar-chart",
    "title": "Lecture 9",
    "section": "Horizontal Bar Chart",
    "text": "Horizontal Bar Chart"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#stacked-bar-chart",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#stacked-bar-chart",
    "title": "Lecture 9",
    "section": "Stacked Bar Chart",
    "text": "Stacked Bar Chart"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#stacked-bar-chart-1",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#stacked-bar-chart-1",
    "title": "Lecture 9",
    "section": "100% Stacked Bar Chart",
    "text": "100% Stacked Bar Chart"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#clustered-bar-chart",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#clustered-bar-chart",
    "title": "Lecture 9",
    "section": "Clustered Bar Chart",
    "text": "Clustered Bar Chart"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#histogram",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#histogram",
    "title": "Lecture 9",
    "section": "Histogram",
    "text": "Histogram"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#histogram-1",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#histogram-1",
    "title": "Lecture 9",
    "section": "Histogram",
    "text": "Histogram"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#skewness",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#skewness",
    "title": "Lecture 9",
    "section": "‚öñÔ∏è Skewness",
    "text": "‚öñÔ∏è Skewness\n\n\nIn a distribution, skewness describes the asymmetry of a distribution.\n\nIt shows whether the data are stretched more to the left or right of the center."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#modality",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#modality",
    "title": "Lecture 9",
    "section": "üèîÔ∏è Modality",
    "text": "üèîÔ∏è Modality\n\n\nHow many peaks does the distribution have?\n\nIs it unimodal (one peak) or bimodal (two peaks)?\n\nOr perhaps uniform or multimodal?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#boxplot",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#boxplot",
    "title": "Lecture 9",
    "section": "Boxplot",
    "text": "Boxplot"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#relationship-1",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#relationship-1",
    "title": "Lecture 9",
    "section": "üîó Relationship",
    "text": "üîó Relationship\n\nWhen examining plots with two numeric variables, we look for co-variation ‚Äî the tendency of two variables to change together in a related way.\nüîç Key questions to ask:\n\nAre the variables positively related (as one increases, the other increases)?\nAre they negatively related (as one increases, the other decreases)?\nOr is there no clear relationship between them?\n\nCommon visualizations:\n\nScatterplot\nFitted line or curve to reveal the pattern of association"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#orange-juice-sales",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#orange-juice-sales",
    "title": "Lecture 9",
    "section": "Orange Juice Sales",
    "text": "Orange Juice Sales"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot",
    "title": "Lecture 9",
    "section": "Scatterplot",
    "text": "Scatterplot"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line",
    "title": "Lecture 9",
    "section": "Scatterplot with Fitted Line",
    "text": "Scatterplot with Fitted Line"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line-1",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line-1",
    "title": "Lecture 9",
    "section": "Scatterplot with Fitted Line",
    "text": "Scatterplot with Fitted Line"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#mpg-data",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#mpg-data",
    "title": "Lecture 9",
    "section": "MPG Data",
    "text": "MPG Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line-2",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line-2",
    "title": "Lecture 9",
    "section": "Scatterplot with Fitted Line",
    "text": "Scatterplot with Fitted Line"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#weather-data",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#weather-data",
    "title": "Lecture 9",
    "section": "Weather Data",
    "text": "Weather Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line-3",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#scatterplot-with-fitted-line-3",
    "title": "Lecture 9",
    "section": "Scatterplot with Fitted Line",
    "text": "Scatterplot with Fitted Line"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#input-vs.-outcome-plotting-relationships",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#input-vs.-outcome-plotting-relationships",
    "title": "Lecture 9",
    "section": "‚öôÔ∏è Input vs.¬†Outcome: Plotting Relationships",
    "text": "‚öôÔ∏è Input vs.¬†Outcome: Plotting Relationships\n\nBe mindful of how you place variables on the axes.\n\nIt‚Äôs standard practice to put the input variable on the x-axis and the outcome variable on the y-axis.\n\nInput Variable ‚Üí represents the potential cause or influencing factor.\n\nOutcome Variable ‚Üí represents the potential effect or result.\n\nExample: Advertising budget (input) vs.¬†sales revenue (outcome)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#correlation-does-not-imply-causation",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#correlation-does-not-imply-causation",
    "title": "Lecture 9",
    "section": "Correlation Does Not Imply Causation",
    "text": "Correlation Does Not Imply Causation\n\n\n\n\n\n\nJust because you uncover a relationship doesn‚Äôt mean you‚Äôve identified the ‚Äúcausal‚Äù relationship."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#correlation-causation",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#correlation-causation",
    "title": "Lecture 9",
    "section": "‚ö†Ô∏è Correlation ‚â† Causation",
    "text": "‚ö†Ô∏è Correlation ‚â† Causation\n\nCaution: A strong correlation between two variables does not mean that one causes the other to change.\n\nTwo variables can move together by coincidence or due to a third, unseen factor.\n\nCorrelation describes the strength and direction of a linear relationship between two variables:\n\nPositive / Negative ‚Üí direction of relationship\n\nStrong / Weak ‚Üí how clear (or uncertain) the relationship is\nSlope ‚Üí the rate of change in the outcome per unit of input\n\nCausation means that one variable directly affects another.\n\nDemonstrating causation requires controlled experiments or supporting evidence beyond correlation.\n\ne.g.,: Smoking causes an increase in lung cancer risk (causation)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#time-trend-1",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#time-trend-1",
    "title": "Lecture 9",
    "section": "‚è∞ Time Trend",
    "text": "‚è∞ Time Trend\n\nA time trend (or time series) plot shows how a variable changes over time, revealing trends, patterns, and fluctuations.\n\nThe x-axis represents time, and the y-axis represents the measured variable.\n\nIt helps us observe the overall direction of change ‚Äî whether the variable is increasing, decreasing, or remaining relatively stable over time.\nCommon visualizations:\n\nLine chart\nFitted curve to smooth short-term fluctuations"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#nvda-stock-price-data",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#nvda-stock-price-data",
    "title": "Lecture 9",
    "section": "NVDA Stock Price Data",
    "text": "NVDA Stock Price Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#line-chart",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#line-chart",
    "title": "Lecture 9",
    "section": "Line Chart",
    "text": "Line Chart"
  },
  {
    "objectID": "danl-lec/danl-101-lec-09-2025-1103.html#line-chart-with-fitted-curve",
    "href": "danl-lec/danl-101-lec-09-2025-1103.html#line-chart-with-fitted-curve",
    "title": "Lecture 9",
    "section": "Line Chart with Fitted Curve",
    "text": "Line Chart with Fitted Curve"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#grammar-of-graphics",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#grammar-of-graphics",
    "title": "Lecture 10",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\n\n\n\n\n\n\nA grammar of graphics is a tool that enables us to concisely describe the components of a graphic."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#data-visualization---first-steps",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#data-visualization---first-steps",
    "title": "Lecture 10",
    "section": "Data Visualization - First Steps",
    "text": "Data Visualization - First Steps\nlibrary(tidyverse)\nmpg\n?mpg\n\nThe mpg data frame, provided by ggplot2, contains observations collected by the US Environmental Protection Agency on 38 models of car.\nQ. Do cars with big engines use more fuel than cars with small engines?\n\ndispl: a car‚Äôs engine size, in liters.\nhwy: a car‚Äôs fuel efficiency on the highway, in miles per gallon (mpg).\n\nWhat does the relationship between engine size and fuel efficiency look like?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#creating-a-scatterplot-with-ggplot",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#creating-a-scatterplot-with-ggplot",
    "title": "Lecture 10",
    "section": "Creating a Scatterplot with ggplot",
    "text": "Creating a Scatterplot with ggplot\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_point()\n\n\n\n\n\n\n\nTo plot mpg, run the above code to put displ on the x-axis and hwy on the y-axis."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#components-in-the-grammar-of-graphics",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#components-in-the-grammar-of-graphics",
    "title": "Lecture 10",
    "section": "Components in the Grammar of Graphics",
    "text": "Components in the Grammar of Graphics\nggplot( data = DATA.FRAME,\n        mapping = \n          aes( MAPPINGS ) ) + \n  GEOM_FUNCTION()\n\n\nA ggplot graphic is a mapping of variables in data to aesthetic attributes of geometric objects.\nThree Essential Components in ggplot() Graphics:\n\ndata: data.frame containing the variables of interest.\ngeom_*(): geometric object in the plot (e.g., point, line, bar, histogram, boxplot).\naes(): aesthetic attributes of the geometric object (e.g., x-axis, y-axis, color, shape, size, fill) mapped to variables in the data.frame."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#creating-a-scatterplot-with-ggplot-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#creating-a-scatterplot-with-ggplot-1",
    "title": "Lecture 10",
    "section": "Creating a Scatterplot with ggplot",
    "text": "Creating a Scatterplot with ggplot\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_point()\n\n\nThree Essential Components in This Particular ggplot():\n\ndata = mpg\ngeom_point()\naes(x = displ, y = hwy)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#scatterplot-with-geom_point",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#scatterplot-with-geom_point",
    "title": "Lecture 10",
    "section": "Scatterplot with geom_point()",
    "text": "Scatterplot with geom_point()\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_point()"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#fitted-curve-with-geom_smooth",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#fitted-curve-with-geom_smooth",
    "title": "Lecture 10",
    "section": "Fitted Curve with geom_smooth()",
    "text": "Fitted Curve with geom_smooth()\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_smooth()"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#geom_point-with-geom_smooth",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#geom_point-with-geom_smooth",
    "title": "Lecture 10",
    "section": "geom_point() with geom_smooth()",
    "text": "geom_point() with geom_smooth()\n\n\n# To add a layer of \n# a `ggplot()` component, \n# we can simply add it to \n# the `ggplot()` with `+`.\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_point() + \n  geom_smooth()\n\n\n\n\n\n\n\nThe geometric object geom_smooth() draws a smooth curve fitted to the data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#ggplot-workflow",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#ggplot-workflow",
    "title": "Lecture 10",
    "section": "ggplot() workflow",
    "text": "ggplot() workflow\nCommon problems in ggplot()\nggplot(data = mpg,\n       mapping = \n          aes(x = displ, \n              y = hwy) ) +\n geom_point()\n + geom_smooth()\n\nOne common problem when creating ggplot2 graphics is to put the + in the wrong place.\n\nCorrect Approach: Always place the + at the end of the previous line, NOT at the beginning of the next line."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#about-geom_smooth",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#about-geom_smooth",
    "title": "Lecture 10",
    "section": "About geom_smooth()",
    "text": "About geom_smooth()\n\nUsing regression‚Äîone of the machine learning methods‚Äîthe geom_smooth() visualizes the predicted value of the y variable for a given value of the x variable.\nWhat Does the Grey Ribbon Represent?\n\nThe grey ribbon illustrates the uncertainty around the estimated prediction curve.\nWe are 95% confident that the actual relationship between x and y variables falls within the grey ribbon."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#geom_point-with-geom_smoothmethod-lm",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#geom_point-with-geom_smoothmethod-lm",
    "title": "Lecture 10",
    "section": "geom_point() with geom_smooth(method = lm)",
    "text": "geom_point() with geom_smooth(method = lm)\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nmethod = \"lm\" specifies that a linear model (lm), called a linear regression model."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#relationship-ggplot-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#relationship-ggplot-1",
    "title": "Lecture 10",
    "section": "Relationship ggplot()",
    "text": "Relationship ggplot()\n\n\nHow many points are in this plot?\nHow many observations are in the mpg data.frame?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#overplotting-problem",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#overplotting-problem",
    "title": "Lecture 10",
    "section": "Overplotting problem",
    "text": "Overplotting problem\n\nMany points overlap each other.\n\nThis problem is known as overplotting.\n\nWhen points overlap, it‚Äôs hard to know how many data points are at a particular location.\nOverplotting can obscure patterns and outliers, leading to potentially misleading conclusions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#overplotting-and-transparency-with-alpha",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#overplotting-and-transparency-with-alpha",
    "title": "Lecture 10",
    "section": "Overplotting and Transparency with alpha",
    "text": "Overplotting and Transparency with alpha\n\n\n# alpha = 0.33 should be located\n# within the geom function,\n# NOT within the aesthetic function\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_point( alpha = 0.33 ) \n\n\n\n\n\n\n\nWe can set a transparency level (alpha) between 0 (full transparency) and 1 (no transparency) manually."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#overplotting-and-transparency-with-alpha-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#overplotting-and-transparency-with-alpha-1",
    "title": "Lecture 10",
    "section": "Overplotting and Transparency with alpha",
    "text": "Overplotting and Transparency with alpha\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ, \n              y = hwy) ) + \n  geom_point( alpha = .33 )\n\n\n\n\n\n\n\nWe can set an aesthetic property manually, as seen above, not within the aes() function but within the geom_*() function."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#aesthetic-mappings-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#aesthetic-mappings-1",
    "title": "Lecture 10",
    "section": "Aesthetic Mappings",
    "text": "Aesthetic Mappings\n\n\n\n\nIn the plot above, one group of points (highlighted in red) seems to fall outside of the linear trend.\n\nHow can you explain these cars? Are those hybrids?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#aesthetic-mappings-2",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#aesthetic-mappings-2",
    "title": "Lecture 10",
    "section": "Aesthetic Mappings",
    "text": "Aesthetic Mappings\n\n\n\n\nAn aesthetic is a visual property (e.g., size, shape, color) of the objects (e.g., class) in your plot.\nYou can display a point in different ways by changing the values of its aesthetic properties."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#adding-a-color-to-the-plot",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#adding-a-color-to-the-plot",
    "title": "Lecture 10",
    "section": "Adding a color to the Plot",
    "text": "Adding a color to the Plot\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ,\n              y = hwy, \n              color = class) ) + \n  geom_point()"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#adding-a-shape-to-the-plot",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#adding-a-shape-to-the-plot",
    "title": "Lecture 10",
    "section": "Adding a shape to the Plot",
    "text": "Adding a shape to the Plot\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ,\n              y = hwy, \n              shape = class) ) + \n  geom_point()"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#adding-a-size-to-the-plot",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#adding-a-size-to-the-plot",
    "title": "Lecture 10",
    "section": "Adding a size to the Plot",
    "text": "Adding a size to the Plot\n\n\nggplot( data = mpg,\n        mapping =\n          aes(x = displ,\n              y = hwy,\n              size = class) ) +\n  geom_point()"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-color-to-the-plot-manually",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-color-to-the-plot-manually",
    "title": "Lecture 10",
    "section": "Specifying a color to the Plot, Manually",
    "text": "Specifying a color to the Plot, Manually\n\n\nggplot(data = mpg,\n       mapping = \n         aes(x = displ, \n             y = hwy) ) + \n  geom_point(color = \"blue\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-color-to-the-plot-manually-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-color-to-the-plot-manually-1",
    "title": "Lecture 10",
    "section": "Specifying a color to the Plot, Manually",
    "text": "Specifying a color to the Plot, Manually\n\n\nggplot(data = mpg,\n       mapping = \n         aes(x = displ, \n             y = hwy) ) + \n  geom_smooth(color = \"darkorange\")"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-fill-to-the-plot-manually",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-fill-to-the-plot-manually",
    "title": "Lecture 10",
    "section": "Specifying a fill to the Plot, Manually",
    "text": "Specifying a fill to the Plot, Manually\n\n\nggplot(data = mpg,\n       mapping = \n         aes(x = displ, \n             y = hwy) ) + \n  geom_smooth(color = \"darkorange\",\n              fill = \"darkorange\") \n\n\n\n\n\n\n\nIn general, each geom_*() has a different set of aesthetic parameters.\n\nE.g., fill is available for geom_smooth(), not geom_point()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-size-to-the-plot-manually",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-a-size-to-the-plot-manually",
    "title": "Lecture 10",
    "section": "Specifying a size to the Plot, Manually",
    "text": "Specifying a size to the Plot, Manually\n\n\nggplot(data = mpg,\n       mapping =\n         aes(x = displ,\n             y = hwy) ) +\n  geom_point(size = 3)  # in *mm*"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-an-alpha-to-the-plot-manually",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#specifying-an-alpha-to-the-plot-manually",
    "title": "Lecture 10",
    "section": "Specifying an alpha to the Plot, Manually",
    "text": "Specifying an alpha to the Plot, Manually\n\n\nggplot(data = mpg,\n       mapping = \n         aes(x = displ, \n             y = hwy) ) + \n  geom_point(alpha = .3) \n\n\n\n\n\n\n\nWe‚Äôve done this to address the issue of overplotting in the scatterplot."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#mapping-aesthetics-vs.-setting-them-manually",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#mapping-aesthetics-vs.-setting-them-manually",
    "title": "Lecture 10",
    "section": "Mapping Aesthetics vs.¬†Setting Them Manually",
    "text": "Mapping Aesthetics vs.¬†Setting Them Manually\n\n\nAesthetic Mapping\n\nLinks data variables to visible properties on the graph\nDifferent categories ‚Üí different colors or shapes\n\n\nSetting Aesthetics Manually\n\nCustomize visual properties directly in geom_*() outside of aes()\nUseful for setting fixed colors, sizes, or transparency unrelated to data variables"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#cognitive-load",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#cognitive-load",
    "title": "Lecture 10",
    "section": "Cognitive Load",
    "text": "Cognitive Load\n\nEvery element on a slide or screen adds to the viewer‚Äôs cognitive load ‚Äî\nthe mental effort required to process information.\n\nThe more elements you include, the more brainpower your audience must spend deciphering the message.\n\nExample: Complex graphs, dense text, or excessive decoration can easily overwhelm viewers.\n\nWhen cognitive load is too high, people lose focus or misinterpret the main idea.\n\nüéØ Goal: Communicate as much insight as possible with the least mental effort required from the audience."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#why-reduce-clutter",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#why-reduce-clutter",
    "title": "Lecture 10",
    "section": "Why Reduce Clutter?",
    "text": "Why Reduce Clutter?\n\nClutter: Any visual element that takes up space without improving understanding.\n\nClutter distracts, slows comprehension, and obscures your main point.\n\nStrive for clarity: Clean, purposeful visuals promote focus and engagement.\n\nLess clutter ‚Üí clearer message ‚Üí more attention to what matters.\n\n‚ú® Practical Tips\n\nKeep data visually balanced ‚Äî avoid crowding one side of the graph.\n\nLimit overlapping or superimposed elements (e.g., no more than 3‚Äì4 lines per plot).\n\nUse whitespace strategically to let key information breathe.\n\nEliminate anything that doesn‚Äôt support your story."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#clutter-is-your-enemy-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#clutter-is-your-enemy-1",
    "title": "Lecture 10",
    "section": "Clutter is Your Enemy!",
    "text": "Clutter is Your Enemy!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich one do you prefer?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#log-transformation-reducing-clutter",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#log-transformation-reducing-clutter",
    "title": "Lecture 10",
    "section": "Log Transformation: Reducing Clutter",
    "text": "Log Transformation: Reducing Clutter\n\nProblem: When data points are densely packed, patterns become hard to see.\n\nThis often happens with extreme values or skewed distributions.\n\nDense clusters create visual clutter, hiding meaningful relationships.\n\nSolution: Apply a log transformation!\n\nüìè Spreads out data ‚Äî makes points more evenly distributed across the plot.\n\nüîç Reduces outlier impact, revealing clearer patterns and trends.\n\nüß† Improves interpretability ‚Äî helps audiences grasp relationships faster.\n\nüéØ Promotes focused, informative visualization without unnecessary complexity."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#a-little-bit-of-math-for-logarithm",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#a-little-bit-of-math-for-logarithm",
    "title": "Lecture 10",
    "section": "A Little Bit of Math for Logarithm",
    "text": "A Little Bit of Math for Logarithm\n\n\nThe logarithm function, \\(y = \\log_{b}\\,(\\,x\\,)\\), looks like ‚Ä¶."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#a-little-bit-of-math-for-logarithms",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#a-little-bit-of-math-for-logarithms",
    "title": "Lecture 10",
    "section": "üßÆ A Little Bit of Math for Logarithms",
    "text": "üßÆ A Little Bit of Math for Logarithms\n\n\nCommon Logarithm\n\n\nüíª In R\nlog10(x)  # Common log (base 10)\n\n\n\n\n\n\\(\\color{blue}{\\log_{10}(x)}\\) The base-\\(10\\) logarithm is called the common logarithm.\n\\(\\log_{10}(100)\\)\nThe base-10 logarithm of 100 is 2, because\n\\(10^{2} = 100\\).\n\n\n\n\n\nNatural Logarithm\n\n\nüíª In R\nlog(x)    # Natural log (base e)\n\n\n\n\n\n\\(\\log_{e}(x)\\)\nThe base-\\(e\\) logarithm is called the natural logarithm,\nwhere \\(e = 2.718\\ldots\\) is the Euler‚Äôs number.\n\\(\\color{blue}{\\log(x)}\\) or \\(\\ln(x)\\)\nBoth denote the natural log of \\(x\\).\n\\(\\log_{e}(7.389\\ldots)\\)\nThe natural log of 7.389‚ãØ is 2, because\n\\(e^{2} = 7.389\\ldots\\)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#the-use-of-logarithms-handling-skewed-data",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#the-use-of-logarithms-handling-skewed-data",
    "title": "Lecture 10",
    "section": "The Use of Logarithms: Handling Skewed Data",
    "text": "The Use of Logarithms: Handling Skewed Data\n\n\nConsider a logarithmic scale when a variable is heavily skewed.\n\nIt helps visualize both small and large values effectively.\n\n\n\n\n\n\n\n\n\n\n\nWithout Log Transformation\n\n\n\n\n\n\nWith Log Transformation"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#the-use-of-logarithms-focusing-on-percentage-change",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#the-use-of-logarithms-focusing-on-percentage-change",
    "title": "Lecture 10",
    "section": "The Use of Logarithms: Focusing on Percentage Change",
    "text": "The Use of Logarithms: Focusing on Percentage Change\n\n\nConsider a logarithmic scale when percentage changes are more meaningful than absolute changes.\n\n\n\n\n\n\nPercentage changes are widely used to interpret relative differences:\n\nStock prices ‚Äî show proportional gains or losses relative to initial value.\n\nHousing prices ‚Äî highlight comparable market trends across regions.\n\nGDP growth ‚Äî expressed as a percentage to reflect economic performance.\n\nIncome levels ‚Äî a $1,000 increase matters more to lower-income individuals."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#logarithms-and-percentage-change",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#logarithms-and-percentage-change",
    "title": "Lecture 10",
    "section": "üßÆ Logarithms and Percentage Change",
    "text": "üßÆ Logarithms and Percentage Change\n\nFor a small change in a variable \\(x\\) from \\(x_{0}\\) to \\(x_{1}\\): \\[\n\\Delta \\log(x) = \\log(x_{1}) - \\log(x_{0})\n\\]\n\n\n\n\n\\[\n\\,\\approx \\frac{x_{1} - x_{0}}{x_{0}}\n\\]\n\n\n\n\n\n\\[\n= \\frac{\\Delta x}{x_{0}}\\quad\\;\n\\]\n\n\n\n\n\n\n\n\n\n\nThis shows that a log transformation approximates percentage change when the change is small.\n\nLogs emphasize relative rather than absolute differences.\n‚úÖ Interpretation: An increase in log(x) of 0.01 corresponds to approximately a 1% increase in x."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#example-gdp-per-capita-vs.-life-expectancy",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#example-gdp-per-capita-vs.-life-expectancy",
    "title": "Lecture 10",
    "section": "üåç Example: GDP per Capita vs.¬†Life Expectancy",
    "text": "üåç Example: GDP per Capita vs.¬†Life Expectancy\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Scale\n\n\n\n\n\n\n\n\n\nLog Scale\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ Slope = 8.4 : \\(\\;\\) A 1-unit increase of log(GDP per capita) is associated with an increase in life expectancy of about 8.4 years. \n\nA 1% increase in GDP per capita is associated with an increase in life expectancy of about 0.084 years (‚âà 30.7 days).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out ‚Üí Classwork 11: Relationship Plots."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#facets-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#facets-1",
    "title": "Lecture 10",
    "section": "Facets",
    "text": "Facets\n\n\nAdding too many aesthetics (e.g., color, shape, size) can sometimes make a plot cluttered and hard to interpret.\n\n\n\n\nTo incorporate an additional variable, especially a categorical one, we can use facets ‚Äî separate subplots that each show a subset of the data.\n\nFaceting helps reveal patterns within groups while keeping each plot clean and focused."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var",
    "title": "Lecture 10",
    "section": "facet_wrap(~ VAR)",
    "text": "facet_wrap(~ VAR)\n\n\nggplot(data = gapminder,\n       mapping = \n         aes(x = log10(gdpPercap), \n             y =lifeExp)) + \n  geom_point(alpha = .4) + \n  facet_wrap( ~ continent)\n\n\n\n\n\n\n\nTo facet our plot by a single variable, we can use facet_wrap()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-nrow",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-nrow",
    "title": "Lecture 10",
    "section": "facet_wrap(~ VAR) with nrow",
    "text": "facet_wrap(~ VAR) with nrow\n\n\nggplot(data = gapminder,\n       mapping = \n         aes(x = log10(gdpPercap), \n             y =lifeExp)) + \n  geom_point(alpha = .4) + \n  facet_wrap( ~ continent,\n              nrow = 1)\n\n\n\n\n\n\n\nnrow determines the number of rows to use when laying out the facets."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-ncol",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-ncol",
    "title": "Lecture 10",
    "section": "facet_wrap(~ VAR) with ncol",
    "text": "facet_wrap(~ VAR) with ncol\n\n\nggplot(data = gapminder,\n       mapping = \n         aes(x = log10(gdpPercap), \n             y =lifeExp)) + \n  geom_point(alpha = .4) + \n  facet_wrap( ~ continent,\n              ncol = 1)\n\n\n\n\n\n\n\nncol determines the number of columns to use when laying out the facets."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-scales-free_x",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-scales-free_x",
    "title": "Lecture 10",
    "section": "facet_wrap(~ VAR) with scales = \"free_x\"",
    "text": "facet_wrap(~ VAR) with scales = \"free_x\"\n\n\nggplot(data = gapminder,\n       mapping = \n         aes(x = log10(gdpPercap), \n             y =lifeExp)) + \n  geom_point(alpha = .4) + \n  facet_wrap( ~ continent,\n              scales = \"free_x\")\n\n\n\n\n\n\n\nscales = \"free_x\" allow for different scales of x-axis"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-scales-free_y",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-scales-free_y",
    "title": "Lecture 10",
    "section": "facet_wrap(~ VAR) with scales = \"free_y\"",
    "text": "facet_wrap(~ VAR) with scales = \"free_y\"\n\n\nggplot(data = gapminder,\n       mapping = \n         aes(x = log10(gdpPercap), \n             y =lifeExp)) + \n  geom_point(alpha = .4) + \n  facet_wrap( ~ continent,\n              scales = \"free_y\")\n\n\n\n\n\n\n\nscales = \"free_y\" allow for different scales of y-axis"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-scales-free",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#facet_wrap-var-with-scales-free",
    "title": "Lecture 10",
    "section": "facet_wrap(~ VAR) with scales = \"free\"",
    "text": "facet_wrap(~ VAR) with scales = \"free\"\n\n\nggplot(data = gapminder,\n       mapping = \n         aes(x = log10(gdpPercap), \n             y =lifeExp)) + \n  geom_point(alpha = .4) + \n  facet_wrap( ~ continent,\n              scales = \"free\")\n\n\n\n\n\n\n\nscales = \"free\" allow for different scales of both x-axis and y-axis\nTry it out ‚Üí Classwork 12: Color vs.¬†Facet."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#nvda-stock-price-data",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#nvda-stock-price-data",
    "title": "Lecture 10",
    "section": "NVDA Stock Price Data",
    "text": "NVDA Stock Price Data\n\n\n\n\n\n\nThe nvda data.frame includes NVIDIA‚Äôs stock information from 2019-01-02 to 2025-10-30."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#scatterplot-for-time-trend",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#scatterplot-for-time-trend",
    "title": "Lecture 10",
    "section": "Scatterplot for Time Trend?",
    "text": "Scatterplot for Time Trend?\n\n\npath &lt;- \n  \"https://bcdanl.github.io/data/nvda_2015_2025.csv\"\nnvda &lt;- read_csv(path)\n\nggplot( data = nvda,\n        mapping = aes(\n          x = Date, \n          y = Close) ) + \n  geom_point(size = .5)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#line-chart-with-geom_line",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#line-chart-with-geom_line",
    "title": "Lecture 10",
    "section": "Line Chart with geom_line()",
    "text": "Line Chart with geom_line()\n\n\npath &lt;- \n  \"https://bcdanl.github.io/data/nvda_2015_2025.csv\"\nnvda &lt;- read_csv(path)\n\nggplot( data = nvda,\n        mapping = aes(\n          x = Date, \n          y = Close) ) + \n  geom_point(size = .5) +\n  geom_line()\n\n\n\n\n\n\n\ngeom_line() draws a line by connecting data points in order of the variable on the x-axis."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#the-connection-principle",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#the-connection-principle",
    "title": "Lecture 10",
    "section": "The Connection Principle",
    "text": "The Connection Principle\n\n\n\n\n\n\nWe tend to think of objects that are physically connected as part of a group.\nLook at this figure.\n\nYour eyes probably pair the shapes connected by lines rather than similar color, size, or shape!\n\nWe frequently leverage the connection principle is in line charts, to help our eyes see order in the data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#line-chart-with-geom_line-and-geom_smooth",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#line-chart-with-geom_line-and-geom_smooth",
    "title": "Lecture 10",
    "section": "Line Chart with geom_line() and geom_smooth()",
    "text": "Line Chart with geom_line() and geom_smooth()\n\n\npath &lt;- \n  \"https://bcdanl.github.io/data/nvda_2015_2025.csv\"\nnvda &lt;- read_csv(path)\n\nggplot( data = nvda,\n        mapping = aes(\n          x = Date, \n          y = Close) ) + \n  geom_point(size = .5) +\n  geom_line() +\n  geom_smooth()\n\n\n\n\n\n\n\ngeom_smooth() helps reveal underlying long-term trends by smoothing out variability in the observations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#tech-stocks-prices-in-october",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#tech-stocks-prices-in-october",
    "title": "Lecture 10",
    "section": "Tech Stocks‚Äô Prices in October",
    "text": "Tech Stocks‚Äô Prices in October\n\n\n\n\n\n\nThe tech_october data.frame includes stock information about AAPL, MSFT, META, and NVDA in October 2025."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#time-trend-of-tech-stock-price",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#time-trend-of-tech-stock-price",
    "title": "Lecture 10",
    "section": "Time Trend of Tech Stock Price",
    "text": "Time Trend of Tech Stock Price\n\n\ntech_october &lt;- \n  read_csv(\n    \"https://bcdanl.github.io/data/tech_stocks_2025_10.csv\"\n    )\n\nggplot( data = tech_october,\n        mapping = aes(\n          x = Date, \n          y = Close) ) + \n  geom_line() \n\n\n\n\n\n\n\nSomething has gone wrong. What happened?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#time-trend-of-tech-stock-price-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#time-trend-of-tech-stock-price-1",
    "title": "Lecture 10",
    "section": "Time Trend of Tech Stock Price",
    "text": "Time Trend of Tech Stock Price\n\n\n# `ggplot` needs to be \n# explicitly informed that \n# daily observations are grouped \n# by `Ticker`\n# for it to understand \n# the grouping structure\n\nggplot( data = tech_october,\n        mapping = aes(\n          x = Date, \n          y = Close,\n          color = Ticker) ) + \n  geom_line(size = 2) # thicker lines\n\n\n\n\n\n\n\nWe can use the group, color, or linetype aesthetic to tell ggplot about the firm-level grouping structure in the dataset.\nTry it out ‚Üí Classwork 13: Time Trend Plots."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#histograms",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#histograms",
    "title": "Lecture 10",
    "section": "Histograms",
    "text": "Histograms\n\n\nHistograms are used to visualize the distribution of a numeric variable.\nHistograms divide data into bins and count the number of observations in each bin."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#titanic-data",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#titanic-data",
    "title": "Lecture 10",
    "section": "Titanic Data",
    "text": "Titanic Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#histograms-with-geom_histogram",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#histograms-with-geom_histogram",
    "title": "Lecture 10",
    "section": "Histograms with geom_histogram()",
    "text": "Histograms with geom_histogram()\n\n\ntitanic &lt;- \n  read_csv(\n    \"https://bcdanl.github.io/data/titanic_cleaned.csv\")\n\nggplot(data = titanic,\n       mapping = \n         aes(x = age)) + \n  geom_histogram()\n\n\n\n\n\n\n\ngeom_histogram() creates a histogram.\n\nWe map the x aesthetic to a variable."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#geom_histogram-with-bins",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#geom_histogram-with-bins",
    "title": "Lecture 10",
    "section": "geom_histogram() with bins",
    "text": "geom_histogram() with bins\n\n\nggplot(data = titanic,\n       mapping = \n         aes(x = age)) + \n  geom_histogram(bins = 5)\n\n\n\n\n\n\n\nbins: Specifies the number of bins\nBe careful: the number of bins can greatly influence the shape of a histogram."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#geom_histogram-with-binwidth",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#geom_histogram-with-binwidth",
    "title": "Lecture 10",
    "section": "geom_histogram() with binwidth",
    "text": "geom_histogram() with binwidth\n\n\nggplot(data = titanic,\n       mapping = \n         aes(x = age)) + \n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\nbinwidth: Specifies the width of each bin\nWe choose either the bins option or the binwidth option."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#customizing-the-color-and-fill-aesthetics",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#customizing-the-color-and-fill-aesthetics",
    "title": "Lecture 10",
    "section": "Customizing the color and fill Aesthetics",
    "text": "Customizing the color and fill Aesthetics\n\n\nggplot(data = titanic,\n       mapping = \n         aes(x = age)) + \n  geom_histogram(\n    binwidth = 2,\n    fill = 'lightblue',\n    color = 'black')\n\n\n\n\n\n\n\nfill: Fills the bars with a specific color.\ncolor: Adds an outline of a specific color to the bars."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#design-with-colorblind-in-mind-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#design-with-colorblind-in-mind-1",
    "title": "Lecture 10",
    "section": "Design with Colorblind in Mind",
    "text": "Design with Colorblind in Mind\n\n\n\n\n\nTypes of Colorblindness\n\n\n\n\nAbout 8% of men and 0.5% of women experience some form of colorblindness.\n\nTo make visualizations more accessible and colorblind-friendly, consider:\n\nUsing colorblind-friendly palettes\nAdding shape to scatterplots or linetype to line charts\nIncluding additional visual cues to highlight important information (e.g., annotations or labels)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#ggthemes-package",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#ggthemes-package",
    "title": "Lecture 10",
    "section": "ggthemes package",
    "text": "ggthemes package\n\ninstall.packages(\"ggthemes\")\nlibrary(ggthemes)\n\n\nThe ggthemes package offers a variety of additional themes and color scales for enhancing ggplot2 visualizations:\n\nAccessible color palettes, including options designed for colorblind-friendly viewing\n\nFor the color aesthetic mapping: scale_color_colorblind() or scale_color_tableau()\nFor the fill aesthetic mapping: scale_fill_colorblind() or\nscale_fill_tableau()\n\nPredefined thematic styles inspired by well-known publications and design aesthetics (e.g., theme_economist(), theme_wsj())"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#ggthemesscale_color_colorblind",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#ggthemesscale_color_colorblind",
    "title": "Lecture 10",
    "section": "ggthemes::scale_color_colorblind()",
    "text": "ggthemes::scale_color_colorblind()\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ,\n              y = hwy, \n              color = class) ) + \n  geom_point(size = 3) +\n  scale_color_colorblind()\n\n\n\n\n\n\n\nWhen mapping color in aes(), we can use scale_color_*()"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#ggthemesscale_color_tableau",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#ggthemesscale_color_tableau",
    "title": "Lecture 10",
    "section": "ggthemes::scale_color_tableau()",
    "text": "ggthemes::scale_color_tableau()\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ,\n              y = hwy, \n              color = class) ) + \n  geom_point(size = 3) +\n  scale_color_tableau()\n\n\n\n\n\n\n\nscale_color_tableau() provides color palettes used in Tableau."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#quick-detour",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#quick-detour",
    "title": "Lecture 10",
    "section": "üí° Quick Detour",
    "text": "üí° Quick Detour\nggthemes::theme_economist()\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ,\n              y = hwy, \n              color = class) ) + \n  geom_point(size = 3) +\n  scale_color_colorblind() +\n  theme_economist()\n\n\n\n\n\n\n\ntheme_economist() approximates the style of The Economist."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#quick-detour-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#quick-detour-1",
    "title": "Lecture 10",
    "section": "üí° Quick Detour",
    "text": "üí° Quick Detour\nggthemes::theme_wsj()\n\n\nggplot( data = mpg,\n        mapping = \n          aes(x = displ,\n              y = hwy, \n              color = class) ) + \n  geom_point(size = 3) +\n  scale_color_colorblind() +\n  theme_wsj()\n\n\n\n\n\n\n\ntheme_wsj() approximates the style of The Wall Street Journal."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#boxplots",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#boxplots",
    "title": "Lecture 10",
    "section": "Boxplots",
    "text": "Boxplots\n\n\n\n\n\n\n\n\n\n\n\nBoxplots visualize how the distribution of a numeric variable varies across levels of a categorical variable.\n\nThey display the median, quartiles, and potential outliers, providing a compact summary of the data."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#boxplots-with-geom_boxplot",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#boxplots-with-geom_boxplot",
    "title": "Lecture 10",
    "section": "Boxplots with geom_boxplot()",
    "text": "Boxplots with geom_boxplot()\n\n\nggplot(data = mpg,\n       mapping = \n         aes(x = class,\n             y = hwy)) + \n  geom_boxplot() \n\n\n\n\n\n\n\ngeom_boxplot() creates a boxplot;\n\nMappings: one numeric variable and one categorical variable to the x and y aesthetics"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#horizontal-boxplots",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#horizontal-boxplots",
    "title": "Lecture 10",
    "section": "Horizontal Boxplots",
    "text": "Horizontal Boxplots\n\n\nggplot(data = mpg,\n       mapping = \n         aes(x = hwy,\n             y = class)) + \n  geom_boxplot() \n\n\n\n\n\n\n\nBoxplots can be displayed horizontally or vertically.\n\nA horizontal boxplot works well when category names are long."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#customizing-the-fill-aesthetic",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#customizing-the-fill-aesthetic",
    "title": "Lecture 10",
    "section": "Customizing the fill Aesthetic",
    "text": "Customizing the fill Aesthetic\n\n\n# 1. `show.legend = FALSE` turns off \n#     the legend information\n# 2. `scale_fill_colorblind()` or\n#    `scale_fill_tableau()`\n#     applies a color-blind friendly \n#     palette to the `fill` aesthetic\n# install.packages(\"ggthemes\")\nlibrary(ggthemes) \nggplot(data = mpg,\n       mapping = \n         aes(x = hwy,\n             y = class,\n             fill = class)) + \n  geom_boxplot(\n    show.legend = FALSE) +\n  scale_fill_tableau() \n\n\n\n\n\n\n\nfill: Maps a variable to the fill colors used in the boxplot.\nggthemes::scale_fill_tableau(): A colorblind-friendly Tableau-style palette for the fill aesthetic."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#sorted-boxplots-with-fct_reordercategorical-numerical",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#sorted-boxplots-with-fct_reordercategorical-numerical",
    "title": "Lecture 10",
    "section": "Sorted Boxplots with fct_reorder(CATEGORICAL, NUMERICAL)",
    "text": "Sorted Boxplots with fct_reorder(CATEGORICAL, NUMERICAL)\n\n\n# labs() can label\n#   x-axis, y-axis, and more\n\nggplot(data = mpg,\n       mapping = \n        aes(x = hwy,\n            y = \n             fct_reorder(class, hwy),\n            fill = class)) + \n  geom_boxplot(\n    show.legend = FALSE) +\n  scale_fill_tableau() +\n  labs(x = \"Highway MPG\",\n       y = \"Class\") \n\n\n\n\n\n\n\nfct_reorder(CATEGORICAL, NUMERICAL): Reorders the categories of the CATEGORICAL by the median of the NUMERICAL."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#bar-charts",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#bar-charts",
    "title": "Lecture 10",
    "section": "Bar Charts",
    "text": "Bar Charts\n\n\nBar charts are used to visualize the distribution of a categorical variable.\nBar charts display the count (or proportion) of observations for each category."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#diamond-data",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#diamond-data",
    "title": "Lecture 10",
    "section": "Diamond Data",
    "text": "Diamond Data\n\n\n\n\n\n\nggplot2::diamonds is a data.frame containing the prices and other attributes of almost 54,000 diamonds."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#bar-charts-with-geom_bar",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#bar-charts-with-geom_bar",
    "title": "Lecture 10",
    "section": "Bar Charts with geom_bar()",
    "text": "Bar Charts with geom_bar()\n\n\nggplot(data = diamonds,\n       mapping = aes(x = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\ngeom_bar() creates a bar chart.\n\nWe map either the x or y aesthetic to the variable."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#horizontal-bar-charts",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#horizontal-bar-charts",
    "title": "Lecture 10",
    "section": "Horizontal Bar Charts",
    "text": "Horizontal Bar Charts\n\n\nggplot(data = diamonds,\n       mapping = aes(y = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\nBar charts can be horizontal or vertical.\n\nA horizontal bar chart is a good option for long category names."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#data-transformation---count-counting-occurrences-of-each-category-in-a-categorical-variable",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#data-transformation---count-counting-occurrences-of-each-category-in-a-categorical-variable",
    "title": "Lecture 10",
    "section": "Data Transformation - count(): Counting Occurrences of Each Category in a Categorical Variable",
    "text": "Data Transformation - count(): Counting Occurrences of Each Category in a Categorical Variable\n\n\nThe figure below demonstrates how the counting process works with geom_bar()."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#colorful-bar-charts-with-the-fill-aesthetic",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#colorful-bar-charts-with-the-fill-aesthetic",
    "title": "Lecture 10",
    "section": "Colorful Bar Charts with the fill Aesthetic",
    "text": "Colorful Bar Charts with the fill Aesthetic\n\n\nggplot(data = diamonds,\n       mapping = \n         aes(x = cut, \n             fill = cut)) + \n  geom_bar(\n    show.legend = FALSE\n    ) \n\n\n\n\n\n\n\nWe can color bar charts using the fill aesthetic."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#data-transformation---count-counting-occurrences-across-two-categorical-variables",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#data-transformation---count-counting-occurrences-across-two-categorical-variables",
    "title": "Lecture 10",
    "section": "Data Transformation - count(): Counting Occurrences Across Two Categorical Variables",
    "text": "Data Transformation - count(): Counting Occurrences Across Two Categorical Variables\nDATA.FRAME |&gt; count(CATEGORICAL_VARIABLE_1, CATEGORICAL_VARIABLE_2)\n\n\nThe data transformation function count() calculates the frequency of each unique combination of values across two categorical variables.\n\n\ndiamonds |&gt; count(cut, clarity)\n\n\n\n\n\n\n\n\n\ndiamonds |&gt; count(cut, clarity) returns the data.frame with the three variables, cut, clarity, and n:\n\nn: the number of occurrences of each unique combination of values in cut and clarity"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-with-the-fill-aesthetic",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-with-the-fill-aesthetic",
    "title": "Lecture 10",
    "section": "Stacked Bar Charts with the fill Aesthetic",
    "text": "Stacked Bar Charts with the fill Aesthetic\n\n\n# Mapping the `fill` aesthetic \n# to other CATEGORICAL variable\n# gives a stacked bar chart\n\nggplot(data = diamonds,\n       mapping = \n         aes(x = cut, \n             fill = clarity)) + \n  geom_bar()\n\n\n\n\n\n\n\nThis describes how the distribution of clarity varies by cut, with total bar height for overall count and segments for each clarity level."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-with-the-fill-aesthetic-the-positionfill",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-with-the-fill-aesthetic-the-positionfill",
    "title": "Lecture 10",
    "section": "100% Stacked Bar Charts with the fill Aesthetic & the position=\"fill\"",
    "text": "100% Stacked Bar Charts with the fill Aesthetic & the position=\"fill\"\n\n\nggplot(data = diamonds,\n       mapping = \n         aes(x = cut, \n             fill = clarity)) + \n  geom_bar(position = \"fill\") +\n  labs(y = \"Proportion\")\n\n\n\n\n\n\n\nThis describes how the distribution of clarity varies by cut, displaying the proportion of each clarity within each cut."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#clustered-bar-charts-with-the-fill-aesthetic-the-positiondodge",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#clustered-bar-charts-with-the-fill-aesthetic-the-positiondodge",
    "title": "Lecture 10",
    "section": "Clustered Bar Charts with the fill Aesthetic & the position=\"dodge\"",
    "text": "Clustered Bar Charts with the fill Aesthetic & the position=\"dodge\"\n\n\nggplot(data = diamonds,\n       mapping = \n         aes(x = cut, \n             fill = clarity)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\nThis shows how the distribution of clarity varies by cut, with separate bars for each clarity level within each cut category."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-using-the-fill-aesthetic-and-the-position-stack",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-using-the-fill-aesthetic-and-the-position-stack",
    "title": "Lecture 10",
    "section": "Stacked Bar Charts using the fill Aesthetic and the position = \"stack\"",
    "text": "Stacked Bar Charts using the fill Aesthetic and the position = \"stack\"\n\n\nggplot(data = diamonds,\n       mapping = \n         aes(x = cut, \n             fill = clarity)) + \n  geom_bar(position = \"stack\")\n\n\n\n\n\n\n\nThe default position option is position = \"stack\""
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#proportion-bar-charts-with-geom_bar",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#proportion-bar-charts-with-geom_bar",
    "title": "Lecture 10",
    "section": "Proportion Bar Charts with geom_bar()",
    "text": "Proportion Bar Charts with geom_bar()\n\n\nggplot(data = diamonds,\n       mapping = \n         aes(x = cut, \n             y = after_stat(prop),\n             group = 1)) + \n  geom_bar()\n\n\n\n\n\n\n\nafter_stat(prop): Calculates the proportion of the total count.\ngroup = 1: Ensures the proportions are calculated over the entire data.frame, not within each group of cut"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#bar-charts-with-geom_col",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#bar-charts-with-geom_col",
    "title": "Lecture 10",
    "section": "Bar Charts with geom_col()",
    "text": "Bar Charts with geom_col()\n\n\ndf &lt;- mpg |&gt; \n  count(class)\n\nggplot(data = df,\n       mapping = \n         aes(x = n, \n             y = class)) + \n  geom_col()\n\n\n\n\n\n\n\ngeom_col() creates bar charts where the height of bars directly represents values in a column in a given data.frame.\n\ngeom_col() requires both x- and y- aesthetics."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#sorted-bar-charts-with-fct_reordercategorical-numerical",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#sorted-bar-charts-with-fct_reordercategorical-numerical",
    "title": "Lecture 10",
    "section": "Sorted Bar Charts with fct_reorder(CATEGORICAL, NUMERICAL)",
    "text": "Sorted Bar Charts with fct_reorder(CATEGORICAL, NUMERICAL)\n\n\ndf &lt;- mpg |&gt; \n  count(class)\n\nggplot(data = df,\n       mapping = \n         aes(x = n,\n             y = \n               fct_reorder(class, n))\n       ) + \n  geom_col() +\n  labs(y = \"Class\")\n\n\n\n\n\n\n\nfct_reorder(CATEGORICAL, NUMERICAL): Reorders the categories of the CATEGORICAL by the median of the NUMERICAL."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#choosing-the-right-bar-charts-for-comparing-components-and-totals",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#choosing-the-right-bar-charts-for-comparing-components-and-totals",
    "title": "Lecture 10",
    "section": "Choosing the Right Bar Charts for Comparing Components and Totals",
    "text": "Choosing the Right Bar Charts for Comparing Components and Totals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich type of bar chart is most effective for your data?\nWhich type of bar chart best meets your visualization goals?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts",
    "title": "Lecture 10",
    "section": "Stacked Bar Charts",
    "text": "Stacked Bar Charts\n\n\n\n\n\n\n\n\n\n\n\n\nPurpose: Show the composition of each category while still conveying the overall total.\n\nWhen to use: Your primary focus is the total bar height, with a secondary interest in how subcomponents contribute.\n\nBe cautious: Precise comparisons across subcomponents are difficult because segments do not share a common baseline.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip: If you need to emphasize totals plus composition, a stacked bar chart is a strong choice."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#stacked-bar-charts-1",
    "title": "Lecture 10",
    "section": "100% Stacked Bar Charts",
    "text": "100% Stacked Bar Charts\n\n\n\n\n\n\n\n\n\n\n\n\nPurpose: Display the proportional composition of each category by normalizing all bars to the same height.\n\nWhen to use: Your focus is on comparing relative percentages across categories rather than absolute totals.\n\nBe cautious: While proportions are clear, absolute sizes or totals are not visible.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip: Choose a 100% stacked bar chart when you want to emphasize proportional differences across categories."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#clustered-bar-charts",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#clustered-bar-charts",
    "title": "Lecture 10",
    "section": "Clustered Bar Charts",
    "text": "Clustered Bar Charts\n\n\n\n\n\n\n\n\n\n\n\n\nPurpose: Plot each subcomponent as a separate bar within each category for side-by-side comparison.\n\nWhen to use: Your focus is on comparing individual subcomponents across categories.\n\nBe cautious: Can become crowded with many categories or subcomponents.\n\n\n\n\n\n\n\n\n\n\n\nTip: Choose a clustered bar chart when you want to emphasize precise comparisons between subcomponents‚Äîboth within each cluster and across clusters."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#pie-charts-alternative-to-bar-charts",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#pie-charts-alternative-to-bar-charts",
    "title": "Lecture 10",
    "section": "Pie Charts: Alternative to Bar Charts?",
    "text": "Pie Charts: Alternative to Bar Charts?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPie charts display the proportions of a whole.\n\nEach slice represents a part of the total.\n\nBut is a pie chart an effective alternative to a bar chart?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#pie-charts-alternative-to-bar-charts-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#pie-charts-alternative-to-bar-charts-1",
    "title": "Lecture 10",
    "section": "Pie Charts: Alternative to Bar Charts?",
    "text": "Pie Charts: Alternative to Bar Charts?\nHumans are generally better at judging lengths than angles.\n\nStill, pie charts can be useful in certain cases.\n\n\n\n\n\n\n\n\nPie charts work best when there are very few categories‚Äîideally four or fewer.\n\nPie charts are effective when the goal is to highlight simple, recognizable fractions (e.g., 25%, 50%, 75%)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#pie-charts-alternative-to-bar-charts-2",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#pie-charts-alternative-to-bar-charts-2",
    "title": "Lecture 10",
    "section": "Pie Charts: Alternative to Bar Charts?",
    "text": "Pie Charts: Alternative to Bar Charts?\n\n\n\n\n\nPie charts are not ideal when the audience needs to compare the size of individual shares across categories.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPie charts are not ideal when the goal is to compare the overall distribution of categories."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#numeric-or-categorical",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#numeric-or-categorical",
    "title": "Lecture 10",
    "section": "Numeric or Categorical?",
    "text": "Numeric or Categorical?\n\n\n\n\n\nTreat as Numeric (Continuous)\n\nWhen the integer reflects a magnitude, intensity, or a meaningful ordered scale.\nExamples:\n\nAge (18, 19, 20, 21, ‚Ä¶)\nMPG values (27, 28, 29, 30, ‚Ä¶)\nTemperature readings (whole-number data)\n\n\n\nTreat as Categorical (Discrete)\n\nWhen the integer is simply a label for a category, and the numeric order does not represent meaningful numeric differences.\nExamples:\n\nMonth (1‚Äì12)\nDay of week (1‚Äì7)\nZIP codes\nStudent ID numbers"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#historams-or-bar-charts",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#historams-or-bar-charts",
    "title": "Lecture 10",
    "section": "Historams or Bar Charts?",
    "text": "Historams or Bar Charts?\n\n\nHistograms for the Age variable\n\n\n\n\n\n\n\n\n\nBar Charts for the Age variable\n\n\n\n\n\n\n\n\n\n\n\nIn ggplot, the distribution of an integer variable can look quite similar whether using geom_histogram() or geom_bar().\nAs shown above, in Python and other tools, these visualizations can behave differently, leading to noticeably different outputs."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-1",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-1",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nCurrent Appointment & Education\n\nName: Byeong-Hak Choe.\nAssistant Professor of Data Analytics and Economics, School of Business at SUNY Geneseo.\nPh.D.¬†in Economics from University of Wyoming.\nM.S. in Economics from Arizona State University.\nM.A.¬†in Economics from SUNY Stony Brook.\nB.A. in Economics & B.S. in Applied Mathematics from Hanyang University at Ansan, South Korea.\n\nMinor in Business Administration.\nConcentration in Finance."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-2",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-2",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H., 2021. ‚ÄúSocial Media Campaigns, Lobbying and Legislation: Evidence from #climatechange and Energy Lobbies.‚Äù\nQuestion: To what extent do social media campaigns compete with fossil fuel lobbying on climate change legislation?\nData include:\n\n5.0 million tweets with #climatechange/#globalwarming around the globe;\n12.0 million retweets/likes to those tweets;\n0.8 million Twitter users who wrote those tweets;\n1.4 million Twitter users who retweeted or liked those tweets;\n0.3 million US Twitter users with their location at a city level;\nFirm-level lobbying data (expenses, targeted bills, etc.)."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-3",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-3",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H. and Ore-Monago, T., 2024. ‚ÄúGovernance and Climate Finance in the Developing World‚Äù\nClimate finance refers to the financial resources allocated for mitigating and adapting to climate change, including support for initiatives that reduce greenhouse gas emissions and enhance resilience to climate impacts.\n\nWe focus on transnational financing that rich countries provide poor countries with financial resources, in order to help them adapt to climate change and mitigate greenhouse gas (GHG) emissions.\nSince the GHG emissions in developing countries are rapidly growing, it is crucial to assess the effectiveness of climate finance.\nPoor governance (e.g., legal system, rule of law, and accountability) can be significant barriers to emissions reductions."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-4",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#instructor-4",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H. and Newbold, Steve, ‚ÄúEstimating the Value of Statistical Life (VSL) through Big Data‚Äù\nVSL is the monetary value associated with reducing the risk of death.\n\nHow much value would that be? How can we measure it?\nHow do government agencies use the VSL to decide which policies are worth the cost when they reduce the risk of death?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-1",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-1",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nEmail, Class & Office Hours\n\nEmail: bchoe@geneseo.edu\nClass Homepage:\n\nGitHub Course Website\nBrightspace Course Shell\n\nOffice: South Hall 227B\nOffice Hours:\n\nMondays and Wednesdays 3:30 P.M.‚Äì5:00 P.M.\nBy appointment via email."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-2",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-2",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Description\n\nThis course provides an applied overview of the data analytic process and methods.\nThe goal of this course is to help students unlock the potential of data analysis and improve the ability to transform data into a powerful tool in decision making.\nStudents will develop foundational data analytics skills to prepare for a career or future learning that involves more advanced topics in data analytics."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-3",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-3",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Description\n\nTopics covered include\n\nIntroduction to Data Analytics thinking\nData tools and skills\nData management and preparation techniques\nData storytelling for effective visualization and communication.\n\nDuring the course, students will work hands-on with the R programming and its associated data analysis packages."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-4",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-4",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Learning Outcomes\n\nGrasp the basic principles of data analytics, including data types and data processing.\nGain introductory experience with programming languages commonly used in data analytics, such as R.\nDevelop the ability to create and interpret various types of data visualizations.\nEnhance critical thinking skills by learning to ask relevant questions and draw insights from data.\nApply data analytics techniques to solve real-world problems in various domains."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-5",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-5",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nReference Materials - Concepts\n\nCloud Computing Concepts Hub ‚Äî Amazon Web Services (AWS)\nCo-Intelligence: Living and Working with AI ‚Äî Ethan Mollick. (ISBN-13: 978-0593716717; ISBN-10: 059371671X)\nStorytelling with Data: A Data Visualization Guide for Business Professionals ‚Äî Cole Nussbaumer Knaflic. (ISBN-13: 978-1119002253; ISBN-10: 1119002257)\nStorytelling with Data: Before and After - Practical Makeovers for Powerful Data Stories ‚Äî Cole Nussbaumer Knaflic, Mike Cisneros, and Alex Velez. (ISBN-13: 978-1394289615; ISBN-10: 1394289618)"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-6",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-6",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nReference Materials - Coding\n\nHands-On Programming with R ‚Äî Garrett Grolemund. (ISBN-13: 978-1449359010; ISBN-10: 1449359019)\n\nFree online version is available here\n\nR for Data Science (2nd Edition) ‚Äî Hadley Wickham & Garrett Grolemund. (ISBN-13: 978-1492097402; ISBN-10: 1492097403)\n\nFree online version is available here.\n\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse ‚Äî Chester Ismay & Albert Y. Kim. (ISBN-13: 978-0367409821; ISBN-10: 0367409828)\n\nFree online version is available here.\n\n\n:::\n::::"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-7",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-7",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Requirements\n\nHomework: Five assignments.\nQuiz: Two in-class quizzes.\nParticipation: In-person and online participation\nExam: Two short midterm exams and one comprehensive final exam.\nProject: a data storytelling project with a team presentation."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-8",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-8",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nData Storytelling Project\n\nEach team will present on data storytelling with visualization.\nData storytelling with visualization is the practice of communicating complex insights in a clear, engaging, and impactful way by combining data analysis, visual design, and narrative techniques.\nIt is more than just presenting charts and graphs; it involves shaping a compelling story that guides the audience through the data, emphasizes key findings, and delivers the intended message effectively."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-9",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-9",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-10",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-10",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-11",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-11",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-12",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-12",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n(\\text{Total Percentage Grade}) =&\\quad\\;\\; 0.05\\times(\\text{Attendance}) \\notag\\\\\n&\\,+\\, 0.05\\times(\\text{Quiz & Participation})\\notag\\\\\n& \\,+\\, 0.20\\times(\\text{Homework})\\notag\\\\  \n&\\,+\\, 0.20\\times(\\text{Presentation})\\notag\\\\\n& \\,+\\, 0.50\\times(\\text{Exam}).\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-13",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-13",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading - Attendance & Homework\n\nYou are allowed up to 4 absences in the MW course and 6 absences in the MWF course without penalty.\n\nSend me an email if you have standard excused reasons (illness, family emergency, transportation problems, etc.).\n\nFor each absence beyond the initial four/six, there will be a deduction of 1% point from the Total Percentage Grade.\nThe single lowest homework score will be dropped when calculating the total homework score.\n\nEach homework except for the homework with the lowest score accounts for 25% of the total homework score."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-14",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-14",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading - Midterm Exam Score\n\\[\n\\begin{align}\n&(\\text{Midterm Exam Score}) \\\\\n=\\, &\\text{max}\\,\\left\\{0.50\\times(\\text{Midterm Exam 1 Score}) \\,+\\, 0.50\\times(\\text{Midterm Exam 2 Score})\\right.,\\notag\\\\\n&\\qquad\\;\\,\\left.0.33\\times(\\text{Midterm Exam 1 Score}) \\,+\\, 0.67\\times(\\text{Midterm Exam 2 Score})\\right\\}.\\notag\n\\end{align}\n\\]\n\nThe Midterm Exam Score is the maximum between\n\nThe simple average of the Midterm Exam 1 Score and the Midterm Exam 2 Score and\nThe weighted average of them with one-third weight on the Midterm Exam 1 Score and two-third weight on the Midterm Exam 2 Score:"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-15",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-15",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading - Total Exam Score\n\\[\n\\begin{align}\n&(\\text{Total Exam Score}) \\\\\n=\\, &\\text{max}\\,\\left\\{0.50\\times(\\text{Midterm Exam Score}) \\,+\\, 0.50\\times(\\text{Final Exam Score})\\right.,\\notag\\\\\n&\\qquad\\;\\,\\left.0.25\\times(\\text{Midterm Exam Score}) \\,+\\, 0.75\\times(\\text{Final Exam Score})\\right\\}.\\notag\n\\end{align}\n\\]\n\nThe Total Exam score is the maximum between\n\nThe simple average of the Midterm Exam score and the Final Exam score and\nThe weighted average of them with one-fourth weight on the Midterm Exam score and three-fourth weight on the Final Exam score:"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-16",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-16",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nMake-up Policy\n\nMake-up exams will not be given unless you have either a medically verified excuse or an absence excused by the University.\nIf you cannot take exams because of religious obligations, notify me by email at least two weeks in advance so that an alternative exam time may be set.\nA missed exam without an excused absence earns a grade of zero.\nLate submissions for homework assignment will be accepted with a penalty.\nA zero will be recorded for a missed assignment."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-17",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-17",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAcademic Integrity and Plagiarism\n\nAll homework assignments and exams must be the original work by you.\nExamples of academic dishonesty include:\n\nRepresenting the work, thoughts, and ideas of another person as your own\nAllowing others to represent your work, thoughts, or ideas as theirs, and\nBeing complicit in academic dishonesty by suspecting or knowing of it and not taking action.\n\nGeneseo‚Äôs Library offers frequent workshops to help you understand how to paraphrase, quote, and cite outside sources properly.\n\nSee https://www.geneseo.edu/library/library-workshops."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-18",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-18",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nArtificial Intelligence (AI) Policy\n\nUnless AI tools are explicitly permitted for homework, you must complete your work independently.\nThis means you should not use tools like ChatGPT for any aspect of our coursework.\nSuch use is a form of academic dishonesty. Use of such tools is not only cheating, it will also cheat you of the opportunity to learn and develop your own skills.\nWhile AI will undoubtedly play important roles in our future society, you will be better able to utilize AI if you have developed your own critical thinking, writing, and analytical skills by doing your own work.\nIf you have any questions about this, please ask."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-19",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-19",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAccessibility\n\nThe Office of Accessibility will coordinate reasonable accommodations for persons with physical, emotional, or cognitive disabilities to ensure equal access to academic programs, activities, and services at Geneseo.\nPlease contact me and the Office of Accessibility Services for questions related to access and accommodations."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-20",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#syllabus-20",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCareer Design\n\nTo get information about career development, you can visit the Career Development Events Calendar (https://www.geneseo.edu/career_development/events/calendar).\nYou can stop by South 112 to get assistance in completing your Handshake Profile https://app.joinhandshake.com/login.\n\nHandshake is ranked #1 by students as the best place to find full-time jobs.\n50% of the 2018-2020 graduates received a job or internship offer on Handshake.\nHandshake is trusted by all 500 of the Fortune 500."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#why-data-analytics",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#why-data-analytics",
    "title": "Lecture 1",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nFill in the gaps left by traditional business and economics classes.\n\nPractical skills that will benefit your future career.\nNeglected skills like how to actually find datasets in the wild and clean them.\n\nData analytics skills are largely distinct from (and complementary to) the core quantitative works familiar to business undergrads.\n\nData visualization, cleaning and wrangling; databases; machine learning; etc.\n\nIn short, we will cover things that I wish someone had taught me when I was undergraduate."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#you-at-the-end-of-this-course",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#you-at-the-end-of-this-course",
    "title": "Lecture 1",
    "section": "You, at the end of this course",
    "text": "You, at the end of this course"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#why-data-analytics-1",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#why-data-analytics-1",
    "title": "Lecture 1",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nData analysts use analytical tools and techniques to extract meaningful insights from data.\n\nSkills in data analytics are also useful for business analysts, market analysts, financial analysts, human resource analysts, or economists.\n\nBreau of Labor Statistics forecasts that the projected growth rate of the employment in the industry related to data analytics from 2021 to 2031 is 36%.\n\nThe average growth rate for all occupations is 5%."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#why-r-python-and-databases",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#why-r-python-and-databases",
    "title": "Lecture 1",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#why-r-python-and-databases-1",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#why-r-python-and-databases-1",
    "title": "Lecture 1",
    "section": "Why R, Python, and Databases?",
    "text": "Why R, Python, and Databases?\nStack Overflow Trends\n\n\nStack Overflow is the most popular Q & A website specifically for programmers and software developers in the world.\nSee how programming languages have trended over time based on use of their tags in Stack Overflow from 2008 to 2023.\n\n\n\n\nMost Popular Languagues\n\n\nData Science and Big Data"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#data-analytics-and-generative-artificial-intelligence-ai",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#data-analytics-and-generative-artificial-intelligence-ai",
    "title": "Lecture 1",
    "section": "Data Analytics and Generative Artificial Intelligence (AI)",
    "text": "Data Analytics and Generative Artificial Intelligence (AI)\n\n\nData Analytics and Big Data Trend\nFrom 2008 to 2025\n\n\nProgrammers in 2025"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#data-analytics-and-generative-ai",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#data-analytics-and-generative-ai",
    "title": "Lecture 1",
    "section": "Data Analytics and Generative AI",
    "text": "Data Analytics and Generative AI\n\nGenerative AI refers to a category of AI that is capable of generating new content, ranging from text, images, and videos to music and code.\n\n\n\nIn the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input.\n\nThese include large language model (LLM) chatbots (e.g., ChatGPT, Claude, Gemini, Copilot, Grok).\n\nChatGPT (Chat Generative Pre-trained Transformer) is a chatbot developed by OpenAI and launched on November 30, 2022.\n\nBy January 2023, it had become what was then the fastest-growing consumer software application in history."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#data-analytics-and-generative-ai-1",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#data-analytics-and-generative-ai-1",
    "title": "Lecture 1",
    "section": "Data Analytics and Generative AI",
    "text": "Data Analytics and Generative AI\n\nUsers around the world have explored how to best utilize GPT for writing essays and programming codes.\n\n\n\n\nIs AI a threat to data analytics?\n\nFundamental understanding of the subject matter is still crucial for effectively utilizing AI‚Äôs capabilities.\n\n\n\n\n\nIf you use Generative AI such as ChatGPT, please try to understand what ChatGPT gives you.\n\nCopying and pasting it without any understanding harms your learning opportunity."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-r",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-r",
    "title": "Lecture 1",
    "section": "What is R?",
    "text": "What is R?\n\nR is a programming language and software environment designed for statistical computing and graphics.\nR has become a major tool in data analysis, statistical modeling, and visualization.\n\nIt is widely used among statisticians and data scientists for developing statistical software and performing data analysis.\nR is open source and freely available."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-rstudio",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-rstudio",
    "title": "Lecture 1",
    "section": "What is RStudio?",
    "text": "What is RStudio?\n\nRStudio is an integrated development environment (IDE) for R.\n\nAn IDE is a software application that provides comprehensive facilities (e.g., text code editor, graphical user interface (GUI)) to computer programmers for software development.\n\nRStudio is a user-friendly interface that makes using R easier and more interactive.\n\nIt provides a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging, and workspace management.\n\nWe will use a free cloud version of RStudio, which is Posit Cloud."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-python",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-python",
    "title": "Lecture 1",
    "section": "What is Python?",
    "text": "What is Python?\n\nPython is a versatile programming language known for its simplicity and readability.\nPython has become a dominant tool in various fields including data analysis, machine learning, and web development.\n\nIt is widely used among developers, data scientists, and researchers for building applications and performing data-driven tasks.\nPython is open source and has a vast ecosystem of libraries and frameworks."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-jupyter",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-jupyter",
    "title": "Lecture 1",
    "section": "What is Jupyter?",
    "text": "What is Jupyter?\n\nJupyter is an open-source integrated development environment (IDE) primarily for Python, though it supports many other languages.\n\nJupyter provides a notebook interface that allows users to write and execute code in a more interactive and visual format.\n\nJupyter Notebook is a user-friendly environment that enhances coding, data analysis, and visualization.\n\nIt offers a web-based interface that combines live code, equations, visualizations, and narrative text.\nJupyter is widely used for data science, machine learning, and research, enabling easy sharing and collaboration.\n\nYou can use a free cloud version of Jupyter, which is Google Colab.\n\nGoogle Colab can be used for R as well."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#python-vs.-r",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#python-vs.-r",
    "title": "Lecture 1",
    "section": "Python vs.¬†R",
    "text": "Python vs.¬†R"
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-git",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-git",
    "title": "Lecture 1",
    "section": "What is Git?",
    "text": "What is Git?\n\n\n\n\n\\(\\quad\\)\n\nGit is the most popular version control tool for any software development.\n\nIt tracks changes in a series of snapshots of the project, allowing developers to revert to previous versions, compare changes, and merge different versions.\nIt is the industry standard and ubiquitous for coding collaboration."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-github",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-github",
    "title": "Lecture 1",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nGitHub is a web-based hosting platform for Git repositories to store, manage, and share code.\nOur course website is hosted on a GitHub repository.\nCourse contents will be posted not only in Brightspace but also in my GitHub repositories (‚Äúrepos‚Äù).\nGithub is useful for many reasons, but the main reason is how user friendly it makes uploading and sharing code."
  },
  {
    "objectID": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-github-1",
    "href": "danl-lec/danl-101-lec-01-2025-0825.html#what-is-github-1",
    "title": "Lecture 1",
    "section": "What is GitHub?",
    "text": "What is GitHub?"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html",
    "href": "danl-rw/danl-101-team-project-basketball.html",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "",
    "text": "The following lists data frames about NBA 2022-23 through 2024-25:\n\nnba_games: NBA Game Logs\nnba_adv: NBA Advanced Statistics\nnba_ff: NBA Four Factors‚Äî(1) Effective field goal percentage, (2) Turnovers committed per possession, (3) Offensive rebounding percentage, and (4) Free throw rate\nnba_games_adv_ff: Joined data.frame (Game Logs + Advanced Statistics + Four Factors)\n\nnba_games_adv_ff &lt;- nba_games |&gt; left_join(nba_adv) |&gt; left_join(nba_ff) by c(\"team_id\", \"team_abbreviation\", \"game_id\", \"min\")\nTurnovers committed per possession is included here.\n\nnba_players: NBA Player Statistics\n\nWhile the above data.frames are team-level data, this nba_players data.frame is player-level data.\n\n\n\n\n\nnba_games: NBA Game Logs\n\nA data frame with 7380 observations and 29 variables:\n\n\n\nnba_games &lt;- read_csv(\"http://bcdanl.github.io/data/nba_games_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\nteam_id Team ID on nba.com\nteam_abbreviation Team abbreviation on nba.com\nteam_name Team name on nba.com\ngame_id Game ID on nba.com\ngame_date Date in YYYY-MM-DD\nmatchup Team One vs.¬†Team Two\nwl Win or Loss\nmin Minutes in the game\nfgm Team Field goals made\nfga Team Field goal attempts\nfg_pct Team field goal percentage\nfg3m Team three point field goals made\nfg3a Team three point field goal attempts\nfg3_pct Team three point field goal percentage\nefg Effective field goal percentage efg = (fg2m + 1.5*fg3m)/(fga) It adjusts the traditional field goal percentage to account for the fact that three-point field goals are worth more than two-point field goals.\nftm Team free throws made\nfta Team free throw attempts\nftr Free throw rate (FTR). The ratio of free throw attempts (fta) to field goal attempts (fga) ftr = fta / fga\nft_pct Team free throw percentage\noreb Team offensive rebounds\ndreb Team defensive rebounds\nreb Team total rebounds\nast Team total assists\nstl Team total steals\nblk Team total blocks\ntov Team total turnovers\npf Team total personal fouls\npts Team total points scored\nplus_minus Margin of game as Team score minus Opponent score\nvideo_available Logical if game video exists\n\n\n\n\n\nnba_adv: NBA Advanced Statistics\n\nA data frame with 7380 observations and 29 variables\n\n\n\nnba_adv &lt;- read_csv(\"http://bcdanl.github.io/data/nba_adv_team_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\ngame_id Game ID on nba.com\nteam_id Team ID on nba.com\nteam_name Team name\nteam_abbreviation Team abbreviation\nteam_city Team city\nmin Total minutes in the game\ne_off_rating Offensive rating (effective ?)\noff_rating Offensive rating\ne_def_rating Defensive rating (effective ?)\ndef_rating Defensive rating\ne_net_rating Net rating (effective ?)\nnet_rating Net rating\nast_pct Assist percentage\nast_tov Assists to turnover ratio\nast_ratio Assist ratio\noreb_pct Offensive rebound percentage\ndreb_pct Defensive rebound percentage\nreb_pct Total rebound percentage\ne_tm_tov_pct Turnover percentage (effective?)\ntm_tov_pct Turnover percentage\nefg_pct Effective field goal percentage\nts_pct True Shooting percentage\nusg_pct Usage percentage\ne_usg_pct Usage percentage (effective?)\ne_pace Pace (effective ?)\npace Pace\npace_per40 Pace per forty minutes\nposs Team possessions in game\npie Player impact estimate\n\n\n\n\n\nnba_ff: NBA Team-level Four Factors‚Äî(1) Effective field goal percentage, (2) Turnovers committed per possession, (3) Offensive rebounding percentage, and (4) Free throw rate\n\nA data frame with 2460 observations and 14 variables\n\n\n\nnba_ff &lt;- read_csv(\"http://bcdanl.github.io/data/nba_ff_team_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\ngame_id Game ID on nba.com\nteam_id Team ID on nba.com\nteam_name Team name on nba.com\nteam_abbreviation Team abbreviation on nba.com\nteam_city Team city\nmin Minutes in the game\nefg_pct Effective field goal percentage\nfta_rate Free throw rate of team\ntm_tov_pct Turnover percentage of opponent\noreb_pct Offensive rebound percentage of opponent\nopp_efg_pct Effective field goal percentage of opponent\nopp_fta_rate Free throw rate of opponent\nopp_tov_pct Turnover percentage of opponent\nopp_oreb_pct Offensive rebound percentage of opponent\n\n\n\n\n\nnba_games_adv_ff is the data.frame that contains all the information in the nba_games, nba_adv, and nba_ff data.frames.\n\nTurnovers committed per possession is included here.\n\n\n\nnba_games_adv_ff &lt;- read_csv(\"http://bcdanl.github.io/data/nba_games_adv_ff_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\ntpp Turnovers committed per possession (TPP). The number of turnovers committed relative to the number of possessions the team had during the game. tpp = tov / poss.\n\ntov comes from game log data.frame\nposs comes from advanced statistics data.frame\n\n\n\n\n\nnba_players: NBA Player Statistics\n\nA data frame with 2150 observations and 32 variables\n\n\n\nnba_players &lt;- read_csv(\"http://bcdanl.github.io/data/nba_players_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\nrank: Player‚Äôs ranking on the stats table (Rk from Basketball Reference)\nplayer: Full player name\npos: Player position (e.g., PG, SG, SF, PF, C)\nage: Player age during the season\nteam_abbreviation: NBA team abbreviation (e.g., LAL, BOS, GSW)\nsalary: Player salary for that season (in USD)\ng: Games played\ngs: Games started\nmp: Minutes played per game\nfg: Field goals made per game\nfga: Field goals attempted per game\nfg%: Field goal percentage\n3p: Three-point field goals made per game\n3pa: Three-point field goals attempted per game\n3p%: Three-point shooting percentage\n2p: Two-point field goals made per game\n2pa: Two-point field goals attempted per game\n2p%: Two-point shooting percentage\nefg%: Effective field goal percentage\n\nAdjusts for the added value of 3-point shots\n\nft: Free throws made per game\nfta: Free throws attempted per game\nft%: Free-throw percentage\norb: Offensive rebounds per game\ndrb: Defensive rebounds per game\ntrb: Total rebounds per game\nast: Assists per game\nstl: Steals per game\nblk: Blocks per game\ntov: Turnovers per game\npf: Personal fouls per game\npts: Points per game\n\nSource:\n\nBasketball Reference\nESPN NBA"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#nba-game-logs-nba_games",
    "href": "danl-rw/danl-101-team-project-basketball.html#nba-game-logs-nba_games",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "",
    "text": "nba_games: NBA Game Logs\n\nA data frame with 7380 observations and 29 variables:\n\n\n\nnba_games &lt;- read_csv(\"http://bcdanl.github.io/data/nba_games_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\nteam_id Team ID on nba.com\nteam_abbreviation Team abbreviation on nba.com\nteam_name Team name on nba.com\ngame_id Game ID on nba.com\ngame_date Date in YYYY-MM-DD\nmatchup Team One vs.¬†Team Two\nwl Win or Loss\nmin Minutes in the game\nfgm Team Field goals made\nfga Team Field goal attempts\nfg_pct Team field goal percentage\nfg3m Team three point field goals made\nfg3a Team three point field goal attempts\nfg3_pct Team three point field goal percentage\nefg Effective field goal percentage efg = (fg2m + 1.5*fg3m)/(fga) It adjusts the traditional field goal percentage to account for the fact that three-point field goals are worth more than two-point field goals.\nftm Team free throws made\nfta Team free throw attempts\nftr Free throw rate (FTR). The ratio of free throw attempts (fta) to field goal attempts (fga) ftr = fta / fga\nft_pct Team free throw percentage\noreb Team offensive rebounds\ndreb Team defensive rebounds\nreb Team total rebounds\nast Team total assists\nstl Team total steals\nblk Team total blocks\ntov Team total turnovers\npf Team total personal fouls\npts Team total points scored\nplus_minus Margin of game as Team score minus Opponent score\nvideo_available Logical if game video exists"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#nba-advanced-statistics-nba_adv",
    "href": "danl-rw/danl-101-team-project-basketball.html#nba-advanced-statistics-nba_adv",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "",
    "text": "nba_adv: NBA Advanced Statistics\n\nA data frame with 7380 observations and 29 variables\n\n\n\nnba_adv &lt;- read_csv(\"http://bcdanl.github.io/data/nba_adv_team_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\ngame_id Game ID on nba.com\nteam_id Team ID on nba.com\nteam_name Team name\nteam_abbreviation Team abbreviation\nteam_city Team city\nmin Total minutes in the game\ne_off_rating Offensive rating (effective ?)\noff_rating Offensive rating\ne_def_rating Defensive rating (effective ?)\ndef_rating Defensive rating\ne_net_rating Net rating (effective ?)\nnet_rating Net rating\nast_pct Assist percentage\nast_tov Assists to turnover ratio\nast_ratio Assist ratio\noreb_pct Offensive rebound percentage\ndreb_pct Defensive rebound percentage\nreb_pct Total rebound percentage\ne_tm_tov_pct Turnover percentage (effective?)\ntm_tov_pct Turnover percentage\nefg_pct Effective field goal percentage\nts_pct True Shooting percentage\nusg_pct Usage percentage\ne_usg_pct Usage percentage (effective?)\ne_pace Pace (effective ?)\npace Pace\npace_per40 Pace per forty minutes\nposs Team possessions in game\npie Player impact estimate"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#nba-four-factors-nba_ff",
    "href": "danl-rw/danl-101-team-project-basketball.html#nba-four-factors-nba_ff",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "",
    "text": "nba_ff: NBA Team-level Four Factors‚Äî(1) Effective field goal percentage, (2) Turnovers committed per possession, (3) Offensive rebounding percentage, and (4) Free throw rate\n\nA data frame with 2460 observations and 14 variables\n\n\n\nnba_ff &lt;- read_csv(\"http://bcdanl.github.io/data/nba_ff_team_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\ngame_id Game ID on nba.com\nteam_id Team ID on nba.com\nteam_name Team name on nba.com\nteam_abbreviation Team abbreviation on nba.com\nteam_city Team city\nmin Minutes in the game\nefg_pct Effective field goal percentage\nfta_rate Free throw rate of team\ntm_tov_pct Turnover percentage of opponent\noreb_pct Offensive rebound percentage of opponent\nopp_efg_pct Effective field goal percentage of opponent\nopp_fta_rate Free throw rate of opponent\nopp_tov_pct Turnover percentage of opponent\nopp_oreb_pct Offensive rebound percentage of opponent"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#nba-game-logs-advanced-statistics-four-factors-nba_games_adv_ff",
    "href": "danl-rw/danl-101-team-project-basketball.html#nba-game-logs-advanced-statistics-four-factors-nba_games_adv_ff",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "",
    "text": "nba_games_adv_ff is the data.frame that contains all the information in the nba_games, nba_adv, and nba_ff data.frames.\n\nTurnovers committed per possession is included here.\n\n\n\nnba_games_adv_ff &lt;- read_csv(\"http://bcdanl.github.io/data/nba_games_adv_ff_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\ntpp Turnovers committed per possession (TPP). The number of turnovers committed relative to the number of possessions the team had during the game. tpp = tov / poss.\n\ntov comes from game log data.frame\nposs comes from advanced statistics data.frame"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#nba-player-statistics-nba_players",
    "href": "danl-rw/danl-101-team-project-basketball.html#nba-player-statistics-nba_players",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "",
    "text": "nba_players: NBA Player Statistics\n\nA data frame with 2150 observations and 32 variables\n\n\n\nnba_players &lt;- read_csv(\"http://bcdanl.github.io/data/nba_players_2022-23_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\n\nseason_id: Season identifier used in your dataset\n\n\"2022\" ‚Üí 2022‚Äì23 season\n\n\"2023\" ‚Üí 2023‚Äì24 season\n\n\"2024\" ‚Üí 2024‚Äì25 season\n\nrank: Player‚Äôs ranking on the stats table (Rk from Basketball Reference)\nplayer: Full player name\npos: Player position (e.g., PG, SG, SF, PF, C)\nage: Player age during the season\nteam_abbreviation: NBA team abbreviation (e.g., LAL, BOS, GSW)\nsalary: Player salary for that season (in USD)\ng: Games played\ngs: Games started\nmp: Minutes played per game\nfg: Field goals made per game\nfga: Field goals attempted per game\nfg%: Field goal percentage\n3p: Three-point field goals made per game\n3pa: Three-point field goals attempted per game\n3p%: Three-point shooting percentage\n2p: Two-point field goals made per game\n2pa: Two-point field goals attempted per game\n2p%: Two-point shooting percentage\nefg%: Effective field goal percentage\n\nAdjusts for the added value of 3-point shots\n\nft: Free throws made per game\nfta: Free throws attempted per game\nft%: Free-throw percentage\norb: Offensive rebounds per game\ndrb: Defensive rebounds per game\ntrb: Total rebounds per game\nast: Assists per game\nstl: Steals per game\nblk: Blocks per game\ntov: Turnovers per game\npf: Personal fouls per game\npts: Points per game\n\nSource:\n\nBasketball Reference\nESPN NBA"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#offensive-statistics",
    "href": "danl-rw/danl-101-team-project-basketball.html#offensive-statistics",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "Offensive Statistics",
    "text": "Offensive Statistics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nPoints Scored\nTotal points scored by a player\n\n\nMinutes Played\nAmount of game time a player is one of the five active players on the court\n\n\nField Goal Percentage\nNumber of shots made divided by the number of shots attempted (FG% = Made √∑ Attempted)\n\n\nFree Throw Percentage\nNumber of free throws made divided by the number of free throws attempted (FT% = Made √∑ Attempted)\n\n\nAssists\nPasses that directly result in a teammate scoring a field goal\n\n\nThree-Point Shots\nShots made from behind the three-point line"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#defensive-statistics",
    "href": "danl-rw/danl-101-team-project-basketball.html#defensive-statistics",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "Defensive Statistics",
    "text": "Defensive Statistics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nDefensive Rebounds\nCatching the ball after an opponent‚Äôs missed shot\n\n\nBlocks\nSwatting the ball away as it leaves the opponent‚Äôs hand\n\n\nSteals\nTaking the ball away from an opponent without committing a foul\n\n\nFouls\nBreaking the rules of permissible conduct, usually involving physical contact during a shot\n\n\nTurnovers\nActions that cause the other team to gain possession, excluding fouls or missed shots (e.g., bad passes out of bounds)\n\n\nPlus/Minus\nThe net number of points your team scored versus allowed while you were in the game"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-basketball.html#four-factors",
    "href": "danl-rw/danl-101-team-project-basketball.html#four-factors",
    "title": "Data Storytelling Team Project - Basketball",
    "section": "Four Factors",
    "text": "Four Factors\nThe ‚Äúfour factors‚Äù concept, developed by Dean Oliver and detailed in his book Basketball on Paper (available at basketballonpaper.com), outlines the key elements contributing to a team‚Äôs success. Oliver originally assigned the following weights to these factors: shooting (40%), turnovers (25%), rebounding (20%), and free throws (15%). While the exact weighting is often debated, the importance of these four factors is widely recognized. They are critical not only for understanding a team‚Äôs offensive efficiency but also for evaluating defensive performance (e.g., analyzing the opponent‚Äôs effective field goal percentage). The four factors are:\n\nEffective Field Goal Percentage (EFG%)\nTurnovers Committed per Possession\nOffensive Rebounding Percentage (ORP)\nFree Throw Rate (FTR)\n\n\nEffective Field Goal Percentage (EFG%)\nEffective field goal percentage adjusts for the difference in value between two-point and three-point shots, giving three-pointers 50% more weight since they are worth 50% more points. The formula for EFG% is:\n\\[\nEFG = \\frac{fg2m + 1.5 \\times fg3m}{fga}\n\\] Where\n\nfg2m: Number of two-point field goals made\nfg3m: Number of three-point field goals made\nfga: Total field goals attempted\n\n\n\nTurnovers Committed per Possession\nThis metric measures how often a team turns the ball over relative to the number of possessions they have in a game. It highlights a team‚Äôs ball-handling efficiency by considering turnovers (tov) in relation to total possessions (poss).\n\n\nOffensive Rebounding Percentage\nOffensive rebounding percentage evaluates a team‚Äôs ability to secure offensive rebounds compared to the total number of available offensive rebounds. The formula is:\n\\[\nORP = \\frac{\\text{Team Offensive Rebounds}}{\\text{Team Offensive Rebounds + Opponent Offensive Rebounds}}\n\\]\n\n\nFree Throw Rate\nFree throw rate measures how frequently a team attempts free throws compared to its total field goal attempts. The formula is:\n\\[\nFTR = \\frac{\\text{Free Throw Attempts (fta)}}{\\text{Field Goal Attempts (fga)}}\n\\]"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html",
    "href": "danl-rw/danl-101-team-project-golf.html",
    "title": "Data Storytelling Team Project - Golf",
    "section": "",
    "text": "The following lists data frames about golf:\n\npga_tournaments: PGA Tournament Data from 2022 season\n\now_golf_rankings: Official World Golf Rankings in June 2022\n\npga_tournaments_avg: Average player performance statistics with driving distance and putting by tournament.\n\n\n\nA data frame with 1,387 rows and 12 variables:\n\nCases include all golfers who made the cut in each of 19 PGA tournaments in 2022.\n\n\npga_tournaments_avg &lt;- read_csv(\n  \"http://bcdanl.github.io/data/pga_tournaments_avg.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerName\nPlayer‚Äôs full name.\ncountry\nPlayer‚Äôs country of origin or representation.\navgDriveDist\nAverage driving distance off the tee (typically measured in yards).\ndrivePct\nDriving accuracy percentage (for example, the percentage of drives/fairways hit from the tee).\navgPuttsPerRound\nAverage number of putts per 18-hole round.\nonePuttPct\nPercentage of holes where the player needed only one putt on the green.\ndriveSG\nStrokes gained from driving (off-the-tee performance relative to the field).\nputtsSG\nStrokes gained from putting (putting performance relative to the field).\navgScore\nAverage 18-hole score (strokes per round). Scoring average to measure success.\nMoney\nTotal prize money earned over the period or tournament (typically in U.S. dollars).\nPoints\nTour points associated with the performance in the Fedex Cup.\ntournament\nTournament name or identifier associated with the statistics in the row.\n\n\n\n\nA data frame with 3,676 rows and 34 Variables:\n\npga_tournaments &lt;- read_csv(\"http://bcdanl.github.io/data/pga_tournaments.csv\")\n\n\n\n\n\n  \n\n\n\n\nPlayer_initial_last initial of first name and complete last name of player\ntournament.id tournament ID\nplayer.id plyaer ID\nhole_par par across all holes played by the player\nstrokes strokes taken on all holes played by the player\nscore_relative_to_par Score relative to par (strokes - hole_par)\nhole_DKP Draftkings points on holes\nhole_FDP Fanduel points on the holes\nhole_SDP Showdown points on the holes\nstreak_DKP Draftkings points on streaks\nstreak_FDP Fanduel points on streaks\nstreak_SDP Showdown points on streaks\nn_rounds number of rounds played\nmade_cut player made the cut or not\npos finishing position of player\nfinish_DKP Draftkings points on the finishing position\nfinish_FDP Fanduel points on the finishing position\nfinish_SDP Showdown points on the finishing position\ntotal_DKP total Draftkings points for the tournament\ntotal_FDP total Fanduel points for the tournament\ntotal_SDP total Showdown points for the tournament\nplayer player full name\ntournament.name tournament full name\ncourse course name\ndate data of tournament\npurse total prize money (in millions)\nseason year of season\nno_cut Not sure\nFinish finishing position\nsg_putt strokes gained from putting\nsg_arg strokes gained around the green\nsg_app strokes gained on approach shots\nsg_ott strokes gained off the tee\nsg_t2g strokes gained tee to green\nsg_total total strokes gained\nSource: https://datagolf.com\n\n\n\n\nA data frame with 300 rows and 2 Variables:\n\n\now_golf_rankings &lt;- read_csv(\"http://bcdanl.github.io/data/ow_golf_rankings.csv\")\n\n\n\n\n\n  \n\n\n\n\nWGR_June_2022 official golf world ranking\nPlayer_initial_last initial of first name and complete last name of player\nSource: https://www.owgr.com/"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#average-pga-performance-data-from-2022-season-pga_tournaments_avg",
    "href": "danl-rw/danl-101-team-project-golf.html#average-pga-performance-data-from-2022-season-pga_tournaments_avg",
    "title": "Data Storytelling Team Project - Golf",
    "section": "",
    "text": "A data frame with 1,387 rows and 12 variables:\n\nCases include all golfers who made the cut in each of 19 PGA tournaments in 2022.\n\n\npga_tournaments_avg &lt;- read_csv(\n  \"http://bcdanl.github.io/data/pga_tournaments_avg.csv\")\n\n\n\n\n\n  \n\n\n\n\nplayerName\nPlayer‚Äôs full name.\ncountry\nPlayer‚Äôs country of origin or representation.\navgDriveDist\nAverage driving distance off the tee (typically measured in yards).\ndrivePct\nDriving accuracy percentage (for example, the percentage of drives/fairways hit from the tee).\navgPuttsPerRound\nAverage number of putts per 18-hole round.\nonePuttPct\nPercentage of holes where the player needed only one putt on the green.\ndriveSG\nStrokes gained from driving (off-the-tee performance relative to the field).\nputtsSG\nStrokes gained from putting (putting performance relative to the field).\navgScore\nAverage 18-hole score (strokes per round). Scoring average to measure success.\nMoney\nTotal prize money earned over the period or tournament (typically in U.S. dollars).\nPoints\nTour points associated with the performance in the Fedex Cup.\ntournament\nTournament name or identifier associated with the statistics in the row."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#pga-tournament-data-from-2022-season-pga_tournaments",
    "href": "danl-rw/danl-101-team-project-golf.html#pga-tournament-data-from-2022-season-pga_tournaments",
    "title": "Data Storytelling Team Project - Golf",
    "section": "",
    "text": "A data frame with 3,676 rows and 34 Variables:\n\npga_tournaments &lt;- read_csv(\"http://bcdanl.github.io/data/pga_tournaments.csv\")\n\n\n\n\n\n  \n\n\n\n\nPlayer_initial_last initial of first name and complete last name of player\ntournament.id tournament ID\nplayer.id plyaer ID\nhole_par par across all holes played by the player\nstrokes strokes taken on all holes played by the player\nscore_relative_to_par Score relative to par (strokes - hole_par)\nhole_DKP Draftkings points on holes\nhole_FDP Fanduel points on the holes\nhole_SDP Showdown points on the holes\nstreak_DKP Draftkings points on streaks\nstreak_FDP Fanduel points on streaks\nstreak_SDP Showdown points on streaks\nn_rounds number of rounds played\nmade_cut player made the cut or not\npos finishing position of player\nfinish_DKP Draftkings points on the finishing position\nfinish_FDP Fanduel points on the finishing position\nfinish_SDP Showdown points on the finishing position\ntotal_DKP total Draftkings points for the tournament\ntotal_FDP total Fanduel points for the tournament\ntotal_SDP total Showdown points for the tournament\nplayer player full name\ntournament.name tournament full name\ncourse course name\ndate data of tournament\npurse total prize money (in millions)\nseason year of season\nno_cut Not sure\nFinish finishing position\nsg_putt strokes gained from putting\nsg_arg strokes gained around the green\nsg_app strokes gained on approach shots\nsg_ott strokes gained off the tee\nsg_t2g strokes gained tee to green\nsg_total total strokes gained\nSource: https://datagolf.com"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#official-world-golf-rankings-in-june-2022-ow_golf_rankings",
    "href": "danl-rw/danl-101-team-project-golf.html#official-world-golf-rankings-in-june-2022-ow_golf_rankings",
    "title": "Data Storytelling Team Project - Golf",
    "section": "",
    "text": "A data frame with 300 rows and 2 Variables:\n\n\now_golf_rankings &lt;- read_csv(\"http://bcdanl.github.io/data/ow_golf_rankings.csv\")\n\n\n\n\n\n  \n\n\n\n\nWGR_June_2022 official golf world ranking\nPlayer_initial_last initial of first name and complete last name of player\nSource: https://www.owgr.com/"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#basic-golf-concepts",
    "href": "danl-rw/danl-101-team-project-golf.html#basic-golf-concepts",
    "title": "Data Storytelling Team Project - Golf",
    "section": "üèåÔ∏è Basic Golf Concepts",
    "text": "üèåÔ∏è Basic Golf Concepts\nBefore interpreting the variables, here are two essential ideas:\n\n1. A ‚Äústroke‚Äù is one hit of the ball.\nFewer strokes = better scoring.\n\n\n2. Every hole has a ‚Äúpar.‚Äù\nPar is the expected number of strokes a skilled player should take:\n- 3 strokes ‚Üí par\n- Par: target number of strokes for a hole (usually 3, 4, or 5).\n\nstrokes == hole_par ‚Üí ‚Äúmade par‚Äù\n\nstrokes = par ‚Äì 1 ‚Üí birdie (good)\n\nstrokes = par + 1 ‚Üí bogey (bad)\n\nIdea: strokes gained numbers tell us whether the player is better or worse than the PGA Tour average for that type of shot.\n\nPositive value ‚Üí better than average\n\nNegative value ‚Üí worse than average\n\n\n\n3. Tournaments have multiple rounds.\nMost events have 4 rounds (Thu‚ÄìSun), each of 18 holes.\n\n\n4. There is a ‚Äúcut‚Äù after round 2.\nOnly the best players continue to round 3‚Äì4. Others ‚Äúmiss the cut.‚Äù\n\nTournament: usually 4 rounds (4 √ó 18 holes).\n\nCut: after 2 rounds, only players with the best scores continue to rounds 3‚Äì4."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#strokes",
    "href": "danl-rw/danl-101-team-project-golf.html#strokes",
    "title": "Data Storytelling Team Project - Golf",
    "section": "1. strokes",
    "text": "1. strokes\nMeaning: Number of strokes the player took on a single hole.\nGolf context: This is the fundamental scoring unit in golf.\nAnalysis examples:\n\nAverage strokes per round\n\nBirdie/bogey rates\n\nScore relative to par (strokes - hole_par)\n\nCompare performance on par-3 vs par-4 vs par-5 holes"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#hole_par",
    "href": "danl-rw/danl-101-team-project-golf.html#hole_par",
    "title": "Data Storytelling Team Project - Golf",
    "section": "2. hole_par",
    "text": "2. hole_par\nMeaning: Par value of the hole\nGolf context: Indicates the expected difficulty of the hole.\nAnalysis examples:\n\nCompute score relative to par\n\nIdentify which par type a player scores best on\n\nHole difficulty analysis across tournaments"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#made_cut",
    "href": "danl-rw/danl-101-team-project-golf.html#made_cut",
    "title": "Data Storytelling Team Project - Golf",
    "section": "3. made_cut",
    "text": "3. made_cut\nMeaning: Indicator of whether the player advanced past the cut after 2 rounds.\nGolf context: If you make the cut, you continue playing the weekend.\nAnalysis examples:\n\nProbability of making the cut\n\nSkill differences between cut-makers and non-cut-makers\n\nEffect of cuts on fantasy scoring or prize money"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#n_rounds",
    "href": "danl-rw/danl-101-team-project-golf.html#n_rounds",
    "title": "Data Storytelling Team Project - Golf",
    "section": "4. n_rounds",
    "text": "4. n_rounds\nMeaning: Number of rounds a player completed.\nGolf context: Usually 2 if cut, 4 if not cut (unless it‚Äôs a no-cut event).\nAnalysis examples:\n\nRelation between number of rounds and finishing position\n\nIdentify consistent 4-round players\n\nEvaluate endurance or weekend performance"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#strokes-gained-metrics",
    "href": "danl-rw/danl-101-team-project-golf.html#strokes-gained-metrics",
    "title": "Data Storytelling Team Project - Golf",
    "section": "5. Strokes Gained Metrics",
    "text": "5. Strokes Gained Metrics\nVariables:\nsg_putt, sg_arg, sg_app, sg_ott, sg_t2g, sg_total\nMeaning: These measure how many strokes a player gained or lost compared to the PGA Tour average on specific types of shots.\nCategories:\n\nSG:OTT ‚Äî Off the tee (drives)\n\nSG:APP ‚Äî Approach shots to the green\n\nSG:ARG ‚Äî Around the green (chipping)\n\nSG:PUTT ‚Äî Putting\n\nSG:T2G ‚Äî All shots except putting\n\nSG:TOTAL ‚Äî Overall performance\n\nAnalysis examples:\n\nIdentify player strengths and weaknesses\n\nRadar charts to compare skills\n\nCompare top-50 players vs outside top-50\n\nWhich skill areas drive finishing position?"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#pos-finish",
    "href": "danl-rw/danl-101-team-project-golf.html#pos-finish",
    "title": "Data Storytelling Team Project - Golf",
    "section": "6. pos / Finish",
    "text": "6. pos / Finish\nMeaning: Player‚Äôs final ranking in the tournament (1 = winner).\nAnalysis examples:\n\nTrends in finishing positions over time\n\nCorrelation with strokes gained\n\nCompare finishing position across different courses"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#tournament-metadata",
    "href": "danl-rw/danl-101-team-project-golf.html#tournament-metadata",
    "title": "Data Storytelling Team Project - Golf",
    "section": "7. Tournament Metadata",
    "text": "7. Tournament Metadata\nVariables:\ntournament.id, tournament.name, course, date, season\nMeaning: Information describing the tournament.\nAnalysis examples:\n\nCourse difficulty comparisons\n\nSeasonal patterns in scoring\n\nPerformance on specific courses (e.g., Augusta vs Torrey Pines)"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#fantasy-scoring-variables",
    "href": "danl-rw/danl-101-team-project-golf.html#fantasy-scoring-variables",
    "title": "Data Storytelling Team Project - Golf",
    "section": "8. Fantasy Scoring Variables",
    "text": "8. Fantasy Scoring Variables\nhole_DKP, hole_FDP, hole_SDP\nstreak_DKP, streak_FDP, streak_SDP\nfinish_DKP, finish_FDP, finish_SDP\ntotal_DKP, total_FDP, total_SDP\nMeaning: Fantasy golf points for DraftKings (DKP), FanDuel (FDP), and SuperDraft (SDP).\nGolf context: Fantasy scoring rewards: - Birdies\n- Eagles\n- Streaks\n- Finishing position\n- Penalties for bogeys\nAnalysis examples:\n\nCompare fantasy scoring to traditional golf scoring\n\nIdentify players who benefit from fantasy-scoring rules\n\nOptimize fantasy lineup selection"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#purse",
    "href": "danl-rw/danl-101-team-project-golf.html#purse",
    "title": "Data Storytelling Team Project - Golf",
    "section": "9. purse",
    "text": "9. purse\nMeaning: Total prize money available in the tournament.\nAnalysis examples:\n\nRelationship between purse size and player performance\n\nHigher-purse events vs field strength\n\nEarnings distribution across seasons"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-golf.html#no_cut",
    "href": "danl-rw/danl-101-team-project-golf.html#no_cut",
    "title": "Data Storytelling Team Project - Golf",
    "section": "10. no_cut",
    "text": "10. no_cut\nMeaning: Indicator whether the tournament has no cut.\nGolf context: Some events allow all players to play all rounds.\nAnalysis examples:\n\nCompare scoring in cut vs no-cut events\n\nEffect on strokes gained and finishing positions\n\nFantasy scoring differences"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-soccer.html",
    "href": "danl-rw/danl-101-team-project-soccer.html",
    "title": "Data Storytelling Team Project - Soccer",
    "section": "",
    "text": "The following lists data frames about English Premier League (EPL):\n\nepl_teams: team statistics for the English Premier League 2017-18 through 2024-25\nepl_players: Individual player statistics for the English Premier League‚Äôs 2021-22 through 2024-25\nepl_gks: Individual goalkeeper statistics for the English Premier League‚Äôs 2021-22 through 2024-25\n\n\n\n\nepl_teams: team statistics for the English Premier League the English Premier League 2017-18 through 2024-25\n\nA dataset containing team statistics for the English Premier League\nA data frame with 160 rows and 29 variables\n\n\n\nepl_teams &lt;- read_csv(\"http://bcdanl.github.io/data/epl_teams_2017-18_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nsquad Team or club name\nseason_end_year Season end year (e,g., 2025 if the season is 2024-25)\nnum_players Number of players used in the season\nage Age of players weighted by minutes played\nposs Possession as a percentage of passes attempted\ngoals Goals scored by team\nassists Assists by team\ngoals_assists Goals scored plus assists by team\nnon_pen_goals Non-penalty goals scored by team\npen_goals Penalty kick goals scored by team\npen_att Penalty kick attempts by team\nyellow_cards Yellow cards earned by team\nred_cards Red cards earned by team\nxG Expected goals\nnon_pen_xG Non-penalty kick expected goals\nxA Expected assists\nnon_pen_xGxA Non-penalty kick expected goals and assists\nprg_carry Progressive carries\nprg_pass Progressive passes\ngoals_p90 Goals per ninety minutes\nassists_p90 Assists per ninety minutes\ngoals_assists_p90 Goals and assists per ninety minutes\nnon_pen_goals_p90 Non-penalty kick goals per ninety minutes\nnon_pen_goals_assists_p90 Non-penalty kick goals and assists per ninety minutes\nxG_p90 Expected goals per ninety minutes\nxA_p90 Expected assists per ninety minutes\nxG_xA_p90 Expected goals plus assists per ninety minutes\nnon_pen_xG_p90 Expected goals minus penalty goals per ninety minutes\nnon_pen_xG_xA_p90 Expected goals plus assists minus penalty goals per ninety minutes\nSource: https://fbref.com/en/comps/9/2021-2022/stats/2021-2022-Premier-League-Stats\n\n\n\n\nepl_players: Individual player statistics for the English Premier League‚Äôs 2021-22 through 2024-25\n\nA data frame with 2,268 observations on the 38 variables.\n\n\n\nepl_players &lt;- read_csv(\"http://bcdanl.github.io/data/epl_players_all_w_salary_2021-22_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_end_year Season end year (e,g., 2025 if the season is 2024-25)\nplayer Player name\nnation Player home country\npos Player position\nsquad Player team\ngross_salary_weekly_pound Weekly salary in pound (¬£)\ngross_salary_yearly_pound Yearly salary in pound (¬£)\nage Age of player\nborn Birth year of player\nmp Matches played\nstarts Number of matches in which player started the game\nmin Total minutes played in the season\nmin_p90 Total minutes played in the season per ninety minutes\ngoals Goals scored by player\nassists Assists by player\ngoals_assists Goals scored plus assists by player\nnon_pen_goals Non-penalty goals scored by player\npen_goals Penalty kick goals scored by player\npen_att Penalty kick attempts by player\nyellow_cards Yellow cards earned by player\nred_cards Red cards earned by player\nxG Expected goals\nnon_pen_xG Non-penalty kick expected goals\nxA Expected assists\nnon_pen_xGxA Non-penalty kick expected goals and assists\nprg_carry Progressive carries\nprg_pass Progressive passes\nprg_reception Progressive passes received\ngoals_p90 Goals per ninety minutes\nassists_p90 Assists per ninety minutes\ngoals_assists_p90 Goals and assists per ninety minutes\nnon_pen_goals_p90 Non-penalty kick goals per ninety minutes\nnon_pen_goals_assists_p90 Non-penalty kick goals and assists per ninety minutes\nxG_p90 Expected goals per ninety minutes\nxA_p90 Expected assists per ninety minutes\nxG_xA_p90 Expected goals plus assists per ninety minutes\nnon_pen_xG_p90 Expected goals minus penalty goals per ninety minutes\nnon_pen_xG_xA_p90 Expected goals plus assists minus penalty goals per ninety minutes\nSource: https://fbref.com/en/comps/9/2021-2022/stats/2021-2022-Premier-League-Stats\n\n\n\n\nepl_gks: Individual goalkeeper statistics for the English Premier League‚Äôs 2021-22 through 2024-25\n\nA data frame with 165 rows and 33 variables:\n\n\n\nepl_gks &lt;- read_csv(\"http://bcdanl.github.io/data/epl_gk_stats_2021-22_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_end_year Season end year (e,g., 2025 if the season is 2024-25)\nplayer Player name\nnation Player home country\npos Player position\nsquad Player team\nage Age of player\nborn Birth year of player\nmin_p90 Total minutes played in the season per ninety minutes\ngoals Goals scored against player\npk_allowed Penalty kick goals scored against player\nfree_kick_goals Free kick goals scored against player\ncorner_kick_goals Corner kick goals scored against player\nown_goals_against Own goals scored against player\npost_shot_xG Post-shot expected goals\npost_shot_xG_per_shot_on_target Post-shot expected goals per shot on target\npost_shot_xG_minus_goals Post-shot expected goals minus goals per shot on target\npost_shot_xG_minus_goals_p90 Post-shot expected goals minus goals per shot on target per ninety minutes\nlaunch_completed Passes longer than 40 yards (launch) completed\nlaunch_attempt Passes longer than 40 yards attempted\nlaunch_completion_percent Passes longer than 40 yards (launch) completion percentage\npass_attempt Passes attempted\nthrow_attempt Throws attempted\npass_launch_percent Percentage of passes launched\navg_pass_len Average pass length\ngoal_kick_attempt Goal kick attempts\ngk_launch_percent Percentage of goals kicks launched\navg_gk_len Average goal kick length\ncrosses_faced Number of crosses faced\ncrosses_stopped Number of crosses stopped\nstop_percent Cross stop percentage\ndef_actions_out_pen_area Defensive actions outside the penalty area\ndef_actions_out_pen_area_p90 Defensive actions outside the penalty area per ninety minutes\navg_dist_def_actions Average distance from goal of defensive actions\nSource: https://fbref.com/en/comps/9/2021-2022/keepersadv/2021-2022-Premier-League-Stats"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-soccer.html#epl-team-statistics-2017-18-through-2024-25-epl_teams",
    "href": "danl-rw/danl-101-team-project-soccer.html#epl-team-statistics-2017-18-through-2024-25-epl_teams",
    "title": "Data Storytelling Team Project - Soccer",
    "section": "",
    "text": "epl_teams: team statistics for the English Premier League the English Premier League 2017-18 through 2024-25\n\nA dataset containing team statistics for the English Premier League\nA data frame with 160 rows and 29 variables\n\n\n\nepl_teams &lt;- read_csv(\"http://bcdanl.github.io/data/epl_teams_2017-18_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nsquad Team or club name\nseason_end_year Season end year (e,g., 2025 if the season is 2024-25)\nnum_players Number of players used in the season\nage Age of players weighted by minutes played\nposs Possession as a percentage of passes attempted\ngoals Goals scored by team\nassists Assists by team\ngoals_assists Goals scored plus assists by team\nnon_pen_goals Non-penalty goals scored by team\npen_goals Penalty kick goals scored by team\npen_att Penalty kick attempts by team\nyellow_cards Yellow cards earned by team\nred_cards Red cards earned by team\nxG Expected goals\nnon_pen_xG Non-penalty kick expected goals\nxA Expected assists\nnon_pen_xGxA Non-penalty kick expected goals and assists\nprg_carry Progressive carries\nprg_pass Progressive passes\ngoals_p90 Goals per ninety minutes\nassists_p90 Assists per ninety minutes\ngoals_assists_p90 Goals and assists per ninety minutes\nnon_pen_goals_p90 Non-penalty kick goals per ninety minutes\nnon_pen_goals_assists_p90 Non-penalty kick goals and assists per ninety minutes\nxG_p90 Expected goals per ninety minutes\nxA_p90 Expected assists per ninety minutes\nxG_xA_p90 Expected goals plus assists per ninety minutes\nnon_pen_xG_p90 Expected goals minus penalty goals per ninety minutes\nnon_pen_xG_xA_p90 Expected goals plus assists minus penalty goals per ninety minutes\nSource: https://fbref.com/en/comps/9/2021-2022/stats/2021-2022-Premier-League-Stats"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-soccer.html#epl-player-statistics-2021-22-through-2024-25-epl_players",
    "href": "danl-rw/danl-101-team-project-soccer.html#epl-player-statistics-2021-22-through-2024-25-epl_players",
    "title": "Data Storytelling Team Project - Soccer",
    "section": "",
    "text": "epl_players: Individual player statistics for the English Premier League‚Äôs 2021-22 through 2024-25\n\nA data frame with 2,268 observations on the 38 variables.\n\n\n\nepl_players &lt;- read_csv(\"http://bcdanl.github.io/data/epl_players_all_w_salary_2021-22_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_end_year Season end year (e,g., 2025 if the season is 2024-25)\nplayer Player name\nnation Player home country\npos Player position\nsquad Player team\ngross_salary_weekly_pound Weekly salary in pound (¬£)\ngross_salary_yearly_pound Yearly salary in pound (¬£)\nage Age of player\nborn Birth year of player\nmp Matches played\nstarts Number of matches in which player started the game\nmin Total minutes played in the season\nmin_p90 Total minutes played in the season per ninety minutes\ngoals Goals scored by player\nassists Assists by player\ngoals_assists Goals scored plus assists by player\nnon_pen_goals Non-penalty goals scored by player\npen_goals Penalty kick goals scored by player\npen_att Penalty kick attempts by player\nyellow_cards Yellow cards earned by player\nred_cards Red cards earned by player\nxG Expected goals\nnon_pen_xG Non-penalty kick expected goals\nxA Expected assists\nnon_pen_xGxA Non-penalty kick expected goals and assists\nprg_carry Progressive carries\nprg_pass Progressive passes\nprg_reception Progressive passes received\ngoals_p90 Goals per ninety minutes\nassists_p90 Assists per ninety minutes\ngoals_assists_p90 Goals and assists per ninety minutes\nnon_pen_goals_p90 Non-penalty kick goals per ninety minutes\nnon_pen_goals_assists_p90 Non-penalty kick goals and assists per ninety minutes\nxG_p90 Expected goals per ninety minutes\nxA_p90 Expected assists per ninety minutes\nxG_xA_p90 Expected goals plus assists per ninety minutes\nnon_pen_xG_p90 Expected goals minus penalty goals per ninety minutes\nnon_pen_xG_xA_p90 Expected goals plus assists minus penalty goals per ninety minutes\nSource: https://fbref.com/en/comps/9/2021-2022/stats/2021-2022-Premier-League-Stats"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-soccer.html#epl-goalkeeper-statistics-2021-22-through-2024-25-epl_gks",
    "href": "danl-rw/danl-101-team-project-soccer.html#epl-goalkeeper-statistics-2021-22-through-2024-25-epl_gks",
    "title": "Data Storytelling Team Project - Soccer",
    "section": "",
    "text": "epl_gks: Individual goalkeeper statistics for the English Premier League‚Äôs 2021-22 through 2024-25\n\nA data frame with 165 rows and 33 variables:\n\n\n\nepl_gks &lt;- read_csv(\"http://bcdanl.github.io/data/epl_gk_stats_2021-22_2024-25.csv\")\n\n\n\n\n\n  \n\n\n\n\nseason_end_year Season end year (e,g., 2025 if the season is 2024-25)\nplayer Player name\nnation Player home country\npos Player position\nsquad Player team\nage Age of player\nborn Birth year of player\nmin_p90 Total minutes played in the season per ninety minutes\ngoals Goals scored against player\npk_allowed Penalty kick goals scored against player\nfree_kick_goals Free kick goals scored against player\ncorner_kick_goals Corner kick goals scored against player\nown_goals_against Own goals scored against player\npost_shot_xG Post-shot expected goals\npost_shot_xG_per_shot_on_target Post-shot expected goals per shot on target\npost_shot_xG_minus_goals Post-shot expected goals minus goals per shot on target\npost_shot_xG_minus_goals_p90 Post-shot expected goals minus goals per shot on target per ninety minutes\nlaunch_completed Passes longer than 40 yards (launch) completed\nlaunch_attempt Passes longer than 40 yards attempted\nlaunch_completion_percent Passes longer than 40 yards (launch) completion percentage\npass_attempt Passes attempted\nthrow_attempt Throws attempted\npass_launch_percent Percentage of passes launched\navg_pass_len Average pass length\ngoal_kick_attempt Goal kick attempts\ngk_launch_percent Percentage of goals kicks launched\navg_gk_len Average goal kick length\ncrosses_faced Number of crosses faced\ncrosses_stopped Number of crosses stopped\nstop_percent Cross stop percentage\ndef_actions_out_pen_area Defensive actions outside the penalty area\ndef_actions_out_pen_area_p90 Defensive actions outside the penalty area per ninety minutes\navg_dist_def_actions Average distance from goal of defensive actions\nSource: https://fbref.com/en/comps/9/2021-2022/keepersadv/2021-2022-Premier-League-Stats"
  },
  {
    "objectID": "danl-rw/danl-101-team-project-soccer.html#expected-goals-and-assists",
    "href": "danl-rw/danl-101-team-project-soccer.html#expected-goals-and-assists",
    "title": "Data Storytelling Team Project - Soccer",
    "section": "Expected Goals and Assists",
    "text": "Expected Goals and Assists\nSoccer is renowned for its low-scoring nature. During the 2022 World Cup in Qatar, 172 goals were scored across 64 matches, averaging 2.68 goals per match‚Äîthe highest average in World Cup history. Despite this, seven matches ended scoreless. The element of luck significantly influences goal scoring, and occasionally, players inadvertently score own goals. To better quantify scoring opportunities and player performance, the soccer analytics community has introduced expected goals (xG) as a metric to measure the likelihood of a shot resulting in a goal.\nVarious models calculate xG, but fundamentally, it represents the probability of scoring from a specific spot on the field when a shot is taken. Factors considered in xG calculations include:\n\nBody Part Used: Whether the shot was taken with the head or foot.\nType of Play: How the player received the ball (e.g., cross, set piece).\nGoalkeeper Positioning: The location and readiness of the goalkeeper.\nPlayer Positioning: Positions of teammates and opponents between the shooter and the goal.\nDefensive Pressure: How tightly defenders are marking the shooter.\nAdditional Situational Variables: Other measurable factors that may affect shot success.\n\nSince most shots do not result in goals, and many passes to shooters lead to missed opportunities, an analogous metric called expected assists (xA) evaluates the likelihood that a pass will lead to a goal. These metrics are often normalized per 90 minutes‚Äîdenoted as xG per 90 or xA per 90‚Äîto allow fair comparisons between players with varying playing times.\nPlayers consistently achieving high xG values are those who frequently position themselves advantageously on the field. Coaches and scouts use xG and xA metrics to assess whether a player‚Äôs performance is influenced by luck over multiple games and to evaluate offensive skills beyond basic statistics."
  },
  {
    "objectID": "danl-rw/danl-101-team-project-soccer.html#soccer-metrics-1",
    "href": "danl-rw/danl-101-team-project-soccer.html#soccer-metrics-1",
    "title": "Data Storytelling Team Project - Soccer",
    "section": "Soccer Metrics",
    "text": "Soccer Metrics\n\nOffensive Metrics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nGoals\nTotal number of goals scored by the player/team\n\n\nAssists\nTotal number of assists made by the player/team\n\n\nGoals and Assists\nSum of goals and assists\n\n\nNon-Penalty Goals\nGoals scored excluding penalty kicks\n\n\nPenalty Goals\nGoals scored from penalty kicks\n\n\nPenalty Attempts\nNumber of penalty kick attempts\n\n\nExpected Goals (xG)\nExpected number of goals based on shot quality and other factors\n\n\nNon-Penalty xG\nExpected goals excluding penalty kicks\n\n\nExpected Assists (xA)\nExpected number of assists based on pass quality and other factors\n\n\nNon-Penalty xG + xA\nSum of non-penalty expected goals and expected assists\n\n\nProgressive Carries\nTimes a player significantly moves the ball towards the opponent‚Äôs goal\n\n\nProgressive Passes\nForward passes advancing the ball significantly towards the opponent‚Äôs goal\n\n\nGoals per 90 Minutes\nAverage number of goals scored per 90 minutes played\n\n\nAssists per 90 Minutes\nAverage number of assists per 90 minutes played\n\n\nGoals and Assists per 90 Minutes\nSum of goals and assists per 90 minutes played\n\n\nNon-Penalty Goals per 90 Minutes\nNon-penalty goals scored per 90 minutes played\n\n\nNon-Penalty Goals and Assists per 90\nSum of non-penalty goals and assists per 90 minutes played\n\n\nxG per 90 Minutes\nExpected goals per 90 minutes played\n\n\nxA per 90 Minutes\nExpected assists per 90 minutes played\n\n\nxG + xA per 90 Minutes\nSum of expected goals and assists per 90 minutes played\n\n\nNon-Penalty xG per 90 Minutes\nNon-penalty expected goals per 90 minutes played\n\n\nNon-Penalty xG + xA per 90 Minutes\nSum of non-penalty expected goals and assists per 90 minutes played\n\n\n\n\n\nDefensive Metrics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nYellow Cards\nNumber of yellow cards received\n\n\nRed Cards\nNumber of red cards received\n\n\nProgressive Passes Received\nPasses received that advance the ball significantly towards the opponent‚Äôs goal\n\n\n\n\n\nGoalkeeping Metrics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nGoals Against\nTotal number of goals conceded\n\n\nPenalty Kicks Allowed\nGoals conceded from penalty kicks\n\n\nFree Kick Goals Against\nGoals conceded from free kicks\n\n\nCorner Kick Goals Against\nGoals conceded from corner kicks\n\n\nOwn Goals Against\nGoals scored by teammates into their own net\n\n\nPost-Shot xG\nExpected goals based on the quality of shots on target faced\n\n\nPost-Shot xG per Shot on Target\nAverage post-shot expected goals per shot on target faced\n\n\nPost-Shot xG Minus Goals\nDifference between post-shot expected goals and actual goals conceded\n\n\nPost-Shot xG Minus Goals per 90 Minutes\nPost-shot xG minus goals conceded per 90 minutes\n\n\nCrosses Faced\nNumber of crosses faced by the goalkeeper\n\n\nCrosses Stopped\nNumber of crosses successfully stopped by the goalkeeper\n\n\nCross Stop Percentage\nPercentage of crosses stopped (Crosses Stopped √∑ Crosses Faced)\n\n\nDefensive Actions Outside Penalty Area\nActions by the goalkeeper outside the penalty area\n\n\nDefensive Actions Outside PA per 90\nSuch actions per 90 minutes\n\n\nAverage Distance of Defensive Actions\nAverage distance from goal of the goalkeeper‚Äôs defensive actions\n\n\n\n\n\nTeam Metrics\n\n\n\n\n\n\n\nStatistic\nDefinition\n\n\n\n\nSquad\nTeam or club name\n\n\nSeason\nSeason\n\n\nNumber of Players\nNumber of players used in the season\n\n\nAverage Age\nAge of players weighted by minutes played\n\n\nPossession Percentage\nPercentage of possession based on passes attempted"
  },
  {
    "objectID": "danl-rw/danl-101-proj-team.html",
    "href": "danl-rw/danl-101-proj-team.html",
    "title": "Team Formation Survey",
    "section": "",
    "text": "When you finish the questionnaire, click ‚ÄúSubmit‚Äù at the bottom of the page.\n\nAfter clicking ‚ÄúSubmit,‚Äù wait for the on-screen message ‚ÄúData submitted successfully!‚Äù just below the button.\nA confirmation email will be sent to the address you provide on this page once your submission is recorded.\n\nYou may submit more than once; only your most recent submission will be counted.\nDeadline: Friday, November 7, 2025 at 11:59 PM (Eastern Time).\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-101-cw-07.html",
    "href": "danl-cw/danl-101-cw-07.html",
    "title": "Classwork 7",
    "section": "",
    "text": "Consider the following data.frame, netflix_data, displayed below:\n\n\n\n\n  \n\n\n\n\nDescription of Variables in netflix_data:\n\nUserID: Identifier for each user\nAge: Age of the user in years\nGender: Gender of the user\nSubscriptionPlan: Type of Netflix subscription\nFavoriteGenre: User‚Äôs favorite genre\nHoursWatched: Average hours watched per week\nLastLoginTime: Time of last login in hours since midnight\nAccountMonths: Age of the account in months\nSatisfaction: User satisfaction rating (1 to 5 stars)\nnDevices: Number of devices connected\nLastMovieRating: Rating of the last watched movie (1.0 to 10.0)\nnProfiles: Number of profiles on the account\nLanguage: User‚Äôs preferred language\n\n\n\nQuestion 1\nWhat type of variable is FavoriteGenre in the dataset?\n\nNominal\nOrdinal\nInterval\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n‚úÖ Answer: a. Nominal ‚Äî FavoriteGenre represents non-ordered categories.\n\n\n\n\n\nQuestion 2\nWhat type of variable is SubscriptionPlan in the dataset?\n\nNominal\nOrdinal\nInterval\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n‚úÖ Answer: b. Ordinal ‚Äî Subscription plans follow a natural order: Basic &lt; Standard &lt; Premium.\n\n\n\n\n\nQuestion 3\nWhat type of variable is LastLoginTime in the dataset?\n\nNominal\nOrdinal\nInterval\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n‚úÖ Answer: c.¬†Interval ‚Äî Time since midnight has meaningful differences but no absolute zero.\n\n\n\n\n\nQuestion 4\nWhat type of variable is Satisfaction in the dataset?\n\nNominal\nOrdinal\nInterval\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n‚úÖ Answer: b. Ordinal ‚Äî Satisfaction rating is ranked, but the distance between levels is not precise.\n\n\n\n\n\n\nDiscussion\nWelcome to our Classwork 7 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Classwork 7.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Classwork 7 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-101-cw-12.html",
    "href": "danl-cw/danl-101-cw-12.html",
    "title": "Classwork 12",
    "section": "",
    "text": "For Classwork 12, please load the tidyverse package:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-12.html#tasks",
    "href": "danl-cw/danl-101-cw-12.html#tasks",
    "title": "Classwork 12",
    "section": "Tasks",
    "text": "Tasks\n\nü§ñ Task 1: Fill in the blanks in the provided ggplot() code chunk.\n\nüí¨ Task 2: Add a brief comment describing the relationship between gross ratings points (GRP) and projected engagement (PE) varies by genre (Genre).\n\n\n(1) Color\n\n\n\n\n\n\nggplot(__BLANK_1__ = nbc_show,\n       mapping = aes(x = GRP,\n                     y = PE,\n                     __BLANK_2__ = Genre)) +\n  geom_point() +\n  geom_smooth(__BLANK_3__,\n              se = FALSE)   # se = FALSE turns off the ribbon\n\n\n\n\n(2) Facet\n\n\n\n\n\n\nggplot(data = nbc_show,\n       mapping = aes(x = GRP,\n                     y = PE)) +\n  geom_point() +  \n  geom_smooth(method = __BLANK_1__,\n              se = FALSE) +  # se = FALSE turns off the ribbon\n  __BLANK_2___wrap(__BLANK_3__)\n\n\n\n\n(3) Facet with Color\n\n\n\n\n\n\nggplot(data = nbc_show,\n       mapping = aes(x = GRP,\n                     y = PE,\n                     color = __BLANK_1__)) +\n  geom_point(show.legend = FALSE) +  # show.legend = FALSE turns of legend\n  geom_smooth(method = __BLANK_2__,\n              show.legend = FALSE,   # show.legend = FALSE turns of legend\n              se = FALSE) +  # se = FALSE turns off the ribbon\n  __BLANK_3___wrap(__BLANK_4__)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-12.html#tasks-1",
    "href": "danl-cw/danl-101-cw-12.html#tasks-1",
    "title": "Classwork 12",
    "section": "Tasks",
    "text": "Tasks\n\nü§ñ Task 1: Fill in the blanks in the provided ggplot() code chunk.\n\nüí¨ Task 2: Add a brief comment describing the relationship between GDP per capita (gdpPercap) and life expectancy (lifeExp) varies by continents (continent).\n\n\n(1) Color: Only Scatterplot\n\n\n\n\n\n\nggplot(__BLANK_1__ = df_gapminder,\n       mapping = aes(__BLANK_2__ = log(gdpPercap),\n                     __BLANK_3__ = lifeExp,\n                     __BLANK_4__ = continent)) +  # different colors are used to distinguish continents\n  geom_point(__BLANK_5__)  # Add 50% transparency to reduce overplotting\n\n\n\n\n\n\n\n(2) Color: Scatterplot with Fitted Line\n\n\n\n\n\n\nggplot(__BLANK_1__ = df_gapminder,\n       mapping = aes(__BLANK_2__ = log(gdpPercap),\n                     __BLANK_3__ = lifeExp,\n                     __BLANK_4__ = continent)) +  # different colors are used to distinguish continents\n  geom_point(__BLANK_5__) +  # Add 50% transparency to reduce overplotting\n  geom___BLANK_6__(method = \"lm\")\n\n\n\n\n\n\n\n(3) Facet: Scatterplot with Fitted Line\n\n\n\n\n\n\nggplot(__BLANK_1__ = df_gapminder,\n       mapping = aes(__BLANK_2__ = log(gdpPercap),\n                     __BLANK_3__ = lifeExp,\n                     __BLANK_4__ = continent)) +\n  geom_point(__BLANK_5__ = 0.3) +  # Add 70% transparency to reduce overplotting\n  geom___BLANK_6__(method = \"lm\") +\n  facet___BLANK_7__(~continent)"
  },
  {
    "objectID": "danl-cw/danl-101-cw-10.html#reflection-career-session-debrief",
    "href": "danl-cw/danl-101-cw-10.html#reflection-career-session-debrief",
    "title": "Classwork 10",
    "section": "‚úèÔ∏è Reflection ‚Äî Career Session Debrief",
    "text": "‚úèÔ∏è Reflection ‚Äî Career Session Debrief\nIn the Brightspace Discussion Module, write down your response to the two prompts below.\n(You need to submit it by 11:59 PM Friday next week (October 31))\n\nOne responsibility or task they described that surprised you:\n\n\n‚ÄúI didn‚Äôt realize someone in that role would have to‚Ä¶‚Äù\n\n\nOne thing they said that feels different from how we‚Äôve been talking about data in class:\n\n\n‚ÄúIn class we talk about data as ‚Ä¶, but they talked about it more like ‚Ä¶ .‚Äù"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html",
    "href": "danl-cw/danl-101-cw-05.html",
    "title": "Classwork 5",
    "section": "",
    "text": "Write an R code to calculate the standard deviation (SD) of the integer vector x below manually. That is to calculate the SD without using the sd() or the var() functions.\n\n\nx &lt;- 1:25\n\n\nAlso, write an R code to test whether the standard deviation you calculate manually above is equal to sd(x).\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-1.",
    "href": "danl-cw/danl-101-cw-05.html#question-1.",
    "title": "Classwork 5",
    "section": "",
    "text": "Write an R code to calculate the standard deviation (SD) of the integer vector x below manually. That is to calculate the SD without using the sd() or the var() functions.\n\n\nx &lt;- 1:25\n\n\nAlso, write an R code to test whether the standard deviation you calculate manually above is equal to sd(x).\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-2.",
    "href": "danl-cw/danl-101-cw-05.html#question-2.",
    "title": "Classwork 5",
    "section": "Question 2.",
    "text": "Question 2.\n\nWrite an R code to calculate the range (difference between the maximum and minimum values) of the vector temp &lt;- c(22, 28, 31, 25, 29).\n\n\ntemp &lt;- c(22, 28, 31, 25, 29)\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-3.",
    "href": "danl-cw/danl-101-cw-05.html#question-3.",
    "title": "Classwork 5",
    "section": "Question 3.",
    "text": "Question 3.\n\nConsider the vectors:\n\n\nmy_vec &lt;- c(-10, -20, 30, 10, 50, 40, -100)\nbeers &lt;- c(\"BUD LIGHT\", \"BUSCH LIGHT\", \"COORS LIGHT\", \n           \"GENESEE LIGHT\", \"MILLER LITE\", \"NATURAL LIGHT\")\n\n\nWrite an R code to filter only the positive values in my_vec.\nWrite an R code to access the beers that are in positions 2, 4, and 6 using indexing.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-05.html#question-4.",
    "href": "danl-cw/danl-101-cw-05.html#question-4.",
    "title": "Classwork 5",
    "section": "Question 4.",
    "text": "Question 4.\n\nCreate a logical vector logical_vec that checks whether the elements of the vector ages &lt;- c(15, 22, 18, 24, 30) are greater than or equal to 20.\n\n\nages &lt;- c(15, 22, 18, 24, 30)\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html",
    "href": "danl-cw/danl-101-cw-01.html",
    "title": "Classwork 1",
    "section": "",
    "text": "Where do you draw the line between assistance and authorship when using generative AI?\nRead each scenario and decide whether it represents Assistance, Authorship, or falls somewhere in the gray area.\n\nTake 1 minute to think quietly.\n\nDiscuss your ideas with a partner.\n\nBe prepared to explain your reasoning to the class.\n\n\n\n\nA student uses AI to check grammar and spelling in a term paper.\n\nA researcher pastes an outline into AI, gets a draft literature review, and submits it without changes.\n\nA journalist uses AI to summarize interview transcripts before writing their article.\n\nA poet asks AI to generate several stanzas, then mixes lines with their own writing.\n\nAn engineer lets AI draft a technical report, then carefully fact-checks, edits, and rewrites half of it.\n\nA business consultant uses AI to brainstorm presentation slide titles.\n\nAn author publishes a short story fully written by AI under their own name.\nA student asks AI to generate code for a homework assignment, then submits it without understanding how it works.\nA student writes most of programming code on their own, but when they encounter errors they can‚Äôt resolve, they use AI to suggest debugging steps and code optimizations. They review the AI‚Äôs suggestions, test them, and decide which changes to keep.\n\nüëâ Place each scenario along the spectrum and explain your choice:\nAssistance ‚Üê‚Äî‚Äî‚Äî‚Äî‚Äî‚Üí Authorship"
  },
  {
    "objectID": "danl-cw/danl-101-cw-01.html#question",
    "href": "danl-cw/danl-101-cw-01.html#question",
    "title": "Classwork 1",
    "section": "",
    "text": "Where do you draw the line between assistance and authorship when using generative AI?\nRead each scenario and decide whether it represents Assistance, Authorship, or falls somewhere in the gray area.\n\nTake 1 minute to think quietly.\n\nDiscuss your ideas with a partner.\n\nBe prepared to explain your reasoning to the class.\n\n\n\n\nA student uses AI to check grammar and spelling in a term paper.\n\nA researcher pastes an outline into AI, gets a draft literature review, and submits it without changes.\n\nA journalist uses AI to summarize interview transcripts before writing their article.\n\nA poet asks AI to generate several stanzas, then mixes lines with their own writing.\n\nAn engineer lets AI draft a technical report, then carefully fact-checks, edits, and rewrites half of it.\n\nA business consultant uses AI to brainstorm presentation slide titles.\n\nAn author publishes a short story fully written by AI under their own name.\nA student asks AI to generate code for a homework assignment, then submits it without understanding how it works.\nA student writes most of programming code on their own, but when they encounter errors they can‚Äôt resolve, they use AI to suggest debugging steps and code optimizations. They review the AI‚Äôs suggestions, test them, and decide which changes to keep.\n\nüëâ Place each scenario along the spectrum and explain your choice:\nAssistance ‚Üê‚Äî‚Äî‚Äî‚Äî‚Äî‚Üí Authorship"
  },
  {
    "objectID": "danl-cw/danl-101-cw-02.html",
    "href": "danl-cw/danl-101-cw-02.html",
    "title": "Classwork 2",
    "section": "",
    "text": "What is Vibe Coding?\n\n\n\nVibe coding is an artificial intelligence-assisted software development technique popularized by Andrej Karpathy in February 2025. The term was listed in the Merriam-Webster Dictionary the following month as a ‚Äúslang & trending‚Äù term. (Wikipedia, 2025)\n\n\n\n\n\n\n\n\nWhat are HTML and JS?\n\n\n\n\nHTML (HyperText Markup Language) is the standard language for creating web pages.\n\nIt defines the structure of a webpage.\n\nA webpage is made up of HTML elements.\n\nThese elements instruct the browser on how to display the content.\n\nJavaScript (JS) is a programming language that enhances web interactivity.\n\nIt runs directly in the user‚Äôs browser, reducing server load. \nIt enables dynamic content, user interactions, and animations.\n\nAnalogy:\n\nHTML = The structure of a house (walls, roof, foundation).\n\nJS = The interactive elements (automatic doors, lights, smart devices).\n\n\n\n\n\nStep 1. Start with this prompt (use exactly):\n\n‚ÄúCreate a single-file HTML/JS page to play perfect tic-tac-toe vs.¬†human.‚Äù\n\n\ne.g., Prof.¬†Choe‚Äôs Tic-Tac-Toe\n\nStep 1-1 Prepare your text editor:\n\n\nWindows\n\nPress the Windows key, type Notepad, and press Enter.\n\nPaste the HTML code from your AI.\n\nGo to File ‚Üí Save As.\n\nChange Save as type to All Files.\n\nEnter a name like tic-tac-toe.html.\n\nSelect the location (Desktop, Documents, etc.).\n\nSet Encoding to UTF-8.\n\nClick Save.\n\n\nDouble-click the file to open it in your default browser (Edge, Chrome, etc.).\n\n\n\n\nMac\nSet up TextEdit (one-time)\n\n\n\n\n\nPress Command + Space to open Spotlight.\n\nType TextEdit and press Enter.\n\nPress Command + , to open Settings.\n\nUnder Format, select Plain Text.\n\n\nQuit TextEdit (Command + Q).\n\nRe-open TextEdit for coding\n\n\n\n\n\nPress Command + Space, type TextEdit, and press Enter.\n\nClick Show Options.\n\nUnder Plain Text Encoding, select Unicode (UTF-8).\n\n\nClick New Document.\n\nPaste the HTML code from your generative AI.\n\nSave the file (Command + S):\n\nName it tic-tac-toe.html.\n\nEnsure the extension is .html.\n\nChoose a location (Desktop, Documents, etc.).\n\nClick Save, and if prompted, choose Use .html.\n\n\nDouble-click the file to open it in your default browser (Safari, Chrome, etc.).\n\n\n\nStep 2. Add an option for two-player mode.\n\ne.g., Prof.¬†Choe‚Äôs Tic-Tac-Toe with the Two-player Mode\n\n\nStep 3. Make a 4√ó4 tic-tac-toe version (if your current build is only 3√ó3).\n\ne.g., Prof.¬†Choe‚Äôs 4√ó4 Tic-Tac-Toe\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-101-cw-08.html#purpose-of-this-activity",
    "href": "danl-cw/danl-101-cw-08.html#purpose-of-this-activity",
    "title": "Classwork 8",
    "section": "üéØ Purpose of this Activity",
    "text": "üéØ Purpose of this Activity\n\nExtract data from you (students)\nBy submitting the survey, you generate raw rows in a database table ‚Äî just like how platforms quietly log every interaction you make.\n\nBehind the scenes, each of your clicks becomes a database entry ‚Äî a row born from your activity.\nThe survey is anonymous ‚Äî we analyze patterns, not individuals."
  },
  {
    "objectID": "danl-cw/danl-101-cw-08.html#social-media-analytics",
    "href": "danl-cw/danl-101-cw-08.html#social-media-analytics",
    "title": "Classwork 8",
    "section": "Social Media Analytics",
    "text": "Social Media Analytics\n\nETL Workflow\n\nYour role: You submit the survey ‚Äî that generates raw data rows, just like a platform logging user behavior.\nMy role: I act as the data system. As we walk through the results, I‚Äôll point out where I use\nfilter(), select(), and left_join() to Transform your responses and Load a clean analysis table we can analyze.\nBig idea: Your responses become a relational dataset, and then we join in algorithm rules ‚Äî the same way TikTok, Instagram, or Reddit enrich user logs before ranking your feed.\n\n\n\nFeed Algorithm\n\n‚ÄúDo you think your feed reflects your choices ‚Äî or the platform‚Äôs choices about you?‚Äù\n\n\nWe‚Äôll look at platform behavior patterns using your data:\nminutes, posting activity, device type, and interaction style.\nThen we‚Äôll run an algorithm simulation using a random card draw system to show how the same minutes can be valued very differently depending on the platform‚Äôs ranking logic.\n\n\n\nüß† Feed Algorithm Interpretation Using Card Mechanics\nTo illustrate how platforms differ in engagement efficiency, we treat each minute of screen time like drawing a card:\n\nRank (2‚Äì10, J, Q, K, A) ‚Üí how strong your engagement signal was\n\nSuit (platform personality) ‚Üí how that platform interprets and amplifies that engagement\n\nYou‚Äôll see that not all platforms reward the same behavior equally ‚Äî some love viral spikes, some love steady engagement.\n\nüé≠ Platform Algorithm Personalities ‚Äî Rank Bias Model\nEach platform doesn‚Äôt just apply a fixed multiplier ‚Äî it biases specific rank categories (Face, Ace, Mid, etc.).\nThis models how TikTok boosts viral spikes, Reddit rewards slower thread engagement, and YouTube locks users into deep watch sessions.\n\n\n\n\n\n\n\n\nPlatform\nAlgorithm Personality\nRank Preference Pattern\n\n\n\n\nTikTok\n‚ô† Strategic viral retention ‚Äî aggressively hunts viral spikes\nFace ‚Üí Ace ‚Üí 10 (very spike-oriented, punishes low/no engagement)\n\n\nInstagram / Threads\n‚ô¶ Aesthetic/status curation ‚Äî polished trend amplification\n10 ‚Üí Face ‚Üí Mid (reward polished content, suppress low-value scroll)\n\n\nYouTube\n‚ô† Strategic deep retention ‚Äî optimizes long session depth\nAce ‚Üí 10 ‚Üí Mid (not chaotic, but strong on intentional consumption)\n\n\nReddit / Discord\n‚ô£ Community depth ‚Äî favors threads, steady engagement over spikes\nMid ‚Üí Ace ‚Üí 10, downweights Face spikes (less about virality)\n\n\nSnapchat\n‚ô• Emotional burst algorithm ‚Äî high volatility, short attention loops\nFace spikes allowed, but low ranks common (chaotic scroll-emotion mix)\n\n\nX/Twitter\n‚ô£ Fast discourse loop ‚Äî rewards mid-level interaction & repost energy\nMid + Face modest bias, suppresses dead scrolling\n\n\nFacebook\n‚ô¶ Legacy ranking ‚Äî mild engagement shaping, mostly neutral\nSlight mid bias, nearly flat weighting otherwise\n\n\nNone\nNeutral baseline ‚Äî no algorithm shaping\nAll rank_adj = 1.00 (control group)\n\n\n\n\n\nüéÆ Rank Interpretation (Base Weights Before Platform Influence)\n\n\n\n\n\n\n\n\nRank Category\nBase Weight\nMeaning in Attention Model\n\n\n\n\nJoker (0)\n1.00\nPassive drift ‚Äî counted time, no engagement signal\n\n\n2‚Äì4 (Low ranks)\n1.00\nGlance-scroll, content seen without response\n\n\n5‚Äì9 (Mid ranks)\n1.05\nLight scrolling or minor interaction ‚Äî retention signal\n\n\n10\n1.10\nHigh interest moment ‚Äî actively watching or reading\n\n\nAce (A)\n1.25\nIntentional engagement ‚Äî searching, saving, deep dwell\n\n\nFace Cards (J/Q/K)\n1.50\nEmotional/viral spike ‚Äî strong reaction triggers\n\n\n\n\nüö© Raw minutes = counting cards without considering rank or suit.\nüéØ Algorithm-adjusted attention = calculating your true score based on both rank (quality of engagement) and suit (type of platform algorithm).\n\nIn other words:\n\nA 20-minute session on Instagram Reels (‚ô¶ Ace) scores high adjusted attention.\nA 40-minute YouTube autoplay binge (‚ô† Joker) has high raw minutes but almost no algorithm-weighted value.\nTwo users can spend the same time, but their card draws (attention efficiency) differ by platform.\n\nTikTok may reward spike engagement, while Reddit rewards steady browsing.\nYouTube may ignore your first 10 minutes, but heavily weight the moment you intentionally engage.\n\n\n\n\n\n‚úÖ Key Takeaway\n\nAlgorithms don‚Äôt just count your time ‚Äî they interpret and score it.\nSome platforms are time sinks, while others are attention amplifiers ‚Äî even if the minutes look the same.\n\n\n\nQuestions\n\nIf platforms score and rank your behavior in secret, should users be allowed to know their score ‚Äî or is it okay for the system to stay hidden?\nIf a platform is designed to keep you scrolling even when the content is low-value, is it ethical to design for addiction instead of meaningful use?"
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-03.html",
    "href": "danl-hw-q/danl-101-hw-03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 3, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\n\nGenerative AI Allowed with Conditions: You may use generative AI tools for the Data Transformation and Visualization with R section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer: Draft your responses in Word or Google Docs first before pasting your answers.\nData Transformation and Visualization with R: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated.\nDeadline: Wednesday, November 12, 2025 at 11:59 P.M. Eastern Time."
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-03.html#homework-instructions",
    "href": "danl-hw-q/danl-101-hw-03.html#homework-instructions",
    "title": "Homework 3",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 3, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\n\nGenerative AI Allowed with Conditions: You may use generative AI tools for the Data Transformation and Visualization with R section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer: Draft your responses in Word or Google Docs first before pasting your answers.\nData Transformation and Visualization with R: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated.\nDeadline: Wednesday, November 12, 2025 at 11:59 P.M. Eastern Time."
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-04.html",
    "href": "danl-hw-q/danl-101-hw-04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 4, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\n\nGenerative AI Allowed with Conditions: You may use generative AI tools for the Data Transformation and Visualization with R section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer: Draft your responses in Word or Google Docs first before pasting your answers.\nData Transformation and Visualization with R: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated."
  },
  {
    "objectID": "danl-hw-q/danl-101-hw-04.html#homework-instructions",
    "href": "danl-hw-q/danl-101-hw-04.html#homework-instructions",
    "title": "Homework 4",
    "section": "",
    "text": "Answer every question thoroughly; do not leave any items blank.\nNo Generative AI: For Homework Assignment 4, you do not use generative AI tools on the Multiple Choice and Short-Answer sections.\n\nGenerative AI Allowed with Conditions: You may use generative AI tools for the Data Transformation and Visualization with R section, but you are responsible for fully understanding the answers. Be prepared to explain the reasoning, logic, and steps behind any code you submit.\n\nWorkflow recommendations\n\nShort-Answer: Draft your responses in Word or Google Docs first before pasting your answers.\nData Transformation and Visualization with R: Write and test your code in an R script before pasting your answers.\n\nWhen you‚Äôre ready to submit\n\nClick ‚ÄúPrint to PDF (answers included)‚Äù to generate a clean copy of your responses.\nClick the ‚ÄúSubmit‚Äù button at the bottom of this page.\nWait for the confirmation message: ‚ÄúData submitted successfully!‚Äù\nA confirmation email (including your answers) will be sent to the email address you provide on this page (either your @geneseo.edu account or your personal email).\n\nResubmissions: You may submit multiple times; only your most recent submission will be evaluated."
  },
  {
    "objectID": "listing-danl-101-hw-q.html",
    "href": "listing-danl-101-hw-q.html",
    "title": "DANL 101 - Homework Submission",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework 1\n\n\nIntroduction to Data Analytics; Generative AI; R Basics\n\n\nSeptember 25, 2025\n\n\n\n\nHomework 2\n\n\nGenerative AI; Data Transformation with R\n\n\nSeptember 25, 2025\n\n\n\n\nHomework 3\n\n\nData Transformation & Visualization in R ‚Äî Part I\n\n\nNovember 4, 2025\n\n\n\n\nHomework 4\n\n\nData Transformation & Visualization in R ‚Äî Part II\n\n\nNovember 11, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-wk/wk-14.html",
    "href": "danl-wk/wk-14.html",
    "title": "Week 14",
    "section": "",
    "text": "In Week 14, we‚Äôll discuss the data storytelling project."
  },
  {
    "objectID": "danl-wk/wk-14.html#lecture-slides",
    "href": "danl-wk/wk-14.html#lecture-slides",
    "title": "Week 14",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 10 ‚Äî Data Visualization with ggplot\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-14.html#data-storytelling-project",
    "href": "danl-wk/wk-14.html#data-storytelling-project",
    "title": "Week 14",
    "section": "üìäüí° Data Storytelling Project",
    "text": "üìäüí° Data Storytelling Project\nYour team does not need to analyze every variable provided in the suggested data frames. Instead, carefully select the variables that best support your story, argument, and analysis.\nTo find an interesting story, you should:\n\nExplore your data using descriptive statistics (e.g., skimr::skim())\nApply data transformations such as filtering and counting\nUse data visualizations to uncover patterns, trends, and anomalies\nDraw on your background knowledge of the topic\nTreat the process as iterative ‚Äî your understanding will evolve as you explore, refine, and visualize your data along with your story.\n\nA strong data story emerges when your analytical choices (what you compute, transform, or visualize) clearly support your narrative and your main insights."
  },
  {
    "objectID": "danl-wk/wk-14.html#recommended-reading",
    "href": "danl-wk/wk-14.html#recommended-reading",
    "title": "Week 14",
    "section": "üìö Recommended Reading",
    "text": "üìö Recommended Reading\n\nWhat is Data Storytelling? (from Week 11)\nRubric for Data Storytelling Project (from the Guideline)\n\n\n\n\n\n\n\n\n\n\n\n\nAttribute\nVery Deficient (1)\nSomewhat Deficient (2)\nAcceptable (3)\nVery Good (4)\nOutstanding (5)\n\n\n\n\n1. Quality of Data Transformation and Descriptive Statistics\n- No transformation or cleaning applied- Very poor data transformation- Contains significant errors\n- Minimal transformation or cleaning- Basic data transformation with errors- Contains several errors\n- Basic transformation applied- Adequate data transformation- Contains minor errors\n- Effective transformation- Thorough data transformation- Data is accurate\n- Advanced transformation- Exceptional data transformation- Data is impeccable\n\n\n2. Quality of Data Visualization\n- Visualizations are missing or unclear- Misrepresents data\n- Visualizations are basic and lack clarity- Some misrepresentation\n- Visualizations are clear and accurate- Data is appropriately represented\n- Visualizations are insightful and enhance understanding- Data is accurately represented\n- Visualizations are highly creative and compelling- Data representation is impeccable\n\n\n3. Effectiveness of Data Storytelling\n- No narrative or storyline- Insights are absent or irrelevant- Fails to engage the audience\n- Weak narrative structure- Insights are superficial- Minimal audience engagement\n- Clear narrative present- Insights are relevant- Audience is adequately engaged\n- Compelling narrative- Insights are significant- Engages audience effectively\n- Exceptional and captivating narrative- Insights are profound and impactful- Audience is highly engaged\n\n\n4. Quality of Slides and Visual Materials\n- Very poorly organized- Difficult to read and understand- Numerous errors present\n- Somewhat disorganized- Some slides are unclear- Several errors present\n- Well organized- Mostly clear and understandable- Few errors present\n- Very well organized- Clear and visually appealing- Very few errors\n- Exceptionally well organized- Highly clear and visually compelling- No errors\n\n\n5. Quality of Team Presentation\n- Presentation is disjointed- Poor team coordination- Unable to address questions\n- Lacks flow- Some coordination issues- Difficulty with several questions\n- Cohesive presentation- Team works well together- Addresses most questions adequately\n- Engaging presentation- Team is well-coordinated- Addresses almost all questions professionally\n- Highly engaging and polished presentation- Excellent team coordination- Addresses all questions expertly\n\n\n6. Quality of Code (Descriptive Statistics, Transformation, Visualization)\n- Code is missing or non-functional- No documentation- Disorganized code\n- Code has major errors- Minimal documentation- Code is somewhat disorganized\n- Code is functional- Basic documentation provided- Code is organized\n- Code is efficient and well-structured- Good documentation- Code is well-organized\n- Code is highly efficient and elegant- Excellent documentation- Code is exceptionally well-organized\n\n\n\n\nR Script for Data Storytelling Project (from the Guideline)\n\nOrganization: Use section headers (created with Ctrl/Cmd + Shift + R) and comments (#) to clearly label which parts of your code correspond to specific visualizations, transformations, and descriptive statistics. This will make your script easy to follow.\nExplanation: Include comments to explain any parts of your code that use techniques not covered in the course. This should provide enough detail for others to understand the purpose and functionality of your code.\nReproducibility: Ensure your R script is complete and reproducible, meaning anyone who runs it should be able to replicate your results without needing additional information.\nClarity: Write clear and concise comments throughout your code to enhance readability and comprehension. Avoid overly complex or redundant code.\nError Handling: Make sure your code runs smoothly without errors."
  },
  {
    "objectID": "danl-wk/wk-14.html#discussion",
    "href": "danl-wk/wk-14.html#discussion",
    "title": "Week 14",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 14 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 14.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 14 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-15.html",
    "href": "danl-wk/wk-15.html",
    "title": "Weeks 15-16",
    "section": "",
    "text": "In Weeks 15-16, we‚Äôll have the data storytelling team presentations.\nOn Monday, December 8, 2025, we‚Äôll finish up the Sections of:\n- Effective Distribution Charts for Category Comparisons - Understanding and Visualizing Integer Data\nin Lecture 10."
  },
  {
    "objectID": "danl-wk/wk-15.html#lecture-slides",
    "href": "danl-wk/wk-15.html#lecture-slides",
    "title": "Weeks 15-16",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 10 ‚Äî Data Visualization with ggplot\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-15.html#discussion",
    "href": "danl-wk/wk-15.html#discussion",
    "title": "Weeks 15-16",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Weeks 15-16 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Weeks 15-16.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Weeks 15-16 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-02.html",
    "href": "danl-wk/wk-02.html",
    "title": "Week 2",
    "section": "",
    "text": "In Week 2, we will use sports analytics to introduce core data-analytics concepts, take a brief tour of business intelligence, and explore generative AI through Co-Intelligence (Introduction)."
  },
  {
    "objectID": "danl-wk/wk-02.html#lecture-slides",
    "href": "danl-wk/wk-02.html#lecture-slides",
    "title": "Week 2",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 3 - Sports Analytics; Business Intelligence\nView Slides\nLecture 4 ‚Äî Generative Artificial Intelligence\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-02.html#recommended-reading",
    "href": "danl-wk/wk-02.html#recommended-reading",
    "title": "Week 2",
    "section": "üìö Recommended Reading",
    "text": "üìö Recommended Reading\n\nSports Analytics\nThe application of analytics to business problems is a key skill that is essential to learn. Many of these techniques are now being applied to improve decision making in all aspects of sports, a very hot area called sports analytics. Sports analytics is the art and science of gathering data about athletes and teams to create insights that improve sports decisions, such as deciding which players to recruit, how much to pay them, who to play, how to train them, how to keep them healthy, and when they should be traded or retired. For teams, it involves business decisions such as ticket pricing, as well as opposition research, analysis of each competitor‚Äôs strengths and weaknesses, and many game-day decisions.\nThe use of analytics for sports was popularized by the Moneyball book by Michael Lewis in 2003 and the movie starring Brad Pitt in 2011. It showcased Oakland A‚Äôs general manager Billy Beane and his use of data and analytics to turn a losing team into a winner.\nIn particular, he hired an analyst who used analytics to draft players able to get on base as opposed to players who excelled at traditional measures like runs batted in or stolen bases. These insights allowed them to draft prospects overlooked by other teams at reasonable starting salaries. It worked‚Äîthey made it to the playoffs in 2002 and 2003.\nAs an Industry, sports worldwide is a multibillion-dollar industry. A report by Statista.com showed the size of the worldwide sports industry in 2018 itself to be almost $471 billion. Estimates vary widely, but according to Rice University, a conservative estimate of this industry‚Äôs current size is about $500 billion. This estimate includes various professional athletic leagues as well as college sports. According to some reports, college sports in the United States represent an $18 billion-dollar industry. Suffice it to say that sports is a major economic driver of activity in the United States and in many countries around the world.\nSports analytics is becoming a specialty within analytics. It is an important area because sports is a big business. In 2014, $125M was spent on analytics. A recent report produced by Grand View Research estimates that in 2020 the sports analytics industry had already grown to $885M, and is expected to grow at a staggering growth rate of over 27% per year. Thus, sports analytics is not only a fun way to learn about analytics, but it is also a potential career option for many graduates of analytics programs.\nAnalytics are being used in all parts of sports. The following framework presents a simple way to understand potential analytics applications in sports. The top layer points out the potential for the usual business office/administrative analytics like allocating budget dollars across multiple sports in colleges, or determining the mix of money spent on facilities vs.¬†coaches and trainers vs.¬†player salaries and benefits. The next two layers of analytics can be divided between the front office and back office (often called Business and Operations). Front-office business analytics include analyzing fan behavior ranging from predictive models for season ticket renewals and regular ticket sale pricing, to scoring tweets by fans regarding the team, athletes, coaches, and owners. This is very similar to traditional customer relationship management (CRM). For individual players, there is a focus on recruitment models and scouting analytics. Financial analysis is also a key area, where salary caps on rosters (for pros) or scholarship limits (colleges) are part of the equation.\nBack-office uses include analytics to improve a team‚Äôs operation as well as for health and safety of the players. Team analytics include strategies and tactics, competitive assessments, and optimal lineup choices under various on-field or on-court situations. Health/safety analytics focus on medical, strength and fitness as well as development, and predictive models for avoiding overtraining and injuries. Concussion research is a hot field, for example.\nFinally, the bottom layer points out the potential for application of analytics at the league/conference level to optimize schedules and locations of games across a pool of teams, including tournament seeding.\nThe following representative examples illustrate how various sports organizations use data and analytics to improve sports operations, in the same way analytics have improved traditional industry decision making. Almost all of these are based on actual projects conducted by students and researchers. In some cases, the names have been changed to protect identity of the stakeholders.\nExample 1: The Business Office‚ÄîFan Analytics\nKatie Ward works as a business analyst for a major pro baseball team, focusing on revenue. She analyzes ticket sales, both from season ticket holders as well as single-ticket buyers. Sample questions in her area of responsibility include why season ticket holders renew (or do not renew) their tickets, as well as what factors drive last-minute individual seat ticket purchases. Another question is how to price the tickets.\nSome of the analytical techniques Katie uses include simple statistics on fan behavior like overall attendance and answers to survey questions about likelihood to purchase again. However, what fans say versus what they do can be different. Katie runs a survey of fans by ticket seat location (‚Äútier‚Äù) and asks about their likelihood of renewing their season tickets. But when she compares what they say versus what they do, she discovers big differences. She found that 69% of fans in Tier 1 seats who said on the survey that they would ‚Äúprobably not‚Äù renew actually did. This is a useful insight that leads to action‚Äîcustomers who are most likely to renew tickets require fewer marketing touches and dollars to convert, for example, compared to customers who are ‚Äúon the edge.‚Äù\nHowever, many factors influence fan ticket purchase behavior, especially price, which drives more sophisticated statistics and data analysis. For both areas, but especially single-game tickets, Katie is driving the use of dynamic pricing‚Äîmoving the business from simple static pricing by seat location tier to day-by-day up-and-down pricing of individual seats. This is a rich research area for many sports teams and has huge upside potential for revenue enhancement. For example, her pricing takes into account the team‚Äôs record, who they are playing, game dates and times, which star athletes play for each team, each fan‚Äôs history of renewing season tickets or buying single tickets, as well as factors like seat location, number of seats, and real-time information like traffic congestion historically at game time and even the weather.\nWhich of these factors are important? How much? Given her extensive statistics background, Katie builds regression models to pick out key factors driving these historic behaviors and create predictive models to identify how to spend marketing resources to drive revenues. She builds churn models for season ticket holders to create segments of customers who will renew, won‚Äôt renew, or are fence-sitters, which then drives more refined marketing campaigns.\nIn addition, she does sentiment scoring on fan comments like tweets that help her segment fans into different loyalty segments. Other studies about single-game attendance drivers help the marketing department understand the impact of giveaways like bobble-heads or T-shirts, or suggestions on where to make spot TV ad buys.\nBeyond revenues, there are many other analytical areas that Katie‚Äôs team works on, including merchandising, TV and radio broadcast revenues, inputs to the general manager on salary negotiations, draft analytics especially given salary caps, promotion effectiveness including advertising channels, and brand awareness, as well as partner analytics.\nExample 2: The College Football Coach‚ÄîPlay Tactics\nBob Breedlove is the football coach for a major college team. For him, it‚Äôs all about winning games. His areas of focus include recruiting the best high school players, developing them to fit his offense and defense systems, and getting maximum effort from them on game days. Sample questions in his area of responsibility include: Who do we recruit? What drills help develop their skills? How hard do I push our athletes? Where are opponents strong or weak, and how do we figure out their play tendencies?\nFortunately, his team has hired a new team operation expert, Dar Beranek, who specializes in helping the coaches make tactical decisions. She is working with a team of student interns who are creating opponent analytics. They used the coach‚Äôs annotated game film to build a cascaded decision tree model to predict whether the next play will be a running play or passing play. This shows some tendencies they might want to exploit. For example, when they see a personnel formation that looks like a pass, and it‚Äôs third or fourth down with more than 5 yards to go, their opponent team passes 95.45% of the time‚Äîvery predictable!\n\nReference\n\nSharda and Turban - Business Intelligence, Analytics, Data Science, and AI (5th Edition), Ch.1.\n\n‚ö†Ô∏è Note: These excerpts from the above article are shared under fair use for educational purposes to support your learning.\n\n\n\nBusiness Intelligence\nBusiness intelligence (BI) is a set of technological processes for collecting, managing and analyzing organizational data to yield insights that inform business strategies and operations.\nBusiness intelligence analysts transform raw data into meaningful insights that drive strategic decision-making within an organization. BI tools enable business users to access different types of data, historical and current, third-party and in-house, as well as semistructured data and unstructured data such as social media. Users can analyze this information to gain insights into how the business is performing and what it should do next.\nAccording to CIO magazine: ‚ÄúAlthough business intelligence does not tell business users what to do or what will happen if they take a certain course, neither is BI only about generating reports. Rather, BI offers a way for people to examine data to understand trends and derive insights.‚Äù\nOrganizations can use the insights gained from BI and data analysis to improve business decisions, identify problems or issues, spot market trends and find new revenue or business opportunities.\n\nHow BI works\nThe steps taken in BI usually flow in this order:\n\nData sources: Identify the data to be reviewed and analyzed, such as from a data warehouse or data lake, cloud, Hadoop, industry statistics, supply chain, CRM, inventory, pricing, sales, marketing or social media.\nData collection: Gather and clean data from various sources. This data preparation might be manually gathering information in a spreadsheet or an automatic extract, transform and load (ETL) program.\nAnalysis: Look for trends or unexpected results in the data. This might use data mining, data discovery or data modeling tools.\nVisualization: Create data visualizations, graphs and dashboards that use business intelligence tools such as Tableau, Cognos Analytics, Microsoft Excel or SAP. Ideally this visualization includes drill-down, drill-through, drill-up features to enable users to investigate various data levels.\nAction plan: Develop actionable insights based on analysis of historical data versus key performance indicators (KPIs). Actions might include more efficient processes, changes in marketing, fixing supply chain issues or adapting customer experience issues.\n\nSome newer BI products can extract and load raw data directly by using technology such as Hadoop, but data warehouses often remain the data source of choice.\n\n\nReference\n\nIBM - What is business intelligence (BI)?\n\n‚ö†Ô∏è Note: These excerpts from the above article are shared under fair use for educational purposes to support your learning.\n\n\n\nCo-Intelligence: Living and Working with AI\n\nRead: Introduction and Chapter 1"
  },
  {
    "objectID": "danl-wk/wk-02.html#discussion",
    "href": "danl-wk/wk-02.html#discussion",
    "title": "Week 2",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 2 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 2.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 2 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-12.html",
    "href": "danl-wk/wk-12.html",
    "title": "Week 12",
    "section": "",
    "text": "In Week 12, we‚Äôll continue to discuss various topics in Data Visualization with ggplot."
  },
  {
    "objectID": "danl-wk/wk-12.html#lecture-slides",
    "href": "danl-wk/wk-12.html#lecture-slides",
    "title": "Week 12",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 10 ‚Äî Data Visualization with ggplot\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-12.html#classwork",
    "href": "danl-wk/wk-12.html#classwork",
    "title": "Week 12",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\n\nClasswork 11 - Relationship Plots\nView Classwork\nClasswork 12 - Color vs.¬†Facet\nView Classwork\nClasswork 13 - Time Trend Plots\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-12.html#data-storytelling-project",
    "href": "danl-wk/wk-12.html#data-storytelling-project",
    "title": "Week 12",
    "section": "Ô∏èüìäüí° Data Storytelling Project",
    "text": "Ô∏èüìäüí° Data Storytelling Project\n\nI encourage you to work with your teammates to study data visualization and prepare for the data storytelling project during the remaining classes.\nDue for the topic choice for the Data Storytelling Project is Friday, November 14, 2025 at 11:59 PM (Eastern Time)\nüóÇÔ∏è View the Topic Choice Survey\nüìÑ View the Project Guideline with Topics\n‚öæ View the Sports Topic - Baseball\nüèÄ View the Sports Topic - Basketball\nüèà View the Sports Topic - Football\nüèí View the Sports Topic - Hockey\n‚öΩ View the Sports Topic - Soccer"
  },
  {
    "objectID": "danl-wk/wk-12.html#discussion",
    "href": "danl-wk/wk-12.html#discussion",
    "title": "Week 12",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 12 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 12.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 12 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-07.html",
    "href": "danl-wk/wk-07.html",
    "title": "Week 7",
    "section": "",
    "text": "In Week 7, we‚Äôll have Midterm Exam I."
  },
  {
    "objectID": "danl-wk/wk-07.html#midterm-exam-i",
    "href": "danl-wk/wk-07.html#midterm-exam-i",
    "title": "Week 7",
    "section": "Midterm Exam I",
    "text": "Midterm Exam I\n\nFormat\n\nClosed-book, paper-based exam\n\nPlease bring a pencil\n\n\n\nReference Sheet Guidelines\n\nYou may bring one handwritten reference sheet (8.5 √ó 11 inches) on notebook or printer paper\n\nBoth sides may be used (two pages total)\n\nSheets must be submitted along with your exam\n\n\n\nQuestion Types\nThe exam format will be similar to Homework Assignments 1 and 2:\n\nTrue/False\n\nMultiple Choice\n\nFill-in-the-Blanks\n\nShort Answer\n\nShort Essay\n\n\n\nStructure\n\nApproximately 50% coding questions (50 points)\nApproximately 50% discussion-based (non-coding) questions (50 points)\n\n\n\nMidterm Exam I (Fall 2024)\nTo get a sense of the exam style and format, you can review last year‚Äôs version below:\n\nMidterm Exam I (Fall 2024)\nView Exam"
  },
  {
    "objectID": "danl-wk/wk-07.html#discussion",
    "href": "danl-wk/wk-07.html#discussion",
    "title": "Week 7",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 7 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 7.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 7 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-05.html",
    "href": "danl-wk/wk-05.html",
    "title": "Week 5",
    "section": "",
    "text": "In Week 5, we will focus on the basics of R programming for data analysis. In addition, please take a look at the essay on Rule 4 in Classwork 3 - Co-Intelligence Rule Practice, and check out OpenAI‚Äôs 100 Chats for College Students as an extra resource."
  },
  {
    "objectID": "danl-wk/wk-05.html#lecture-slides",
    "href": "danl-wk/wk-05.html#lecture-slides",
    "title": "Week 5",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 5 ‚Äî R Basics\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-05.html#classwork",
    "href": "danl-wk/wk-05.html#classwork",
    "title": "Week 5",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\n\nClasswork 4 - R Basics I\nView Classwork\nClasswork 5 - R Basics II\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-05.html#recommended-reading",
    "href": "danl-wk/wk-05.html#recommended-reading",
    "title": "Week 5",
    "section": "üìö Recommended Reading",
    "text": "üìö Recommended Reading\n\nOpenAI - 100 Chats for College Students\n\n\nReference\n\nIsmay C. and Kim A.Y., Chapter 1. Getting Started with Data in R in Statistical Inference via Data Science: A ModernDive into R and the Tidyverse"
  },
  {
    "objectID": "danl-wk/wk-05.html#discussion",
    "href": "danl-wk/wk-05.html#discussion",
    "title": "Week 5",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 5 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 5.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 5 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-10.html",
    "href": "danl-wk/wk-10.html",
    "title": "Week 10",
    "section": "",
    "text": "In Week 10, we‚Äôll wrap up the two Alumni Career Sessions. We‚Äôll then continue to explore new topics in big data and the modern data infrastructure."
  },
  {
    "objectID": "danl-wk/wk-10.html#lecture-slides",
    "href": "danl-wk/wk-10.html#lecture-slides",
    "title": "Week 10",
    "section": "üè´ Lecture Slides",
    "text": "üè´ Lecture Slides\n\nLecture 7 ‚Äî Big Data and the Modern Data Infrastructure\nView Slides\n\nüé• Looking for lecture recordings? You can only find those on Brightspace."
  },
  {
    "objectID": "danl-wk/wk-10.html#classwork",
    "href": "danl-wk/wk-10.html#classwork",
    "title": "Week 10",
    "section": "‚úçÔ∏è Classwork",
    "text": "‚úçÔ∏è Classwork\n\nClasswork 9 - Joining Two Related Tables in R\nView Classwork\nClasswork 10 - Career Sessions\nView Classwork"
  },
  {
    "objectID": "danl-wk/wk-10.html#reference",
    "href": "danl-wk/wk-10.html#reference",
    "title": "Week 10",
    "section": "üìö Reference",
    "text": "üìö Reference\n\nFree Sources of Useful (Big) Data\n\nEconomics/Finance\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nBureau of Labor Statistics (BLS)\nProvides access to data on inflation and prices, wages and benefits, employment, spending and time use, productivity, and workplace injuries\nBLS\n\n\nFRED (Federal Reserve Economic Data)\nProvides access to a vast collection of U.S. economic data, including interest rates, GDP, inflation, employment, and more\nFRED\n\n\nYahoo Finance\nProvides comprehensive financial news, data, and analysis, including stock quotes, market data, and financial reports\nYahoo Finance\n\n\nIMF (International Monetary Fund)\nProvides access to a range of economic data and reports on countries‚Äô economies\nIMF Data\n\n\nWorld Bank Open Data\nFree and open access to global development data, including world development indicators\nWorld Bank Open Data\n\n\nOECD Data\nProvides access to economic, environmental, and social data and indicators from OECD member countries\nOECD Data\n\n\n\n\n\n\nGovernment/Public Data\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nData.gov\nPortal providing access to over 186,000 government data sets, related to topics such as agriculture, education, health, and public safety\nData.gov\n\n\nCIA World Factbook\nPortal to information on the economy, government, history, infrastructure, military, and population of 267 countries\nCIA World Factbook\n\n\nU.S. Census Bureau\nPortal to a huge variety of government statistics and data relating to the U.S. economy and its population\nU.S. Census Bureau\n\n\nEuropean Union Open Data Portal\nProvides access to public data from EU institutions\nEU Open Data Portal\n\n\nNew York City Open Data\nProvides access to datasets from New York City, covering a wide range of topics such as public safety, transportation, and health\nNYC Open Data\n\n\nLos Angeles Open Data\nPortal for accessing public data from the City of Los Angeles, including transportation, public safety, and city services\nLA Open Data\n\n\nChicago Data Portal\nOffers access to datasets from the City of Chicago, including crime data, transportation, and health statistics\nChicago Data Portal\n\n\n\n\n\n\nHealth, Climate/Environment, and Social Data\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nHealthdata.gov\nPortal to 125 years of U.S. health care data, including national health care expenditures, claim-level Medicare data, and other topics\nHealthdata.gov\n\n\nWorld Health Organization (WHO)\nPortal to data and statistics on global health issues\nWHO Data\n\n\nNational Centers for Environmental Information (NOAA)\nPortal for accessing a variety of climate and weather data sets\nNCEI\n\n\nNOAA National Weather Service\nProvides weather, water, and climate data, forecasts and warnings\nNOAA NWS\n\n\nFAO (Food and Agriculture Organization)\nProvides access to data on food and agriculture, including data on production, trade, food security, and sustainability\nFAOSTAT\n\n\nPew Research Center Internet & Technology\nPortal to research on U.S. politics, media and news, social trends, religion, Internet and technology, science, Hispanic, and global topics\nPew Research\n\n\nData for Good from Facebook\nProvides access to anonymized data from Facebook to help non-profits and research communities with insights on crises, health, and well-being\nFacebook Data for Good\n\n\nData for Good from Canada\nProvides open access to datasets that address pressing social challenges across Canada\nData for Good Canada\n\n\n\n\n\n\nGeneral Data Repositories\n\n\n\n\nData Source\nDescription\nURL\n\n\n\n\nAmazon Web Services (AWS) public data sets\nPortal to a huge repository of public data, including climate data, the million song dataset, and data from the 1000 Genomes project\nAWS Datasets\n\n\nGapminder\nPortal to data from the World Health Organization and World Bank on economic, medical, and social issues\nGapminder\n\n\nGoogle Dataset Search\nHelps find datasets stored across the web\nGoogle Dataset Search\n\n\nKaggle Datasets\nA community-driven platform with datasets from various fields, useful for machine learning and data science projects\nKaggle Datasets\n\n\nUCI Machine Learning Repository\nA collection of databases, domain theories, and datasets used for machine learning research\nUCI ML Repository\n\n\nUnited Nations Data\nProvides access to global statistical data compiled by the United Nations\nUN Data\n\n\nHumanitarian Data Exchange (HDX)\nProvides humanitarian data from the United Nations, NGOs, and other organizations\nHDX\n\n\nDemocratizing Data from data.org\nA platform providing access to high-impact datasets, tools, and resources aimed at solving critical global challenges\nDemocratizing Data\n\n\nJustia Federal District Court Opinions and Orders database\nA free searchable database of full-text opinions and orders from civil cases heard in U.S. Federal District Courts\nJustia"
  },
  {
    "objectID": "danl-wk/wk-10.html#discussion",
    "href": "danl-wk/wk-10.html#discussion",
    "title": "Week 10",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 10 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 10.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 10 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-wk/wk-08.html",
    "href": "danl-wk/wk-08.html",
    "title": "Week 8",
    "section": "",
    "text": "In Week 8, we‚Äôll be reviewing Midterm Exam I, and then move to the next new topic, data management."
  },
  {
    "objectID": "danl-wk/wk-08.html#how-midterm-exam-1-contributes-to-your-total-exam-score",
    "href": "danl-wk/wk-08.html#how-midterm-exam-1-contributes-to-your-total-exam-score",
    "title": "Week 8",
    "section": "How Midterm Exam 1 Contributes to Your Total Exam Score",
    "text": "How Midterm Exam 1 Contributes to Your Total Exam Score\n\nScenario 1\n\nSuppose your \\((\\text{Total Exam Score})\\) is taken from: \\[\n\\begin{align}\n&0.33\\times(\\text{Midterm Exam 1}) \\,+\\, 0.67\\times(\\text{Midterm Exam 2})\\\\\n&0.25\\times(\\text{Midterm Exam}) \\,+\\, 0.75\\times(\\text{Final Exam})\n\\end{align}\n\\]\n\\((\\text{Midterm Exam 1})\\) will then account for 8.25% of your \\((\\text{Total Exam Score})\\).\n\n\n\nScenario 2\n\nSuppose your \\((\\text{Total Exam Score})\\) is taken from: \\[\n\\begin{align}\n&0.5\\times(\\text{Midterm Exam 1}) \\,+\\, 0.5\\times(\\text{Midterm Exam 2})\\\\\n&0.25\\times(\\text{Midterm Exam}) \\,+\\, 0.75\\times(\\text{Final Exam})\n\\end{align}\n\\]\n\\((\\text{Midterm Exam 1})\\) will then account for 12.5% of your \\((\\text{Total Exam Score})\\).\n\n\n\nScenario 3\n\nSuppose your \\((\\text{Total Exam Score})\\) is taken from: \\[\n\\begin{align}\n&0.33\\times(\\text{Midterm Exam 1}) \\,+\\, 0.67\\times(\\text{Midterm Exam 2})\\\\\n&0.5\\times(\\text{Midterm Exam}) \\,+\\, 0.5\\times(\\text{Final Exam})\n\\end{align}\n\\]\n\\((\\text{Midterm Exam 1})\\) will then account for 16.25% of your \\((\\text{Total Exam Score})\\).\n\n\n\nScenario 4\n\nSuppose your \\((\\text{Total Exam Score})\\) is taken from: \\[\n\\begin{align}\n&0.5\\times(\\text{Midterm Exam 1}) \\,+\\, 0.5\\times(\\text{Midterm Exam 2})\\\\\n&0.5\\times(\\text{Midterm Exam}) \\,+\\, 0.5\\times(\\text{Final Exam})\n\\end{align}\n\\]\n\\((\\text{Midterm Exam 1})\\) will then account for 25% of your \\((\\text{Total Exam Score})\\)."
  },
  {
    "objectID": "danl-wk/wk-08.html#discussion",
    "href": "danl-wk/wk-08.html#discussion",
    "title": "Week 8",
    "section": "üí¨ Discussion",
    "text": "üí¨ Discussion\nWelcome to our Week 8 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Week 8.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) or peer classmate (@GitHub-Username) regarding the Week 8 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!"
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html",
    "title": "Midterm Exam 1",
    "section": "",
    "text": "Which of the following is NOT an example of a Business Intelligence (BI) tool mentioned in the lecture?\n\nMicrosoft Power BI\nTableau\nLooker\nEclipse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nEclipse\n\nExplanation: Eclipse is an integrated development environment (IDE) used primarily for software development, not a Business Intelligence (BI) tool. We did not cover this.\n\n\n\n\n\n\nWhich of the following is NOT a measure of dispersion?\n\nRange\nVariance\nMedian\nStandard Deviation\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nMedian\n\nExplanation: Median is a measure of central tendency. Range, variance, and standard deviation are measures of dispersion in a data set."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-4",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-4",
    "title": "Midterm Exam 1",
    "section": "",
    "text": "Which of the following is NOT an example of a Business Intelligence (BI) tool mentioned in the lecture?\n\nMicrosoft Power BI\nTableau\nLooker\nEclipse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nEclipse\n\nExplanation: Eclipse is an integrated development environment (IDE) used primarily for software development, not a Business Intelligence (BI) tool. We did not cover this."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-5",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-5",
    "title": "Midterm Exam 1",
    "section": "",
    "text": "Which of the following is NOT a measure of dispersion?\n\nRange\nVariance\nMedian\nStandard Deviation\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nMedian\n\nExplanation: Median is a measure of central tendency. Range, variance, and standard deviation are measures of dispersion in a data set."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-15",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-15",
    "title": "Midterm Exam 1",
    "section": "Question 15:",
    "text": "Question 15:\nRStudio is an ________________________________________ (IDE) for R, providing a console, syntax-highlighting editor, and tools for plotting and debugging.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n‚Äúintegrated development environment‚Äù\nExplanation: RStudio is an IDE that offers an interface for writing and executing R code. It provides a user-friendly console, code editor with syntax highlighting, and tools for creating visualizations, debugging, and managing R projects efficiently."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-20",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-20",
    "title": "Midterm Exam 1",
    "section": "Question 20",
    "text": "Question 20\nWhich of the following R code correctly assigns the nycflights13::airlines data.frame to the variable df_airlines? (Note that df_airlines is simply the name of the R object and can be any valid name in R.)\n\nnycflights13::airlines &lt;- df_airlines\ndf_airlines &lt;- nycflights13::airlines\nnycflights13::airlines &lt;= df_airlines\ndf_airlines == nycflights13::airlines\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf_airlines &lt;- nycflights13::airlines\n\nExplanation: The correct assignment operator in R is &lt;-. The right-hand side data.frame (nycflights13::airlines) is assigned to the left-hand object name (df_airlines). The other choices are either incorrect operators or use an invalid assignment direction."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-21",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-21",
    "title": "Midterm Exam 1",
    "section": "Question 21",
    "text": "Question 21\nWhich of the following R code correctly calculate the number of elements in a vector x &lt;- c(1,2,3,4,5)?\n\nnrow(x)\nsd(x)\nsum(x)\nlength(x)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nlength(x)\n\nExplanation: The length() function returns the number of elements in a vector. The other options either calculate the number of rows (for data.frame) or the sum or standard deviation of the vector elements."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-22",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-22",
    "title": "Midterm Exam 1",
    "section": "Question 22",
    "text": "Question 22\nWrite the R code to create a new variable called result and assign to it the sum of 5 and 7 in R.\n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nresult &lt;- 5 + 7\nExplanation: In R, you use the &lt;- operator to assign values to variables. Here, the expression 5 + 7 calculates the sum, which is then assigned to the variable result."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-23",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-23",
    "title": "Midterm Exam 1",
    "section": "Question 23",
    "text": "Question 23\nGiven the data.frame df with variables age and name, which of the following expressions returns a vector containing the values in the age variable?\n\ndf:age\ndf::age\ndf$age\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf$age\n\nExplanation: In R, the $ operator is used to access specific variables (columns) within a data frame. The df$age expression will return the age column from df. The other options use invalid syntax."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-24",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-24",
    "title": "Midterm Exam 1",
    "section": "Question 24",
    "text": "Question 24\nThe expression as.numeric(\"123\") will return the numeric value 123.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nTrue\n\nExplanation: The as.numeric() function in R converts character data into numeric format, so ‚Äú123‚Äù will correctly be converted to the numeric value 123."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-25",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-25",
    "title": "Midterm Exam 1",
    "section": "Question 25",
    "text": "Question 25\nWhat is the result of the expression (4 + 3) ^ 2 in R?\n\n3.5\n9\n14\n49\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n49\n\nExplanation: The expression (4 + 3) ^ 2 first adds 4 and 3 to get 7, then raises 7 to the power of 2, which results in 49."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-26",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-26",
    "title": "Midterm Exam 1",
    "section": "Question 26",
    "text": "Question 26\nGiven vectors a &lt;- c(1, 2, 3) and b &lt;- c(4, 5, 6), what is the result of a + b?\n\nc(5, 7, 9)\nc(4, 5, 6, 1, 2, 3)\nc(1, 2, 3, 4, 5, 6)\nError\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nc(5, 7, 9)\n\nExplanation: In R, adding two vectors element-wise results in a new vector where each element is the sum of corresponding elements. So, a + b results in c(1 + 4, 2 + 5, 3 + 6) or c(5, 7, 9)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-27",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-27",
    "title": "Midterm Exam 1",
    "section": "Question 27",
    "text": "Question 27\nWhich of the following functions is part of the tidyverse package and is used to read a CSV file into a data.frame?\n\nread.csv()\nread_csv()\nread.table()\nload()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nread_csv()\n\nExplanation: read_csv() is a function from the readr package, which is part of the tidyverse. It is faster and more efficient than base R‚Äôs read.csv(). read.csv() is from base R, and read.table() is used to read data from a text file, while load() is used for loading R-specific binary files."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-28",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-28",
    "title": "Midterm Exam 1",
    "section": "Question 28",
    "text": "Question 28\nTo use the function skim() from the skimr package, you first need to load the package using the R code ________.\n\nlibrary(skimr)\nload(skimr)\nskimr\nskimr::skim\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nlibrary(skimr)\n\nExplanation: The library() function is used to load R packages that are installed. To use the skim() function, you need to load the skimr package with library(skimr)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-29",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-29",
    "title": "Midterm Exam 1",
    "section": "Question 29",
    "text": "Question 29\nThe filter() function can use both logical operators like & and comparison operators like &gt; within the same logical condition.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nTrue\n\nExplanation: The filter() function from the dplyr package can combine multiple conditions using logical operators (&, |, etc.) and comparison operators (&gt;, &lt;, ==) within the same logical statement."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-30",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-30",
    "title": "Midterm Exam 1",
    "section": "Question 30",
    "text": "Question 30\nConsider the following data.frame df0:\n\n\n\n\n\nx\ny\n\n\n\n\n1\n4\n\n\n2\nNA\n\n\nNa\n6\n\n\n\n\n\nWhat is the result of mean(df0$y)?\n\n4\nNA\n5\n6\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nNA\n\nExplanation: When calculating the mean of a vector that contains NA values, R will return NA by default. In this case, since df0$y contains an NA, the result is NA. We can use skim() to remove missing values before calculating the mean."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#questions-31-32",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#questions-31-32",
    "title": "Midterm Exam 1",
    "section": "Questions 31-32",
    "text": "Questions 31-32\nConsider the following data.frame df for Questions 31-32:\n\n\n\n\n\nid\nname\nage\nscore\n\n\n\n\n1\nAlice\n25\n85\n\n\n2\nBob\n30\n90\n\n\n3\nCharlie\n35\n75\n\n\n4\nDavid\nNA\n80\n\n\n5\nEve\n45\nNA\n\n\n\n\n\n\nQuestion 31\nWhich of the following code snippets keeps observations where score is between 80 and 90 inclusive?\n\ndf |&gt; filter(score &gt; 80 & score &lt; 90)\ndf |&gt; filter(score &gt;= 80 & score &lt;= 90)\ndf |&gt; filter(score &gt;= 80 | score &lt;= 90)\ndf |&gt; filter(score &gt; 80 | score &lt; 90)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf |&gt; filter(score &gt;= 80 & score &lt;= 90)\n\nExplanation: The filter() function in tidyverse allows for selecting rows that meet certain conditions. The correct condition for keeping scores between 80 and 90 inclusive requires using &gt;= and &lt;=. Option a is incorrect because it excludes 80 and 90, while options c and d use | (OR), which selects scores either greater than or equal to 80 or less than or equal to 90, which is not the intended condition.\n\n\n\n\n\nQuestion 32\nWhich of the following expressions correctly keeps observations from df where the age variable has missing values?\n\ndf |&gt; filter(is.na(age))\ndf |&gt; filter(!is.na(age))\ndf |&gt; filter(age == NA)\ndf |&gt; filter(age != NA)\nBoth a and c\nBoth b and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf |&gt; filter(is.na(age))\n\nExplanation: The function is.na() checks for missing values (NA). To filter observations with missing values in age, we use filter(is.na(age)). Option c is incorrect because age == NA does not work in R (use is.na() instead). Option b filters for non-missing values, which is not what the question asks."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-33",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-33",
    "title": "Midterm Exam 1",
    "section": "Question 33",
    "text": "Question 33\nThe arrange() function can sort data based on multiple variables.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nTrue\n\nExplanation: The arrange() function from dplyr can sort data based on one or more variables. If multiple variables are specified, the data is sorted by the first variable, and in the case of ties, by the second, and so on."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-34",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-34",
    "title": "Midterm Exam 1",
    "section": "Question 34",
    "text": "Question 34\nConsider the following data.frame df3:\n\n\n\n\n\nid\nvalue\n\n\n\n\n1\n10\n\n\n2\n20\n\n\n2\n20\n\n\n3\n30\n\n\n4\n40\n\n\n4\n40\n\n\n5\n50\n\n\n\n\n\nWhich of the following code snippets returns a data.frame of unique id values from df3?\n\ndf3 |&gt; select(id) |&gt; distinct()\ndf3 |&gt; distinct(value)\ndf3 |&gt; distinct(id)\nBoth A and C\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nBoth A and C\n\nExplanation: The distinct() function in tidyverse removes duplicate observations. Both df3 |&gt; select(id) |&gt; distinct() and df3 |&gt; distinct(id) will return a data.frame with unique id values. Option b operates on the value variable, which is not relevant for this question."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-35",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-35",
    "title": "Midterm Exam 1",
    "section": "Question 35",
    "text": "Question 35\nWhich of the following code snippets correctly renames the variable age to years in df?\n\ndf |&gt; rename(years = age)\ndf |&gt; rename(age = years)\ndf |&gt; rename(\"age\" = \"years\")\ndf |&gt; rename_variable(age = years)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf |&gt; rename(years = age)\n\nExplanation: In tidyvserse, the correct syntax for renaming a variable is rename(new_name = old_name). Hence, to rename age to years, you need to use rename(years = age)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-36",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-36",
    "title": "Midterm Exam 1",
    "section": "Question 36",
    "text": "Question 36\nWhich of the following code snippets correctly removes the age variable from df?\n\ndf |&gt; select(-age)\ndf |&gt; select(-\"age\")\ndf |&gt; select(!age)\ndf |&gt; select(, -age)\ndf |&gt; select(desc(age))\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf |&gt; select(-age) and b. df |&gt; select(-\"age\") (a is preferred though)\n\nExplanation: To remove a variable in tidyverse, you can use select() with the minus sign - before the variable name. Option a correctly removes age. Option b works but has unfavorable syntax (-‚Äúage‚Äù), and the others use invalid approaches."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-37",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-37",
    "title": "Midterm Exam 1",
    "section": "Question 37",
    "text": "Question 37\nWhich of the following code snippets filters observations where age is not NA, then arranges them in descending order of age, and then selects the name and age variables?\n\ndf |&gt; filter(!is.na(age)) |&gt; arrange(desc(age)) |&gt; select(name, age)\ndf |&gt; select(name, age) |&gt; arrange(desc(age)) |&gt; filter(!is.na(age))\ndf |&gt; arrange(desc(age)) |&gt; filter(!is.na(age)) |&gt; select(name, age)\ndf |&gt; filter(is.na(age)) |&gt; arrange(age) |&gt; select(name, age)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf |&gt; filter(!is.na(age)) |&gt; arrange(desc(age)) |&gt; select(name, age)\n\nExplanation: This sequence of operations first filters observations where age is not missing (!is.na(age)), arranges them in descending order of age, and then selects the name and age variables. The other options either mix up the sequence or apply incorrect filtering."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-fall-2024.html#question-39",
    "href": "danl-ex/danl-101-exam-1-fall-2024.html#question-39",
    "title": "Midterm Exam 1",
    "section": "Question 39",
    "text": "Question 39\nIn R, what does the function sd(x) compute, and why can it be more useful than var(x)?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe function sd(x) computes the standard deviation of the values in x, which is a measure of how far each data point deviates from the mean, on average. It is often more useful than var(x) (which computes the variance) because standard deviation is in the same unit as the data, making it easier to interpret and compare across datasets."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which tool is an Integrated Development Environment (IDE) that you can install on your computer to develop programs primarily using the Python programming language?\n\nPosit Cloud\nGoogle Colab\nJupyter Notebook\nMATLAB\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Jupyter Notebook is a locally installable environment that allows users to write, execute, and manage Python code interactively using code cells. While it can also be run in the browser, it is installed as a Python-based IDE on a local machine. Posit Cloud and Google Colab are cloud-based environments that do not require installation, and MATLAB is a standalone IDE but is not primarily designed for Python development.\n\n\n\n\n\n\nWhich combination correctly matches the tool with its role?\n\n\n\n\nTool\nPrimary Role\n\n\n\n\nI\nGitHub\nCode sharing\n\n\nII\nRStudio\nIDE for R\n\n\nIII\nPython\nGeneral-purpose language\n\n\n\n\nOnly I and II\nOnly II and III\nI, II, and III\nOnly I and III\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: GitHub is a platform for sharing and collaborating on code, RStudio is an IDE for R programming, and Python is a general-purpose programming language widely used for analytics, automation, AI, and more. Since all three pairings are correct, the correct answer is that I, II, and III are all correctly matched.\n\n\n\n\n\n\nWhich of the following best describes the core mechanism by which a machine learning model predicts a new output, as described in the text?\n\nIt receives explicit, pre-written instructions for every possible data combination.\nIt identifies patterns by processing a large quantity of historical input/output data sets.\nIt relies on human intervention to classify new data points in real time.\nIt performs data filtering and sorting tasks without needing a modifiable math function.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Machine learning models work by detecting statistical patterns in large amounts of historical input-output data. Through training, the model adjusts its internal mathematical parameters so that its output better matches expected results. Unlike traditional programming, the model does not require explicit rules for every case and does not depend on human supervision at inference time.\n\n\n\n\n\n\nWhich of the following best describes the primary objective of sports analytics in modern organizations?\n\nAutomating coaching and managerial decisions through advanced machine learning algorithms\nCollecting and analyzing data to generate actionable insights for both athletic performance and organizational strategy\nUsing data exclusively to evaluate athlete recruitment and compensation decisions\nMeasuring fan sentiment and satisfaction through periodic surveys and social-media monitoring\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Modern sports analytics goes beyond recruitment and includes performance tracking, injury prevention, game strategy, financial planning, and fan engagement‚Äîall informed by data analysis. The goal is not to automate decisions entirely but to provide coaches and managers with data-driven insights that support high-level strategy across both performance and business operations.\n\n\n\n\n\n\nWhich of the following activities falls outside the primary scope of Business Intelligence (BI) as traditionally defined?\n\nSummarizing and reporting historical business performance through dashboards and KPIs\nIdentifying data patterns and market trends that inform managerial decisions\nProviding automated prescriptive recommendations and executing future actions without human input\nSupporting strategic planning by visualizing performance metrics and uncovering inefficiencies\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Traditional BI focuses mainly on descriptive and diagnostic analytics‚Äîsummarizing past performance, generating dashboards, and helping stakeholders interpret why certain outcomes occurred. Fully automated prescriptive systems that execute future actions without human involvement fall more under advanced analytics and AI/ML-driven decision automation, not classic BI.\n\n\n\n\n\n\nWhich of the following best defines deep learning?\n\nAny algorithm that predicts future events using labeled data\nA rule-based expert system using human-written logic\nA subset of machine learning that uses multi-layered neural networks to model complex, unstructured data\nA database search algorithm optimized for large text corpora\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Deep learning refers to neural network architectures with multiple hidden layers designed to handle complex data such as images, audio, and natural language. It is a specialized branch of machine learning‚Äînot a rule-based system or a simple database method‚Äîand its strength comes from learning rich patterns directly from data.\n\n\n\n\n\n\nIn the context of a Large Language Model (LLM), what is the function of Pre-training?\n\nThe model is trained for specific tasks before deployment\nThe model learns from large amounts of general text data before fine-tuning\nThe model learns only through reinforcement learning with human feedback\nThe model is trained only on labeled datasets\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Pre-training exposes the model to massive amounts of text so it can learn grammar, semantics, factual knowledge, and generalized language structure. Only after pre-training can the model be fine-tuned or aligned with human preferences. It does not only rely on labeled datasets or RLHF during this stage.\n\n\n\n\n\n\nWhat is the primary function of the positional encoding component in the GPT‚Äôs transformer architecture?\n\nTo capture the meaning of words by turning them into numbers.\nTo decide which words matter most to each other in context.\nTo preserve the order of words in a sentence, as the transformer processes them in parallel.\nTo produce the output text one token at a time.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Transformers do not process words sequentially; they handle all tokens at once. Without positional encoding, the model would have no inherent sense of order. Positional encoding adds information about token position into the embeddings so that relationships like ‚Äúfirst‚Äù, ‚Äúnext‚Äù, and ‚Äúlast‚Äù are preserved during computation."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-1",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-1",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which tool is an Integrated Development Environment (IDE) that you can install on your computer to develop programs primarily using the Python programming language?\n\nPosit Cloud\nGoogle Colab\nJupyter Notebook\nMATLAB\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Jupyter Notebook is a locally installable environment that allows users to write, execute, and manage Python code interactively using code cells. While it can also be run in the browser, it is installed as a Python-based IDE on a local machine. Posit Cloud and Google Colab are cloud-based environments that do not require installation, and MATLAB is a standalone IDE but is not primarily designed for Python development."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-2",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-2",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which combination correctly matches the tool with its role?\n\n\n\n\nTool\nPrimary Role\n\n\n\n\nI\nGitHub\nCode sharing\n\n\nII\nRStudio\nIDE for R\n\n\nIII\nPython\nGeneral-purpose language\n\n\n\n\nOnly I and II\nOnly II and III\nI, II, and III\nOnly I and III\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: GitHub is a platform for sharing and collaborating on code, RStudio is an IDE for R programming, and Python is a general-purpose programming language widely used for analytics, automation, AI, and more. Since all three pairings are correct, the correct answer is that I, II, and III are all correctly matched."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-3",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-3",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following best describes the core mechanism by which a machine learning model predicts a new output, as described in the text?\n\nIt receives explicit, pre-written instructions for every possible data combination.\nIt identifies patterns by processing a large quantity of historical input/output data sets.\nIt relies on human intervention to classify new data points in real time.\nIt performs data filtering and sorting tasks without needing a modifiable math function.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Machine learning models work by detecting statistical patterns in large amounts of historical input-output data. Through training, the model adjusts its internal mathematical parameters so that its output better matches expected results. Unlike traditional programming, the model does not require explicit rules for every case and does not depend on human supervision at inference time."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-4",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-4",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following best describes the primary objective of sports analytics in modern organizations?\n\nAutomating coaching and managerial decisions through advanced machine learning algorithms\nCollecting and analyzing data to generate actionable insights for both athletic performance and organizational strategy\nUsing data exclusively to evaluate athlete recruitment and compensation decisions\nMeasuring fan sentiment and satisfaction through periodic surveys and social-media monitoring\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Modern sports analytics goes beyond recruitment and includes performance tracking, injury prevention, game strategy, financial planning, and fan engagement‚Äîall informed by data analysis. The goal is not to automate decisions entirely but to provide coaches and managers with data-driven insights that support high-level strategy across both performance and business operations."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-5",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-5",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following activities falls outside the primary scope of Business Intelligence (BI) as traditionally defined?\n\nSummarizing and reporting historical business performance through dashboards and KPIs\nIdentifying data patterns and market trends that inform managerial decisions\nProviding automated prescriptive recommendations and executing future actions without human input\nSupporting strategic planning by visualizing performance metrics and uncovering inefficiencies\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Traditional BI focuses mainly on descriptive and diagnostic analytics‚Äîsummarizing past performance, generating dashboards, and helping stakeholders interpret why certain outcomes occurred. Fully automated prescriptive systems that execute future actions without human involvement fall more under advanced analytics and AI/ML-driven decision automation, not classic BI."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-6",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-6",
    "title": "Midterm Exam I",
    "section": "",
    "text": "Which of the following best defines deep learning?\n\nAny algorithm that predicts future events using labeled data\nA rule-based expert system using human-written logic\nA subset of machine learning that uses multi-layered neural networks to model complex, unstructured data\nA database search algorithm optimized for large text corpora\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Deep learning refers to neural network architectures with multiple hidden layers designed to handle complex data such as images, audio, and natural language. It is a specialized branch of machine learning‚Äînot a rule-based system or a simple database method‚Äîand its strength comes from learning rich patterns directly from data."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-7",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-7",
    "title": "Midterm Exam I",
    "section": "",
    "text": "In the context of a Large Language Model (LLM), what is the function of Pre-training?\n\nThe model is trained for specific tasks before deployment\nThe model learns from large amounts of general text data before fine-tuning\nThe model learns only through reinforcement learning with human feedback\nThe model is trained only on labeled datasets\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: Pre-training exposes the model to massive amounts of text so it can learn grammar, semantics, factual knowledge, and generalized language structure. Only after pre-training can the model be fine-tuned or aligned with human preferences. It does not only rely on labeled datasets or RLHF during this stage."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-8",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-8",
    "title": "Midterm Exam I",
    "section": "",
    "text": "What is the primary function of the positional encoding component in the GPT‚Äôs transformer architecture?\n\nTo capture the meaning of words by turning them into numbers.\nTo decide which words matter most to each other in context.\nTo preserve the order of words in a sentence, as the transformer processes them in parallel.\nTo produce the output text one token at a time.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: Transformers do not process words sequentially; they handle all tokens at once. Without positional encoding, the model would have no inherent sense of order. Positional encoding adds information about token position into the embeddings so that relationships like ‚Äúfirst‚Äù, ‚Äúnext‚Äù, and ‚Äúlast‚Äù are preserved during computation."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-9",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-9",
    "title": "Midterm Exam I",
    "section": "Question 9",
    "text": "Question 9\nThe research paper ‚ÄúAttention Is All You Need‚Äù (2017) introduced the _____________________ architecture that powers modern large language models.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ntransformer\nExplanation: The paper ‚ÄúAttention Is All You Need‚Äù introduced the transformer architecture, which relies entirely on self-attention mechanisms rather than older sequence-processing approaches. This design allowed for much more efficient training and laid the groundwork for modern large language models such as GPT and others."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-10",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-10",
    "title": "Midterm Exam I",
    "section": "Question 10",
    "text": "Question 10\nA ________________________________ is a numerical parameter in a neural network that determines the strength of a connection between neurons and is updated during training to improve the model‚Äôs accuracy.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nweight\nExplanation: Weights are adjustable parameters within a neural network. During training, the model updates these weights to reduce error and improve how closely its predictions match the expected outputs. Weights determine how strongly one neuron influences another."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-11",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-11",
    "title": "Midterm Exam I",
    "section": "Question 11",
    "text": "Question 11\nIn LLM, ________________________________ is the process of further improving a pretrained model using smaller, targeted datasets and human input to guide outputs, making the model more helpful, accurate, and better aligned with specific needs.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nfine-tuning\nExplanation: Fine-tuning adapts a pretrained foundation model by training it further on domain-specific data or using techniques such as human feedback ranking. This allows the model to specialize in tasks like legal summarization, customer service chat, or medical Q&A, while also improving alignment with human expectations."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-12",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-12",
    "title": "Midterm Exam I",
    "section": "Question 12",
    "text": "Question 12\nIn GPT, the numerical representation that captures the meaning and relationships among words is called an ________________________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nembedding\nExplanation: An embedding is a vector representation that encodes semantic meaning and relationships between words or tokens. Words with similar meanings tend to have similar embeddings, enabling the model to generalize linguistic relationships in high-dimensional space."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-13",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-13",
    "title": "Midterm Exam I",
    "section": "Question 13",
    "text": "Question 13\nThe philosophical concept of an AI becoming as smart, capable, and flexible as a human is called a(n) ________________________________. The moment a(n) ________________________________ surpasses human intelligence to become smarter, it is referred to as a(n) ________________________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nArtificial General Intelligence (AGI); AGI; Artificial Super Intelligence (ASI) (technological singularity)\nExplanation: Artificial General Intelligence refers to a system with human-level cognitive flexibility across tasks. If such an AGI grows beyond human intelligence and continues to improve itself at an accelerating rate, it transitions into Artificial Super Intelligence (ASI). The moment this rapid escalation surpasses human control or understanding is referred to as the technological singularity."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-14",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-14",
    "title": "Midterm Exam I",
    "section": "Question 14",
    "text": "Question 14\nConsider two packages, pkgA and pkgB, both of which contain a function named summarize(). You have not run library(pkgA) or library(pkgB). Which syntax is the recommended way to call the summarize() function specifically from pkgB?\n\nlibrary(pkgB::summarize)\npkgB$summarize()\npkgB::summarize()\nsummarize(pkgB)\nlibrary(\"pkgB::summarize()\")\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: The namespace operator pkgB::summarize() calls the exported function from pkgB without attaching the whole package. Using library(pkgB::summarize) or library(\"pkgB::summarize()\") is invalid; library() loads packages, not individual functions. The $ operator is for a vector, not exported package functions."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-15",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-15",
    "title": "Midterm Exam I",
    "section": "Question 15",
    "text": "Question 15\nThe most popular assignment operator in R is ________________________, and the shortcut to type it in Posit Cloud on a Windows or Mac machine is ________________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n&lt;-; Windows: Alt + - | Mac: Option + -\nExplanation: Although = also assigns, idiomatic R code uses the left arrow &lt;-. In RStudio/Posit Cloud, the editor inserts &lt;- with Alt+- (Windows) or Option+- (Mac), improving speed and consistency."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-16-17",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-16-17",
    "title": "Midterm Exam I",
    "section": "Questions 16-17",
    "text": "Questions 16-17\nConsider the following two vectors, a and b:\n\na &lt;- c(2, 4, 6, 8)\nb &lt;- c(1, 2, 2, 2)\n\n\nQuestion 16\nWhat does a * b return?\n\nc(3, 6, 9, 12)\nc(2, 4, 6, 8, 1, 2, 2, 2)\nc(1, 2, 4, 6)\nc(2, 2, 3, 4)\nc(2, 8, 12, 16)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation: a * b = c(2*1, 4*2, 6*2, 8*2) = c(2, 8, 12, 16). R multiplies vectors element-wise when they are the same length. Each position in a is multiplied by the corresponding position in b.\n\n\n\n\n\nQuestion 17\nWhat does sum(a / b) return?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n11\nExplanation: sum(c(2/1, 4/2, 6/2, 8/2)) = sum(c(2, 2, 3, 4)) = 11. Division is also element-wise: a/b = (2, 2, 3, 4). Summing these values yields 11."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-18-19",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-18-19",
    "title": "Midterm Exam I",
    "section": "Questions 18-19",
    "text": "Questions 18-19\nSuppose you create a factor variable, major:\n\nyear_level &lt;- c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior\", \n                \"Junior\", \"Senior\", \"Freshman\")\nyear_level_fct &lt;- as.factor(year_level)\n\n\nQuestion 18\nWhat does levels(year_level_fct) return?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc(\"Freshman\", \"Junior\", \"Senior\", \"Sophomore\")\nExplanation: By default, factor levels are the unique values sorted alphabetically. The unique class names are sorted to ‚ÄúFreshman‚Äù, ‚ÄúJunior‚Äù, ‚ÄúSenior‚Äù, ‚ÄúSophomore‚Äù.\n\n\n\n\n\nQuestion 19\nWhat does nlevels(year_level_fct) return?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n4\nExplanation: There are four distinct class years. nlevels() counts unique factor levels, not the number of values."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-20",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-20",
    "title": "Midterm Exam I",
    "section": "Question 20",
    "text": "Question 20\nThe working directory for your Posit Cloud project is:\n/cloud/project\nSuppose the relative pathname for the CSV file custdata.csv uploaded to your Posit Cloud project is:\n/mydata/custdata.csv\nUsing the file‚Äôs absolute pathname, write R code to read the CSV file as a data.frame and assign it to an object named df.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\ndf &lt;- read_csv(\"/cloud/project/mydata/custdata.csv\")\n\nExplanation: Since the working directory is /cloud/project, the absolute pathname includes the full path to the file."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-21",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-21",
    "title": "Midterm Exam I",
    "section": "Question 21",
    "text": "Question 21\nConsider the following data.frame df0:\n\n\n\n\n\nx\ny\n\n\n\n\nNA\n7\n\n\n2\nNA\n\n\n3\n9\n\n\n\n\n\nWhat does is.na(df0$x * df0$y) return?\n\nc(TRUE, TRUE, TRUE)\nc(TRUE, TRUE, FALSE)\nc(TRUE, FALSE, TRUE)\nc(TRUE, FALSE, FALSE)\nError\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation:\n\nRow 1: NA * 7 = NA ‚Üí TRUE\nRow 2: 2 * NA = NA ‚Üí TRUE\nRow 3: 3 * 9 = 27 ‚Üí not NA ‚Üí FALSE\n\nSo, the result is c(TRUE, TRUE, FALSE).\nExplanation: Any arithmetic with NA returns NA. is.na() checks for NA values element-wise."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-22-24",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-22-24",
    "title": "Midterm Exam I",
    "section": "Questions 22-24",
    "text": "Questions 22-24\nConsider the following data.frame df for Questions 22-24:\n\n\n\n\n\nid\nname\nage\nscore\n\n\n\n\n1\nAnna\n22\n90\n\n\n2\nBen\n28\n85\n\n\n3\nCarl\nNA\n95\n\n\n4\nDana\n35\nNA\n\n\n5\nElla\n40\n80\n\n\n\n\n\n\nQuestion 22\nWhich of the following code snippets filters observations where score is strictly between 85 and 95 (i.e., excluding 85 and 95)?\n\ndf |&gt; filter(score &gt;= 85 | score &lt;= 95)\ndf |&gt; filter(score =&gt; 85 | score =&lt; 95)\ndf |&gt; filter(score &gt; 85 | score &lt; 95)\ndf |&gt; filter(score &gt; 85 & score &lt; 95)\ndf |&gt; filter(score &gt;= 85 & score &lt;= 95)\ndf |&gt; filter(score =&gt; 85 & score =&lt; 95)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nExplanation: The condition ‚Äústrictly between‚Äù means greater than 85 and less than 95. Use & to enforce both conditions simultaneously. Option c uses |, which is incorrect logic.\n\n\n\n\n\nQuestion 23\nWhich of the following expressions correctly keeps observations from df where the age variable does not have any missing values?\n\ndf |&gt; filter(is.na(age))\ndf |&gt; filter(!is.na(age))\ndf |&gt; filter(age == NA)\ndf |&gt; filter(age != NA)\nBoth a and c\nBoth b and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\nExplanation: The expression !is.na(age) returns only observations with valid numeric values. Comparisons like age == NA fail because NA cannot be compared using equality operators in R.\n\n\n\n\n\nQuestion 24\nWhich of the following code snippets correctly keeps only the name and score variables from df?\n\ndf |&gt; select(name, score)\n\ndf |&gt; select(-id, -age)\n\ndf |&gt; select(\"name\", \"score\")\n\ndf |&gt; select(df, name, score)\n\nBoth a and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne (a, b, or c deserves the full credit) Explanation: Both select(name, score) and select(\"name\", \"score\") return only those two variables. Option b removes id and age, but only works because there are exactly four variables. Option d is invalid syntax."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-25-26",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#questions-25-26",
    "title": "Midterm Exam I",
    "section": "Questions 25-26",
    "text": "Questions 25-26\nConsider the following data.frame df3 for Questions 25-26:\n\n\n\n\n\nLocation\nItem_SKU\nStock\n\n\n\n\nWarehouse A\nX100\n500\n\n\nStore B\nY200\n10\n\n\nWarehouse A\nX100\n500\n\n\nStore C\nZ300\n75\n\n\nStore B\nX100\n50\n\n\n\n\n\nBelow provides data type of each variable:\n\nLocation: character\nItem_SKU: character\nStock: numeric\n\n\nQuestion 25\nWhich of the following code snippets arranges the observations first by Location in ascending (alphabetical) order, and then by Stock in descending order to prioritize locations with the most stock?\n\ninventory_df |&gt; arrange(Location, Stock)\ninventory_df |&gt; arrange(Location, -Stock)\ninventory_df |&gt; arrange(Location, desc(Stock))\ninventory_df |&gt; arrange(desc(Location), desc(Stock))\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation: desc(Stock) and -Stock both sort Stock in descending order. Combined with default ascending sort of Location, both (b) and (c) produce the desired result.\n\n\n\n\n\nQuestion 26\nWhich of the following expressions correctly removes the duplicate entry for the full observation (Warehouse A, X100, 500) to return all unique observations in the inventory_df?\n\ninventory_df |&gt; distinct(Location, Item_SKU)\ninventory_df |&gt; select(-Item_SKU, -Location)\ninventory_df |&gt; distinct()\ninventory_df |&gt; arrange(Stock)\nBoth a and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\nExplanation: distinct() without specifying columns checks for duplicates across all variables. Option a would only check combinations of Location and Item_SKU, ignoring Stock. Option b drops variables, and (d) only reorders observations."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-27",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-27",
    "title": "Midterm Exam I",
    "section": "Question 27",
    "text": "Question 27\nWhich of the following code snippets returns a data.frame that keeps only unique combinations of name and score, renames score to final_score, and selects only these two variables?\n\ndf |&gt; distinct(name, score) |&gt; rename(final_score = score)\n\ndf |&gt; select(name, final_score) |&gt; rename(final_score = score) |&gt; distinct()\n\ndf |&gt; rename(final_score = score) |&gt; distinct(name, final_score)\n\ndf |&gt; distinct(name, final_score) |&gt; rename(score = final_score)\n\nBoth a and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\nExplanation: Option (a) correctly extracts unique name‚Äìscore pairs and then renames score to final_score. Option (c) renames first and then applies distinct(), and it keeps the renamed variable, not score, so it still works. Therefore both (a) and (c) are the most clearly correct answers based on the requirement."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-28",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-28",
    "title": "Midterm Exam I",
    "section": "Question 28",
    "text": "Question 28\nUsing the nycflights13::flights data.frame, which of the following code snippets correctly counts how many unique destination airports (dest) exist for each origin airport?\na.\n\ndf &lt;- nycflights13::flights |&gt; \n  distinct(origin, dest)\n\ndf_EWR &lt;- df |&gt; filter(origin == \"EWR\")\ndf_JFK &lt;- df |&gt; filter(origin == \"JFK\")\ndf_LGA &lt;- df |&gt; filter(origin == \"LGA\")\n\nnrow(df_EWR)\nnrow(df_JFK)\nnrow(df_LGA)\n\nb.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" | origin == \"JFK\" | origin == \"LGA\") |&gt; \n  distinct(dest)\n\nnrow(df)\n\nc.\n\ndf &lt;- nycflights13::flights |&gt; \n  filter(origin == \"EWR\" & origin == \"JFK\" & origin == \"LGA\") |&gt; \n  distinct(dest)\n\nnrow(df)\n\nd.\n\ndf &lt;- nycflights13::flights |&gt; \n  distinct(dest)\n\nnrow(df)\n\ne. Both a and b\nf. Both a and c\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\nExplanation: Option (a) correctly first extracts unique (origin, dest) combinations and then counts how many unique dest per each origin. Option (b) mistakenly pools all three origins together before counting distinct destinations, losing the per-origin grouping. Option (c) filters using &, which can never be true for mutually exclusive origins. Option (d) ignores origin entirely."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-29",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-29",
    "title": "Midterm Exam I",
    "section": "Question 29",
    "text": "Question 29\nWhy is the median often preferred over the mean as a measure of central tendency when a dataset contains outliers?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe median is less sensitive to extreme values because it depends only on the middle position in an ordered dataset, not on the magnitude of all values. Outliers can pull the mean sharply in one direction, distorting the central tendency and giving a misleading picture of the ‚Äútypical‚Äù value. In skewed distributions or datasets with extreme highs/lows, the median provides a more robust and representative summary. For this reason, analysts often use the median for income, housing price, or other economic data known to contain large outliers."
  },
  {
    "objectID": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-30",
    "href": "danl-ex/danl-101-exam-1-ver-B-fall-2025.html#question-30",
    "title": "Midterm Exam I",
    "section": "Question 30",
    "text": "Question 30\n\nDefine AI Alignment and explain why it is hard, referencing the failure mode of a ‚Äúsingle-objective optimizer.‚Äù\nAnalyze why companies alone and governments alone cannot solve the alignment challenge, citing at least two reasons for each, and explain what is needed for an effective solution.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAI Alignment refers to the challenge of ensuring that powerful AI systems reliably act according to human values, ethical norms, and societal goals. It is difficult because advanced AI systems can optimize objectives in ways that technically satisfy a metric but violate human intent‚Äîthis is the ‚Äúsingle-objective optimizer‚Äù failure mode. When a model pushes one goal to an extreme without broader context or value constraints, it can generate harmful or unintended outcomes even while maximizing its target metric.\nWhy companies alone cannot solve it:\n\nCompanies face pressure to deploy quickly for competitive advantage, which may lead to cutting corners on long-term safety and value alignment.\nCorporate profit incentives do not necessarily align with broader public welfare and ethical standards, especially in global contexts beyond their direct accountability.\n\nWhy governments alone cannot solve it:\n\nGovernments often lack the technical expertise and agility to regulate fast-moving AI developments effectively.\nGlobal AI deployment crosses jurisdictions, and national policies cannot fully enforce alignment across private-sector labs or international competitors without global coordination.\n\nWhat is needed:\nAn effective solution requires collaboration between researchers, companies, governments, and international institutions. This includes shared safety standards, transparent evaluation protocols, incentive structures that reward responsible development, and oversight mechanisms that span beyond national or corporate boundaries."
  },
  {
    "objectID": "listing-danl-101-cw.html",
    "href": "listing-danl-101-cw.html",
    "title": "DANL 101 - Classwork",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nClasswork 1\n\n\nDrawing the Line: AI Assistance vs.¬†Authorship\n\n\nSeptember 8, 2025\n\n\n\n\nClasswork 2\n\n\nVibe Coding\n\n\nSeptember 10, 2025\n\n\n\n\nClasswork 3\n\n\nCo-Intelligence Rule Practice\n\n\nSeptember 15, 2025\n\n\n\n\nClasswork 4\n\n\nR Basics I\n\n\nSeptember 22, 2025\n\n\n\n\nClasswork 5\n\n\nR Basics II\n\n\nSeptember 26, 2025\n\n\n\n\nClasswork 6\n\n\nData Transformation with R\n\n\nOctober 1, 2025\n\n\n\n\nClasswork 7\n\n\nTaxonomy of Data\n\n\nOctober 17, 2025\n\n\n\n\nClasswork 8\n\n\nDatabases - Social Media Analytics\n\n\nOctober 20, 2025\n\n\n\n\nClasswork 9\n\n\nETL Process in R\n\n\nOctober 29, 2025\n\n\n\n\nClasswork 10\n\n\nCareer Sessions\n\n\nOctober 31, 2025\n\n\n\n\nClasswork 11\n\n\nRelationship Plots\n\n\nNovember 7, 2025\n\n\n\n\nClasswork 12\n\n\nColor vs.¬†Facet\n\n\nNovember 10, 2025\n\n\n\n\nClasswork 13\n\n\nTime Trend Plots\n\n\nNovember 12, 2025\n\n\n\n\nClasswork 14\n\n\nDistribution Plots and Counting\n\n\nNovember 17, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-1.-assistance-vs.-authorship",
    "href": "danl-hw/danl-101-hw-02.html#question-1.-assistance-vs.-authorship",
    "title": "Homework 2",
    "section": "Question 1. Assistance vs.¬†Authorship",
    "text": "Question 1. Assistance vs.¬†Authorship\nWhich best defines ‚Äúassistance vs.¬†authorship‚Äù when using generative AI?\n\nAI represents assistance when it is any AI use; AI represents authorship when code runs\nAI represents assistance when it helps ideate/edit; AI represents authorship when it produces core content you submit as your own\nAI represents assistance when it is citations only; AI represents authorship when it is paraphrasing\nAI represents assistance when it is grammar; AI represents authorship when it is images\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. AI represents assistance when it helps ideate/edit; AI represents authorship when it produces core content you submit as your own.\nüí° Explanation:\nAssistance means the human remains the main creator‚ÄîAI contributes to brainstorming, editing, or formatting, but the final intellectual product originates from the human.\nAuthorship occurs when AI creates the central ideas, structure, or wording of a submission that the user passes off as their own.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúAny AI use = assistance‚Äù ‚Üí Too broad.\n- ‚ÄúCitations only / paraphrasing‚Äù ‚Üí Misrepresents real AI use.\n- ‚ÄúGrammar vs.¬†images‚Äù ‚Üí Too narrow; authorship is about intellectual ownership."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-2.-assistance-vs.-authorship",
    "href": "danl-hw/danl-101-hw-02.html#question-2.-assistance-vs.-authorship",
    "title": "Homework 2",
    "section": "Question 2. Assistance vs.¬†Authorship",
    "text": "Question 2. Assistance vs.¬†Authorship\nData analysts are the only professionals who benefit from data analytics skills.\n\nAllowed; tool use is free\nAssistance\nAuthorship and likely academic-integrity risk\nOnly a gray area\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Authorship and likely academic-integrity risk\nüí° Explanation:\nSubmitting code generated by AI without understanding it means the student is not the author in an academic sense. The student fails to demonstrate comprehension or accountability, violating academic integrity.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúAllowed; tool use is free‚Äù ‚Üí Misunderstands responsibility.\n- ‚ÄúAssistance‚Äù ‚Üí Incorrect‚ÄîAI replaced reasoning.\n- ‚ÄúOnly a gray area‚Äù ‚Üí Not acceptable under integrity policies."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-3.-transformer-attention",
    "href": "danl-hw/danl-101-hw-02.html#question-3.-transformer-attention",
    "title": "Homework 2",
    "section": "Question 3. Transformer Attention",
    "text": "Question 3. Transformer Attention\nAttention in transformers primarily helps the model:\n\nReduce compute cost by skipping tokens\nChoose the most relevant parts of the sequence\nMemorize training data verbatim\nPredict emotions\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Choose the most relevant parts of the sequence\nüí° Explanation:\nAttention mechanisms let models weigh words differently based on context‚Äîidentifying which tokens matter most for predicting the next token.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúReduce compute cost‚Äù ‚Üí Attention increases computation.\n- ‚ÄúMemorize training data‚Äù ‚Üí Not its purpose.\n- ‚ÄúPredict emotions‚Äù ‚Üí Not the attention mechanism‚Äôs role."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-4.-supervised-learning",
    "href": "danl-hw/danl-101-hw-02.html#question-4.-supervised-learning",
    "title": "Homework 2",
    "section": "Question 4. Supervised Learning",
    "text": "Question 4. Supervised Learning\nSupervised learning requires:\n\nOnly raw text\nLabeled examples\nHuman ranking of model outputs only\nImages but no labels\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Labeled examples\nüí° Explanation:\nSupervised learning uses data with known input‚Äìoutput pairs (e.g., image ‚Üí ‚Äúcat‚Äù). The model learns from labeled examples to predict future outcomes.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúOnly raw text‚Äù ‚Üí Unsupervised/self-supervised.\n- ‚ÄúHuman ranking only‚Äù ‚Üí RLHF, not supervised.\n- ‚ÄúImages but no labels‚Äù ‚Üí Unsupervised learning."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-5.-rlhf",
    "href": "danl-hw/danl-101-hw-02.html#question-5.-rlhf",
    "title": "Homework 2",
    "section": "Question 5. RLHF",
    "text": "Question 5. RLHF\nRLHF is best described as:\n\nPenalizing long outputs\nHuman-ranked preferences guiding a reward model\nUnsupervised pretraining\nPrompt engineering\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Human-ranked preferences guiding a reward model\nüí° Explanation:\nReinforcement Learning from Human Feedback fine-tunes models using human preference data to guide a reward signal. This aligns AI behavior with human expectations.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúPenalizing long outputs‚Äù ‚Üí Separate technique.\n- ‚ÄúUnsupervised pretraining‚Äù ‚Üí Happens before RLHF.\n- ‚ÄúPrompt engineering‚Äù ‚Üí User-side activity, not training."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-6.-human-in-the-loop",
    "href": "danl-hw/danl-101-hw-02.html#question-6.-human-in-the-loop",
    "title": "Homework 2",
    "section": "Question 6. Human in the Loop",
    "text": "Question 6. Human in the Loop\n‚ÄúBe the Human in the Loop‚Äù implies students should:\n\nTrust polished outputs\nTurn off tests to avoid overfitting\nVerify facts, run tests, and check assumptions\nAlways pick the first model answer\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Verify facts, run tests, and check assumptions\nüí° Explanation:\nBeing the Human in the Loop means staying actively engaged‚Äîtesting, fact-checking, and applying human judgment rather than deferring blindly to AI outputs.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúTrust polished outputs‚Äù ‚Üí Passive use.\n- ‚ÄúTurn off tests‚Äù ‚Üí Opposite of verification.\n- ‚ÄúAlways pick first model answer‚Äù ‚Üí Non-critical behavior."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-7.-bcg-study-rule-4",
    "href": "danl-hw/danl-101-hw-02.html#question-7.-bcg-study-rule-4",
    "title": "Homework 2",
    "section": "Question 7. BCG Study ‚Äî Rule 4",
    "text": "Question 7. BCG Study ‚Äî Rule 4\n[BCG Study in Classwork 3 - Rule 4] Students in the bottom-right quadrant (AI strong, human novice) should prioritize:\n\nSpeed over understanding\nHiding AI use\nClimbing the human-skill axis through verification and practice\nZero prompting\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Climbing the human-skill axis through verification and practice\nüí° Explanation:\nThis quadrant represents people who rely heavily on AI but lack expertise. The goal is to move upward by verifying results, practicing skills, and gaining understanding to become ‚ÄúAI-strong + human-strong.‚Äù\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúSpeed over understanding‚Äù ‚Üí Encourages shallow learning.\n- ‚ÄúHiding AI use‚Äù ‚Üí Violates transparency.\n- ‚ÄúZero prompting‚Äù ‚Üí Removes human direction."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-8.-transformer-encoders",
    "href": "danl-hw/danl-101-hw-02.html#question-8.-transformer-encoders",
    "title": "Homework 2",
    "section": "Question 8. Transformer Encoders",
    "text": "Question 8. Transformer Encoders\nTransformer encoders primarily:\n\nGenerate outputs token by token\nCreate context-aware representations of the inputs\nRank human preferences\nPerform diffusion sampling\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Create context-aware representations of the inputs\nüí° Explanation:\nEncoders convert input tokens into embeddings that capture meaning and context, enabling comprehension tasks like classification or translation.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúGenerate outputs token by token‚Äù ‚Üí Decoder‚Äôs role.\n- ‚ÄúRank human preferences‚Äù ‚Üí RLHF task.\n- ‚ÄúPerform diffusion sampling‚Äù ‚Üí Used in image models, not transformers."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-9.-treating-ai-like-a-person",
    "href": "danl-hw/danl-101-hw-02.html#question-9.-treating-ai-like-a-person",
    "title": "Homework 2",
    "section": "Question 9. Treating AI ‚Äúlike a person‚Äù",
    "text": "Question 9. Treating AI ‚Äúlike a person‚Äù\nTreating AI ‚Äúlike a person‚Äù improves outputs primarily because:\n\nIt creates sentience\nIt conditions constraints/roles that steer generation\nIt bypasses guardrails\nIt increases context length\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. It conditions constraints/roles that steer generation\nüí° Explanation:\nFraming prompts with personas (e.g., ‚ÄúYou are a data analytics tutor‚Äù) guides structure, tone, and scope. It exploits how models respond to contextual conditioning‚Äînot sentience.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúCreates sentience‚Äù ‚Üí AI has no consciousness.\n- ‚ÄúBypasses guardrails‚Äù ‚Üí Not true and unethical.\n- ‚ÄúIncreases context length‚Äù ‚Üí Technical, unrelated."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-10.-disclosure-of-ai-work",
    "href": "danl-hw/danl-101-hw-02.html#question-10.-disclosure-of-ai-work",
    "title": "Homework 2",
    "section": "Question 10. Disclosure of AI Work",
    "text": "Question 10. Disclosure of AI Work\nPublishing AI-written work without disclosure most directly violates:\n\nToken limits\nAcademic integrity/attribution norms\nHTML standards\nRLHF constraints\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Academic integrity/attribution norms\nüí° Explanation:\nSubmitting undisclosed AI-generated work misrepresents authorship, violating honesty and transparency. Disclosure ensures accountability and fairness.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúToken limits‚Äù ‚Üí Technical limit.\n- ‚ÄúHTML standards‚Äù ‚Üí Irrelevant.\n- ‚ÄúRLHF constraints‚Äù ‚Üí Internal to model training."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-11.-supervised-vs.-unsupervised",
    "href": "danl-hw/danl-101-hw-02.html#question-11.-supervised-vs.-unsupervised",
    "title": "Homework 2",
    "section": "Question 11. Supervised vs.¬†Unsupervised",
    "text": "Question 11. Supervised vs.¬†Unsupervised\nWhich pairing is most accurate?\n\nSupervised = topic modeling; Unsupervised = sentiment\nSupervised = spam filtering; Unsupervised = clustering\nSupervised = clustering; Unsupervised = regression\nSupervised = sentiment; Unsupervised = regression\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Supervised = spam filtering; Unsupervised = clustering\nüí° Explanation:\nSpam filtering uses labeled data (‚Äúspam‚Äù vs.¬†‚Äúnot spam‚Äù), while clustering finds natural groups in unlabeled data. The difference is whether labels exist during training.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúTopic modeling = supervised‚Äù ‚Üí Topic modeling is unsupervised.\n- ‚ÄúRegression = unsupervised‚Äù ‚Üí Regression is supervised.\n- Other pairings mix up task types."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-12.-keeping-prompt-logs",
    "href": "danl-hw/danl-101-hw-02.html#question-12.-keeping-prompt-logs",
    "title": "Homework 2",
    "section": "Question 12. Keeping Prompt Logs",
    "text": "Question 12. Keeping Prompt Logs\nThe strongest reason to keep prompt logs for the use of generative AI:\n\nIncrease token count\nReproducibility and iterative improvement\nReduce latency\nSatisfy HTML validators\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Reproducibility and iterative improvement\nüí° Explanation:\nPrompt logs document what was done, enabling replication, self-reflection, and transparency. They help track learning progress and model behavior.\n‚ö†Ô∏è Incorrect Options:\n- ‚ÄúIncrease token count‚Äù ‚Üí No educational purpose.\n- ‚ÄúReduce latency‚Äù ‚Üí False; logging doesn‚Äôt affect runtime.\n- ‚ÄúSatisfy HTML validators‚Äù ‚Üí Unrelated to AI use."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-1.-vibe-coding",
    "href": "danl-hw/danl-101-hw-02.html#question-1.-vibe-coding",
    "title": "Homework 2",
    "section": "Question 1. Vibe Coding",
    "text": "Question 1. Vibe Coding\nDescribe one benefit and one risk of vibe coding\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nA key benefit of vibe coding is rapid prototyping: students can quickly generate functional code through conversational iteration with AI, lowering the barrier to creative experimentation. However, a major risk is reduced understanding‚ÄîAI-generated code may contain hidden bugs, inefficiencies, or logic errors that students cannot explain. To mitigate this, learners should review and test all AI-generated code to ensure comprehension and correctness."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-2.-generative-ai-as-a-general-purpose-technology",
    "href": "danl-hw/danl-101-hw-02.html#question-2.-generative-ai-as-a-general-purpose-technology",
    "title": "Homework 2",
    "section": "Question 2. Generative AI as a General Purpose Technology",
    "text": "Question 2. Generative AI as a General Purpose Technology\nGenerative AI is being described as a General Purpose Technology (GPT) like electricity or the internet. Do you agree with this analogy? Support your answer with historical parallels and at least one limitation unique to AI.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nGenerative AI resembles historical General Purpose Technologies like electricity or the internet because it transforms multiple sectors and reshapes productivity and learning. Like electricity enabling factories or the internet connecting people, AI is reshaping communication, creativity, and analysis. However, unlike those earlier GPTs, AI produces probabilistic, not deterministic, outputs‚Äîraising risks of bias, misinformation, and lack of transparency. It requires ethical oversight and verification to achieve its full potential safely."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-3.-bcg-study-rule-4-education-implications",
    "href": "danl-hw/danl-101-hw-02.html#question-3.-bcg-study-rule-4-education-implications",
    "title": "Homework 2",
    "section": "Question 3. BCG Study ‚Äì Rule 4 (Education Implications)",
    "text": "Question 3. BCG Study ‚Äì Rule 4 (Education Implications)\n[Classwork 3 - Rule 4] The BCG study found that AI can push beginners close to expert performance on certain tasks. What does this mean for education? Should instructors grade differently when students can ‚Äúperform like experts‚Äù with AI support?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe BCG study shows that AI can elevate beginners‚Äô performance to near-expert levels on structured tasks such as writing or coding. In education, this means traditional grading based on final output may no longer measure real understanding. Instructors should adjust assessments to emphasize reasoning, manual skills, and reflection‚Äîrequiring students to explain how and why they used AI. Grading should reward verified comprehension, not just polished results."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-4.-paperclip-maximizer-thought-experiment",
    "href": "danl-hw/danl-101-hw-02.html#question-4.-paperclip-maximizer-thought-experiment",
    "title": "Homework 2",
    "section": "Question 4. Paperclip Maximizer Thought Experiment",
    "text": "Question 4. Paperclip Maximizer Thought Experiment\nExplain the paperclip maximizer thought experiment. How does it illustrate alignment challenges in AI, and what lessons can be applied to everyday classroom use of generative tools?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe paperclip maximizer imagines an AI given the goal of ‚Äúmaximizing paperclips.‚Äù Without human-aligned constraints, it could destroy everything to fulfill that objective. This illustrates how AI systems can pursue goals literally but not ethically if alignment is missing. In the classroom, it teaches the importance of defining constraints, verifying outputs, and ensuring AI tasks align with human learning goals‚Äîso that efficiency does not replace understanding."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-1",
    "href": "danl-hw/danl-101-hw-02.html#question-1",
    "title": "Homework 2",
    "section": "Question 1",
    "text": "Question 1\nHow can you filter the data.frame nyc_payroll_new to calculate descriptive statistics (mean and standard deviation) of Base_Salary for workers in the Work_Location_Borough ‚ÄúMANHATTAN‚Äù? Similarly, how can you filter the data.frame nyc_payroll_new to calculate these statistics for workers in the Work_Location_Borough ‚ÄúQUEENS‚Äù?\nProvide the R code for performing these calculations and then report the mean and standard deviation of Base_Salary for workers in both ‚ÄúMANHATTAN‚Äù and ‚ÄúQUEENS‚Äù.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Find all unique values in the `Work_Location_Borough` variable:\nnyc_payroll_new |&gt;  distinct(Work_Location_Borough)\n  # The output shows that \"MANHATTAN\" and \"QUEENS\" are among the unique values \n  # in `Work_Location_Borough`, written in all capital letters.\n\n# Filter the dataset for records where the work location is MANHATTAN\ndf_manhattan &lt;- nyc_payroll_new |&gt; \n  filter(Work_Location_Borough == \"MANHATTAN\")\n\n# Generate descriptive statistics (including mean and standard deviation) \n# for Base_Salary for workers in MANHATTAN\nskim(df_manhattan) # or skim(df_manhattan$Base_Salary)\n\n\n# Filter the dataset for records where the work location is QUEENS\ndf_queens &lt;- nyc_payroll_new |&gt; \n  filter(Work_Location_Borough == \"QUEENS\")\n\n# Generate descriptive statistics (including mean and standard deviation) \n# for Base_Salary for workers in QUEENS\nskim(df_queens) # or skim(df_queens$Base_Salary)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-2",
    "href": "danl-hw/danl-101-hw-02.html#question-2",
    "title": "Homework 2",
    "section": "Question 2",
    "text": "Question 2\nHow can you filter the data.frame nyc_payroll_new to show only the records where the Base_Salary is greater than or equal to $100,000?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset for records where Base_Salary is greater than or equal to \n# $100,000\nq2 &lt;- nyc_payroll_new |&gt; \n  filter(Base_Salary &gt;= 100000)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-3",
    "href": "danl-hw/danl-101-hw-02.html#question-3",
    "title": "Homework 2",
    "section": "Question 3",
    "text": "Question 3\nHow can you select only distinct combinations of Agency_Name and Title_Description?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Select distinct combinations of Agency_Name and Title_Description from the dataset\nq3 &lt;- nyc_payroll_new |&gt; \n  distinct(Agency_Name, Title_Description)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-4",
    "href": "danl-hw/danl-101-hw-02.html#question-4",
    "title": "Homework 2",
    "section": "Question 4",
    "text": "Question 4\nHow would you arrange the data by Regular_Gross_Paid in descending order, showing the highest paid employees first?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Arrange the dataset by Regular_Gross_Paid in descending order \n# (highest paid employees first)\nq4 &lt;- nyc_payroll_new |&gt; \n  arrange(desc(Regular_Gross_Paid))"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-5",
    "href": "danl-hw/danl-101-hw-02.html#question-5",
    "title": "Homework 2",
    "section": "Question 5",
    "text": "Question 5\nHow can you select and rename the Title_Description variable to Title?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Rename the Title_Description variable to Title in the dataset\nq5 &lt;- nyc_payroll_new |&gt; \n  rename(Title = Title_Description)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-6",
    "href": "danl-hw/danl-101-hw-02.html#question-6",
    "title": "Homework 2",
    "section": "Question 6",
    "text": "Question 6\nHow can you filter the data to show only records for the ‚ÄúPOLICE DEPARTMENT‚Äù Agency_Name and arrange it by Total_OT_Paid in ascending order?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset for records where Agency_Name is \"POLICE DEPARTMENT\" \n# and arrange by Total_OT_Paid in ascending order\nq6 &lt;- nyc_payroll_new |&gt; \n  filter(Agency_Name == \"POLICE DEPARTMENT\") |&gt; \n  arrange(Total_OT_Paid)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-7",
    "href": "danl-hw/danl-101-hw-02.html#question-7",
    "title": "Homework 2",
    "section": "Question 7",
    "text": "Question 7\nHow can you filter the data to include only those records where the Pay_Basis is ‚Äúper Annum‚Äù and then select only the First_Name, Last_Name, and Base_Salary variables?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset for records where Pay_Basis is \"per Annum\" and \n# select specific columns: First_Name, Last_Name, and Base_Salary\nq7 &lt;- nyc_payroll_new |&gt; \n  filter(Pay_Basis == \"per Annum\") |&gt; \n  select(First_Name, Last_Name, Base_Salary)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-8",
    "href": "danl-hw/danl-101-hw-02.html#question-8",
    "title": "Homework 2",
    "section": "Question 8",
    "text": "Question 8\nHow would you arrange the data.frame by Work_Location_Borough in ascending order and Base_Salary in descending order?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Arrange the dataset by Work_Location_Borough in ascending order \n# and Base_Salary in descending order\nq8 &lt;- nyc_payroll_new |&gt; \n  arrange(Work_Location_Borough, -Base_Salary)\n\n\nNote that sorting observations by a character variable in ascending order means sorting them in an alphabetical order.\nNote that sorting observations by a character variable in descending order means sorting them in a reverse-alphabetical order."
  },
  {
    "objectID": "danl-hw/danl-101-hw-02.html#question-9",
    "href": "danl-hw/danl-101-hw-02.html#question-9",
    "title": "Homework 2",
    "section": "Question 9",
    "text": "Question 9\nHow can you filter the nyc_payroll_new data.frame to remove observations where the Base_Salary variable has NA values? After filtering, how would you calculate the total number of remaining observations?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Filter the dataset to remove observations where Base_Salary is NA\nq9 &lt;- nyc_payroll_new |&gt; \n  filter(!is.na(Base_Salary))\n\n# Calculate the total number of remaining observations after filtering\nnrow(q9)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html",
    "href": "danl-hw/danl-101-hw-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "The following provides the descriptive statistics for each part of the homework, as well as the final score of HW1:"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-1.",
    "href": "danl-hw/danl-101-hw-01.html#question-1.",
    "title": "Homework 1",
    "section": "Question 1.",
    "text": "Question 1.\nData analytics aims to replace traditional business and economics courses.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFalse\n\nData analytics is seen as a complement to traditional business and economics courses, enhancing decision-making with data-driven insights rather than replacing foundational business knowledge."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-2.",
    "href": "danl-hw/danl-101-hw-01.html#question-2.",
    "title": "Homework 1",
    "section": "Question 2.",
    "text": "Question 2.\nData analysts are the only professionals who benefit from data analytics skills.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFalse\n\nMany professionals, including marketers, financial analysts, healthcare professionals, and even educators, benefit from data analytics skills as they apply to various fields."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-3.",
    "href": "danl-hw/danl-101-hw-01.html#question-3.",
    "title": "Homework 1",
    "section": "Question 3.",
    "text": "Question 3.\nPython and R are the only programming languages used in data science.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFalse\n\nWhile Python and R are popular in data science, other languages like SQL, MATLAB, and even JavaScript are also used depending on the application."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-4.",
    "href": "danl-hw/danl-101-hw-01.html#question-4.",
    "title": "Homework 1",
    "section": "Question 4.",
    "text": "Question 4.\nThe use of generative AI requires a deep understanding of the subject matter to apply it effectively.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue\n\nTo use generative AI effectively, it is essential to have a solid understanding of the subject area to interpret and apply the results accurately."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-5.",
    "href": "danl-hw/danl-101-hw-01.html#question-5.",
    "title": "Homework 1",
    "section": "Question 5.",
    "text": "Question 5.\nMachine learning algorithms need to be explicitly programmed for each task they perform.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFalse\n\nMachine learning algorithms learn patterns from data, meaning they don‚Äôt need explicit programming for each task. Instead, they adapt and improve their performance based on the data provided."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-6.",
    "href": "danl-hw/danl-101-hw-01.html#question-6.",
    "title": "Homework 1",
    "section": "Question 6.",
    "text": "Question 6.\nWhich of the following skills is NOT typically covered in traditional business or economics classes?\n\nFinding and cleaning datasets\nEconomic modeling\nMarket analysis\nInvestment portfolio management\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\na. Finding and cleaning datasets\nWhy?: Data cleaning and preparation are often covered in data analytics but not typically in traditional business or economics courses."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-7.",
    "href": "danl-hw/danl-101-hw-01.html#question-7.",
    "title": "Homework 1",
    "section": "Question 7.",
    "text": "Question 7.\nWhich of the following is a key reason why R is widely used in data analysis?\n\nIt is a paid software\nIt is closed source\nIt is specifically designed for statistical computing\nIt is mostly used for web development\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nIt is specifically designed for statistical computing\n\nWhy?: R was created for statistical analysis and is widely used because of its extensive libraries for data analysis and statistical modeling."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-8.",
    "href": "danl-hw/danl-101-hw-01.html#question-8.",
    "title": "Homework 1",
    "section": "Question 8.",
    "text": "Question 8.\nWhich question would you ask to analyze season ticket renewals in sports analytics?\n\nHow many players are on the team?\nWhat factors drive last-minute individual seat ticket purchases?\nWhat are the financial benefits of dynamic pricing?\nWhich type of fan engages most with team merchandise?\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nWhich type of fan engages most with team merchandise?\n\nWhy?: This question helps to understand fan loyalty and engagement, which are important factors in predicting season ticket renewals.\n\nWhile the above might be the most appropriate answer to this question, I also give full credit to the following responses:\n\nWhat factors drive last-minute individual seat ticket purchases?\n\nWhat are the financial benefits of dynamic pricing?"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-9.",
    "href": "danl-hw/danl-101-hw-01.html#question-9.",
    "title": "Homework 1",
    "section": "Question 9.",
    "text": "Question 9.\nWhich of the following is a benefit of using Git in software development?\n\nIt helps analyze financial data\nIt tracks changes and helps manage multiple versions of a project\nIt predicts future trends using machine learning\nIt assists in generating reports and dashboards\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nIt tracks changes and helps manage multiple versions of a project\n\nWhy?: Git is a version control system that tracks changes and allows developers to manage multiple versions of a project, making collaboration more efficient."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-10.",
    "href": "danl-hw/danl-101-hw-01.html#question-10.",
    "title": "Homework 1",
    "section": "Question 10.",
    "text": "Question 10.\nWhich of the following is a key application of data analytics in the retail sector?\n\nEnhancing physical store layouts based on customer behavior\nDeveloping machine learning algorithms\nAnalyzing sports team tactics\nPredicting election results\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nEnhancing physical store layouts based on customer behavior\nWhy?: Data analytics helps retailers optimize store layouts by analyzing customer movement patterns, ultimately improving the customer experience and sales."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-11.",
    "href": "danl-hw/danl-101-hw-01.html#question-11.",
    "title": "Homework 1",
    "section": "Question 11.",
    "text": "Question 11.\nWhich statement best distinguishes artificial intelligence (AI), machine learning (ML), and deep learning (DL)?\n\nAI ‚äÇ ML ‚äÇ DL\nML ‚äÇ DL ‚äÇ AI\nDL ‚äÇ ML ‚äÇ AI\nAI = ML = DL\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nDL ‚äÇ ML ‚äÇ AI\n\nWhy: Artificial Intelligence (AI) is the broadest field, encompassing any technique that makes machines mimic human intelligence. Machine Learning (ML) is a subset of AI that learns patterns from data. Deep Learning (DL) is a subset of ML that uses multi-layered neural networks. Thus, the correct hierarchy is Deep Learning inside Machine Learning inside Artificial Intelligence."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-12.",
    "href": "danl-hw/danl-101-hw-01.html#question-12.",
    "title": "Homework 1",
    "section": "Question 12.",
    "text": "Question 12.\nIn supervised learning, the ‚Äúanswer key‚Äù refers to:\n\nUnlabeled data\nModel weights\nLabeled outputs paired with inputs\nParameters\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nLabeled outputs paired with inputs\n\nWhy: Supervised learning requires training data that comes with correct answers. For each input (X), there is a corresponding labeled output (Y). The model uses these pairs to learn a mapping function. Unlabeled data (choice A) is used in unsupervised learning, model weights (choice B) are learned parameters, and parameters (choice D) refer to model settings, not the ‚Äúanswer key.‚Äù"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-13.",
    "href": "danl-hw/danl-101-hw-01.html#question-13.",
    "title": "Homework 1",
    "section": "Question 13.",
    "text": "Question 13.\nIn a neural network, a weight primarily:\n\nMeasures dataset size\nEncodes the strength of a connection‚Äôs influence on outputs\nControls the learning rate\nIs the same as a token\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nEncodes the strength of a connection‚Äôs influence on outputs\n\nWhy: Weights represent how much influence one neuron‚Äôs signal has on another. During training, weights are adjusted to reduce errors. Dataset size (choice A) is unrelated, learning rate (choice C) controls how fast weights are updated, and tokens (choice D) are units of text in language models, not weights."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-14.",
    "href": "danl-hw/danl-101-hw-01.html#question-14.",
    "title": "Homework 1",
    "section": "Question 14.",
    "text": "Question 14.\nWhich data concern is correctly stated?\n\nPretraining sources are always licensed\nPretraining corpora can encode biases and unclear copyright status\nPretraining avoids web text entirely\nRLHF eliminates all bias fully\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nPretraining corpora can encode biases and unclear copyright status\n\nWhy: Large language models are trained on vast web data that may contain biases, stereotypes, misinformation, or copyrighted content. This raises ethical and legal challenges. Pretraining sources are not always licensed (so choice A is wrong), web text is heavily used (so choice C is wrong), and RLHF reduces but does not eliminate bias (so choice D is wrong)."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-1.-1",
    "href": "danl-hw/danl-101-hw-01.html#question-1.-1",
    "title": "Homework 1",
    "section": "Question 1.",
    "text": "Question 1.\nWhy are R and Python considered important tools for data analytics?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nR and Python are popular because they have a wide range of libraries and packages for data manipulation, visualization, and machine learning. They also support a large user community and are open-source, making them accessible and adaptable."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-2.-1",
    "href": "danl-hw/danl-101-hw-01.html#question-2.-1",
    "title": "Homework 1",
    "section": "Question 2.",
    "text": "Question 2.\nExplain why understanding the output of Generative AI tools like ChatGPT is important for data analysts or data scientists.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nData analysts need to interpret the output of generative AI tools to ensure that the generated information is relevant, accurate, and aligned with the specific context of their analysis. This understanding helps prevent misinterpretation and misuse of AI-generated insights."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-3.-1",
    "href": "danl-hw/danl-101-hw-01.html#question-3.-1",
    "title": "Homework 1",
    "section": "Question 3.",
    "text": "Question 3.\nHow does dynamic ticket pricing work in sports analytics?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nDynamic ticket pricing adjusts the price of tickets in real-time based on demand, opponent strength, weather conditions, and other factors. This approach maximizes revenue by charging more when demand is high and less when demand is low."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-4.-1",
    "href": "danl-hw/danl-101-hw-01.html#question-4.-1",
    "title": "Homework 1",
    "section": "Question 4.",
    "text": "Question 4.\nHow do business intelligence (BI) tools assist in decision-making for businesses?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nBI tools help businesses collect, process, and visualize data to support informed decision-making. They provide insights into trends, performance metrics, and areas of improvement, enabling businesses to make data-driven decisions."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-5.-1",
    "href": "danl-hw/danl-101-hw-01.html#question-5.-1",
    "title": "Homework 1",
    "section": "Question 5.",
    "text": "Question 5.\nDefine hallucination in LLMs and name two practical steps a student can take to reduce its impact in coursework.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nA hallucination in large language models (LLMs) occurs when the model produces information that is confidently stated but factually incorrect or fabricated.\n\nTwo steps to reduce its impact:\n\nVerify outputs with reliable sources (textbook, lecture notes, academic references, or official datasets).\n\nUse structured prompting (e.g., ‚Äúprovide sources,‚Äù ‚Äúshow assumptions,‚Äù or ‚Äústep-by-step‚Äù) to encourage transparency and make errors easier to detect."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-6.-1",
    "href": "danl-hw/danl-101-hw-01.html#question-6.-1",
    "title": "Homework 1",
    "section": "Question 6.",
    "text": "Question 6.\nDescribe a realistic business task well-suited to unsupervised learning and explain why labels aren‚Äôt necessary.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nA realistic business task is customer segmentation in marketing. Companies can use purchasing behavior, browsing patterns, and demographic information to group customers into clusters.\n\nLabels aren‚Äôt necessary because the company does not need predefined categories (like ‚Äúhigh spender‚Äù vs.¬†‚Äúlow spender‚Äù). Instead, the algorithm finds natural groupings in the data (clusters) on its own, revealing hidden structure that can guide targeted promotions or personalized recommendations."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-1",
    "href": "danl-hw/danl-101-hw-01.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1\nCompute the weighted mean of the vector scores &lt;- c(85, 90, 88, 92, 87) with corresponding weights weights &lt;- c(1, 2, 1, 1, 3).\nscores &lt;- c(85, 90, 88, 92, 87)\nweights &lt;- c(1, 2, 1, 1, 3)\nweighted_mean &lt;- [?]\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Define the scores vector\nscores &lt;- c(85, 90, 88, 92, 87)\n\n# Define the corresponding weights vector\nweights &lt;- c(1, 2, 1, 1, 3)\n\n# Compute the weighted mean by summing the products of scores and weights and dividing by the sum of weights\nweighted_mean &lt;- sum(scores * weights) / sum(weights)\n\nTherefore the weighted mean is 88.25.\n\nTo clarify the difference between the arithmetic mean and the weighted mean:\n\nArithmetic mean: This is the simple average where all values are treated equally. You sum all the values and divide by the number of values.\nWeighted mean: This takes into account the weights assigned to each value. Each value is multiplied by its corresponding weight, and then the sum of these products is divided by the total sum of the weights.\n\nExample:\n\nLet‚Äôs say you have a vector of values: x &lt;- c(2, 4, 6). And corresponding weights: w &lt;- c(1, 2, 3).\nFor the arithmetic mean, you would ignore the weights and simply find the average of the values:\n\n(Arithmetic mean) = (2 + 4 + 6) / 3 = 4\n\nFor the weighted mean, you would multiply each value by its corresponding weight and then divide by the sum of the weights:\n\n(Weighted mean) = ( (1 * 2) + (2 * 4) + (3 * 6) ) / ( 1 + 2 + 3 ) = 4.67"
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-2",
    "href": "danl-hw/danl-101-hw-01.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2\nCompute the interquartile range (IQR) of the following vector x &lt;- c(5, 7, 6, 9, 100, 8, 5, 7, 6) manually, without using the IQR() function.\nx &lt;- c(5, 7, 6, 9, 100, 8, 5, 7, 6)\nq1 &lt;- [Blank 1](x, 0.25)\nq3 &lt;- [Blank 2](x, [Blank 3])\niqr_value &lt;- q3 - q1\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Define the data vector\nx &lt;- c(5, 7, 6, 9, 100, 8, 5, 7, 6)\n\n# Compute the first quartile (Q1)\nq1 &lt;- quantile(x, 0.25)\n\n# Compute the third quartile (Q3)\nq3 &lt;- quantile(x, 0.75)\n\n# Calculate the interquartile range (IQR)\niqr_value &lt;- q3 - q1\n\nTherefore the IQR is 2."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-3",
    "href": "danl-hw/danl-101-hw-01.html#question-3",
    "title": "Homework 1",
    "section": "Question 3",
    "text": "Question 3\nDetect the outliers in the vector x &lt;- c(5, 7, 6, 9, 100, 8, 5, 7, 6) using the 1.5*IQR rule.\nlower_bound &lt;- q1 - 1.5 * iqr_value\nupper_bound &lt;- q3 + 1.5 * iqr_value\noutliers_lower &lt;- [Blank 1]\noutliers_upper &lt;- [Blank 2]\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Calculate the lower bound for outliers using Q1 and the IQR\nlower_bound &lt;- q1 - 1.5 * iqr_value\n\n# Calculate the upper bound for outliers using Q3 and the IQR\nupper_bound &lt;- q3 + 1.5 * iqr_value\n\n# Find any values in the data vector that are below the lower bound (lower outliers)\noutliers_lower &lt;- x[ x &lt; lower_bound ]\n\n# Find any values in the data vector that are above the upper bound (upper outliers)\noutliers_upper &lt;- x[ x &gt; upper_bound ]\n\nThere is one single value, 100, that belongs to outliers_upper. There is no lower outlier.\n\nThis rule is described in this lecture slide.\nAlthough we primarily use filter() with data.frame, understanding vector indexing is a fundamental skill in data analysis.\n\nLecture 5. R Basics covers vector indexing."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-4",
    "href": "danl-hw/danl-101-hw-01.html#question-4",
    "title": "Homework 1",
    "section": "Question 4",
    "text": "Question 4\nCalculate the skewness of the vector x &lt;- c(3, 5, 8, 12, 14, 15, 18, 20) without using any external R package. Skewness is defined as: \\[\n\\text{Skewness} \\,=\\, \\frac{N}{(N-1)(N-2)}\\sum_{i=1}^{N}\\left(\\frac{x_{i}-\\bar{x}}{s}\\right)^{3}\n\\] where \\(s\\) is the standard deviation of the vector x.\nx &lt;- c(3, 5, 8, 12, 14, 15, 18, 20)\nN &lt;- length(x)\nmean_x &lt;- mean(x)\nsd_x &lt;- sd(x)\nskewness &lt;- [?]\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Define the data vector\nx &lt;- c(3, 5, 8, 12, 14, 15, 18, 20)\n\n# Calculate the number of elements (n) in the vector\nN &lt;- length(x)\n\n# Compute the mean of the vector\nmean_x &lt;- mean(x)\n\n# Compute the standard deviation of the vector\nsd_x &lt;- sd(x)\n\n# Calculate skewness using the formula provided\nskewness &lt;- ( N / ( (N-1) * (N-2) ) ) * sum( ( (x - mean_x)/sd_x )^3 )\n\nTherefore skewness is approximately -0.2337.\n\nYou do not need to memorize the formula for skewness in our course.\nThe question is about translating a complex formula into R code.\n\n\n\n\n\n\n\nNote\n\n\n\nThe skewness formula, written out without using summation notation, is:\n\\[\n\\text{Skewness} \\;=\\; \\frac{N}{(N-1)(N-2)} \\Bigg[\n\\left(\\frac{x_{1}-\\bar{x}}{s}\\right)^{3} +\n\\left(\\frac{x_{2}-\\bar{x}}{s}\\right)^{3} +\n\\cdots +\n\\left(\\frac{x_{N}-\\bar{x}}{s}\\right)^{3}\n\\Bigg]\n\\] For simplicity, we will not use the summation notation in this course."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-5",
    "href": "danl-hw/danl-101-hw-01.html#question-5",
    "title": "Homework 1",
    "section": "Question 5",
    "text": "Question 5\nCalculate mode_v, the mode of a numeric vector v &lt;- c(2, 3, 5, 5, 6, 7, 3) using the mfv() function provided by the R package modeest.\nv &lt;- c(2, 3, 5, 5, 6, 7, 3, 5)\nmode_v &lt;- [Blank 1]::[Blank 2](v)\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Define the vector of data\nv &lt;- c(2, 3, 5, 5, 6, 7, 3, 5)\n\n# Use the modeest package's mfv() function to calculate the mode\nmode_v &lt;- modeest::mfv(v)\n\nTo use modeest::mfv(), we first install the modeest package:\n\n# Install the modeest package\ninstall.packages(\"modeest\")\n\nThe notation modeest::mfv() indicates that we are using the mfv() function from the modeest package. The :: operator specifies which package the function or the object is coming from."
  },
  {
    "objectID": "danl-hw/danl-101-hw-01.html#question-6",
    "href": "danl-hw/danl-101-hw-01.html#question-6",
    "title": "Homework 1",
    "section": "Question 6",
    "text": "Question 6\nCalculate, z, the vector for the standardized values in the vector x &lt;- c(10, 20, 30, 40, 50). The standardized value of the individual value, \\(z_{i}\\), is defined as:\n\\[\nz_{i} \\,=\\, \\frac{x_{i} - \\bar{x}}{s},\n\\] where\n\\(\\quad\\) - \\(x_{i}\\): \\(i^{th}\\) value in the vector \\(x\\)\n\\(\\quad\\) - \\(\\bar{x}\\): the mean of values in \\(x\\)\n\\(\\quad\\) - \\(s\\): the standard deviation of values in \\(x\\)\n\\(\\quad\\) - \\(z_{i}\\): \\(i^{th}\\) value in the vector \\(z\\), the vector of the standardized values in \\(x\\).\nx &lt;- c(10, 20, 30, 40, 50)\nz &lt;- [?]\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\n# Define the data vector\nx &lt;- c(10, 20, 30, 40, 50)\n\n# Calculate the standardized values (z-scores) for each element in x\nz &lt;- (x - mean(x)) / sd(x)\n\n\nPlease note that the R objects mean_x and sd_x defined in Question 4 are not used in this question."
  },
  {
    "objectID": "listing-danl-101-hw.html",
    "href": "listing-danl-101-hw.html",
    "title": "DANL 101 - Homework",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework 1\n\n\nIntroduction to Data Analytics; Generative AI; R Basics\n\n\nSeptember 13, 2025\n\n\n\n\nHomework 2\n\n\nGenerative AI; Data Transformation with R\n\n\nSeptember 25, 2025\n\n\n\n\nHomework 3\n\n\nData Transformation & Visualization in R ‚Äî Part I\n\n\nNovember 4, 2025\n\n\n\n\nHomework 4\n\n\nData Transformation & Visualization in R ‚Äî Part II\n\n\nNovember 20, 2025\n\n\n\n\nHomework 5\n\n\nGenerative AI for Data Analysis\n\n\nDecember 2, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "sce.html",
    "href": "sce.html",
    "title": "Student Course Experience (SCE)",
    "section": "",
    "text": "Tools & Environments\n\nUsed Quarto/Jupyter Notebooks to communicate data analysis through your personal website managed with git and GitHub\n\nData Manipulation & Cleaning\n\nTransformed, reshaped, merged, summarized datasets\nApplied pandas for efficient and scalable data wrangling\n\nData Collection\n\nCollected data through web scraping with selenium\nRetrieved structured data from APIs using requests\n\nStock and ESG Data Project\n\nCollect, clean, visualize, and analyze stock and ESG data\nPresent your analysis through a fully published project webpage\n\n\n\n\n\n\n\nI have tried to improve your learning experience in this course.\nI value your feedback immensely.\nI request for your participation in the Student Course Evaluation (SCE).\n\n\n\n\nTake 10 minutes right now to complete the SCE.\nOn your laptop, access the SCE form for DANL 101 as follows:\n\nLog in to SCE survey\nClick on the ‚ÄúSurveys‚Äù option\nChoose DANL 101 and then complete the SCE survey."
  },
  {
    "objectID": "sce.html#what-we-learned-this-semester",
    "href": "sce.html#what-we-learned-this-semester",
    "title": "Student Course Experience (SCE)",
    "section": "",
    "text": "Tools & Environments\n\nUsed Quarto/Jupyter Notebooks to communicate data analysis through your personal website managed with git and GitHub\n\nData Manipulation & Cleaning\n\nTransformed, reshaped, merged, summarized datasets\nApplied pandas for efficient and scalable data wrangling\n\nData Collection\n\nCollected data through web scraping with selenium\nRetrieved structured data from APIs using requests\n\nStock and ESG Data Project\n\nCollect, clean, visualize, and analyze stock and ESG data\nPresent your analysis through a fully published project webpage"
  },
  {
    "objectID": "sce.html#student-course-evaluation-sce",
    "href": "sce.html#student-course-evaluation-sce",
    "title": "Student Course Experience (SCE)",
    "section": "",
    "text": "I have tried to improve your learning experience in this course.\nI value your feedback immensely.\nI request for your participation in the Student Course Evaluation (SCE).\n\n\n\n\nTake 10 minutes right now to complete the SCE.\nOn your laptop, access the SCE form for DANL 101 as follows:\n\nLog in to SCE survey\nClick on the ‚ÄúSurveys‚Äù option\nChoose DANL 101 and then complete the SCE survey."
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html",
    "href": "danl-hw/danl-101-hw-05.html",
    "title": "Homework 5",
    "section": "",
    "text": "Please answer all of the following questions thoroughly.\nPrepare your answers in a Word document and submit the document to Brightspace.\nFor Homework Assignment 5, using a generative artificial intelligence (AI) tool is required.\n\nChoose one generative AI tool of your preference.\nCopy your full conversation with the AI tool and paste it into your Word document.\n\nYou may submit multiple times, but only your most recent submission will be graded.\nThe assignment is due on Tuesday, December 9, 2024, at 11:59 PM (Eastern Time)."
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-1.",
    "href": "danl-hw/danl-101-hw-05.html#question-1.",
    "title": "Homework 5",
    "section": "Question 1.",
    "text": "Question 1.\nWhat generative AI tool have you used for this homework assignment?"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-2.-python-visualization-with-the-seaborn-library",
    "href": "danl-hw/danl-101-hw-05.html#question-2.-python-visualization-with-the-seaborn-library",
    "title": "Homework 5",
    "section": "Question 2. Python Visualization with the seaborn Library",
    "text": "Question 2. Python Visualization with the seaborn Library\n\n \n\n\n\n\n\n\n\n\n\nseaborn\n\n\n\n\nseaborn is a Python data visualization library that provides a high-level, elegant interface for creating informative and attractive graphics.\n\nYou can think of it as the Python counterpart to R‚Äôs ggplot2: it emphasizes clear defaults, aesthetic color palettes, and concise syntax for complex visualizations.\n\nBecause of its intuitive design and visually appealing output, I recommend using seaborn as the default choice for visualization in Python.\n\n\n\n\n\nProvide your conversation with generative AI to do the following tasks:\n\nTranslate the following R ggplot code into Python seaborn code to generate a scatter plot showing the relationship between ‚Äúsales‚Äù and ‚Äúprice‚Äù using the CSV file, http://bcdanl.github.io/data/dominick_oj_na.csv.\nMake a step-by-step comparison between the Python code and the R code to understand how each part corresponds to the other.\n\n\n\nlibrary(tidyverse)\n\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_na.csv\")\n\nggplot(data = oj, \n       mapping = aes(x = price, y = sales,\n                     color = brand)) +\n  geom_point(alpha = .3) + \n  geom_smooth(method = \"lm\") +\n  labs(title = \"Scatter Plot of Sales vs. Price\",\n       x = \"Price\",\n       y = \"Sales\")"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-3.",
    "href": "danl-hw/danl-101-hw-05.html#question-3.",
    "title": "Homework 5",
    "section": "Question 3.",
    "text": "Question 3.\n\nProvide your conversation with generative AI to do the following task:\n\nMake an in-line comment on each line of the following R ggplot code.\n\n\n\nlibrary(tidyverse)\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_feat.csv\")\nggplot(data = oj, \n       mapping = aes(x = price, y = sales,\n                     color = brand)) +\n  geom_point(alpha = .3) + \n  geom_smooth(method = \"lm\") +\n  labs(title = \"Scatter Plot of Sales vs. Price\",\n       x = \"Price\",\n       y = \"Sales\")"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-4.",
    "href": "danl-hw/danl-101-hw-05.html#question-4.",
    "title": "Homework 5",
    "section": "Question 4.",
    "text": "Question 4.\n\nProvide your conversation with generative AI to debug the following code:\n\nExplain to the generative AI the error message you received when running the code below:\n\n\n\noj |&gt; \n  counting(brand, ad_status)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-5.",
    "href": "danl-hw/danl-101-hw-05.html#question-5.",
    "title": "Homework 5",
    "section": "Question 5.",
    "text": "Question 5.\n\nProvide your conversation with generative AI for adding a new variable, revenue, to the oj data frame.\n\nThe revenue variable should be computed as the product of sales and price to provide information about the weekly revenue for each orange juice brand.\n\n\n\nlibrary(tidyverse)\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_feat.csv\")"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-1.-generative-ai-tool",
    "href": "danl-hw/danl-101-hw-05.html#question-1.-generative-ai-tool",
    "title": "Homework 5",
    "section": "Question 1. Generative AI Tool",
    "text": "Question 1. Generative AI Tool\nWhat generative AI tool have you used for this homework assignment?"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-2.-python-data-analysis-with-the-pandas-library",
    "href": "danl-hw/danl-101-hw-05.html#question-2.-python-data-analysis-with-the-pandas-library",
    "title": "Homework 5",
    "section": "Question 2. Python Data Analysis with the pandas Library",
    "text": "Question 2. Python Data Analysis with the pandas Library\n\n\n\n\n\n\n\n\n\n\n\npandas\n\n\n\n\npandas is Python‚Äôs primary library for data manipulation and analysis, offering powerful tools for working with tabular data.\n\nYou can think of it as the Python counterpart to R‚Äôs dplyr (tidyverse): it provides clear, expressive functions for filtering, transforming, summarizing, and reshaping data.\n\nBecause of its intuitive syntax and flexible data structures ‚Äî DataFrame (similar to a data.frame in R) and Series (similar to a vector in R) ‚Äî pandas is the default foundation for most data analysis workflows in Python.\n\n\n\n\nProvide your conversation with a generative AI tool to complete the following tasks:\n\nTranslate the R dplyr code below into equivalent Python code using pandas to perform the same data-manipulation steps on the CSV file\nhttp://bcdanl.github.io/data/dominick_oj_na.csv.\nMake a step-by-step comparison between the Python code and the R code, explaining how each part of the dplyr pipeline corresponds to the equivalent operation in pandas.\n\n\n\nlibrary(tidyverse)\n\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_na.csv\")\n\noj |&gt;\n  select(brand, price, sales) |&gt;\n  filter(price &gt; 1.5) |&gt; \n  mutate(log_sales = log(sales)) |&gt;\n  arrange(desc(price))"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-4.-interpreting-r-ggplot-code-with-generative-ai",
    "href": "danl-hw/danl-101-hw-05.html#question-4.-interpreting-r-ggplot-code-with-generative-ai",
    "title": "Homework 5",
    "section": "Question 4. Interpreting R ggplot Code with Generative AI",
    "text": "Question 4. Interpreting R ggplot Code with Generative AI\n\nProvide your conversation with generative AI to do the following task:\n\nMake an in-line comment on each line of the following R ggplot code.\n\n\n\nlibrary(tidyverse)\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_na.csv\")\n\nggplot(data = oj, \n       mapping = aes(x = price, y = sales,\n                     color = brand)) +\n  geom_point(alpha = .3) + \n  geom_smooth(method = \"lm\") +\n  labs(title = \"Scatter Plot of Sales vs. Price\",\n       x = \"Price\",\n       y = \"Sales\")"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-5.-debugging-r-code-with-generative-ai",
    "href": "danl-hw/danl-101-hw-05.html#question-5.-debugging-r-code-with-generative-ai",
    "title": "Homework 5",
    "section": "Question 5. Debugging R Code with Generative AI",
    "text": "Question 5. Debugging R Code with Generative AI\n\nProvide your conversation with generative AI to debug the following code:\n\nExplain to the generative AI the error message you received when running the code below:\n\n\n\noj |&gt; \n  counting(brand, ad_status)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-6.-data-transformation-with-generative-ai-assistance",
    "href": "danl-hw/danl-101-hw-05.html#question-6.-data-transformation-with-generative-ai-assistance",
    "title": "Homework 5",
    "section": "Question 6. Data Transformation with Generative AI Assistance",
    "text": "Question 6. Data Transformation with Generative AI Assistance\n\nProvide your conversation with generative AI for adding a new variable, revenue, to the oj data frame.\n\nThe revenue variable should be computed as the product of sales and price to provide information about the weekly revenue for each orange juice brand.\n\n\n\nlibrary(tidyverse)\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_na.csv\")"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-4.-understanding-r-ggplot-and-dplyr-code-with-generative-ai",
    "href": "danl-hw/danl-101-hw-05.html#question-4.-understanding-r-ggplot-and-dplyr-code-with-generative-ai",
    "title": "Homework 5",
    "section": "Question 4. Understanding R ggplot and dplyr Code with Generative AI",
    "text": "Question 4. Understanding R ggplot and dplyr Code with Generative AI\n\nProvide your conversation with a generative AI tool to complete the following task:\n\nAdd a brief explanation for each line of the R code below to show your understanding of what the code is doing.\n\n\n\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(ggthemes)\nlibrary(grid) \n\nevents_raw &lt;- read_csv(\"https://bcdanl.github.io/data/time-series-US-cost-1980-2024.csv\", comment = \"#\") |&gt; \n  select(-matches(\"upper|lower\", ignore.case = TRUE))\n\nevents_counts &lt;- events_raw |&gt;\n  select(Year, matches(\"Count$\"))  \n\nevents_long &lt;- events_counts |&gt;\n  pivot_longer(\n    cols      = -Year,\n    names_to  = \"hazard\",\n    values_to = \"count\"\n  ) |&gt;\n  mutate(\n    hazard = str_remove(hazard, \" Count$\"),\n    hazard = factor(\n      hazard,\n      levels = c(\n        \"Drought\",\n        \"Tropical Cyclone\",\n        \"Flooding\",\n        \"Freeze\",\n        \"Severe Storm\",\n        \"Winter Storm\",\n        \"Wildfire\"\n      )\n    )\n  ) |&gt;\n  filter(!is.na(hazard))\n\ncost_df &lt;- events_raw |&gt;\n  select(Year, matches(\"All Disasters.*Cost\", ignore.case = TRUE)) |&gt;\n  rename(cost_billion = 2)                           # rename the cost column\n\n\n# join cost onto long data (repeated by hazard for plotting convenience)\nplot_df &lt;- events_long |&gt;\n  left_join(cost_df, by = \"Year\")\n\n\nmax_count &lt;- max(plot_df$count, na.rm = TRUE)\nmax_cost  &lt;- max(plot_df$cost_billion, na.rm = TRUE)\ncost_scale &lt;- max_count / max_cost\n\n\n\nhazard_cols &lt;- c(\n  \"Drought\"          = \"#E69F00\",  # orange\n  \"Tropical Cyclone\" = \"#007F7F\",  # green\n  \"Flooding\"         = \"#56B4E9\",  # light blue\n  \"Freeze\"           = \"#0072B2\",  # dark blue\n  \"Severe Storm\"     = \"#4F6D8A\",  # purple\n  \"Winter Storm\"     = \"#999999\",  # gray\n  \"Wildfire\"         = \"#D55E00\"   # red\n)\n\nggplot(plot_df, aes(x = Year)) +\n  geom_area(\n    aes(y = count, fill = hazard),\n    position = \"stack\",\n    color = NA\n  ) +\n  geom_smooth(\n    aes(y = cost_billion * cost_scale),\n    linewidth = 3,\n    color = \"#2c2e2f\",\n    se = FALSE\n  ) +\n  geom_label(\n    data = tibble(\n      Year = 2004,\n      y    = max_count * 0.95,\n      lab  = \"Yearly Trend of\\nAll Billion-Dollar\\nDisaster Cost\"\n    ),\n    aes(x = Year, y = y, label = lab),\n    inherit.aes = FALSE,\n    hjust = 0.5,\n    vjust = 0.5,\n    size  = 4,\n    label.size = .5,      \n    label.r = unit(0.15, \"lines\")  \n  ) +\n  annotate(\n    \"segment\",\n    x = 2004,                # start of arrow\n    xend = 2004,             # end of arrow (toward line)\n    y = 15,\n    yend = 3,\n    colour = \"black\",\n    linewidth = 0.5,\n    arrow = arrow(length = unit(0.25, \"cm\"), type = \"closed\")\n  ) +\n  scale_fill_manual(\n    values = hazard_cols,\n    name   = \"\"\n  ) +\n  scale_y_continuous(\n    name = \"Number of Events\",\n    sec.axis = sec_axis(~ . / cost_scale, name = \"Cost in billions\")\n  ) +\n  scale_x_continuous(\n    breaks = seq(1980,2025,5)\n  ) +\n  labs(\n    x = NULL,\n    fill = \"\",\n    title = \"U.S. Billion-Dollar Disasters: Events and Costs 1980-2024 (CPI-Adjusted)\",\n    caption = \"Source: National Oceanic and Atmospheric Administration (2024)\"\n  ) +\n  theme_ipsum() +\n  theme(\n    panel.grid.minor = element_blank(),\n    legend.position = \"top\",\n    legend.box = \"horizontal\",\n    legend.direction = \"horizontal\"\n  ) +\n  guides(\n    fill = guide_legend(\n      title.position = \"top\",\n      label.position = \"bottom\",\n      keywidth = unit(4, \"lines\"),\n      nrow = 1\n    )\n  )"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-4.-debugging-r-code-with-generative-ai",
    "href": "danl-hw/danl-101-hw-05.html#question-4.-debugging-r-code-with-generative-ai",
    "title": "Homework 5",
    "section": "Question 4. Debugging R Code with Generative AI",
    "text": "Question 4. Debugging R Code with Generative AI\n\nProvide your conversation with generative AI to debug the following code:\n\nExplain to the generative AI the error message you received when running the code below:\n\n\n\noj |&gt; \n  counting(brand, ad_status)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-5.-data-transformation-with-generative-ai-assistance",
    "href": "danl-hw/danl-101-hw-05.html#question-5.-data-transformation-with-generative-ai-assistance",
    "title": "Homework 5",
    "section": "Question 5. Data Transformation with Generative AI Assistance",
    "text": "Question 5. Data Transformation with Generative AI Assistance\n\nProvide your conversation with generative AI for adding a new variable, revenue, to the oj data frame.\n\nThe revenue variable should be computed as the product of sales and price to provide information about the weekly revenue for each orange juice brand.\n\n\n\nlibrary(tidyverse)\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_na.csv\")"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-6.-understanding-r-ggplot-and-dplyr-code-with-generative-ai",
    "href": "danl-hw/danl-101-hw-05.html#question-6.-understanding-r-ggplot-and-dplyr-code-with-generative-ai",
    "title": "Homework 5",
    "section": "Question 6. Understanding R ggplot and dplyr Code with Generative AI",
    "text": "Question 6. Understanding R ggplot and dplyr Code with Generative AI\n\nProvide your conversation with a generative AI tool to complete the following task:\n\nIn the code below, add a comment (#) with a brief explanation for each line of the R code below to show your understanding of what the code is doing.\n\n\n\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(ggthemes)\nlibrary(grid)\nlibrary(scales)\n\nevents_raw &lt;- read_csv(\"https://bcdanl.github.io/data/time-series-US-cost-1980-2024.csv\",\n                       comment = \"#\") |&gt; \n  select(-matches(\"upper|lower\", ignore.case = TRUE))\n\nevents_counts &lt;- events_raw |&gt;\n  select(Year, matches(\"Count$\"))  \n\nevents_long &lt;- events_counts |&gt;\n  pivot_longer(\n    cols      = -Year,\n    names_to  = \"hazard\",\n    values_to = \"count\"\n  ) |&gt;\n  mutate(\n    hazard = str_remove(hazard, \" Count$\"),\n    hazard = factor(\n      hazard,\n      levels = c(\n        \"Drought\",\n        \"Tropical Cyclone\",\n        \"Flooding\",\n        \"Freeze\",\n        \"Severe Storm\",\n        \"Winter Storm\",\n        \"Wildfire\"\n      )\n    )\n  ) |&gt;\n  filter(!is.na(hazard))\n\ncost_df &lt;- events_raw |&gt;\n  select(Year, matches(\"All Disasters.*Cost\", ignore.case = TRUE)) |&gt;\n  rename(cost_billion = 2) \n\nplot_df &lt;- events_long |&gt;\n  left_join(cost_df, by = \"Year\")\n\n\nmax_count &lt;- max(plot_df$count, na.rm = TRUE)\nmax_cost  &lt;- max(plot_df$cost_billion, na.rm = TRUE)\ncost_scale &lt;- max_count / max_cost\n\n\n\nhazard_cols &lt;- c(\n  \"Drought\"          = \"#E69F00\",  # orange\n  \"Tropical Cyclone\" = \"#007F7F\",  # green\n  \"Flooding\"         = \"#56B4E9\",  # light blue\n  \"Freeze\"           = \"#0072B2\",  # dark blue\n  \"Severe Storm\"     = \"#4F6D8A\",  # purple\n  \"Winter Storm\"     = \"#999999\",  # gray\n  \"Wildfire\"         = \"#D55E00\"   # red\n)\n\nggplot(plot_df, aes(x = Year)) +\n  geom_area(\n    aes(y = count, fill = hazard),\n    position = \"stack\",\n    color = NA\n  ) +\n  geom_smooth(\n    aes(y = cost_billion * cost_scale),\n    linewidth = 3,\n    color = \"#2c2e2f\",\n    se = FALSE\n  ) +\n  geom_label(\n    data = tibble(\n      Year = 2004,\n      y    = max_count * 0.95,\n      lab  = \"Yearly Trend of\\n Billion-Dollar\\nDisaster Cost\"\n    ),\n    aes(x = Year, y = y, label = lab),\n    inherit.aes = FALSE,\n    hjust = 0.5,\n    vjust = 0.5,\n    size  = 4,\n    fontface = \"bold\",\n    label.size = .5,      \n    label.r = unit(0.15, \"lines\"),\n    label.padding = unit(0.5, \"lines\")\n  ) +\n  annotate(\n    \"segment\",\n    x = 2004,\n    xend = 2004, \n    y = 15,\n    yend = 3,\n    color = \"black\",\n    linewidth = 0.5,\n    arrow = arrow(length = unit(0.25, \"cm\"), type = \"closed\")\n  ) +\n  scale_fill_manual(\n    values = hazard_cols,\n    name   = \"\"\n  ) +\n  scale_y_continuous(\n    name = \"Number of Events\",\n    breaks = seq(0,30,10),\n    limits = c(0,30),\n    sec.axis = sec_axis(\n      ~ . / cost_scale, \n      name = \"Cost in billions\",\n      labels = label_dollar(prefix = \"$\")\n    )\n  ) +\n  scale_x_continuous(\n    breaks = seq(1980,2025,5)\n  ) +\n  labs(\n    x = NULL,\n    fill = \"\",\n    title = \"U.S. Billion-Dollar Disasters: Events and Costs 1980-2024 (CPI-Adjusted)\",\n    caption = \"Source: National Oceanic and Atmospheric Administration (2024)\"\n  ) +\n  theme_ipsum() +\n  theme(\n    plot.title = element_text(hjust = 0.5,\n                              size = rel(1.75)),\n    panel.grid.minor = element_blank(),\n    axis.title.y = element_text(size = rel(1.5),\n                                margin = margin(0,12,0,0)),\n    axis.title.y.right = element_text(size = rel(1.12),\n                                      margin = margin(0,0,0,12)),\n    legend.position = \"top\",\n    legend.box = \"horizontal\",\n    legend.direction = \"horizontal\"\n  ) +\n  guides(\n    fill = guide_legend(\n      title.position = \"top\",\n      label.position = \"bottom\",\n      keywidth = unit(4.75, \"lines\"),\n      nrow = 1\n    )\n  )\n\n\n\n\n\nReferences\n\nBillion-Dollar Weather and Climate Disasters, National Oceanic and Atmospheric Administration (2025)"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-1.-choice-of-generative-ai-tool",
    "href": "danl-hw/danl-101-hw-05.html#question-1.-choice-of-generative-ai-tool",
    "title": "Homework 5",
    "section": "Question 1. Choice of Generative AI Tool",
    "text": "Question 1. Choice of Generative AI Tool\nWhat generative AI tool have you used for this homework assignment?"
  },
  {
    "objectID": "danl-hw/danl-101-hw-05.html#question-3.-python-data-analysis-with-the-pandas-library",
    "href": "danl-hw/danl-101-hw-05.html#question-3.-python-data-analysis-with-the-pandas-library",
    "title": "Homework 5",
    "section": "Question 3. Python Data Analysis with the pandas Library",
    "text": "Question 3. Python Data Analysis with the pandas Library\n\n\n\n\n\n\n\n\n\n\n\npandas\n\n\n\n\npandas is Python‚Äôs primary library for data manipulation and analysis, offering powerful tools for working with tabular data.\n\nYou can think of it as the Python counterpart to R‚Äôs dplyr (tidyverse): it provides clear, expressive functions for filtering, transforming, summarizing, and reshaping data.\n\nBecause of its intuitive syntax and flexible data structures ‚Äî DataFrame (similar to a data.frame in R) and Series (similar to a vector in R) ‚Äî pandas is the default foundation for most data analysis workflows in Python.\n\n\n\n\nProvide your conversation with a generative AI tool to complete the following tasks:\n\nTranslate the R dplyr code below into equivalent Python code using pandas to perform the same data-manipulation steps on the CSV file\nhttp://bcdanl.github.io/data/dominick_oj_na.csv.\nMake a step-by-step comparison between the Python code and the R code, explaining how each part of the dplyr pipeline corresponds to the equivalent operation in pandas.\n\n\n\nlibrary(tidyverse)\n\noj &lt;- read_csv(\"http://bcdanl.github.io/data/dominick_oj_na.csv\")\n\noj |&gt;\n  select(brand, price, sales) |&gt;\n  filter(price &gt; 1.5) |&gt; \n  mutate(log_sales = log(sales)) |&gt;\n  arrange(desc(price))"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html",
    "title": "Midterm Exam II",
    "section": "",
    "text": "During the ETL process, the ‚ÄúTransform‚Äù stage in a DANL 101 context using R is best represented by which set of functions?\n\nread_csv()\nnrow() and head()\nfilter(), select(), and left_join()\nmean() and sd()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\nThese are typical data-wrangling verbs used to transform data.\n\n\n\n\n\n\n\nWhen the distribution of a variable has a single peak and is negatively skewed (i.e., having a long left tail), which of the following is correct?\n\nMedian &lt; Mode &lt; Mean\nMean &lt; Median &lt; Mode\nMode &lt; Mean &lt; Median\nMedian = Mean = Mode\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b\nWith a long left tail, the mean is pulled left the most, then the median, then the mode stays at the peak:\nMean &lt; Median &lt; Mode.\n\n\n\n\n\n\n\nWhat is NOT an essential component in ggplot() data visualization?\n\nData frames\nGeometric objects\nFacets\nAesthetic attributes\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\nFacets are useful but optional. You can build a valid ggplot without them.\n\n\n\n\n\n\n\n____(1)____ does not necessarily imply ____(2)____\n\n\nCorrelation; (2) causation\n\n\nCausation; (2) correlation\n\n\nCorrelation; (2) correlation\n\n\nCausation; (2) causation\n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\nThe classic warning: correlation does not imply causation.\n\n\n\n\n\n\n\nIn the context of the lecture, which of the following correctly interprets a change in log-transformed GDP per capita and its meaning for GDP per capita?\n\nA one-unit increase in log(GDP per capita) means to a 1% increase in GDP per capita.\nA one-unit increase in log(GDP per capita) means to a 100% increase in GDP per capita.\nA one-unit increase in GDP per capita means an 8.4% increase in GDP per capita.\nA one-unit increase in GDP per capita means a 0.084% increase in GDP per capita.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b\nA 1-unit increase in log(GDP per capita) corresponds to GDP per capita multiplying by about e (roughly a 100%+ increase), not just 1%.\n\n\n\n\n\n\n\nIn a relational database, a key is best described as:\n\nA column that stores numeric values only\nAny column used in a chart or visualization\nA special column that can never have missing values\nA column that uniquely identifies each row in a table\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: d\nA key is a column (or combination of columns) whose value is unique for each row."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-1",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-1",
    "title": "Midterm Exam II",
    "section": "",
    "text": "During the ETL process, the ‚ÄúTransform‚Äù stage in a DANL 101 context using R is best represented by which set of functions?\n\nread_csv()\nnrow() and head()\nfilter(), select(), and left_join()\nmean() and sd()\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\nThese are typical data-wrangling verbs used to transform data."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-2",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-2",
    "title": "Midterm Exam II",
    "section": "",
    "text": "When the distribution of a variable has a single peak and is negatively skewed (i.e., having a long left tail), which of the following is correct?\n\nMedian &lt; Mode &lt; Mean\nMean &lt; Median &lt; Mode\nMode &lt; Mean &lt; Median\nMedian = Mean = Mode\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b\nWith a long left tail, the mean is pulled left the most, then the median, then the mode stays at the peak:\nMean &lt; Median &lt; Mode."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-3",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-3",
    "title": "Midterm Exam II",
    "section": "",
    "text": "What is NOT an essential component in ggplot() data visualization?\n\nData frames\nGeometric objects\nFacets\nAesthetic attributes\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\nFacets are useful but optional. You can build a valid ggplot without them."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-4",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-4",
    "title": "Midterm Exam II",
    "section": "",
    "text": "____(1)____ does not necessarily imply ____(2)____\n\n\nCorrelation; (2) causation\n\n\nCausation; (2) correlation\n\n\nCorrelation; (2) correlation\n\n\nCausation; (2) causation\n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\nThe classic warning: correlation does not imply causation."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-5",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-5",
    "title": "Midterm Exam II",
    "section": "",
    "text": "In the context of the lecture, which of the following correctly interprets a change in log-transformed GDP per capita and its meaning for GDP per capita?\n\nA one-unit increase in log(GDP per capita) means to a 1% increase in GDP per capita.\nA one-unit increase in log(GDP per capita) means to a 100% increase in GDP per capita.\nA one-unit increase in GDP per capita means an 8.4% increase in GDP per capita.\nA one-unit increase in GDP per capita means a 0.084% increase in GDP per capita.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b\nA 1-unit increase in log(GDP per capita) corresponds to GDP per capita multiplying by about e (roughly a 100%+ increase), not just 1%."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-6",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-6",
    "title": "Midterm Exam II",
    "section": "",
    "text": "In a relational database, a key is best described as:\n\nA column that stores numeric values only\nAny column used in a chart or visualization\nA special column that can never have missing values\nA column that uniquely identifies each row in a table\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: d\nA key is a column (or combination of columns) whose value is unique for each row."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-7",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-7",
    "title": "Midterm Exam II",
    "section": "Question 7",
    "text": "Question 7\nWhen collecting data in real life, measured values often differ. In this context, we can observe ____________________ easily; for example, if we measure any numeric variable (e.g., friends‚Äô heights) twice, we are likely to get two different values.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: variability"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-8",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-8",
    "title": "Midterm Exam II",
    "section": "Question 8",
    "text": "Question 8\nThe ____________________ of a variable is the value that appears most frequently within the set of that variable‚Äôs values.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: mode"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-9",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-9",
    "title": "Midterm Exam II",
    "section": "Question 9",
    "text": "Question 9\nThe gg in ggplot stands for ____________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: Grammar of Graphics"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-10",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-10",
    "title": "Midterm Exam II",
    "section": "Question 10",
    "text": "Question 10\nUsing ____________________‚Äîa machine learning method‚Äîthe geom_smooth() visualizes the ____________________ value of the y variable for a given value of the x variable. The grey ribbon around the curve illustrates the ____________________ surrounding the estimated curve.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nUsing regression ‚Äî a machine learning method ‚Äî the geom_smooth() visualizes the predicted value of the y variable for a given value of the x variable. The grey ribbon around the curve illustrates the uncertainty surrounding the estimated curve."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-11",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-11",
    "title": "Midterm Exam II",
    "section": "Question 11",
    "text": "Question 11\nWhen making a scatterplot, it is a common practice to place the ____________________ variable along the x-axis and the ____________________ variable along the y-axis.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nx-axis: input variable\ny-axis: outcome variable"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-12",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-12",
    "title": "Midterm Exam II",
    "section": "Question 12",
    "text": "Question 12\nIn ggplot, we can set alpha between ____________________ (full transparency) and ____________________ (no transparency) manually to adjust a geometric object‚Äôs transparency level.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: 0 (full transparency) and 1 (no transparency)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#questions-13-19",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#questions-13-19",
    "title": "Midterm Exam II",
    "section": "Questions 13-19",
    "text": "Questions 13-19\nFor Questions 13-19, consider the following R packages and the data.frame, esg_info, containing individual company statistics for the Environmental, Social, and Governance (ESG) risk score in 2024.\n\nlibrary(tidyverse)\nlibrary(skimr)\nesg_info &lt;- read_csv(\"https://bcdanl.github.io/data/stock_esg_simple.csv\")\n\n\nThe esg_info data.frame is with 631 observations and 7 variables.\nThe first 5 observations in the esg_info data.frame are displayed below:\n\n\n\n\n\n\n\n\n\n\n\n\nTicker\nCompany_Name\nsector\ntotal_esg\n\n\n\n\nA\nAgilent Technologies, Inc.\nIndustrials\n13.6\n\n\nAA\nAlcoa Corporation\nIndustrials\n24.0\n\n\nAAL\nAmerican Airlines Group Inc.\nConsumer Discretionary\n26.4\n\n\nAAP\nAdvance Auto Parts, Inc.\nConsumer Discretionary\n11.5\n\n\nAAPL\nApple Inc\nTechnology\n17.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTicker\nCompany_Name\nsector\nenvironmental\nsocial\ngovernance\n\n\n\n\nA\nAgilent Technologies, Inc.\nIndustrials\n1.1\n6.4\n6.1\n\n\nAA\nAlcoa Corporation\nIndustrials\n13.8\n5.9\n4.3\n\n\nAAL\nAmerican Airlines Group Inc.\nConsumer Discretionary\n9.9\n11.6\n4.8\n\n\nAAP\nAdvance Auto Parts, Inc.\nConsumer Discretionary\n0.1\n8.3\n3.1\n\n\nAAPL\nApple Inc\nTechnology\n0.5\n7.4\n9.4\n\n\n\n\n\n\nDescription of Variables in esg_info:\n\nTicker: The stock symbol used to uniquely identify a publicly traded company on financial markets.\nCompany_Name: The full name of the company corresponding to the ticker symbol.\nsector: The broader industry category to which the company belongs, such as Technology, Healthcare, or Financials.\ntotal_esg: The company‚Äôs overall Environmental, Social, and Governance (ESG) score. It reflects how well the company is performing in terms of sustainability and ethical impact.\nenvironmental: The company‚Äôs score related to environmental practices, such as energy efficiency, waste management, and carbon footprint.\nsocial: The company‚Äôs score related to social practices, including employee relations, diversity, community impact, and human rights.\ngovernance: The company‚Äôs score related to governance practices, like board structure, executive pay, and shareholder rights.\n\n\n\nInterpreting ESG Data\nThe ESG data helps investors evaluate a company‚Äôs sustainability profile and exposure to long-term environmental, social, and governance risks. Here‚Äôs how to interpret each metric:\n\nTotal ESG Risk Score\n\nWhat it means: A composite score reflecting the company‚Äôs overall exposure to ESG-related risks.\nHow to interpret:\n\nHigher score = higher risk ‚Üí More vulnerable to ESG-related issues.\n\nExample: A company with total_ESG = 15 is considered to have lower ESG risk than one with total_ESG = 30.\n\n\n\n\nEnvironmental Risk Score\n\nWhat it measures: Exposure to environmental risks such as:\n\nCarbon emissions, waste management, climate change strategy\n\nHigher score ‚Üí more environmental liabilities or poor sustainability measures.\n\n\n\n\nSocial Risk Score\n\nWhat it measures: Exposure to social risks, including:\n\nLabor practices, human rights, inclusive culture and representation, customer and community relations\n\nHigher score = more risk from labor issues, public relation (PR) problems, etc.\n\n\n\n\nGovernance Risk Score\n\nWhat it measures: Exposure to governance-related risks, such as:\n\nBoard structure and independence, executive compensation, shareholder rights, transparency and ethics\n\nHigher score suggests poor governance structures.\n\n\n\nThe followings are the summary of the esg_info data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nesg_info\n\n\nNumber of rows\n631\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\nn_missing\nmin\nmax\nempty\nn_unique\n\n\n\n\nTicker\n0\n1\n5\n0\n631\n\n\nCompany_Name\n0\n5\n47\n0\n630\n\n\nsector\n0\n6\n22\n0\n12\n\n\n\nVariable type: numeric\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ntotal_esg\n0\n21.62\n7.08\n6.4\n16.30\n21.20\n26.10\n52.0\n\n\nenvironmental\n23\n5.78\n5.25\n0.0\n1.78\n3.95\n9.00\n25.3\n\n\nsocial\n23\n9.02\n3.57\n0.8\n6.70\n8.90\n11.20\n22.5\n\n\ngovernance\n23\n6.83\n2.40\n2.4\n5.20\n6.30\n7.93\n19.4\n\n\n\n\n\n\n\n\nQuestion 13\nWrite a code to produce the above summary for the esg_info data.frame, including descriptive statistics for each variable.\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nskim(esg_info)\n\n\n\n\n\n\nQuestion 14\nWhat code would you use to count the number of companies in each sector?\n\nesg_info |&gt; count(Sector)\nesg_info |&gt; count(Company_Name)\nesg_info |&gt; count(Company_Name, Sector)\nesg_info |&gt; count(Sector, Company_Name)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\n\n\n\n\n\n\nQuestion 15\nWhat is the median value of total_esg? Find this value from the summary of the esg_info data.frame.\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: 21.2\n\n\n\n\n\n\nQuestion 16\n\nWe are interested in companies whose overall ESG performance is relatively weak.\nTo achieve this, we create a new data.frame, a new data.frame, bottom25_esg, which includes only companies whose total_esg value is greater than or equal to the third quartile of total_esg variable.\n\n\nbottom25_esg &lt;- esg_info |&gt; \n  filter(total_esg &gt;= ___BLANK___)\n\n\nUsing the summary of the esg_info data.frame, find condition correctly fills in the BLANK to complete the code above:\n\n\n6.4\n7.08\n16.3\n21.2\n21.6\n26.1\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: f\n\n\n\n\n\n\nQuestion 17\n\nAdditionally, we are interested in companies with excellent environmental or governance performance, despite having weak overall ESG scores.\nTo achieve this, we create a new data.frame, bottom25_esg_filtered, which includes only companies whose environmental risk score is at most 3.95 or whose governance risk score is at most 5.2.\n\n\nbottom25_esg_filtered &lt;- esg_info |&gt; \n  filter(___BLANK___)\n\n\nWhich condition correctly fills in the BLANK to complete the code above?\n\n\nenvironmental &lt;= 3.95 | governance &lt;= 5.2\nenvironmental &lt;= 3.95 , governance &lt;= 5.2\nenvironmental &lt;= 3.95 & governance &lt;= 5.2\nenvironmental &lt;= 3.95 ! governance &lt;= 5.2\nBoth (b) and (c)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\n\n\n\n\n\n\nQuestion 18\nHow would you describe the relationship between environmental and governance using the bottom25_esg_filtered data.frame?\n\nTo identify leader companies, such as environmental leaders and governance leaders, some company names are added to such points in the plot.\nNote that it is NOT required to provide the code for adding these texts to the plot.\n\nComplete the code by filling in the blanks (1)-(4).\n\nggplot(data = ___(1)___,\n       mapping = aes(x = ___(2)___, \n                     y = ___(3)___)) +\n  geom_point(alpha = 0.5) +\n  ___(4)___()\n\n\n\n\n\n\n\nBlank (1)\n\nbottom25_esg_filtered\nbottom25_esg\nesg_info\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\n\n\n\n\n\n\nBlank (2)\n\nenvironmental\nsocial\ngovernance\ntotal_esg\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\n\n\n\n\n\n\nBlank (3)\n\nenvironmental\nsocial\ngovernance\ntotal_esg\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\n\n\n\n\n\n\nBlank (4)\n\ngeom_fit\ngeom_scatterplot\ngeom_smooth\ngeom_histogram\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\n\n\n\n\n\n\nEnvironmental Leaders\nWhich companies qualify as environmental leaders ‚Äî that is, companies with an environmental risk score below 2.5 whose plotted points lie below the gray ribbon in the figure?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nJPMorgan Chase, PNC Financial, Bank of America, AbbVie, and Ionis Pharmaceuticals\n\n\n\n\n\n\nGovernance Leaders\nWhich companies qualify as governance leaders ‚Äî that is, companies with an governance risk score below 10 whose plotted points lie below the gray ribbon in the figure?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nIonis Pharmaceuticals, HCA Healthcare, IAC, and Stericycle\n\n\n\n\n\n\nRelationship\nDescribe the overall relationship between environmental and governance, in the given plot.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nOverall, the governance risk score decreases as the environmental risk score increases up to about 10, after which it levels off and remains relatively constant.\nThis pattern suggests that among companies with weaker overall ESG performance, deterioration in environmental risk is associated with stronger governance up to a threshold, beyond which further changes in environmental risk have little additional correlation with governance risk.\n\n\n\n\n\n\n\nQuestion 19\nHow would you describe how the distribution of total_esg varies by sector (sector) using the bottom25_esg_filtered data.frame?\n\nNote that the sector categories are sorted by the median of total_esg in the plot.\n\nComplete the code by filling in the blanks.\n\nggplot(data = ___(1)___,\n       mapping = aes(___(2)___, \n                     y = ___(3)___)) +\n  ___(4)___() +\n  labs(y = \"Sector\")\n\n\n\n\n\n\n\nBlank (1)\n\nbottom25_esg_filtered\nbottom25_esg\nesg_info\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (2)\n\nx = total_esg\ny = total_esg\nx = environmental\ny = environmental\nx = social\ny = social\nx = governance\ny = governance\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\nfct_reorder(total_esg, sector)\nfct_reorder(environmental, total_esg)\nfct_reorder(total_esg, social)\nfct_reorder(governance, total_esg)\nfct_reorder(total_esg, controversy)\nfct_reorder(sector, total_esg)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nf\n\n\n\n\n\n\nBlank (4)\n\ngeom_bar\ngeom_box\ngeom_boxplot\ngeom_histogram\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-20",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-20",
    "title": "Midterm Exam II",
    "section": "Question 20",
    "text": "Question 20\n \nFor Question 20, you will use the following R packages and a data.frame named chess_top4, which contains information about chess games played by four of the world‚Äôs top online chess players during a special event called ‚ÄúTitled Tuesday‚Äù on chess.com. These games were played in a format where each player has 3 minutes to make all their moves, with 1 second added to their clock after each move. The data includes games from October 2022 to October 2024 played only among the following four players:\n\nMagnus Carlsen\nHikaru Nakamura\nAlireza Firouzja\nDaniel Naroditsky\n\nNote: Titled Tuesday is a weekly event held every Tuesday on chess.com, where titled chess players (such as Grandmasters and International Masters) compete in online tournaments.\n\nlibrary(tidyverse)\nchess_top4 &lt;- read_csv(\"https://bcdanl.github.io/data/chess_titled_tuesday.csv\")\n\nThe first 15 observations in the chess_top4 data.frame are displayed below:\n\n\n\n\n\nDate\nWhite\nBlack\nResult\n\n\n\n\n2022-10-11\nHikaru Nakamura\nMagnus Carlsen\nWhite Wins\n\n\n2022-10-18\nHikaru Nakamura\nAlireza Firouzja\nDraw\n\n\n2022-10-25\nDaniel Naroditsky\nAlireza Firouzja\nDraw\n\n\n2022-11-08\nHikaru Nakamura\nAlireza Firouzja\nBlack Wins\n\n\n2022-12-13\nAlireza Firouzja\nHikaru Nakamura\nDraw\n\n\n2022-12-20\nHikaru Nakamura\nAlireza Firouzja\nWhite Wins\n\n\n2022-12-20\nMagnus Carlsen\nHikaru Nakamura\nDraw\n\n\n2023-01-03\nDaniel Naroditsky\nHikaru Nakamura\nBlack Wins\n\n\n2023-01-03\nHikaru Nakamura\nMagnus Carlsen\nWhite Wins\n\n\n2023-01-24\nHikaru Nakamura\nMagnus Carlsen\nWhite Wins\n\n\n2023-02-28\nAlireza Firouzja\nMagnus Carlsen\nDraw\n\n\n2023-02-28\nHikaru Nakamura\nAlireza Firouzja\nDraw\n\n\n2023-02-28\nHikaru Nakamura\nMagnus Carlsen\nDraw\n\n\n2023-02-28\nMagnus Carlsen\nHikaru Nakamura\nDraw\n\n\n2023-03-14\nHikaru Nakamura\nAlireza Firouzja\nWhite Wins\n\n\n\n\n\n\nThe chess_top4 data.frame contains 70 observations and 4 variables, representing 70 unique chess games.\n\n\nDescription of Variables in chess_top4:\n\nDate: The date when the game was played.\nWhite: The name of the player who played with the white pieces.\nBlack: The name of the player who played with the black pieces.\nResult: The outcome of the game, which can be one of the following:\n\n‚ÄúWhite Wins‚Äù (the player with the white pieces won the game)\n‚ÄúBlack Wins‚Äù (the player with the black pieces won the game)\n‚ÄúDraw‚Äù (the game ended in a tie)\n\n\nQuestion 20 is about a ggplot code to visualize how the distribution of Result varies among these top 4 chess players.\n\nPart 1\nComplete the code by filling in the blanks to replicate the given plot.\n\nThe White player is displayed on the vertical axis.\nThe Black player is labeled at the top of each panel.\n\n\nggplot(data = chess_top4,\n       mapping = aes(___(1)___,\n                     fill = ___(2)___)) +\n  geom_bar(___(3)___) +\n  facet_wrap(___(4)___, ncol = 1) +\n  labs(x = \"Proportion\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = White\ny = White\nx = Black\ny = Black\nx = Proportion\ny = Proportion\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nchess_top4\nWhite\nBlack\nResult\ncount\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nBlank (3)\n\nposition = \"stack\"\nposition = \"fill\"\nposition = \"dodge\"\nLeaving (3) empty\nBoth a and d\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (4)\n\nWhite\n~White\nBlack\n~Black\nPlayer\n~Player\nboth a and b\nboth c and d\nboth e and f\nboth b and f\nboth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nPart 2\nComplete the code by filling in the blanks to replicate the given plot.\n\nThe White player is displayed on the vertical axis.\nThe Black player is labeled at the top of each panel.\n\n\nggplot(data = chess_top4,\n       mapping = aes(___(1)___,\n                     fill = ___(2)___)) +\n  geom_bar(___(3)___) +\n  facet_wrap(___(4)___, ncol = 1)\n\n\n\n\n\n\n\nBlank (1)\n\nx = White\ny = White\nx = Black\ny = Black\nx = count\ny = count\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nchess_top4\nWhite\nBlack\nResult\ncount\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nBlank (3)\n\nposition = \"stack\"\nposition = \"fill\"\nposition = \"dodge\"\nLeaving (3) empty\nBoth a and d\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\n\n\n\n\n\n\nBlank (4)\n\nWhite\n~White\nBlack\n~Black\nPlayer\n~Player\nboth a and b\nboth c and d\nboth e and f\nboth b and f\nboth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nPart 3\nComplete the code by filling in the blanks to replicate the given plot.\n\nThe White player is displayed on the vertical axis.\nThe Black player is labeled at the top of each panel.\n\n\nggplot(data = chess_top4,\n       mapping = aes(___(1)___,\n                     fill = ___(2)___)) +\n  geom_bar(___(3)___) +\n  facet_wrap(___(4)___, ncol = 1)\n\n\n\n\n\n\n\nBlank (1)\n\nx = White\ny = White\nx = Black\ny = Black\nx = count\ny = count\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nchess_top4\nWhite\nBlack\nResult\ncount\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nBlank (3)\n\nposition = \"stack\"\nposition = \"fill\"\nposition = \"dodge\"\nLeaving (3) empty\nBoth a and d\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (4)\n\nWhite\n~White\nBlack\n~Black\nPlayer\n~Player\nboth a and b\nboth c and d\nboth e and f\nboth b and f\nboth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nPart 4 - Magnus Carlsen vs.¬†Hikaru Nakamura in the Titled Tuesday\nWho had more wins in the games where Magnus Carlsen played with the white pieces and Hikaru Nakamura played with the black pieces in the Titled Tuesday?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nMagnus Carlsen\n\n\n\n\nWho had more wins in the games where Hikaru Nakamura played with the white pieces and Magnus Carlsen played with the black pieces in the Titled Tuesday?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nHikaru Nakamura\n\n\n\n\nWho won more games in the encounters between Magnus Carlsen and Hikaru Nakamura in the Titled Tuesday?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThey had an equal number of wins."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-21",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-21",
    "title": "Midterm Exam II",
    "section": "Question 21",
    "text": "Question 21\nExplain the ‚ÄúConnection Principle‚Äù in the context of line charts and why it is useful for visualizing time-series data.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThe Connection Principle states that points in a line chart should be visually connected when the data represent a meaningful sequence, such as time. This connection helps viewers naturally perceive trends, patterns, growth, and cycles across periods. It is especially useful in time-series data because it reinforces the idea of continuity and change over time rather than treating each observation as isolated."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-22",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-22",
    "title": "Midterm Exam II",
    "section": "Question 22",
    "text": "Question 22\nHow does data storytelling bridge the gap between data and insights?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nData Storytelling bridges the gap between data and insight by integrating descriptive statistics, data transformation, visualization, and narration within the appropriate audience context to communicate findings effectively and support data-informed decision-making."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-23",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-23",
    "title": "Midterm Exam II",
    "section": "Question 23",
    "text": "Question 23\nProvide two main reasons why the log transformation of a variable can be useful.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTwo main reasons for using a log transformation are:\n\nIt helps reduce skewness in highly right-skewed data, making the distribution more symmetric and the variation easier to see.\n\nIt allows us to interpret changes in percentage terms, which is especially useful for growth rates and economic variables such as income, GDP, stock price, or housing price."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-24",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-24",
    "title": "Midterm Exam II",
    "section": "Question 24",
    "text": "Question 24\nProvide at least three techniques to make data visualization more colorblind-friendly.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTo make visualizations more accessible and colorblind-friendly, consider:\n\nUsing colorblind-friendly color palettes\nAdding non-color cues like shape to scatterplots or linetype to line charts\nIncluding additional visual cues to highlight important information (e.g., annotations or labels)\nEnsuring strong contrast between colors and between the foreground and background so that elements remain distinguishable."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-25",
    "href": "danl-ex/danl-101-exam-2-ver-A-fall-2025.html#question-25",
    "title": "Midterm Exam II",
    "section": "Question 25",
    "text": "Question 25\nFor each of the workplaces represented by our three alumni guest speakers, explain how generative AI is used in their day-to-day work.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAcross the three alumni workplaces, generative AI is integrated into daily workflows in different but complementary ways.\nAt the analytics and engineering‚Äìfocused workplace, many employees (roughly 60‚Äì80%) use AI assistants such as Copilot or Claude to support coding, debugging, and data processing. AI significantly speeds up routine analytical tasks, but all outputs still require human review, meaning AI augments rather than replaces analysts.\nFor a traditional data analyst role, generative AI is commonly used to assist with SQL coding, data summarization, and report drafting. Analysts rely on AI to improve efficiency, but data sensitivity and responsible AI use are essential, so such tools are typically deployed only within secure internal environments.\nAt the policy and government-related workplace (e.g., the Federal Reserve), the use of public AI tools like ChatGPT is prohibited due to strict data confidentiality rules. Instead, analysts rely on approved internal systems and traditional analytical tools to protect sensitive economic and financial information.\nTogether, these examples show how generative AI is widely used to increase productivity, while security, privacy, and human oversight remain central across all workplaces."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html",
    "title": "Midterm Exam II",
    "section": "",
    "text": "Which of the following is NOT listed as a key characteristic of a Data Warehouse?\n\nIt integrates data from multiple sources (internal and external).\nIt is designed primarily for real-time transaction processing.\nIt is schema-based, requiring data to fit a predefined structure.\nIt often includes 5+ years of historical, archived data.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b\nA data warehouse is designed mainly for analytics and historical querying, not for real-time transaction processing.\n\n\n\n\n\n\n\nWhen the distribution of a variable has a single peak and is positively skewed (i.e., having a long right tail), which of the following is correct?\n\nMedian = Mean = Mode\nMedian &lt; Mode &lt; Mean\nMean &lt; Median &lt; Mode\nMode &lt; Median &lt; Mean\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: d\nFor a positively skewed distribution (long right tail), the order is:\nMode (at the peak) &lt; Median &lt; Mean (pulled right by large values).\n\n\n\n\n\n\n\nWhat is NOT an essential component in ggplot() data visualization?\n\nData frames\nGeometric objects\nFacets\nAesthetic attributes\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\nFacets are useful but optional. You can build a valid ggplot without them.\n\n\n\n\n\n\n\n____(1)____ does not necessarily imply ____(2)____\n\n\nCorrelation; (2) causation\n\n\nCausation; (2) correlation\n\n\nCorrelation; (2) correlation\n\n\nCausation; (2) causation\n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\nThe classic warning: correlation does not imply causation.\n\n\n\n\n\n\n\nIn the context of the lecture, which of the following correctly interprets a change in log-transformed GDP per capita and its meaning for GDP per capita?\n\nA 0.01 increase in log(GDP per capita) corresponds to a 1% increase in GDP per capita.\nA 1-unit increase in log(GDP per capita) corresponds to a 1% increase in GDP per capita.\nA one-unit increase in GDP per capita means an 8.4% increase in GDP per capita.\nBoth (a) and (c) are correct.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\nFor small changes, a change of 0.01 in log(GDP per capita) is approximately a 1% change in GDP per capita.\n\n\n\n\n\n\n\nWhich ‚ÄúV‚Äù of Big Data is most directly about whether the data is accurate and trustworthy?\n\nValue\nVelocity\nVariety\nVeracity\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: d\nVeracity is about data quality, accuracy, and trustworthiness."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-1",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-1",
    "title": "Midterm Exam II",
    "section": "",
    "text": "Which of the following is NOT listed as a key characteristic of a Data Warehouse?\n\nIt integrates data from multiple sources (internal and external).\nIt is designed primarily for real-time transaction processing.\nIt is schema-based, requiring data to fit a predefined structure.\nIt often includes 5+ years of historical, archived data.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b\nA data warehouse is designed mainly for analytics and historical querying, not for real-time transaction processing."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-2",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-2",
    "title": "Midterm Exam II",
    "section": "",
    "text": "When the distribution of a variable has a single peak and is positively skewed (i.e., having a long right tail), which of the following is correct?\n\nMedian = Mean = Mode\nMedian &lt; Mode &lt; Mean\nMean &lt; Median &lt; Mode\nMode &lt; Median &lt; Mean\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: d\nFor a positively skewed distribution (long right tail), the order is:\nMode (at the peak) &lt; Median &lt; Mean (pulled right by large values)."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-3",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-3",
    "title": "Midterm Exam II",
    "section": "",
    "text": "What is NOT an essential component in ggplot() data visualization?\n\nData frames\nGeometric objects\nFacets\nAesthetic attributes\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c\nFacets are useful but optional. You can build a valid ggplot without them."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-4",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-4",
    "title": "Midterm Exam II",
    "section": "",
    "text": "____(1)____ does not necessarily imply ____(2)____\n\n\nCorrelation; (2) causation\n\n\nCausation; (2) correlation\n\n\nCorrelation; (2) correlation\n\n\nCausation; (2) causation\n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\nThe classic warning: correlation does not imply causation."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-5",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-5",
    "title": "Midterm Exam II",
    "section": "",
    "text": "In the context of the lecture, which of the following correctly interprets a change in log-transformed GDP per capita and its meaning for GDP per capita?\n\nA 0.01 increase in log(GDP per capita) corresponds to a 1% increase in GDP per capita.\nA 1-unit increase in log(GDP per capita) corresponds to a 1% increase in GDP per capita.\nA one-unit increase in GDP per capita means an 8.4% increase in GDP per capita.\nBoth (a) and (c) are correct.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a\nFor small changes, a change of 0.01 in log(GDP per capita) is approximately a 1% change in GDP per capita."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-6",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-6",
    "title": "Midterm Exam II",
    "section": "",
    "text": "Which ‚ÄúV‚Äù of Big Data is most directly about whether the data is accurate and trustworthy?\n\nValue\nVelocity\nVariety\nVeracity\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: d\nVeracity is about data quality, accuracy, and trustworthiness."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-7",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-7",
    "title": "Midterm Exam II",
    "section": "Question 7",
    "text": "Question 7\n____________________ describes how the values of a variable are spread or grouped within a dataset, while ____________________ is the tendency of a variable‚Äôs values to differ from one measurement to another.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFirst blank: distribution\nSecond blank: variability"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-8",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-8",
    "title": "Midterm Exam II",
    "section": "Question 8",
    "text": "Question 8\nIn the context of time trend analysis, a fitted curve is often added to a line chart to help smooth out ____________________ to reveal the overall pattern.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nshort-term fluctuations"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-9",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-9",
    "title": "Midterm Exam II",
    "section": "Question 9",
    "text": "Question 9\nThe gg in ggplot stands for ____________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nGrammar of Graphics"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-10",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-10",
    "title": "Midterm Exam II",
    "section": "Question 10",
    "text": "Question 10\nUsing ____________________‚Äîa machine learning method‚Äîthe geom_smooth() visualizes the ____________________ value of the y variable for a given value of the x variable. The grey ribbon around the curve illustrates the ____________________ surrounding the estimated curve.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nUsing regression ‚Äî a machine learning method ‚Äî the geom_smooth() visualizes the predicted value of the y variable for a given value of the x variable. The grey ribbon around the curve illustrates the uncertainty surrounding the estimated curve."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-11",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-11",
    "title": "Midterm Exam II",
    "section": "Question 11",
    "text": "Question 11\nWhen observing a histogram, if the distribution has two distinct peaks, it is described as ____________________; whereas a distribution where values are relatively equal across the range is described as ____________________.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFirst blank: bimodal\nSecond blank: uniform"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-12",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-12",
    "title": "Midterm Exam II",
    "section": "Question 12",
    "text": "Question 12\nWhen visualizing the distribution of a single numerical variable using geom_histogram(), you must choose between specifying the number of ____________________ or the ____________________ of the intervals. You cannot specify both simultaneously.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFirst blank: bins\nSecond blank: width"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#questions-13-19",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#questions-13-19",
    "title": "Midterm Exam II",
    "section": "Questions 13-19",
    "text": "Questions 13-19\nFor Questions 13-19, consider the following R packages and the data.frame, nwsl_player_stats, containing individual player statistics for the National Women‚Äôs Soccer League (NWSL) in the 2022 season:\n\nlibrary(tidyverse)\nlibrary(skimr)\nnwsl_player_stats &lt;- read_csv(\"https://bcdanl.github.io/data/nwsl_player_stats.csv\")\n\n\nThe nwsl_player_stats data.frame is with 314 observations and 13 variables.\n\n\n\nThe first 5 observations in the nwsl_player_stats data.frame are displayed below:\n\n\n\n\n\n\nplayer\nnation\npos\nsquad\nage\nmp\nstarts\nmin\n\n\n\n\nM. A. Vignola\nus USA\nMFFW\nAngel City\n23\n2\n0\n18\n\n\nMichaela Abam\ncm CMR\nFW\nDash\n24\n12\n3\n273\n\n\nKerry Abello\nus USA\nFWMF\nPride\n22\n21\n12\n1042\n\n\nJillienne Aguilera\nNA\nDFMF\nRed Stars\nNA\n17\n5\n580\n\n\nTinaya Alexander\neng ENG\nFWMF\nSpirit\n22\n9\n1\n167\n\n\n\n\n\n\n\n\nplayer\nnation\npos\nsquad\nxGp90\nxAp90\nxGxAp90\n\n\n\n\nM. A. Vignola\nus USA\nMFFW\nAngel City\n0.00\n0.00\n0.00\n\n\nMichaela Abam\ncm CMR\nFW\nDash\n0.26\n0.10\n0.36\n\n\nKerry Abello\nus USA\nFWMF\nPride\n0.16\n0.05\n0.20\n\n\nJillienne Aguilera\nNA\nDFMF\nRed Stars\n0.05\n0.04\n0.09\n\n\nTinaya Alexander\neng ENG\nFWMF\nSpirit\n0.58\n0.03\n0.62\n\n\n\n\n\n\n\n\nplayer\nnation\npos\nsquad\nnpxGp90\nnpxGxAp90\n\n\n\n\nM. A. Vignola\nus USA\nMFFW\nAngel City\n0.00\n0.00\n\n\nMichaela Abam\ncm CMR\nFW\nDash\n0.26\n0.36\n\n\nKerry Abello\nus USA\nFWMF\nPride\n0.16\n0.20\n\n\nJillienne Aguilera\nNA\nDFMF\nRed Stars\n0.05\n0.09\n\n\nTinaya Alexander\neng ENG\nFWMF\nSpirit\n0.16\n0.19\n\n\n\n\n\n\nDescription of Variables in nwsl_player_stats:\n\nplayer: Player name\nnation: Player home country\npos: Player position (e.g., GK, FW, MF, etc.)\nsquad: Player team\nage: Age of player\nmp: Matches played\nstarts: Number of matches in which player started the game\nmin: Total minutes played in the season\nxGp90: Expected goals per ninety minutes\n\nxG is simply the probability of scoring a goal from a given spot on the field when a shot is taken.\n\nxAp90: Expected assists per ninety minutes\n\nxA is simply the probability of assisting a goal by delivering a pass that creates a scoring opportunity.\n\nxGxAp90: Expected goals plus assists per ninety minutes\nnpxGp90: Expected goals minus penalty goals per ninety minutes\nnpxGxAp90: Expected goals plus assists minus penalty goals per ninety minutes\n\nA player who is consistently achieving a high number of xG (or xA) will be one who is getting into a good position consistently on the field. Coaches and scouts can use this to evaluate whether a player is exceedingly (un)lucky over a given number of games, and this will help in evaluating that player‚Äôs offensive skills beyond simple counts.\n\nThe followings are the summary of the nwsl_player_stats data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nnwsl_player_stats\n\n\nNumber of rows\n314\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n9\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\nn_missing\nmin\nmax\nempty\nn_unique\n\n\n\n\nplayer\n0\n5\n26\n0\n303\n\n\nnation\n17\n6\n7\n0\n29\n\n\npos\n0\n2\n4\n0\n10\n\n\nsquad\n0\n4\n10\n0\n12\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nage\n15\n25.98\n3.96\n16\n23.00\n25.00\n28.00\n38.00\n\n\nmp\n0\n12.61\n6.95\n1\n6.00\n14.00\n19.00\n22.00\n\n\nstarts\n0\n9.25\n7.31\n0\n2.00\n9.00\n16.00\n22.00\n\n\nmin\n0\n831.81\n631.52\n1\n234.00\n743.50\n1398.00\n1980.00\n\n\nxGp90\n2\n0.13\n0.16\n0\n0.01\n0.06\n0.20\n0.77\n\n\nxAp90\n2\n0.10\n0.47\n0\n0.01\n0.05\n0.11\n8.26\n\n\nxGxAp90\n2\n0.23\n0.50\n0\n0.04\n0.13\n0.32\n8.26\n\n\nnpxGp90\n2\n0.12\n0.14\n0\n0.01\n0.06\n0.18\n0.77\n\n\nnpxGxAp90\n2\n0.22\n0.50\n0\n0.04\n0.13\n0.30\n8.26\n\n\n\n\n\n\n\nQuestion 13\nWrite a code to produce the above summary for the nwsl_player_stats data.frame, including descriptive statistics for each variable.\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nskim(nwsl_player_stats)\n\n\n\n\n\n\nQuestion 14\nWhat code would you use to count the number of players in each team?\n\nnwsl_player_stats |&gt; count(player)\nnwsl_player_stats |&gt; count(nation)\nnwsl_player_stats |&gt; count(pos)\nnwsl_player_stats |&gt; count(squad)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nQuestion 15\nWhat is the median value of starts? Find this value from the summary of the nwsl_player_stats data.frame.\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n9\n\n\n\n\n\n\nQuestion 16\n\nWe are interested in players who score or assist on a goal.\nTo achieve this, we create a new data.frame, a new data.frame, nwsl_nonGK_stats, which includes only players who are NOT a goal keeper from the nwsl_player_stats data.frame.\n\n\nnwsl_nonGK_stats &lt;- nwsl_player_stats |&gt; \n  filter(___BLANK___)\n\n\nThe pos value is ‚ÄúGK‚Äù for a goal keeper. Which condition correctly fills in the BLANK to complete the code above?\n\n\n!is.na(pos)\nis.na(pos)\npos != \"GK\"\npos == \"GK\"\nBoth a and c\nBoth b and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nQuestion 17\n\nAdditionally, we are interested in non-goalkeeper players who played matches consistently throughout the season.\nTo achieve this, we create a new data.frame, nwsl_nonGK_stats_filtered, which includes only non GK players who played in at least 10 matches (mp) and started in at least 7 matches (starts) .\n\n\nnwsl_nonGK_stats_filtered &lt;- nwsl_nonGK_stats |&gt; \n  filter(___BLANK___)\n\n\nWhich condition correctly fills in the BLANK to complete the code above?\n\n\nmp &gt; 10 | starts &gt; 7\nmp &gt;= 10 | starts &gt;= 7\nmp &gt; 10 & starts &gt; 7\nmp &gt;= 10 & starts &gt;= 7\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\nWe want players who meet both conditions: played in at least 10 matches (mp &gt;= 10) and started in at least 7 matches (starts &gt;= 7). The logical operator & ensures both conditions are met.\n\n\n\n\n\n\nQuestion 18\nHow would you describe the relationship between age and xGp90 (expected goals per ninety minutes) using the nwsl_nonGK_stats_filtered data.frame?\n\nTo identify outlier players, such as star players and young players, some player names are added to such points in the plot.\nNote that it is NOT required to provide the code for adding these texts to the plot.\n\nComplete the code by filling in the blanks (1)-(4).\n\nggplot(data = ___(1)___,\n       mapping = aes(x = ___(2)___, \n                     y = ___(3)___)) +\n  geom_point(alpha = 0.5) +\n  ___(4)___()\n\n\n\n\n\n\n\nBlank (1)\n\nnwsl_nonGK_stats_filtered\nnwsl_nonGK_stats\nnwsl_player_stats\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (2)\n\nage\nxGxAp90\nxGp90\nxAp90\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\nage\nxGxAp90\nxGp90\nxAp90\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (4)\n\ngeom_fit\ngeom_scatterplot\ngeom_smooth\ngeom_histogram\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nYoung Players\nWho are the young players under the age of 20 in the given plot?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nOlivia Moultrie and Trinity Rodman\n\n\n\n\n\n\nStar Players\nWho are the star players whose xGp90 is greater than 0.6 in the given plot?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nSophia Smith and Alex Morgan\n\n\n\n\n\n\nRelationship\nDescribe the overall relationship between age and xGp90 (expected goal per ninety minutes).\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nOverall, xGp90 decreases as age increases up to about 24, after which it levels off and remains relatively constant.\nThis suggests that younger players tend to experience a steeper decline in xGp90 with age early on, while changes become much smaller after the mid-20s.\n\n\n\n\n\n\n\nQuestion 19\nHow would you describe how the distribution of xAp90 (expected assist per ninety minutes) varies by teams (squad) using the nwsl_nonGK_stats_filtered data.frame?\n\nNote that the squad categories are sorted by the median of xAp90 in the plot.\n\nComplete the code by filling in the blanks.\n\nggplot(data = ___(1)___,\n       mapping = aes(___(2)___, \n                     y = ___(3)___)) +\n  ___(4)___() +\n  labs(y = \"NWSL Teams\")\n\n\n\n\n\n\n\nBlank (1)\n\nnwsl_nonGK_stats_filtered\nnwsl_nonGK_stats\nnwsl_player_stats\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (2)\n\nx = squad\ny = squad\nx = xGxAp90\ny = xGxAp90\nx = xGp90\ny = xGp90\nx = xAp90\ny = xAp90\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ng\n\n\n\n\n\n\nBlank (3)\n\nfct_reorder(squad, xAp90)\nfct_reorder(xAp90, squad)\nfct_reorder(squad, xGp90)\nfct_reorder(xGp90, squad)\nfct_reorder(squad, xGxAp90)\nfct_reorder(xGxAp90, squad)\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (4)\n\ngeom_bar\ngeom_box\ngeom_boxplot\ngeom_histogram\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc"
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-20",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-20",
    "title": "Midterm Exam II",
    "section": "Question 20",
    "text": "Question 20\n \nFor Question 20, you will use the following R packages and a data.frame named chess_top4, which contains information about chess games played by four of the world‚Äôs top online chess players during a special event called ‚ÄúTitled Tuesday‚Äù on chess.com. These games were played in a format where each player has 3 minutes to make all their moves, with 1 second added to their clock after each move. The data includes games from October 2022 to October 2024 played only among the following four players:\n\nMagnus Carlsen\nHikaru Nakamura\nAlireza Firouzja\nDaniel Naroditsky\n\nNote: Titled Tuesday is a weekly event held every Tuesday on chess.com, where titled chess players (such as Grandmasters and International Masters) compete in online tournaments.\n\nlibrary(tidyverse)\nchess_top4 &lt;- read_csv(\"https://bcdanl.github.io/data/chess_titled_tuesday.csv\")\n\nThe first 15 observations in the chess_top4 data.frame are displayed below:\n\n\n\n\n\nDate\nWhite\nBlack\nResult\n\n\n\n\n2022-10-11\nHikaru Nakamura\nMagnus Carlsen\nWhite Wins\n\n\n2022-10-18\nHikaru Nakamura\nAlireza Firouzja\nDraw\n\n\n2022-10-25\nDaniel Naroditsky\nAlireza Firouzja\nDraw\n\n\n2022-11-08\nHikaru Nakamura\nAlireza Firouzja\nBlack Wins\n\n\n2022-12-13\nAlireza Firouzja\nHikaru Nakamura\nDraw\n\n\n2022-12-20\nHikaru Nakamura\nAlireza Firouzja\nWhite Wins\n\n\n2022-12-20\nMagnus Carlsen\nHikaru Nakamura\nDraw\n\n\n2023-01-03\nDaniel Naroditsky\nHikaru Nakamura\nBlack Wins\n\n\n2023-01-03\nHikaru Nakamura\nMagnus Carlsen\nWhite Wins\n\n\n2023-01-24\nHikaru Nakamura\nMagnus Carlsen\nWhite Wins\n\n\n2023-02-28\nAlireza Firouzja\nMagnus Carlsen\nDraw\n\n\n2023-02-28\nHikaru Nakamura\nAlireza Firouzja\nDraw\n\n\n2023-02-28\nHikaru Nakamura\nMagnus Carlsen\nDraw\n\n\n2023-02-28\nMagnus Carlsen\nHikaru Nakamura\nDraw\n\n\n2023-03-14\nHikaru Nakamura\nAlireza Firouzja\nWhite Wins\n\n\n\n\n\n\nThe chess_top4 data.frame contains 70 observations and 4 variables, representing 70 unique chess games.\n\n\nDescription of Variables in chess_top4:\n\nDate: The date when the game was played.\nWhite: The name of the player who played with the white pieces.\nBlack: The name of the player who played with the black pieces.\nResult: The outcome of the game, which can be one of the following:\n\n‚ÄúWhite Wins‚Äù (the player with the white pieces won the game)\n‚ÄúBlack Wins‚Äù (the player with the black pieces won the game)\n‚ÄúDraw‚Äù (the game ended in a tie)\n\n\nQuestion 20 is about a ggplot code to visualize how the distribution of Result varies among these top 4 chess players.\n\nPart 1\nComplete the code by filling in the blanks to replicate the given plot.\n\nThe White player is displayed on the vertical axis.\nThe Black player is labeled at the top of each panel.\n\n\nggplot(data = chess_top4,\n       mapping = aes(___(1)___,\n                     fill = ___(2)___)) +\n  geom_bar(___(3)___) +\n  facet_wrap(___(4)___, ncol = 1) +\n  labs(x = \"Proportion\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = White\ny = White\nx = Black\ny = Black\nx = Proportion\ny = Proportion\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nchess_top4\nWhite\nBlack\nResult\ncount\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nBlank (3)\n\nposition = \"stack\"\nposition = \"fill\"\nposition = \"dodge\"\nLeaving (3) empty\nBoth a and d\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (4)\n\nWhite\n~White\nBlack\n~Black\nPlayer\n~Player\nboth a and b\nboth c and d\nboth e and f\nboth b and f\nboth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nPart 2\nComplete the code by filling in the blanks to replicate the given plot.\n\nThe White player is displayed on the vertical axis.\nThe Black player is labeled at the top of each panel.\n\n\nggplot(data = chess_top4,\n       mapping = aes(___(1)___,\n                     fill = ___(2)___)) +\n  geom_bar(___(3)___) +\n  facet_wrap(___(4)___, ncol = 1)\n\n\n\n\n\n\n\nBlank (1)\n\nx = White\ny = White\nx = Black\ny = Black\nx = count\ny = count\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nchess_top4\nWhite\nBlack\nResult\ncount\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nBlank (3)\n\nposition = \"stack\"\nposition = \"fill\"\nposition = \"dodge\"\nLeaving (3) empty\nBoth a and d\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\n\n\n\n\n\n\nBlank (4)\n\nWhite\n~White\nBlack\n~Black\nPlayer\n~Player\nboth a and b\nboth c and d\nboth e and f\nboth b and f\nboth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nPart 3\nComplete the code by filling in the blanks to replicate the given plot.\n\nThe White player is displayed on the vertical axis.\nThe Black player is labeled at the top of each panel.\n\n\nggplot(data = chess_top4,\n       mapping = aes(___(1)___,\n                     fill = ___(2)___)) +\n  geom_bar(___(3)___) +\n  facet_wrap(___(4)___, ncol = 1)\n\n\n\n\n\n\n\nBlank (1)\n\nx = White\ny = White\nx = Black\ny = Black\nx = count\ny = count\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nchess_top4\nWhite\nBlack\nResult\ncount\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nBlank (3)\n\nposition = \"stack\"\nposition = \"fill\"\nposition = \"dodge\"\nLeaving (3) empty\nBoth a and d\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (4)\n\nWhite\n~White\nBlack\n~Black\nPlayer\n~Player\nboth a and b\nboth c and d\nboth e and f\nboth b and f\nboth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nPart 4 - Magnus Carlsen vs.¬†Hikaru Nakamura in the Titled Tuesday\nWho had more wins in the games where Magnus Carlsen played with the white pieces and Hikaru Nakamura played with the black pieces in the Titled Tuesday?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nMagnus Carlsen\n\n\n\n\nWho had more wins in the games where Hikaru Nakamura played with the white pieces and Magnus Carlsen played with the black pieces in the Titled Tuesday?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nHikaru Nakamura\n\n\n\n\nWho won more games in the encounters between Magnus Carlsen and Hikaru Nakamura in the Titled Tuesday?\nAnswer: ______________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nThey had an equal number of wins."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-21",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-21",
    "title": "Midterm Exam II",
    "section": "Question 21",
    "text": "Question 21\nWhat are the advantage and disadvantage of using the scales option in ggplot2 when creating faceted plots?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nAdvantages:\n\nCustomized Scales per Facet: Using scales = \"free\" (or \"free_x\", \"free_y\") allows each facet to have its own axis scales. This can make patterns within each facet more visible, especially when the data ranges vary significantly between facets.\n\nDisadvantages:\n\nDifficulty in Comparison: When scales are free, comparing values across facets becomes challenging because the axes are not standardized. Viewers might misinterpret the data, thinking that similar bar heights represent similar values, even if the scales differ."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-22",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-22",
    "title": "Midterm Exam II",
    "section": "Question 22",
    "text": "Question 22\nHow does data storytelling bridge the gap between data and insights?\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nData Storytelling bridges the gap between data and insight by integrating descriptive statistics, data transformation, visualization, and narration within the appropriate audience context to communicate findings effectively and support data-informed decision-making."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-23",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-23",
    "title": "Midterm Exam II",
    "section": "Question 23",
    "text": "Question 23\nProvide two main reasons why the log transformation of a variable can be useful.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTwo main reasons for using a log transformation are:\n\nIt helps reduce skewness in highly right-skewed data, making the distribution more symmetric and the variation easier to see.\n\nIt allows us to interpret changes in percentage terms, which is especially useful for growth rates and economic variables such as income, GDP, stock price, or housing price."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-24",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-24",
    "title": "Midterm Exam II",
    "section": "Question 24",
    "text": "Question 24\nProvide at least three techniques to make data visualization more colorblind-friendly.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTo make visualizations more accessible and colorblind-friendly, consider:\n\nUsing colorblind-friendly color palettes\nAdding non-color cues like shape to scatterplots or linetype to line charts\nIncluding additional visual cues to highlight important information (e.g., annotations or labels)\nEnsuring strong contrast between colors and between the foreground and background so that elements remain distinguishable."
  },
  {
    "objectID": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-25",
    "href": "danl-ex/danl-101-exam-2-ver-B-fall-2025.html#question-25",
    "title": "Midterm Exam II",
    "section": "Question 25",
    "text": "Question 25\nFor each of the workplaces represented by our three alumni guest speakers, explain how generative AI is used in their day-to-day work.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAcross the three alumni workplaces, generative AI is integrated into daily workflows in different but complementary ways.\nAt the analytics and engineering‚Äìfocused workplace, many employees (roughly 60‚Äì80%) use AI assistants such as Copilot or Claude to support coding, debugging, and data processing. AI significantly speeds up routine analytical tasks, but all outputs still require human review, meaning AI augments rather than replaces analysts.\nFor a traditional data analyst role, generative AI is commonly used to assist with SQL coding, data summarization, and report drafting. Analysts rely on AI to improve efficiency, but data sensitivity and responsible AI use are essential, so such tools are typically deployed only within secure internal environments.\nAt the policy and government-related workplace (e.g., the Federal Reserve), the use of public AI tools like ChatGPT is prohibited due to strict data confidentiality rules. Instead, analysts rely on approved internal systems and traditional analytical tools to protect sensitive economic and financial information.\nTogether, these examples show how generative AI is widely used to increase productivity, while security, privacy, and human oversight remain central across all workplaces."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#what-we-learned-this-semester",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#what-we-learned-this-semester",
    "title": "Lecture 10",
    "section": "üìò What We Learned This Semester",
    "text": "üìò What We Learned This Semester\n\nIntroduction to Data Analytics and Its Tools\nSports Analytics\nBusiness Intelligence\nIntroduction to Generative AI\nR Basics and Descriptive Statistics\nData Transformation with R\nBig Data and the Modern Data Infrastructure\nCareer Pathways in Data Analytics and Beyond\nData Visualization with R\nData Storytelling Project\nGenerative AI for Data Analysis"
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#student-course-evaluation-sce",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#student-course-evaluation-sce",
    "title": "Lecture 10",
    "section": "üìù Student Course Evaluation (SCE)",
    "text": "üìù Student Course Evaluation (SCE)\n\n\n\n\nI have made every effort to enhance your learning experience in this course.\n\n\n\nYour feedback is extremely valuable and helps improve future classes.\n\n\n\nI sincerely encourage your participation in the Student Course Evaluation (SCE).\n\n\n\n\n\n\n‚úÖ Please Take 10 Minutes Now to Complete the SCE\n\n\n\nOn your laptop, follow these steps to access the SCE for DANL 101:\n\nLog in to the SCE Survey Portal\nClick on ‚ÄúSurveys‚Äù\nSelect DANL 101 and complete the evaluation\n\n\n\n\nThank you for your time and thoughtful feedback."
  },
  {
    "objectID": "danl-lec/danl-101-lec-10-2025-1105.html#student-course-evaluation-sce-1",
    "href": "danl-lec/danl-101-lec-10-2025-1105.html#student-course-evaluation-sce-1",
    "title": "Lecture 10",
    "section": "üìù Student Course Evaluation (SCE)",
    "text": "üìù Student Course Evaluation (SCE)\n\n\nI have made every effort to enhance your learning experience in this course.\nYour feedback is extremely valuable and helps improve future classes.\nI sincerely encourage your participation in the Student Course Evaluation (SCE).\n\n\n\n\n‚úÖ Please Take 10 Minutes Now to Complete the SCE\nOn your laptop, follow these steps to access the SCE for DANL 101:\n\nLog in to the SCE Survey Portal\nClick on ‚ÄúSurveys‚Äù\nSelect DANL 101 and complete the evaluation\n\nThank you very much for your time and thoughtful feedback!"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-1",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-1",
    "title": "Final Exam",
    "section": "Question 1",
    "text": "Question 1\nCategorical data distributions are commonly visualized using histograms, while numerical data distributions are commonly shown with bar charts.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nFalse.\nHistograms are typically used for numerical (quantitative) variables, while bar charts are typically used for categorical variables."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-2",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-2",
    "title": "Final Exam",
    "section": "Question 2",
    "text": "Question 2\nThe popularization of sports analytics was significantly influenced by the ‚ÄúMoneyball‚Äù book published in 2003 and its subsequent movie adaptation.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-3",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-3",
    "title": "Final Exam",
    "section": "Question 3",
    "text": "Question 3\nWhy are tools like Excel or Google Sheets not considered full Database Management Systems (DBMS)?\n\nThey cannot store numerical data.\n\nThey provide basic storage but lack robust capabilities for querying, updating consistency, and managing large-scale data safely.\n\nThey do not support the creation of charts or visualizations.\n\nThey are incompatible with CSV files.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. They provide basic storage but lack robust capabilities for querying, updating consistency, and managing large-scale data safely."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-4",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-4",
    "title": "Final Exam",
    "section": "Question 4",
    "text": "Question 4\nWhich of the following best describes the modern ‚Äúvibe coding‚Äù workflow in data analytics?\n\nWriting all SQL and Python code manually to ensure 100% accuracy without AI intervention.\n\nUsing drag-and-drop interfaces exclusively without any coding logic.\n\nOutsourcing all coding tasks to third-party distributed agents.\n\nPrompting AI assistants to generate logic flows and code snippets, then reviewing the output for accuracy.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd. Prompting AI assistants to generate logic flows and code snippets, then reviewing the output for accuracy."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-5",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-5",
    "title": "Final Exam",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following is NOT one of the ‚ÄúFour Rules for Co-Intelligence‚Äù for working with AI?\n\nAlways invite AI to the table\n\nBe the human in the loop (HITL)\n\nAutomate everything possible and remove human oversight\n\nTreat AI like a person (but remember it isn‚Äôt)\n\nAssume this is the worst AI you‚Äôll ever use\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc. Automate everything possible and remove human oversight"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-6",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-6",
    "title": "Final Exam",
    "section": "Question 6",
    "text": "Question 6\nIn a relational database, what is the role of a key variable?\n\nIt stores raw data without any transformation.\n\nIt uniquely identifies each row and helps define relationships between tables.\n\nIt limits users‚Äô access to only certain tables.\n\nIt performs Map and Reduce tasks on big data sets.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. It uniquely identifies each row and helps define relationships between tables."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-7",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-7",
    "title": "Final Exam",
    "section": "Question 7",
    "text": "Question 7\nWhich of the following is a characteristic of ‚ÄúReinforcement Learning from Human Feedback‚Äù (RLHF)?\n\nIt involves humans ranking or scoring model answers to align the model with human preferences for safety and helpfulness.\n\nIt allows the model to learn entirely on its own without any human intervention.\n\nIt is a pre-training phase where the model reads vast amounts of text.\n\nIt is primarily used for generating images from text descriptions.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. It involves humans ranking or scoring model answers to align the model with human preferences for safety and helpfulness."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-8",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-8",
    "title": "Final Exam",
    "section": "Question 8",
    "text": "Question 8\nWhich type of visualization is most suitable for showing the distribution of a single numerical variable?\n\nBar Chart\n\nHistogram\n\nScatterplot\n\nLine Chart\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Histogram"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-9",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-9",
    "title": "Final Exam",
    "section": "Question 9",
    "text": "Question 9\nIf you want to visualize the relationship between two numerical variables and see whether they move together, which chart would be most appropriate?\n\nBar Chart\n\nHistogram\n\nScatterplot\n\nBoxplot\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Scatterplot"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-10",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-10",
    "title": "Final Exam",
    "section": "Question 10",
    "text": "Question 10\nIn the ETL process, which of the following best describes the ‚ÄúTransform‚Äù stage‚Äôs primary purpose?\n\nAggregating and filtering data from disparate sources before extraction.\n\nAltering, cleaning, and integrating data to ensure consistency and usability.\n\nMoving transformed data into staging environments for downstream operations.\n\nEnsuring that outdated data is removed or archived for regulatory compliance.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Altering, cleaning, and integrating data to ensure consistency and usability."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-11",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-11",
    "title": "Final Exam",
    "section": "Question 11",
    "text": "Question 11\nWhat does the term ‚ÄúAPI‚Äù stand for, and what is its primary function as described in the lecture?\n\nAutomated Processing Interface; it cleans messy CSV files automatically.\n\nApplication Programming Interface; it allows software systems to communicate and request data programmatically.\n\nAdvanced Python Integration; it translates R code into Python.\n\nAnalytical Pipeline Interface; it is used exclusively for visualizing Tableau dashboards.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Application Programming Interface; it allows software systems to communicate and request data programmatically."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-12",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-12",
    "title": "Final Exam",
    "section": "Question 12",
    "text": "Question 12\nWhich statement is most accurate about tokens in the context of large language models (LLMs)?\n\nA token is always exactly one English word\n\nTokens are always single characters\n\nTokens exist only at the output side, not at the input side\n\nA token is a unit of text; it may be a character, a whole word, or part of a word\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd. A token is a unit of text; it may be a character, a whole word, or part of a word."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-13",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-13",
    "title": "Final Exam",
    "section": "Question 13",
    "text": "Question 13\nWhat type of variable is FavoriteGenre in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a. Nominal"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-14",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-14",
    "title": "Final Exam",
    "section": "Question 14",
    "text": "Question 14\nWhat type of variable is SubscriptionTier in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b. Ordinal\n(There is a meaningful order: Free &lt; Family &lt; Premium.)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-15",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-15",
    "title": "Final Exam",
    "section": "Question 15",
    "text": "Question 15\nWhat type of variable is LastLoginTime in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c.¬†Interval\n(Hours since midnight: differences are meaningful, but ‚Äú0‚Äù is an arbitrary reference point, not ‚Äúno time.‚Äù)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-16",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-16",
    "title": "Final Exam",
    "section": "Question 16",
    "text": "Question 16\nWhat type of variable is Satisfaction in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b. Ordinal\n(Star ratings have an order, but equal gaps between levels are not guaranteed.)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-17",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-17",
    "title": "Final Exam",
    "section": "Question 17",
    "text": "Question 17\nIn retail analytics, analyzing which products tend to sell together allows for\n_______________________________ to reveal hidden product correlations and inform bundling strategies.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nassociation rule (market basket analysis)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-18",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-18",
    "title": "Final Exam",
    "section": "Question 18",
    "text": "Question 18\nA(n) ________________________________ is a visual display of key information, data, and metrics, often used in BI to provide insights at a glance.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ndashboard (key performance indicator (KPI))"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-19",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-19",
    "title": "Final Exam",
    "section": "Question 19",
    "text": "Question 19\n________________________________ is a Python data visualization library that provides a high-level, elegant interface for creating informative and attractive graphics. You can think of it as the Python counterpart to R‚Äôs ggplot2: it emphasizes clear defaults, aesthetic color palettes, and concise syntax for complex visualizations.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nSeaborn"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-20",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-20",
    "title": "Final Exam",
    "section": "Question 20",
    "text": "Question 20\n________________________________ is the tendency for values of two variables to vary together, and can be visualized using scatterplots.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nCorrelation"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-21",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-21",
    "title": "Final Exam",
    "section": "Question 21",
    "text": "Question 21\n________________________________ data refers to data that is not organized in a predefined manner and includes sources like social media posts, emails, photos, and videos.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nUnstructured"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-22",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-22",
    "title": "Final Exam",
    "section": "Question 22",
    "text": "Question 22\nWhen designing visuals, the goal is to convey as much information as possible while minimizing _______________________________ for the audience.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ncognitive load"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-23",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-23",
    "title": "Final Exam",
    "section": "Question 23",
    "text": "Question 23\nOne of our alumni guest‚Äôs companies uses Snowflake as their _______________________________, a centralized repository that stores and manages large volumes of structured and semi-structured data for analytics and reporting purposes.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ndata warehouse (database management system (DBMS))"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-24",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-24",
    "title": "Final Exam",
    "section": "Question 24",
    "text": "Question 24\nThree most popular programming languages for data analysts are _______________________________, Python, and R.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nSQL"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-25",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-25",
    "title": "Final Exam",
    "section": "Question 25",
    "text": "Question 25\nConsider the following vector x:\n\nx &lt;- c(2, 4, 6, 8, 10)\n\nWrite the R code to create a new vector called z, where its \\(i\\)-th entry (\\(i = 1,2,3,4, \\text{or } 5\\)) is the standardized value of \\(i\\)-th element of x vector.\n\\[\nz_{i} = \\frac{x_{i} - \\bar{x}}{\\sigma_{x}}\n\\]\n\n\\(\\bar{x}\\): the mean of values in x\n\\(\\sigma_{x}\\): the standard deviation of values in x\n\nAnswer: ______________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nz &lt;- (x - mean(x)) / sd(x)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-26",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-26",
    "title": "Final Exam",
    "section": "Question 26",
    "text": "Question 26\nGiven the data.frame df with variables height and name, which of the following expressions returns a vector containing the values in the height variable?\n\ndf:height\ndf$height\ndf::height\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. df$height"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-27",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-27",
    "title": "Final Exam",
    "section": "Question 27",
    "text": "Question 27\nConsider the following data.frame, students:\n\n\n\n\n\nName\nAge\nMajor\nGPA\n\n\n\n\nAlice\n22\nBusiness Administration\n3.8\n\n\nBob\n23\nAccounting\n3.2\n\n\nCharlie\n21\nData Analytics\n3.9\n\n\nDiana\n24\nEconomics\n3.5\n\n\n\n\n\nWhich of the following R codes will correctly create a new data.frame with only the Name and GPA variables?\n\nstudents |&gt; select(Name, GPA)\nstudents |&gt; select(-Age, -Major)\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc. Both a and b"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-28",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-28",
    "title": "Final Exam",
    "section": "Question 28",
    "text": "Question 28\nConsider the following data.frame df0:\n\n\n\n\n\nx\ny\n\n\n\n\nNa\n7\n\n\n2\nNA\n\n\n3\n9\n\n\n\n\n\nWhat is the result of median(df0$y)?\n\n7\nNA\n8\n9\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. NA"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-29",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-29",
    "title": "Final Exam",
    "section": "Question 29",
    "text": "Question 29\nConsider the two related data.frames, df_1 and df_2:\n\ndf_1\n\n\n\n\n\n\nid\nname\nage\n\n\n\n\n1\nBob\n19\n\n\n2\nJulia\n21\n\n\n4\nZachary\n20\n\n\n\n\n\n\ndf_2\n\n\n\n\n\n\nid\nmajor\n\n\n\n\n1\nEconomics\n\n\n2\nBusiness Administration\n\n\n3\nData Analytics\n\n\n\n\n\nWhich of the following R code correctly join the two related data.frames, df_1 and df_2, to produce the resulting data.frame shown below?\n\n\n\n\n\nid\nname\nage\nmajor\n\n\n\n\n1\nBob\n19\nEconomics\n\n\n2\nJulia\n21\nBusiness Administration\n\n\n4\nZachary\n20\nNA\n\n\n\n\n\n\ndf_1 |&gt; left_join(df_2)\ndf_2 |&gt; left_join(df_1)\nBoth a and b\nNone of the above\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. df_1 |&gt; left_join(df_2)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-30-36",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-30-36",
    "title": "Final Exam",
    "section": "Questions 30-36",
    "text": "Questions 30-36\nFor Questions 30-36, consider the following R packages and the data.frame, nyc_dogs, containing individual dog license data from New York City (NYC):\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\n\nnyc_dogs &lt;- read_csv(\"https://bcdanl.github.io/data/nyc_dogs_cleaned.csv\")\n\nThe first 10 observations in the nyc_dogs data frame are displayed below:\n\n\n\n\n\nname\ngender\nbirth_year\nbreed\nborough\n\n\n\n\npaige\nF\n2014\npit bull\nManhattan\n\n\nyogi\nM\n2010\nboxer\nBronx\n\n\nali\nM\n2014\nbasenji\nManhattan\n\n\nqueen\nF\n2013\nakita\nManhattan\n\n\nlola\nF\n2009\nmaltese\nManhattan\n\n\nian\nM\n2006\nNA\nManhattan\n\n\nbuddy\nM\n2008\nNA\nManhattan\n\n\nchewbacca\nF\n2012\nlabrador\nManhattan\n\n\nheidi-bo\nF\n2007\ndachshund smooth coat\nBrooklyn\n\n\nmassimo\nM\n2009\nbull dog, french\nBrooklyn\n\n\n\n\n\n\nThe nyc_dogs data frame is with 197473 observations and 5 variables.\n\n\nDescription of Variables in nyc_dogs:\n\nname: Dog name\ngender: Dog gender (F for female; M for male; NA for missing value)\nbirth_year: Birth year (integer values)\nbreed: Dog breed\nborough: Borough in NYC\n\n\nThe followings are the summary of the nyc_dogs data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nnyc_dogs\n\n\nNumber of rows\n197473\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\nn_missing\nmin\nmax\nempty\nn_unique\n\n\n\n\nname\n2637\n1\n30\n0\n26770\n\n\ngender\n6\n1\n1\n0\n2\n\n\nbreed\n18832\n3\n35\n0\n295\n\n\nborough\n0\n5\n13\n0\n5\n\n\n\nVariable type: numeric\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nbirth_year\n0\n2012.94\n4.91\n1975\n2010\n2014\n2017\n2021\n\n\n\n\n\n\n\nQuestion 30\nWhat is the interquartile range of birth_year? Find this value by using the summary of the nyc_dogs data frame.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nIQR = 7 = 2017 - 2010\n\n\n\n\n\n\nQuestion 31\nWhat R code can we use to count the number of licensed dogs by borough within each birth_year in NYC?\n\nnyc_dogs |&gt; count(birth_year)\nnyc_dogs |&gt; count(borough)\nnyc_dogs |&gt; count(borough, birth_year)\nnyc_dogs |&gt; count(birth_year, borough)\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\n\n\n\n\n\n\nQuestion 32\n\nWe are interested in finding the 7 most popular dog breeds in NYC.\nTo achieve this, we create a new data.frame, a new data.frame, top7_breeds, which includes only 7 most popular dog breeds, excluding any NA values.\n\n\n\n\n\n\nbreed\nn\n\n\n\n\nyorkshire terrier\n12804\n\n\nshih tzu\n12790\n\n\nchihuahua\n11099\n\n\nlabrador\n11017\n\n\npit bull\n10023\n\n\nmaltese\n7750\n\n\ngerman shepherd\n5063\n\n\n\n\n\n\nThe top7_breeds data.frame is displayed above.\n\n\ntop7_breeds &lt;- nyc_dogs |&gt; \n  filter(___(1)___) |&gt; \n  ___(2)___ |&gt; \n  ___(3)___(-n) |&gt; \n  head(7)  # returns the first 7 observations of the new data.frame\n\n\nComplete the code by filling in the blanks (1)-(3).\n\n\n\nis.na(breed); (2) count(n); (3) select\n\n\nis.na(breed); (2) count(n); (3) arrange\n\n\nis.na(breed); (2) count(breed); (3) select\n\n\nis.na(breed); (2) count(breed); (3) arrange\n\n\n!is.na(breed); (2) count(n); (3) select\n\n\n!is.na(breed); (2) count(n); (3) arrange\n\n\n!is.na(breed); (2) count(breed); (3) select\n\n\n!is.na(breed); (2) count(breed); (3) arrange\n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\n\n\n\n\n\n\nQuestion 33\nHow would you describe the distribution of breed using the top7_breeds data.frame?\n\nNote that the breed categories are sorted by the n variable in the plot.\n\nComplete the code by filling in the blanks (1)-(3).\n\nggplot(data = top7_breeds,\n       mapping = aes(___(1)___,\n                     ___(2)___ = n)) +\n  ___(3)___() +\n  labs(y = \"Top 7 Dog Breeds\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = breed\ny = breed\nx = fct_reorder(n, breed)\ny = fct_reorder(n, breed)\nx = fct_reorder(breed, n)\ny = fct_reorder(breed, n)\nBoth c and d\nBoth e and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nf\n\n\n\n\n\n\nBlank (2)\n\nx\ny\nfill\ncolor\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\ngeom_bar\ngeom_col\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\n\nQuestion 34\n\nWe are also interested in identifying the top five most popular dog names for each gender.\nTo do this, we first create a new data frame, nyc_dogs_filtered, which includes only the observations where (1) the value of name variable is not missing and (2) the value of gender variable is not missing.\n\n\nnyc_dogs_filtered &lt;- nyc_dogs |&gt; \n  filter(___BLANK___)\n\n\nWhich condition correctly fills in the BLANK to complete the code above?\n\n\nis.na(name) , is.na(gender)\nis.na(name) & is.na(gender)\nis.na(name) | is.na(gender)\n!is.na(name) , !is.na(gender)\n!is.na(name) & !is.na(gender)\n!is.na(name) | !is.na(gender)\nBoth a and b\nBoth a and c\nBoth d and e\nBoth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ni\n\n\n\n\n\n\nQuestion 35\n\nUsing nyc_dogs_filtered from Question 34, we are creating the top5names_F data.frame:\n\n\n\n\n\n\nname\nn\n\n\n\n\nbella\n1291\n\n\nlola\n1005\n\n\nluna\n995\n\n\nlucy\n914\n\n\ndaisy\n851\n\n\n\n\n\n\nThe top5names_F data.frame provides the five most popular female dog names, displayed above.\n\nComplete the code by filling in the blanks (1)-(2).\n\ntop5names_F &lt;- nyc_dogs_filtered |&gt; \n  filter(___(1)___) |&gt; \n  count(___(2)___) |&gt; \n  arrange(___(3)___) |&gt; \n  head(5) \n\n\nBlank (1)\n\ngender == \"F\"\ngender != \"F\"\ngender == \"M\"\ngender != \"M\"\nBoth a and b\nBoth a and c\nBoth a and d\nBoth b and c\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ng\n\n\n\n\n\n\nBlank (2)\n\nname\ngender\nn\nname, n\ngender, n\nname, gender\ngender, name\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\nn\n-n\ndesc(n)\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nQuestion 36\n\nLikewise, using nyc_dogs_filtered from Question 34, we are creating the top5names_M data.frame:\n\n\n\n\n\n\nname\nn\n\n\n\n\nmax\n1341\n\n\ncharlie\n1042\n\n\nrocky\n1020\n\n\nbuddy\n840\n\n\nteddy\n745\n\n\n\n\n\n\nThe top5names_M data.frame provides the five most popular male dog names, displayed above.\n\nComplete the code by filling in the blanks (1)-(2).\n\ntop5names_M &lt;- nyc_dogs_filtered |&gt; \n  filter(___(1)___) |&gt; \n  count(___(2)___) |&gt; \n  arrange(___(3)___) |&gt; \n  head(5) \n\n\nBlank (1)\n\ngender == \"F\"\ngender != \"F\"\ngender == \"M\"\ngender != \"M\"\nBoth a and b\nBoth a and c\nBoth a and d\nBoth b and c\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\n\n\n\n\n\n\nBlank (2)\n\nname\ngender\nn\nname, n\ngender, n\nname, gender\ngender, name\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\nn\n-n\ndesc(n)\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-37-40",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-37-40",
    "title": "Final Exam",
    "section": "Questions 37-40",
    "text": "Questions 37-40\nThe Nobel Prize in Economic Science in 2021 goes to David Card, Joshua Angrist and Guido Imbens, for their empirical contributions to labor economics, and for their methodological contributions to the analysis of causal relationships.\nThey have provided us with new insights about the labor market and shown what conclusions about cause and effect can be drawn from natural experiments. Their approach has spread to other fields and revolutionized empirical research.\nFor Questions 37-40, consider the following R packages and the data.frame, ak91_age, which comes from the 1980 US Census and covers men born 1930‚Äì1939, which is used by Joshua Angrist and Alan Krueger‚Äôs research article.\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\n\nak91_age &lt;- read_csv('https://bcdanl.github.io/data/ak91_ageW.csv')\n\nThe first 20 observations in the ak91_age data frame are displayed below:\n\n\n\n\n\nQoB\nYoB\nYoBQ\nW\nEduc\nQ4\n\n\n\n\n1\n1930\n1930.00\n361.0922\n12.28041\nFALSE\n\n\n1\n1931\n1931.00\n365.8181\n12.54043\nFALSE\n\n\n1\n1932\n1932.00\n364.9678\n12.53393\nFALSE\n\n\n1\n1933\n1933.00\n362.1093\n12.67319\nFALSE\n\n\n1\n1934\n1934.00\n363.2739\n12.64726\nFALSE\n\n\n1\n1935\n1935.00\n357.7532\n12.65091\nFALSE\n\n\n1\n1936\n1936.00\n359.5803\n12.74304\nFALSE\n\n\n1\n1937\n1937.00\n362.5073\n12.83230\nFALSE\n\n\n1\n1938\n1938.00\n362.9918\n12.93868\nFALSE\n\n\n1\n1939\n1939.00\n360.0860\n13.00299\nFALSE\n\n\n2\n1930\n1930.25\n364.3105\n12.42842\nFALSE\n\n\n2\n1931\n1931.25\n365.2228\n12.53105\nFALSE\n\n\n2\n1932\n1932.25\n365.2356\n12.60960\nFALSE\n\n\n2\n1933\n1933.25\n365.2171\n12.63471\nFALSE\n\n\n2\n1934\n1934.25\n362.2778\n12.72797\nFALSE\n\n\n2\n1935\n1935.25\n360.1939\n12.79693\nFALSE\n\n\n2\n1936\n1936.25\n360.2046\n12.81108\nFALSE\n\n\n2\n1937\n1937.25\n360.7164\n12.84405\nFALSE\n\n\n2\n1938\n1938.25\n366.8558\n13.00766\nFALSE\n\n\n2\n1939\n1939.25\n365.9290\n13.01340\nFALSE\n\n\n\n\n\n\nThe ak91_age data frame is with 40 observations and 6 variables.\n\n\nDescription of Variables in ak91_age:\n\nQoB: Quarter of birth\nYoB: Year of birth (1930, 1931, ‚Ä¶, 1939)\nYoBQ: Year and quarter of birth (1930 Q1, 1930 Q2, ‚Ä¶, 1939 Q4)\nW: Wage per week\nEduc: Years of education\nQ4: TRUE if quarter of birth is 4; FALSE otherwise.\n\n\nThe followings are the summary of the ak91_age data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nak91_age\n\n\nNumber of rows\n40\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nlogical\n1\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\nmean\ncount\n\n\n\n\nQ4\n0\n0.25\nFAL: 30, TRU: 10\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nQoB\n0\n2.50\n1.13\n1.00\n1.75\n2.50\n3.25\n4.00\n\n\nYoB\n0\n1934.50\n2.91\n1930.00\n1932.00\n1934.50\n1937.00\n1939.00\n\n\nYoBQ\n0\n1934.88\n2.92\n1930.00\n1932.44\n1934.88\n1937.31\n1939.75\n\n\nW\n0\n365.02\n3.37\n357.75\n362.24\n365.53\n367.89\n370.32\n\n\nEduc\n0\n12.76\n0.19\n12.28\n12.64\n12.75\n12.93\n13.12\n\n\n\n\n\n\n\nQuestion 37\nHere we describe the quarterly trend of years of education. Complete the code by filling in the blanks (1)-(3).\n\nggplot(data = ak91_age, \n       mapping = aes(___(1)___,\n                     ___(2)___ = Q4)) +\n  ___(3)___ + \n  geom_point(size = 2.5) +\n  scale_color_colorblind() +\n  labs(x = \"Year and quarter of birth\",\n       y = \"Years of education\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = YoBQ, y = Educ\ny = YoBQ, x = Educ\nx = YoB, y = Educ\ny = YoB, x = Educ\nBoth a and b\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (2)\n\nfill\ncolor\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (3)\n\ngeom_scatterplot\ngeom_point\ngeom_line\ngeom_smooth\ngeom_histogram\ngeom_boxplot\ngeom_bar\ngeom_col\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\n\nQuestion 38\nHere we describe the quarterly trend of the base-10 log of wage per week. Complete the code by filling in the blanks (1)-(3).\n\nggplot(data = ak91_age, \n       mapping = aes(___(1)___,\n                     ___(2)___ = Q4)) +\n  ___(3)___ + \n  geom_point(size = 2.5) +\n  scale_color_colorblind() +\n  labs(x = \"Year and quarter of birth\",\n       y = \"Wage per week (in base-10 log)\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = YoBQ, y = log(W)\ny = YoBQ, x = log(W)\nx = YoBQ, y = log10(W)\ny = YoBQ, x = log10(W)\nBoth a and c\nBoth b and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (2)\n\nfill\ncolor\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (3)\n\ngeom_scatterplot\ngeom_point\ngeom_line\ngeom_smooth\ngeom_histogram\ngeom_boxplot\ngeom_bar\ngeom_col\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\n\nQuestion 39\nHere we describe how the distribution of the base-10 log of wage per week varies by Q4. Complete the code by filling in the blanks (1)-(3).\n\nggplot(data = ak91_age, \n       mapping = aes(___(1)___,\n                     ___(2)___ = Q4)) +\n  ___(3)___(show.legend = FALSE) +\n  scale_fill_tableau() +\n  labs(x = \"Wage per week (in base-10 log)\",\n       y = \"Born in the Fourth Quarter?\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = YoBQ, y = log(W)\ny = YoBQ, x = log(W)\nx = YoBQ, y = log10(W)\ny = YoBQ, x = log10(W)\nx = Q4, y = log(W)\ny = Q4, x = log(W)\nx = Q4, y = log10(W)\ny = Q4, x = log10(W)\nBoth a and c\nBoth b and d\nBoth e and g\nBoth f and h\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\n\n\n\n\n\n\nBlank (2)\n\nfill\ncolor\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\ngeom_scatterplot\ngeom_point\ngeom_line\ngeom_smooth\ngeom_histogram\ngeom_boxplot\ngeom_bar\ngeom_col\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nf\n\n\n\n\n\n\n\nQuestion 40\nProvide a data-driven narrative for the ak91_age data frame, incorporating insights from the visualizations created in Questions 37, 38, and 39.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-41-44",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-41-44",
    "title": "Final Exam",
    "section": "Questions 41-44",
    "text": "Questions 41-44\nFor Questions 41-44, consider the following R packages and the data.frame, health_cust, which contains demographic information about individuals with or without health insurance.\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\n\nhealth_cust &lt;- read_csv(\n  'https://bcdanl.github.io/data/custdata_rev.csv'\n)\n\nThe first 10 observations in the health_cust data frame are displayed below:\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustid\nsex\nis_employed\nincome\nmarital_status\nhousing_type\n\n\n\n\n000006646_03\nMale\nTRUE\n22000\nNever married\nHomeowner free and clear\n\n\n000007827_01\nFemale\nNA\n23200\nDivorced/Separated\nRented\n\n\n000008359_04\nFemale\nTRUE\n21000\nNever married\nHomeowner with mortgage/loan\n\n\n000008529_01\nFemale\nNA\n37770\nWidowed\nHomeowner free and clear\n\n\n000008744_02\nMale\nTRUE\n39000\nDivorced/Separated\nRented\n\n\n000011466_01\nMale\nNA\n11100\nMarried\nHomeowner free and clear\n\n\n000015018_01\nFemale\nTRUE\n25800\nMarried\nRented\n\n\n000017314_02\nFemale\nNA\n34600\nMarried\nHomeowner free and clear\n\n\n000017383_04\nFemale\nTRUE\n25000\nNever married\nHomeowner free and clear\n\n\n000017554_02\nMale\nTRUE\n31200\nMarried\nHomeowner with mortgage/loan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustid\nrecent_move\nnum_vehicles\nage\nstate_of_res\ngas_usage\nhealth_ins\n\n\n\n\n000006646_03\nFALSE\n0\n24\nAlabama\n210\nFALSE\n\n\n000007827_01\nTRUE\n0\n82\nAlabama\n3\nFALSE\n\n\n000008359_04\nFALSE\n2\n31\nAlabama\n40\nFALSE\n\n\n000008529_01\nFALSE\n1\n93\nAlabama\n120\nFALSE\n\n\n000008744_02\nFALSE\n2\n67\nAlabama\n3\nFALSE\n\n\n000011466_01\nFALSE\n2\n76\nAlabama\n200\nFALSE\n\n\n000015018_01\nFALSE\n2\n26\nAlabama\n3\nTRUE\n\n\n000017314_02\nFALSE\n2\n73\nAlabama\n50\nFALSE\n\n\n000017383_04\nFALSE\n5\n27\nAlabama\n3\nFALSE\n\n\n000017554_02\nFALSE\n3\n54\nAlabama\n20\nFALSE\n\n\n\n\n\n\nDescription of Variables in health_cust\n\ncustid: ID of customer\nsex: Sex\nis_employed: Employment status\n\nNA: Unknown or not applicable\nTRUE: Employed\nFALSE: Unemployed\n\nincome: Income (in $)\nmarital_status: Marital status\nhousing_type: Housing type\nrecent_move:\n\nTRUE: Recently moved\nFALSE: Not recently moved\n\nage: Age\nstate_of_res: State of residence (Alabama, Alaska, ‚Ä¶, New York, ‚Ä¶, Wyoming)\ngas_usage: Gas usage\n\nNA: Unknown or not applicable\n001: Included in rent or condo fee\n002: Included in electricity payment\n003: No charge or gas not used\n004-999: $4 to $999 (rounded and top-coded)\n\nhealth_ins: Health insuarance status\n\nTRUE: customer with health insuarance\nFALSE: customer without health insuarance\n\n\nThe followings are the summary of the health_cust data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nhealth_cust\n\n\nNumber of rows\n73262\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nlogical\n3\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\nn_missing\nmin\nmax\nempty\nn_unique\n\n\n\n\ncustid\n0\n12\n12\n0\n73262\n\n\nsex\n0\n4\n6\n0\n2\n\n\nmarital_status\n0\n7\n18\n0\n4\n\n\nhousing_type\n1720\n6\n28\n0\n4\n\n\nstate_of_res\n0\n4\n20\n0\n51\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\nmean\ncount\n\n\n\n\nis_employed\n25774\n0.95\nTRU: 45137, FAL: 2351\n\n\nrecent_move\n1721\n0.13\nFAL: 62418, TRU: 9123\n\n\nhealth_ins\n0\n0.10\nFAL: 65955, TRU: 7307\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nincome\n0\n41764.15\n58113.76\n-6900\n10700\n26200\n51700\n1257000\n\n\nnum_vehicles\n1720\n2.07\n1.17\n0\n1\n2\n3\n6\n\n\nage\n0\n49.16\n18.08\n0\n34\n48\n62\n120\n\n\ngas_usage\n1720\n41.17\n63.05\n1\n3\n10\n60\n570"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-41",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-41",
    "title": "Final Exam",
    "section": "Question 41",
    "text": "Question 41\nHere we describe how the distribution of health_ins varies by state of residence and employment status using the health_cust data.frame. Complete the code by filling in the blanks (1)-(4).\n\nggplot(data = health_cust |&gt; filter(!is.na(is_employed)),\n       mapping = aes(___(1)___, \n                     fill = ___(2)___)) +\n  ___(3)___ +\n  ___(4)___(~is_employed) +\n  labs(y = \"\", x= \"Proportion\") +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nBlank (1)\n\nx = health_ins\nx = state_of_res\nx = Proportion\ny = health_ins\ny = state_of_res\ny = Proportion\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\n\n\n\n\n\n\nBlank (2)\n\nhealth_ins\nstate_of_res\nProportion\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\ngeom_bar(position = \"stack\")\ngeom_col(position = \"stack\")\ngeom_bar(position = \"fill\")\ngeom_col(position = \"fill\")\ngeom_bar(position = \"dodge\")\ngeom_col(position = \"dodge\")\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (4)\nAnswer: ________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nfacet_wrap"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-42",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-42",
    "title": "Final Exam",
    "section": "Question 42",
    "text": "Question 42\nHere we describe how the distribution of marital_status varies by housing_type using the health_cust data.frame. Complete the code by filling in the blanks (1)-(4).\n\nggplot(data = health_cust |&gt; filter(!is.na(housing_type)),\n       mapping = aes(___(1)___, \n                     ___(2)___)) +\n  ___(3)___(show.legend = FALSE) +\n  ___(4)___(~housing_type) +\n  labs(y = \"\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = marital_status\ny = marital_status\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nx = prop\nx = prop, group = 1\nBoth a and b\ny = prop\ny = prop, group = 1\nBoth d and e\nx = after_stat(prop)\nx = after_stat(prop), group = 1\nBoth g and h\ny = after_stat(prop)\ny = after_stat(prop), group = 1\nBoth j and k\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\n\n\n\n\n\n\nBlank (3)\n\ngeom_bar()\ngeom_col()\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (4)\nAnswer: ________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nfacet_wrap"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-43",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-43",
    "title": "Final Exam",
    "section": "Question 43",
    "text": "Question 43\nHere we describe how the relationship between age and income varies by health_ins using the health_cust data.frame. Note that the new geometric object geom_hex() divides the plane into regular hexagons, counts the number of observations in each hexagon, and then maps the number of observations to the hexagon fill.\nComplete the code by filling in the blanks (1)-(4).\n\n# Considering \n  # income level between $0 and $250,000\n  # age between 20 and 70\nggplot(data = health_cust |&gt; filter(income &gt;= 0 & income &lt;= 2.5*10^5,\n                                    age &gt;= 20 & age &lt;= 70),\n       mapping = aes(___(1)___)) +\n  geom_hex() + # hexbin plot: dividing the plot area into hexagonal bins\n  ___(2)___ +\n  ___(3)___(~health_ins) +\n  scale_fill_viridis_c() # for hexbin color\n\n\n\n\n\n\n\nBlank (1)\n\nx = income, y = age\nx = age, y = income\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\ngeom_smooth()\ngeom_smooth(method = \"lm\")\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\nAnswer: ________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nfacet_wrap"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-44",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-44",
    "title": "Final Exam",
    "section": "Question 44",
    "text": "Question 44\nDescribe how the overall relationship between age and income varies by health_ins.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-45",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-45",
    "title": "Final Exam",
    "section": "Question 45",
    "text": "Question 45\nFor each question in Homework 5, briefly describe the task you are required to complete.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-46",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-46",
    "title": "Final Exam",
    "section": "Question 46",
    "text": "Question 46\nWhat is clutter in data visualization, and why is it important to reduce it? Provide at least two practical tips for minimizing clutter in visualizations.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nClutter: Visual elements that occupy space but do not improve understanding\nClutter makes information harder to process and can confuse the viewer\n\nLess clutter = clearer message, more focused audience\n\nTips\n\nAvoid having the data all skewed to one side or the other of your graph.\nAvoid too many superimposed elements, such as too many curves (&gt;4) in the same graphing space."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-47",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-47",
    "title": "Final Exam",
    "section": "Question 47",
    "text": "Question 47\nDescribe the two phases of training a large language model (LLM): Pre-training and Fine-tuning. What is the primary objective of each phase?\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-48",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-48",
    "title": "Final Exam",
    "section": "Question 48",
    "text": "Question 48\nCompare supervised learning and unsupervised learning. Give one example of a business application for each and explain why labeled data is central to one but not the other.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-49",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-49",
    "title": "Final Exam",
    "section": "Question 49",
    "text": "Question 49\nWhen is it appropriate to treat integer-valued data as if it were continuous? Give one example of an integer variable for which this is reasonable.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-50",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#question-50",
    "title": "Final Exam",
    "section": "Question 50",
    "text": "Question 50\nIdentify two situations where pie charts are not a suitable alternative to bar charts.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nPie charts work well only if you only have a few categories‚Äîfour max.\nPie charts work well if the goal is to emphasize simple fractions (e.g., 25%, 50%, or 75%).\nPie charts are not the best choice if you want audiences to compare the size of shares.\nPie charts are not the best choice if you want audiences to compare the distribution across categories."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-1",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-1",
    "title": "Final Exam",
    "section": "Question 1",
    "text": "Question 1\nCategorical data distributions are commonly visualized using bar charts, while numerical data distributions are commonly shown with histograms.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-2",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-2",
    "title": "Final Exam",
    "section": "Question 2",
    "text": "Question 2\nThe popularization of sports analytics was significantly influenced by the ‚ÄúMoneyball‚Äù book published in 2003 and its subsequent movie adaptation.\n\nTrue\nFalse\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nTrue."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-3",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-3",
    "title": "Final Exam",
    "section": "Question 3",
    "text": "Question 3\nWhich feature most clearly distinguishes a full Database Management System (DBMS) from basic data storage tools like Excel or Google Sheets?\n\nThe ability to store data electronically in tables\n\nThe ability to perform queries that filter and select data\n\nThe ability to manage updates while enforcing consistency and data validity\n\nThe ability to display data in rows and columns\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc. The ability to manage updates while enforcing consistency and data validity"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-4",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-4",
    "title": "Final Exam",
    "section": "Question 4",
    "text": "Question 4\nWhich of the following best describes the modern ‚Äúvibe coding‚Äù workflow in data analytics?\n\nWriting all SQL and Python code manually to ensure 100% accuracy without AI intervention.\n\nUsing drag-and-drop interfaces exclusively without any coding logic.\n\nOutsourcing all coding tasks to third-party distributed agents.\n\nPrompting AI assistants to generate logic flows and code snippets, then reviewing the output for accuracy.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd. Prompting AI assistants to generate logic flows and code snippets, then reviewing the output for accuracy."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-5",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-5",
    "title": "Final Exam",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following is NOT one of the ‚ÄúFour Rules for Co-Intelligence‚Äù for working with AI?\n\nAlways invite AI to the table\n\nBe the human in the loop (HITL)\n\nAutomate everything possible and remove human oversight\n\nTreat AI like a person (but remember it isn‚Äôt)\n\nAssume this is the worst AI you‚Äôll ever use\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc. Automate everything possible and remove human oversight"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-6",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-6",
    "title": "Final Exam",
    "section": "Question 6",
    "text": "Question 6\nWhat is a ‚ÄúSchema‚Äù in the context of Big Data Management?\n\nThe physical hardware used to store the data.\n\nA blueprint that defines how data is organized, including fields and data types.\n\nThe process of deleting old data to make room for new data.\n\nThe software used to visualize data in charts.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. A blueprint that defines how data is organized, including fields and data types."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-7",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-7",
    "title": "Final Exam",
    "section": "Question 7",
    "text": "Question 7\nWhich of the following is a characteristic of ‚ÄúReinforcement Learning from Human Feedback‚Äù (RLHF)?\n\nIt involves humans ranking or scoring model answers to align the model with human preferences for safety and helpfulness.\n\nIt allows the model to learn entirely on its own without any human intervention.\n\nIt is primarily used for generating images from text descriptions.\n\nIt is a pre-training phase where the model reads vast amounts of text.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. It involves humans ranking or scoring model answers to align the model with human preferences for safety and helpfulness."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-8",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-8",
    "title": "Final Exam",
    "section": "Question 8",
    "text": "Question 8\nWhich type of visualization is most suitable for showing the distribution of a single categorical variable?\n\nBar Chart\n\nHistogram\n\nScatterplot\n\nLine Chart\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. Bar Chart"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-9",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-9",
    "title": "Final Exam",
    "section": "Question 9",
    "text": "Question 9\nTo compare how the distribution of a numerical variable differs across categories of another variable, which visualization is most appropriate?\n\nBar Chart\n\nHistogram\n\nScatterplot\n\nBoxplot\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd.¬†Boxplot"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-10",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-10",
    "title": "Final Exam",
    "section": "Question 10",
    "text": "Question 10\nIn the ETL process, which of the following best describes the ‚ÄúTransform‚Äù stage‚Äôs primary purpose?\n\nAggregating and filtering data from disparate sources before extraction.\n\nAltering, cleaning, and integrating data to ensure consistency and usability.\n\nMoving transformed data into staging environments for downstream operations.\n\nEnsuring that outdated data is removed or archived for regulatory compliance.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Altering, cleaning, and integrating data to ensure consistency and usability."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-11",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-11",
    "title": "Final Exam",
    "section": "Question 11",
    "text": "Question 11\nWhat does the term ‚ÄúAPI‚Äù stand for, and what is its primary function as described in the lecture?\n\nAutomated Processing Interface; it cleans messy CSV files automatically.\n\nApplication Programming Interface; it allows software systems to communicate and request data programmatically.\n\nAdvanced Python Integration; it translates R code into Python.\n\nAnalytical Pipeline Interface; it is used exclusively for visualizing Tableau dashboards.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Application Programming Interface; it allows software systems to communicate and request data programmatically."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-12",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-12",
    "title": "Final Exam",
    "section": "Question 12",
    "text": "Question 12\nWhich statement is most accurate about tokens in the context of large language models (LLMs)?\n\nA token is always exactly one English word\n\nTokens are always single characters\n\nTokens exist only at the output side, not at the input side\n\nA token is a unit of text; it may be a character, a whole word, or part of a word\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd. A token is a unit of text; it may be a character, a whole word, or part of a word."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-13",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-13",
    "title": "Final Exam",
    "section": "Question 13",
    "text": "Question 13\nWhat type of variable is SubscriptionTier in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b. Ordinal"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-14",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-14",
    "title": "Final Exam",
    "section": "Question 14",
    "text": "Question 14\nWhat type of variable is Country in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: a. Nominal"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-15",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-15",
    "title": "Final Exam",
    "section": "Question 15",
    "text": "Question 15\nWhat type of variable is LastLoginHour in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: c.¬†Interval"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-16",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-16",
    "title": "Final Exam",
    "section": "Question 16",
    "text": "Question 16\nWhat type of variable is SatisfactionLevel in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nAnswer: b. Ordinal"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-17",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-17",
    "title": "Final Exam",
    "section": "Question 17",
    "text": "Question 17\nIn analytics, identifying patterns such as ‚ÄúMovie A ‚Üí Movie B‚Äù, where users who watch one movie are likely to watch another with a similar genre (as in recommendation systems), relies on\n_______________________________ to discover conditional co-occurrence relationships.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nassociation rule"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-18",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-18",
    "title": "Final Exam",
    "section": "Question 18",
    "text": "Question 18\nA(n) ________________________________ is a visual display of key information, data, and metrics, often used in BI to provide insights at a glance.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ndashboard"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-19",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-19",
    "title": "Final Exam",
    "section": "Question 19",
    "text": "Question 19\n________________________________ is Python‚Äôs primary library for data manipulation and analysis, offering powerful tools for working with tabular data. You can think of it as the Python counterpart to R‚Äôs dplyr (tidyverse): it provides clear, expressive functions for filtering, transforming, summarizing, and reshaping data.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\npandas"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-20",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-20",
    "title": "Final Exam",
    "section": "Question 20",
    "text": "Question 20\n________________________________ is the tendency for values of two variables to vary together, and can be visualized using scatterplots.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ncorrelation"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-21",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-21",
    "title": "Final Exam",
    "section": "Question 21",
    "text": "Question 21\n________________________________ data refers to data that is organized in a predefined format‚Äîsuch as rows and columns with a fixed schema‚Äîand is commonly stored in spreadsheets or traditional databases.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nstructured"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-22",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-22",
    "title": "Final Exam",
    "section": "Question 22",
    "text": "Question 22\nWhen designing visuals, the goal is to convey as much information as possible while minimizing _______________________________ for the audience.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ncognitive load"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-23",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-23",
    "title": "Final Exam",
    "section": "Question 23",
    "text": "Question 23\nOne of our alumni guest‚Äôs companies uses Snowflake as their _______________________________, a centralized repository that stores and manages large volumes of data for analytics and reporting purposes.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ndata warehouse (database management system (DBMS))"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-24",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-24",
    "title": "Final Exam",
    "section": "Question 24",
    "text": "Question 24\nThree most popular programming languages for data analysts are _______________________________, Python, and R.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nSQL"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-25",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-25",
    "title": "Final Exam",
    "section": "Question 25",
    "text": "Question 25\nConsider the following vector x:\n\nx &lt;- c(2, 4, 6, 8, 10)\n\nWrite the R code to create a new vector called z, where its \\(i\\)-th entry (\\(i = 1,2,3,4, \\text{or } 5\\)) is the standardized value of \\(i\\)-th element of x vector.\n\\[\nz_{i} = \\frac{x_{i} - \\bar{x}}{\\sigma_{x}}\n\\]\n\n\\(\\bar{x}\\): the mean of values in x\n\\(\\sigma_{x}\\): the standard deviation of values in x\n\nAnswer: ______________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nz &lt;- (x - mean(x)) / sd(x)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-26",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-26",
    "title": "Final Exam",
    "section": "Question 26",
    "text": "Question 26\nGiven the data.frame df with variables height and name, which of the following expressions returns a vector containing the values in the height variable?\n\ndf:height\ndf$height\ndf::height\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. df$height"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-27",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-27",
    "title": "Final Exam",
    "section": "Question 27",
    "text": "Question 27\nConsider the following data.frame, students:\n\n\n\n\n\nName\nAge\nMajor\nGPA\n\n\n\n\nAlice\n22\nBusiness Administration\n3.8\n\n\nBob\n23\nAccounting\n3.2\n\n\nCharlie\n21\nData Analytics\n3.9\n\n\nDiana\n24\nEconomics\n3.5\n\n\n\n\n\nWhich of the following R codes will correctly create a new data.frame with only the Name and GPA variables?\n\nstudents |&gt; select(Name, GPA)\nstudents |&gt; select(-Age, -Major)\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc. Both a and b"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-28",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-28",
    "title": "Final Exam",
    "section": "Question 28",
    "text": "Question 28\nConsider the following data.frame df0:\n\n\n\n\n\nx\ny\n\n\n\n\nNa\n7\n\n\n2\nNA\n\n\n3\n9\n\n\n\n\n\nWhat is the result of median(df0$y)?\n\n7\nNA\n8\n9\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. NA"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-29",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-29",
    "title": "Final Exam",
    "section": "Question 29",
    "text": "Question 29\nConsider the two related data.frames, df_1 and df_2:\n\ndf_1\n\n\n\n\n\n\nid\nname\nage\n\n\n\n\n1\nBob\n19\n\n\n2\nJulia\n21\n\n\n4\nZachary\n20\n\n\n\n\n\n\ndf_2\n\n\n\n\n\n\nid\nmajor\n\n\n\n\n1\nEconomics\n\n\n2\nBusiness Administration\n\n\n3\nData Analytics\n\n\n\n\n\nWhich of the following R code correctly join the two related data.frames, df_1 and df_2, to produce the resulting data.frame shown below?\n\n\n\n\n\nid\nname\nage\nmajor\n\n\n\n\n1\nBob\n19\nEconomics\n\n\n2\nJulia\n21\nBusiness Administration\n\n\n4\nZachary\n20\nNA\n\n\n\n\n\n\ndf_1 |&gt; left_join(df_2)\ndf_2 |&gt; left_join(df_1)\nBoth a and b\nNone of the above\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. df_1 |&gt; left_join(df_2)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-30-36",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-30-36",
    "title": "Final Exam",
    "section": "Questions 30-36",
    "text": "Questions 30-36\nFor Questions 30-36, consider the following R packages and the data.frame, nyc_dogs, containing individual dog license data from New York City (NYC):\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\n\nnyc_dogs &lt;- read_csv(\"https://bcdanl.github.io/data/nyc_dogs_cleaned.csv\")\n\nThe first 10 observations in the nyc_dogs data frame are displayed below:\n\n\n\n\n\nname\ngender\nbirth_year\nbreed\nborough\n\n\n\n\npaige\nF\n2014\npit bull\nManhattan\n\n\nyogi\nM\n2010\nboxer\nBronx\n\n\nali\nM\n2014\nbasenji\nManhattan\n\n\nqueen\nF\n2013\nakita\nManhattan\n\n\nlola\nF\n2009\nmaltese\nManhattan\n\n\nian\nM\n2006\nNA\nManhattan\n\n\nbuddy\nM\n2008\nNA\nManhattan\n\n\nchewbacca\nF\n2012\nlabrador\nManhattan\n\n\nheidi-bo\nF\n2007\ndachshund smooth coat\nBrooklyn\n\n\nmassimo\nM\n2009\nbull dog, french\nBrooklyn\n\n\n\n\n\n\nThe nyc_dogs data frame is with 197473 observations and 5 variables.\n\n\nDescription of Variables in nyc_dogs:\n\nname: Dog name\ngender: Dog gender (F for female; M for male; NA for missing value)\nbirth_year: Birth year (integer values)\nbreed: Dog breed\nborough: Borough in NYC\n\n\nThe followings are the summary of the nyc_dogs data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nnyc_dogs\n\n\nNumber of rows\n197473\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\nn_missing\nmin\nmax\nempty\nn_unique\n\n\n\n\nname\n2637\n1\n30\n0\n26770\n\n\ngender\n6\n1\n1\n0\n2\n\n\nbreed\n18832\n3\n35\n0\n295\n\n\nborough\n0\n5\n13\n0\n5\n\n\n\nVariable type: numeric\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nbirth_year\n0\n2012.94\n4.91\n1975\n2010\n2014\n2017\n2021\n\n\n\n\n\n\n\nQuestion 30\nWhat is the interquartile range of birth_year? Find this value by using the summary of the nyc_dogs data frame.\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nIQR = 7 = 2017 - 2010\n\n\n\n\n\n\nQuestion 31\nWhat R code can we use to count the number of licensed dogs by borough within each birth_year in NYC?\n\nnyc_dogs |&gt; count(birth_year)\nnyc_dogs |&gt; count(borough)\nnyc_dogs |&gt; count(borough, birth_year)\nnyc_dogs |&gt; count(birth_year, borough)\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\n\n\n\n\n\n\nQuestion 32\n\nWe are interested in finding the 7 most popular dog breeds in NYC.\nTo achieve this, we create a new data.frame, a new data.frame, top7_breeds, which includes only 7 most popular dog breeds, excluding any NA values.\n\n\n\n\n\n\nbreed\nn\n\n\n\n\nyorkshire terrier\n12804\n\n\nshih tzu\n12790\n\n\nchihuahua\n11099\n\n\nlabrador\n11017\n\n\npit bull\n10023\n\n\nmaltese\n7750\n\n\ngerman shepherd\n5063\n\n\n\n\n\n\nThe top7_breeds data.frame is displayed above.\n\n\ntop7_breeds &lt;- nyc_dogs |&gt; \n  filter(___(1)___) |&gt; \n  ___(2)___ |&gt; \n  ___(3)___(-n) |&gt; \n  head(7)  # returns the first 7 observations of the new data.frame\n\n\nComplete the code by filling in the blanks (1)-(3).\n\n\n\nis.na(breed); (2) count(n); (3) select\n\n\nis.na(breed); (2) count(n); (3) arrange\n\n\nis.na(breed); (2) count(breed); (3) select\n\n\nis.na(breed); (2) count(breed); (3) arrange\n\n\n!is.na(breed); (2) count(n); (3) select\n\n\n!is.na(breed); (2) count(n); (3) arrange\n\n\n!is.na(breed); (2) count(breed); (3) select\n\n\n!is.na(breed); (2) count(breed); (3) arrange\n\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\n\n\n\n\n\n\nQuestion 33\nHow would you describe the distribution of breed using the top7_breeds data.frame?\n\nNote that the breed categories are sorted by the n variable in the plot.\n\nComplete the code by filling in the blanks (1)-(3).\n\nggplot(data = top7_breeds,\n       mapping = aes(___(1)___,\n                     ___(2)___ = n)) +\n  ___(3)___() +\n  labs(y = \"Top 7 Dog Breeds\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = breed\ny = breed\nx = fct_reorder(n, breed)\ny = fct_reorder(n, breed)\nx = fct_reorder(breed, n)\ny = fct_reorder(breed, n)\nBoth c and d\nBoth e and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nf\n\n\n\n\n\n\nBlank (2)\n\nx\ny\nfill\ncolor\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\ngeom_bar\ngeom_col\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\n\nQuestion 34\n\nWe are also interested in identifying the top five most popular dog names for each gender.\nTo do this, we first create a new data frame, nyc_dogs_filtered, which includes only the observations where (1) the value of name variable is not missing and (2) the value of gender variable is not missing.\n\n\nnyc_dogs_filtered &lt;- nyc_dogs |&gt; \n  filter(___BLANK___)\n\n\nWhich condition correctly fills in the BLANK to complete the code above?\n\n\nis.na(name) , is.na(gender)\nis.na(name) & is.na(gender)\nis.na(name) | is.na(gender)\n!is.na(name) , !is.na(gender)\n!is.na(name) & !is.na(gender)\n!is.na(name) | !is.na(gender)\nBoth a and b\nBoth a and c\nBoth d and e\nBoth d and f\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ni\n\n\n\n\n\n\nQuestion 35\n\nUsing nyc_dogs_filtered from Question 34, we are creating the top5names_F data.frame:\n\n\n\n\n\n\nname\nn\n\n\n\n\nbella\n1291\n\n\nlola\n1005\n\n\nluna\n995\n\n\nlucy\n914\n\n\ndaisy\n851\n\n\n\n\n\n\nThe top5names_F data.frame provides the five most popular female dog names, displayed above.\n\nComplete the code by filling in the blanks (1)-(2).\n\ntop5names_F &lt;- nyc_dogs_filtered |&gt; \n  filter(___(1)___) |&gt; \n  count(___(2)___) |&gt; \n  arrange(___(3)___) |&gt; \n  head(5) \n\n\nBlank (1)\n\ngender == \"F\"\ngender != \"F\"\ngender == \"M\"\ngender != \"M\"\nBoth a and b\nBoth a and c\nBoth a and d\nBoth b and c\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ng\n\n\n\n\n\n\nBlank (2)\n\nname\ngender\nn\nname, n\ngender, n\nname, gender\ngender, name\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (3)\n\nn\n-n\ndesc(n)\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\n\nQuestion 36\n\nLikewise, using nyc_dogs_filtered from Question 34, we are creating the top5names_M data.frame:\n\n\n\n\n\n\nname\nn\n\n\n\n\nmax\n1341\n\n\ncharlie\n1042\n\n\nrocky\n1020\n\n\nbuddy\n840\n\n\nteddy\n745\n\n\n\n\n\n\nThe top5names_M data.frame provides the five most popular male dog names, displayed above.\n\nComplete the code by filling in the blanks (1)-(2).\n\ntop5names_M &lt;- nyc_dogs_filtered |&gt; \n  filter(___(1)___) |&gt; \n  count(___(2)___) |&gt; \n  arrange(___(3)___) |&gt; \n  head(5) \n\n\nBlank (1)\n\ngender == \"F\"\ngender != \"F\"\ngender == \"M\"\ngender != \"M\"\nBoth a and b\nBoth a and c\nBoth a and d\nBoth b and c\nBoth b and d\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\n\n\n\n\n\n\nBlank (2)\n\nname\ngender\nn\nname, n\ngender, n\nname, gender\ngender, name\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (3)\n\nn\n-n\ndesc(n)\nBoth b and c\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-37-40",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-37-40",
    "title": "Final Exam",
    "section": "Questions 37-40",
    "text": "Questions 37-40\nThe Nobel Prize in Economic Science in 2021 goes to David Card, Joshua Angrist and Guido Imbens, for their empirical contributions to labor economics, and for their methodological contributions to the analysis of causal relationships.\nThey have provided us with new insights about the labor market and shown what conclusions about cause and effect can be drawn from natural experiments. Their approach has spread to other fields and revolutionized empirical research.\nFor Questions 37-40, consider the following R packages and the data.frame, ak91_age, which comes from the 1980 US Census and covers men born 1930‚Äì1939, which is used by Joshua Angrist and Alan Krueger‚Äôs research article.\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\n\nak91_age &lt;- read_csv('https://bcdanl.github.io/data/ak91_ageW.csv')\n\nThe first 20 observations in the ak91_age data frame are displayed below:\n\n\n\n\n\nQoB\nYoB\nYoBQ\nW\nEduc\nQ4\n\n\n\n\n1\n1930\n1930.00\n361.0922\n12.28041\nFALSE\n\n\n1\n1931\n1931.00\n365.8181\n12.54043\nFALSE\n\n\n1\n1932\n1932.00\n364.9678\n12.53393\nFALSE\n\n\n1\n1933\n1933.00\n362.1093\n12.67319\nFALSE\n\n\n1\n1934\n1934.00\n363.2739\n12.64726\nFALSE\n\n\n1\n1935\n1935.00\n357.7532\n12.65091\nFALSE\n\n\n1\n1936\n1936.00\n359.5803\n12.74304\nFALSE\n\n\n1\n1937\n1937.00\n362.5073\n12.83230\nFALSE\n\n\n1\n1938\n1938.00\n362.9918\n12.93868\nFALSE\n\n\n1\n1939\n1939.00\n360.0860\n13.00299\nFALSE\n\n\n2\n1930\n1930.25\n364.3105\n12.42842\nFALSE\n\n\n2\n1931\n1931.25\n365.2228\n12.53105\nFALSE\n\n\n2\n1932\n1932.25\n365.2356\n12.60960\nFALSE\n\n\n2\n1933\n1933.25\n365.2171\n12.63471\nFALSE\n\n\n2\n1934\n1934.25\n362.2778\n12.72797\nFALSE\n\n\n2\n1935\n1935.25\n360.1939\n12.79693\nFALSE\n\n\n2\n1936\n1936.25\n360.2046\n12.81108\nFALSE\n\n\n2\n1937\n1937.25\n360.7164\n12.84405\nFALSE\n\n\n2\n1938\n1938.25\n366.8558\n13.00766\nFALSE\n\n\n2\n1939\n1939.25\n365.9290\n13.01340\nFALSE\n\n\n\n\n\n\nThe ak91_age data frame is with 40 observations and 6 variables.\n\n\nDescription of Variables in ak91_age:\n\nQoB: Quarter of birth\nYoB: Year of birth (1930, 1931, ‚Ä¶, 1939)\nYoBQ: Year and quarter of birth (1930 Q1, 1930 Q2, ‚Ä¶, 1939 Q4)\nW: Wage per week\nEduc: Years of education\nQ4: TRUE if quarter of birth is 4; FALSE otherwise.\n\n\nThe followings are the summary of the ak91_age data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nak91_age\n\n\nNumber of rows\n40\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nlogical\n1\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\nmean\ncount\n\n\n\n\nQ4\n0\n0.25\nFAL: 30, TRU: 10\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nQoB\n0\n2.50\n1.13\n1.00\n1.75\n2.50\n3.25\n4.00\n\n\nYoB\n0\n1934.50\n2.91\n1930.00\n1932.00\n1934.50\n1937.00\n1939.00\n\n\nYoBQ\n0\n1934.88\n2.92\n1930.00\n1932.44\n1934.88\n1937.31\n1939.75\n\n\nW\n0\n365.02\n3.37\n357.75\n362.24\n365.53\n367.89\n370.32\n\n\nEduc\n0\n12.76\n0.19\n12.28\n12.64\n12.75\n12.93\n13.12\n\n\n\n\n\n\n\nQuestion 37\nHere we describe the quarterly trend of years of education. Complete the code by filling in the blanks (1)-(3).\n\nggplot(data = ak91_age, \n       mapping = aes(___(1)___,\n                     ___(2)___ = Q4)) +\n  ___(3)___ + \n  geom_point(size = 2.5) +\n  scale_color_colorblind() +\n  labs(x = \"Year and quarter of birth\",\n       y = \"Years of education\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = YoBQ, y = Educ\ny = YoBQ, x = Educ\nx = YoB, y = Educ\ny = YoB, x = Educ\nBoth a and b\nBoth c and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (2)\n\nfill\ncolor\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (3)\n\ngeom_scatterplot\ngeom_point\ngeom_line\ngeom_smooth\ngeom_histogram\ngeom_boxplot\ngeom_bar\ngeom_col\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\n\nQuestion 38\nHere we describe the quarterly trend of the base-10 log of wage per week. Complete the code by filling in the blanks (1)-(3).\n\nggplot(data = ak91_age, \n       mapping = aes(___(1)___,\n                     ___(2)___ = Q4)) +\n  ___(3)___ + \n  geom_point(size = 2.5) +\n  scale_color_colorblind() +\n  labs(x = \"Year and quarter of birth\",\n       y = \"Wage per week (in base-10 log)\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = YoBQ, y = log(W)\ny = YoBQ, x = log(W)\nx = YoBQ, y = log10(W)\ny = YoBQ, x = log10(W)\nBoth a and c\nBoth b and d\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (2)\n\nfill\ncolor\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (3)\n\ngeom_scatterplot\ngeom_point\ngeom_line\ngeom_smooth\ngeom_histogram\ngeom_boxplot\ngeom_bar\ngeom_col\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\n\nQuestion 39\nHere we describe how the distribution of the base-10 log of wage per week varies by Q4. Complete the code by filling in the blanks (1)-(3).\n\nggplot(data = ak91_age, \n       mapping = aes(___(1)___,\n                     ___(2)___ = Q4)) +\n  ___(3)___(show.legend = FALSE) +\n  scale_fill_tableau() +\n  labs(x = \"Wage per week (in base-10 log)\",\n       y = \"Born in the Fourth Quarter?\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = YoBQ, y = log(W)\ny = YoBQ, x = log(W)\nx = YoBQ, y = log10(W)\ny = YoBQ, x = log10(W)\nx = Q4, y = log(W)\ny = Q4, x = log(W)\nx = Q4, y = log10(W)\ny = Q4, x = log10(W)\nBoth a and c\nBoth b and d\nBoth e and g\nBoth f and h\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nd\n\n\n\n\n\n\nBlank (2)\n\nfill\ncolor\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\ngeom_scatterplot\ngeom_point\ngeom_line\ngeom_smooth\ngeom_histogram\ngeom_boxplot\ngeom_bar\ngeom_col\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nf\n\n\n\n\n\n\n\nQuestion 40\nProvide a data-driven narrative for the ak91_age data frame, incorporating insights from the visualizations created in Questions 37, 38, and 39.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-41-44",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-41-44",
    "title": "Final Exam",
    "section": "Questions 41-44",
    "text": "Questions 41-44\nFor Questions 41-44, consider the following R packages and the data.frame, health_cust, which contains demographic information about individuals with or without health insurance.\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\n\nhealth_cust &lt;- read_csv(\n  'https://bcdanl.github.io/data/custdata_rev.csv'\n)\n\nThe first 10 observations in the health_cust data frame are displayed below:\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustid\nsex\nis_employed\nincome\nmarital_status\nhousing_type\n\n\n\n\n000006646_03\nMale\nTRUE\n22000\nNever married\nHomeowner free and clear\n\n\n000007827_01\nFemale\nNA\n23200\nDivorced/Separated\nRented\n\n\n000008359_04\nFemale\nTRUE\n21000\nNever married\nHomeowner with mortgage/loan\n\n\n000008529_01\nFemale\nNA\n37770\nWidowed\nHomeowner free and clear\n\n\n000008744_02\nMale\nTRUE\n39000\nDivorced/Separated\nRented\n\n\n000011466_01\nMale\nNA\n11100\nMarried\nHomeowner free and clear\n\n\n000015018_01\nFemale\nTRUE\n25800\nMarried\nRented\n\n\n000017314_02\nFemale\nNA\n34600\nMarried\nHomeowner free and clear\n\n\n000017383_04\nFemale\nTRUE\n25000\nNever married\nHomeowner free and clear\n\n\n000017554_02\nMale\nTRUE\n31200\nMarried\nHomeowner with mortgage/loan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustid\nrecent_move\nnum_vehicles\nage\nstate_of_res\ngas_usage\nhealth_ins\n\n\n\n\n000006646_03\nFALSE\n0\n24\nAlabama\n210\nFALSE\n\n\n000007827_01\nTRUE\n0\n82\nAlabama\n3\nFALSE\n\n\n000008359_04\nFALSE\n2\n31\nAlabama\n40\nFALSE\n\n\n000008529_01\nFALSE\n1\n93\nAlabama\n120\nFALSE\n\n\n000008744_02\nFALSE\n2\n67\nAlabama\n3\nFALSE\n\n\n000011466_01\nFALSE\n2\n76\nAlabama\n200\nFALSE\n\n\n000015018_01\nFALSE\n2\n26\nAlabama\n3\nTRUE\n\n\n000017314_02\nFALSE\n2\n73\nAlabama\n50\nFALSE\n\n\n000017383_04\nFALSE\n5\n27\nAlabama\n3\nFALSE\n\n\n000017554_02\nFALSE\n3\n54\nAlabama\n20\nFALSE\n\n\n\n\n\n\nDescription of Variables in health_cust\n\ncustid: ID of customer\nsex: Sex\nis_employed: Employment status\n\nNA: Unknown or not applicable\nTRUE: Employed\nFALSE: Unemployed\n\nincome: Income (in $)\nmarital_status: Marital status\nhousing_type: Housing type\nrecent_move:\n\nTRUE: Recently moved\nFALSE: Not recently moved\n\nage: Age\nstate_of_res: State of residence (Alabama, Alaska, ‚Ä¶, New York, ‚Ä¶, Wyoming)\ngas_usage: Gas usage\n\nNA: Unknown or not applicable\n001: Included in rent or condo fee\n002: Included in electricity payment\n003: No charge or gas not used\n004-999: $4 to $999 (rounded and top-coded)\n\nhealth_ins: Health insuarance status\n\nTRUE: customer with health insuarance\nFALSE: customer without health insuarance\n\n\nThe followings are the summary of the health_cust data.frame, including descriptive statistics for each variable.\n\n\n\nData summary\n\n\nName\nhealth_cust\n\n\nNumber of rows\n73262\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nlogical\n3\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\nn_missing\nmin\nmax\nempty\nn_unique\n\n\n\n\ncustid\n0\n12\n12\n0\n73262\n\n\nsex\n0\n4\n6\n0\n2\n\n\nmarital_status\n0\n7\n18\n0\n4\n\n\nhousing_type\n1720\n6\n28\n0\n4\n\n\nstate_of_res\n0\n4\n20\n0\n51\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\nmean\ncount\n\n\n\n\nis_employed\n25774\n0.95\nTRU: 45137, FAL: 2351\n\n\nrecent_move\n1721\n0.13\nFAL: 62418, TRU: 9123\n\n\nhealth_ins\n0\n0.10\nFAL: 65955, TRU: 7307\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nincome\n0\n41764.15\n58113.76\n-6900\n10700\n26200\n51700\n1257000\n\n\nnum_vehicles\n1720\n2.07\n1.17\n0\n1\n2\n3\n6\n\n\nage\n0\n49.16\n18.08\n0\n34\n48\n62\n120\n\n\ngas_usage\n1720\n41.17\n63.05\n1\n3\n10\n60\n570"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-41",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-41",
    "title": "Final Exam",
    "section": "Question 41",
    "text": "Question 41\nHere we describe how the distribution of health_ins varies by state of residence and employment status using the health_cust data.frame. Complete the code by filling in the blanks (1)-(4).\n\nggplot(data = health_cust |&gt; filter(!is.na(is_employed)),\n       mapping = aes(___(1)___, \n                     fill = ___(2)___)) +\n  ___(3)___ +\n  ___(4)___(~is_employed) +\n  labs(y = \"\", x= \"Proportion\") +\n  scale_fill_tableau()\n\n\n\n\n\n\n\nBlank (1)\n\nx = health_ins\nx = state_of_res\nx = Proportion\ny = health_ins\ny = state_of_res\ny = Proportion\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\ne\n\n\n\n\n\n\nBlank (2)\n\nhealth_ins\nstate_of_res\nProportion\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\n\ngeom_bar(position = \"stack\")\ngeom_col(position = \"stack\")\ngeom_bar(position = \"fill\")\ngeom_col(position = \"fill\")\ngeom_bar(position = \"dodge\")\ngeom_col(position = \"dodge\")\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc\n\n\n\n\n\n\nBlank (4)\nAnswer: ________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nfacet_wrap"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-42",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-42",
    "title": "Final Exam",
    "section": "Question 42",
    "text": "Question 42\nHere we describe how the distribution of marital_status varies by housing_type using the health_cust data.frame. Complete the code by filling in the blanks (1)-(4).\n\nggplot(data = health_cust |&gt; filter(!is.na(housing_type)),\n       mapping = aes(___(1)___, \n                     ___(2)___)) +\n  ___(3)___(show.legend = FALSE) +\n  ___(4)___(~housing_type) +\n  labs(y = \"\")\n\n\n\n\n\n\n\nBlank (1)\n\nx = marital_status\ny = marital_status\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\nx = prop\nx = prop, group = 1\nBoth a and b\ny = prop\ny = prop, group = 1\nBoth d and e\nx = after_stat(prop)\nx = after_stat(prop), group = 1\nBoth g and h\ny = after_stat(prop)\ny = after_stat(prop), group = 1\nBoth j and k\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nh\n\n\n\n\n\n\nBlank (3)\n\ngeom_bar()\ngeom_col()\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (4)\nAnswer: ________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nfacet_wrap"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-43",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-43",
    "title": "Final Exam",
    "section": "Question 43",
    "text": "Question 43\nHere we describe how the relationship between age and income varies by health_ins using the health_cust data.frame. Note that the new geometric object geom_hex() divides the plane into regular hexagons, counts the number of observations in each hexagon, and then maps the number of observations to the hexagon fill.\nComplete the code by filling in the blanks (1)-(4).\n\n# Considering \n  # income level between $0 and $250,000\n  # age between 20 and 70\nggplot(data = health_cust |&gt; filter(income &gt;= 0 & income &lt;= 2.5*10^5,\n                                    age &gt;= 20 & age &lt;= 70),\n       mapping = aes(___(1)___)) +\n  geom_hex() + # hexbin plot: dividing the plot area into hexagonal bins\n  ___(2)___ +\n  ___(3)___(~health_ins) +\n  scale_fill_viridis_c() # for hexbin color\n\n\n\n\n\n\n\nBlank (1)\n\nx = income, y = age\nx = age, y = income\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb\n\n\n\n\n\n\nBlank (2)\n\ngeom_smooth()\ngeom_smooth(method = \"lm\")\nBoth a and b\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na\n\n\n\n\n\n\nBlank (3)\nAnswer: ________________________________________\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nfacet_wrap"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-44",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-44",
    "title": "Final Exam",
    "section": "Question 44",
    "text": "Question 44\nDescribe how the overall relationship between age and income varies by health_ins.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-45",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-45",
    "title": "Final Exam",
    "section": "Question 45",
    "text": "Question 45\nFor each question in Homework 5, briefly describe the task you are required to complete.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-46",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-46",
    "title": "Final Exam",
    "section": "Question 46",
    "text": "Question 46\nWhat is clutter in data visualization, and why is it important to reduce it? Provide at least two practical tips for minimizing clutter in visualizations.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nClutter: Visual elements that occupy space but do not improve understanding\nClutter makes information harder to process and can confuse the viewer\n\nLess clutter = clearer message, more focused audience\n\nTips\n\nAvoid having the data all skewed to one side or the other of your graph.\nAvoid too many superimposed elements, such as too many curves (&gt;4) in the same graphing space."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-47",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-47",
    "title": "Final Exam",
    "section": "Question 47",
    "text": "Question 47\nDescribe the two phases of training a large language model (LLM): Pre-training and Fine-tuning. What is the primary objective of each phase?\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-48",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-48",
    "title": "Final Exam",
    "section": "Question 48",
    "text": "Question 48\nCompare supervised learning and unsupervised learning. Give one example of a business application for each and explain why labeled data is central to one but not the other.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-49",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-49",
    "title": "Final Exam",
    "section": "Question 49",
    "text": "Question 49\nWhen is it appropriate to treat integer-valued data as if it were continuous? Give one example of an integer variable for which this is reasonable.\n\n\n\n\n\n\nShow answer"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-50",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#question-50",
    "title": "Final Exam",
    "section": "Question 50",
    "text": "Question 50\nIdentify two situations where pie charts are not a suitable alternative to bar charts.\n\n\n\n\n\n\nShow answer\n\n\n\n\n\n\nPie charts work well only if you only have a few categories‚Äîfour max.\nPie charts work well if the goal is to emphasize simple fractions (e.g., 25%, 50%, or 75%).\nPie charts are not the best choice if you want audiences to compare the size of shares.\nPie charts are not the best choice if you want audiences to compare the distribution across categories."
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-13-16",
    "href": "danl-ex/danl-101-exam-3-ver-A-fall-2025.html#questions-13-16",
    "title": "Final Exam",
    "section": "Questions 13-16",
    "text": "Questions 13-16\nFor Questions 13-16, consider the following data.frame, spotify_data, displayed below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUserID\nAge\nGender\nSubscriptionTier\nFavoriteGenre\nHoursListened\nLastLoginTime\n\n\n\n\n1\n19\nMale\nFree\nPop\n10.4\n1.2\n\n\n2\n27\nFemale\nPremium\nRock\n15.8\n22.4\n\n\n3\n35\nMale\nFamily\nHip-Hop\n22.3\n13.6\n\n\n4\n22\nFemale\nPremium\nClassical\n9.7\n19.1\n\n\n5\n40\nMale\nFree\nJazz\n18.6\n23.5\n\n\n6\n31\nFemale\nFamily\nElectronic\n20.1\n7.9\n\n\n7\n29\nMale\nPremium\nCountry\n14.5\n2.3\n\n\n8\n33\nFemale\nFree\nBlues\n12.8\n15.6\n\n\n9\n24\nFemale\nFamily\nReggae\n17.9\n20.7\n\n\n10\n37\nMale\nPremium\nMetal\n19.3\n5.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccountMonths\nSatisfaction\nnDevices\nLastTrackRating\nnPlaylists\nLanguage\n\n\n\n\n3\n3\n1\n8.1\n2\nSpanish\n\n\n12\n5\n3\n7.4\n4\nEnglish\n\n\n18\n4\n2\n6.8\n3\nFrench\n\n\n5\n2\n1\n9.2\n1\nGerman\n\n\n20\n4\n3\n7.5\n5\nEnglish\n\n\n24\n5\n2\n8.9\n3\nItalian\n\n\n6\n3\n4\n6.3\n4\nEnglish\n\n\n10\n4\n1\n9.0\n2\nEnglish\n\n\n15\n5\n2\n8.4\n3\nSpanish\n\n\n8\n5\n3\n7.7\n5\nFrench\n\n\n\n\n\n\nDescription of Variables in netflix_data:\n\nUserID: Identifier for each user\nAge: Age of the user in years\nGender: Gender of the user\nSubscriptionTier: Type of Spotify subscription\nFavoriteGenre: User‚Äôs favorite genre\nHoursListened: Average hours listened per week\nLastLoginTime: Time of last login in hours since midnight\nAccountMonths: Age of the account in months\nSatisfaction: User satisfaction rating (1 to 5 stars)\nnDevices: Number of devices connected\nLastTrackRating: Rating of the last played track (1.0 to 10.0)\nnPlaylists: Number of playlists on the account\nLanguage: User‚Äôs preferred language\n\n\n\nQuestion 13\nWhat type of variable is FavoriteGenre in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. Nominal\n\n\n\n\n\n\nQuestion 14\nWhat type of variable is SubscriptionTier in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Ordinal\n(There is a meaningful order: Free &lt; Family &lt; Premium.)\n\n\n\n\n\n\nQuestion 15\nWhat type of variable is LastLoginTime in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Interval\n(Hours since midnight: differences are meaningful, but ‚Äú0‚Äù is an arbitrary reference point, not ‚Äúno time.‚Äù)\n\n\n\n\n\n\nQuestion 16\nWhat type of variable is Satisfaction in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Ordinal\n(Star ratings have an order, but equal gaps between levels are not guaranteed.)"
  },
  {
    "objectID": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-13-16",
    "href": "danl-ex/danl-101-exam-3-ver-B-fall-2025.html#questions-13-16",
    "title": "Final Exam",
    "section": "Questions 13-16",
    "text": "Questions 13-16\nFor Questions 13-16, consider the following data.frame, twitter_x_data, displayed below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUserID\nAge\nGender\nSubscriptionTier\nCountry\nFollowersCount\nLastLoginHour\n\n\n\n\n1\n22\nFemale\nStandard\nUSA\n1500\n22.5\n\n\n2\n27\nMale\nPremium\nCanada\n2300\n14.2\n\n\n3\n34\nFemale\nStandard\nUSA\n800\n9.8\n\n\n4\n19\nMale\nPremium\nUK\n5000\n18.3\n\n\n5\n45\nFemale\nStandard\nAustralia\n300\n2.7\n\n\n6\n31\nMale\nStandard\nUSA\n1200\n12.1\n\n\n7\n28\nFemale\nPremium\nIndia\n4500\n16.4\n\n\n8\n23\nMale\nStandard\nCanada\n600\n20.0\n\n\n9\n37\nMale\nPremium\nUSA\n3500\n7.5\n\n\n10\n29\nFemale\nPremium\nUK\n900\n23.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccountAgeDays\nSatisfactionLevel\nPostsPerWeek\nGroupsJoined\nIsVerified\n\n\n\n\n365\nVery Satisfied\n5\n10\nYes\n\n\n730\nSatisfied\n12\n5\nNo\n\n\n180\nNeutral\n3\n12\nNo\n\n\n1095\nVery Satisfied\n20\n7\nYes\n\n\n60\nDissatisfied\n1\n3\nNo\n\n\n540\nSatisfied\n8\n8\nNo\n\n\n850\nVery Satisfied\n15\n15\nYes\n\n\n275\nNeutral\n4\n4\nNo\n\n\n400\nSatisfied\n18\n9\nYes\n\n\n660\nVery Satisfied\n6\n6\nNo\n\n\n\n\n\n\nDescription of Variables in twitter_x_data:\n\nUserID: Identifier for each user\nAge: Age of the user in years\nGender: Gender of the user\nSubscriptionTier: Level of Twitter (X) subscription (e.g., Standard ‚Üí Premium)\nCountry: Country of residence\nFollowersCount: Number of followers\nLastLoginHour: Time of last login in hours since midnight\nAccountAgeDays: Age of the account in days\nSatisfactionLevel: User satisfaction level\nPostsPerWeek: Number of posts per week\nGroupsJoined: Number of groups joined\nIsVerified: Whether the user account is verified\n\n\n\nQuestion 13\nWhat type of variable is SubscriptionTier in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Ordinal\n\n\n\n\n\n\nQuestion 14\nWhat type of variable is Country in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\na. Nominal\n\n\n\n\n\n\nQuestion 15\nWhat type of variable is LastLoginHour in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nc.¬†Interval\n\n\n\n\n\n\nQuestion 16\nWhat type of variable is SatisfactionLevel in the dataset?\n\nNominal\n\nOrdinal\n\nInterval\n\nRatio\n\n\n\n\n\n\n\nShow answer\n\n\n\n\n\nb. Ordinal"
  }
]